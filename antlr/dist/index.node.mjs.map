{"version":3,"file":"index.node.mjs","mappings":"AACA,IAAIA,EAAsB,CCA1BA,EAAwB,CAACC,EAASC,KACjC,IAAI,IAAIC,KAAOD,EACXF,EAAoBI,EAAEF,EAAYC,KAASH,EAAoBI,EAAEH,EAASE,IAC5EE,OAAOC,eAAeL,EAASE,EAAK,CAAEI,YAAY,EAAMC,IAAKN,EAAWC,IAE1E,ECNDH,EAAwB,CAACS,EAAKC,IAAUL,OAAOM,UAAUC,eAAeC,KAAKJ,EAAKC,GCClFV,EAAyBC,IACH,qBAAXa,QAA0BA,OAAOC,aAC1CV,OAAOC,eAAeL,EAASa,OAAOC,YAAa,CAAEC,MAAO,WAE7DX,OAAOC,eAAeL,EAAS,aAAc,CAAEe,OAAO,GAAO,G,qmGCDvD,IAAMC,EAAQ,WACnB,SAAAA,K,4FAAcC,CAAA,KAAAD,GACZE,KAAKC,MAAQ,EACbD,KAAKE,KAAO,CACd,C,UAMC,O,EANAJ,E,EAAA,EAAAd,IAAA,SAAAa,MAQD,WACE,IAAK,IAAIM,EAAI,EAAGA,EAAIC,UAAUC,OAAQF,IAAK,CACzC,IAAMN,EAAQO,UAAUD,GACxB,GAAa,MAATN,EACJ,GAAIS,MAAMC,QAAQV,GAAQG,KAAKQ,OAAOC,MAAMT,KAAMH,OAC7C,CACH,IAAIa,EAAI,EACR,OAAAC,EAAed,IACb,IAAK,YACL,IAAK,WACH,SACF,IAAK,SACL,IAAK,UACHa,EAAIb,EACJ,MACF,IAAK,SACHa,EAAIb,EAAMe,WACV,MACF,QACMf,EAAMgB,eAAgBhB,EAAMgB,eAAeb,MAC1Cc,QAAQC,IAAI,yBAA2BlB,EAAMmB,YAClD,SAGJN,GADAA,GAAQ,aACE,GAAOA,IAAO,GACxBA,GAAQ,UACRV,KAAKC,MAAQD,KAAKC,MAAQ,EAC1B,IAAIC,EAAOF,KAAKE,KAAOQ,EAEvBR,EAAc,GADdA,EAAQA,GAAQ,GAAOA,IAAU,IACf,WAClBF,KAAKE,KAAOA,CACd,CACF,CACF,GAAC,CAAAlB,IAAA,SAAAa,MAED,WACE,IAAIK,EAAOF,KAAKE,KAAqB,EAAbF,KAAKC,MAM7B,OALAC,GAAeA,IAAS,GACxBA,GAAc,WACdA,GAAeA,IAAS,GACxBA,GAAc,WACdA,GAAeA,IAAS,EAE1B,I,EAAC,EAAAlB,IAAA,YAAAa,MAjDD,WACE,IAAMK,EAAO,IAAIJ,EAEjB,OADAI,EAAKM,OAAOC,MAAMP,EAAME,WACjBF,EAAKe,QACd,I,iFAACnB,CAAA,CAVkB,G,6sBCOd,IAAMoB,EAAW,WACtB,SAAAA,EAAYC,I,4FAAQpB,CAAA,KAAAmB,GAClBlB,KAAKoB,WAAaD,EAClBnB,KAAKqB,qBAAsB,CAC7B,C,UAcC,O,EAdAH,G,EAAA,EAAAlC,IAAA,WAAAa,MAED,WACE,IAAMK,EAAO,IAAIJ,EAEjB,OADAE,KAAKa,eAAeX,GACbA,EAAKe,QACd,GAAC,CAAAjC,IAAA,iBAAAa,MAED,SAAeK,GACbA,EAAKM,OAAOR,KAAKoB,WACnB,GAAC,CAAApC,IAAA,SAAAa,MAED,SAAOyB,GACL,OAAOtB,OAASsB,CAClB,M,8EAACJ,CAAA,CAlBqB,GCPXK,EAAkB,CAE7BC,QAAS,EAETC,OAAQ,EAERC,KAAM,EAENC,KAAM,EAENC,SAAU,EAEVC,UAAW,EAEXC,KAAM,EAENC,KAAM,G,+pDCPD,IAAMC,EAAkB,SAAAC,I,sRAAAC,CAAAF,EAASd,GAAT,I,MAAAiB,EAAAC,EAAAJ,GAC7B,SAAAA,EAAYK,GAAS,IAAAC,EAEI,O,4FAFJvC,CAAA,KAAAiC,IACnBM,EAAAH,EAAAzC,KAAA,KAAM6B,EAAgBC,UACjBa,QAAUA,EAAQC,CACzB,CA0BC,O,EAxBDN,G,EAAA,EAAAhD,IAAA,UAAAa,MAIA,SAAQ0C,GACNA,EAAMC,SAAWxC,KAAKqC,OACxB,GAAC,CAAArD,IAAA,iBAAAa,MAED,SAAeK,GACbA,EAAKM,OAAOR,KAAKoB,WAAYpB,KAAKqC,QACpC,GAAC,CAAArD,IAAA,SAAAa,MAED,SAAOyB,GACL,OAAItB,OAASsB,GAEAA,aAAiBU,GAGrBhC,KAAKqC,UAAYf,EAAMe,OAElC,GAAC,CAAArD,IAAA,WAAAa,MAED,WACE,MAAO,WAAaG,KAAKqC,QAAU,GACrC,M,8EAACL,CAAA,CA9B4B,G,+pDCIxB,IAAMS,EAAiB,SAAAR,I,sRAAAC,CAAAO,EAASvB,GAAT,I,MAAAiB,EAAAC,EAAAK,GAU5B,SAAAA,EAAYC,EAAWC,GAAa,IAAAL,EAIF,O,4FAJEvC,CAAA,KAAA0C,IAClCH,EAAAH,EAAAzC,KAAA,KAAM6B,EAAgBE,SACjBiB,UAAYA,EACjBJ,EAAKK,YAAcA,EACnBL,EAAKjB,qBAAsB,EAAKiB,CAClC,CAsBC,O,EApBDG,G,EAAA,EAAAzD,IAAA,UAAAa,MAIA,SAAQ0C,GACNA,EAAMpB,OAAO,KAAMnB,KAAK0C,UAAW1C,KAAK2C,YAC1C,GAAC,CAAA3D,IAAA,iBAAAa,MAED,SAAeK,GACbA,EAAKM,OAAOR,KAAKoB,WAAYpB,KAAK0C,UAAW1C,KAAK2C,YACpD,GAAC,CAAA3D,IAAA,SAAAa,MAED,SAAOyB,GACL,OAAItB,OAASsB,GAEAA,aAAiBmB,GAGrBzC,KAAK0C,YAAcpB,EAAMoB,WAAa1C,KAAK2C,cAAgBrB,EAAMqB,WAE5E,M,8EAACF,CAAA,CArC2B,G,+pDCWvB,IAAMG,EAAwB,SAAAX,I,sRAAAC,CAAAU,EAAS1B,GAAT,I,MAAAiB,EAAAC,EAAAQ,GACnC,SAAAA,EAAYC,EAAQ1B,GAAQ,IAAAmB,EAIM,O,4FAJNvC,CAAA,KAAA6C,IAC1BN,EAAAH,EAAAzC,KAAA,KAAMyB,EAAOC,aACRyB,OAASA,EACdP,EAAKnB,OAASA,EACdmB,EAAKjB,qBAAsB,EAAKiB,CAClC,CAuBC,O,EArBDM,G,EAAA,EAAA5D,IAAA,UAAAa,MAIA,SAAQ0C,GAENvC,KAAKmB,OAAO2B,QAAQP,EACtB,GAAC,CAAAvD,IAAA,iBAAAa,MAED,SAAeK,GACbA,EAAKM,OAAOR,KAAKoB,WAAYpB,KAAK6C,OAAQ7C,KAAKmB,OACjD,GAAC,CAAAnC,IAAA,SAAAa,MAED,SAAOyB,GACL,OAAItB,OAASsB,GAEAA,aAAiBsB,GAGrB5C,KAAK6C,SAAWvB,EAAMuB,QAAU7C,KAAKmB,SAAWG,EAAMH,MAEjE,M,8EAACyB,CAAA,CA7BkC,G,+pDCjB9B,IAAMG,EAAe,SAAAd,I,sRAAAC,CAAAa,EAAS7B,GAAT,I,MAAAiB,EAAAC,EAAAW,GAC1B,SAAAA,EAAYC,GAAM,IAAAV,EAEC,O,4FAFDvC,CAAA,KAAAgD,IAChBT,EAAAH,EAAAzC,KAAA,KAAM6B,EAAgBG,OACjBsB,KAAOA,EAAKV,CACnB,CA0BC,O,EAxBDS,G,EAAA,EAAA/D,IAAA,UAAAa,MAIA,SAAQ0C,GACNA,EAAMS,KAAKhD,KAAKgD,KAClB,GAAC,CAAAhE,IAAA,iBAAAa,MAED,SAAeK,GACbA,EAAKM,OAAOR,KAAKoB,WAAYpB,KAAKgD,KACpC,GAAC,CAAAhE,IAAA,SAAAa,MAED,SAAOyB,GACL,OAAItB,OAASsB,GAEAA,aAAiByB,GAGrB/C,KAAKgD,OAAS1B,EAAM0B,IAE/B,GAAC,CAAAhE,IAAA,WAAAa,MAED,WACE,MAAO,QAAUG,KAAKgD,KAAO,GAC/B,M,8EAACD,CAAA,CA9ByB,G,+pDCErB,IAAME,EAAe,SAAAhB,I,sRAAAC,CAAAe,EAAS/B,GAAT,I,MAAAiB,EAAAC,EAAAa,GAC1B,SAAAA,IAAc,O,4FAAAlD,CAAA,KAAAkD,GAAAd,EAAAzC,KAAA,KACN6B,EAAgBI,KACxB,CAWC,O,EATDsB,G,EAAA,EAAAjE,IAAA,UAAAa,MAGA,SAAQ0C,GACNA,EAAMW,MACR,GAAC,CAAAlE,IAAA,WAAAa,MAED,WACE,MAAO,MACT,M,8EAACoD,CAAA,CAdyB,G,+pDAiB5BA,EAAgBE,SAAW,IAAIF,ECjBxB,IAAMG,EAAkB,SAAAnB,I,sRAAAC,CAAAkB,EAASlC,GAAT,I,MAAAiB,EAAAC,EAAAgB,GAC7B,SAAAA,IAAc,O,4FAAArD,CAAA,KAAAqD,GAAAjB,EAAAzC,KAAA,KACN6B,EAAgBK,SACxB,CAWC,O,EATDwB,G,EAAA,EAAApE,IAAA,UAAAa,MAGA,SAAQ0C,GACNA,EAAMc,SACR,GAAC,CAAArE,IAAA,WAAAa,MAED,WACE,MAAO,SACT,M,8EAACuD,CAAA,CAd4B,G,+pDAiB/BA,EAAmBD,SAAW,IAAIC,ECnB3B,IAAME,EAAmB,SAAArB,I,sRAAAC,CAAAoB,EAASpC,GAAT,I,MAAAiB,EAAAC,EAAAkB,GAC9B,SAAAA,EAAYN,GAAM,IAAAV,EAEC,O,4FAFDvC,CAAA,KAAAuD,IAChBhB,EAAAH,EAAAzC,KAAA,KAAM6B,EAAgBM,YACjBmB,KAAOA,EAAKV,CACnB,CA0BC,O,EAxBDgB,G,EAAA,EAAAtE,IAAA,UAAAa,MAIA,SAAQ0C,GACNA,EAAMgB,SAASvD,KAAKgD,KACtB,GAAC,CAAAhE,IAAA,iBAAAa,MAED,SAAeK,GACbA,EAAKM,OAAOR,KAAKoB,WAAYpB,KAAKgD,KACpC,GAAC,CAAAhE,IAAA,SAAAa,MAED,SAAOyB,GACL,OAAItB,OAASsB,GAEAA,aAAiBgC,GAGrBtD,KAAKgD,OAAS1B,EAAM0B,IAE/B,GAAC,CAAAhE,IAAA,WAAAa,MAED,WACE,MAAO,YAAcG,KAAKgD,KAAO,GACnC,M,8EAACM,CAAA,CA9B6B,G,qqDCEzB,IAAME,GAAe,SAAAvB,I,sRAAAC,CAAAsB,EAAStC,GAAT,I,MAAAiB,EAAAC,GAAAoB,GAC1B,SAAAA,IAAc,O,4FAAAzD,CAAA,KAAAyD,GAAArB,EAAAzC,KAAA,KACN6B,EAAgBO,KACxB,CAQC,O,EARA0B,G,EAAA,EAAAxE,IAAA,UAAAa,MAED,SAAQ0C,GACNA,EAAMkB,MACR,GAAC,CAAAzE,IAAA,WAAAa,MAED,WACE,MAAO,MACT,M,8EAAC2D,CAAA,CAXyB,G,grDAe5BA,GAAgBL,SAAW,IAAIK,GChBxB,IAAME,GAAe,SAAAzB,I,uRAAAC,CAAAwB,EAASxC,GAAT,I,MAAAiB,EAAAC,GAAAsB,GAC1B,SAAAA,EAAYC,GAAM,IAAArB,EAEC,O,4FAFDvC,CAAA,KAAA2D,IAChBpB,EAAAH,EAAAzC,KAAA,KAAM6B,EAAgBQ,OACjB4B,KAAOA,EAAKrB,CACnB,CAsBC,O,EAtBAoB,G,EAAA,EAAA1E,IAAA,UAAAa,MAED,SAAQ0C,GACNA,EAAMoB,KAAO3D,KAAK2D,IACpB,GAAC,CAAA3E,IAAA,iBAAAa,MAED,SAAeK,GACbA,EAAKM,OAAOR,KAAKoB,WAAYpB,KAAK2D,KACpC,GAAC,CAAA3E,IAAA,SAAAa,MAED,SAAOyB,GACL,OAAItB,OAASsB,GAEAA,aAAiBoC,GAGrB1D,KAAK2D,OAASrC,EAAMqC,IAE/B,GAAC,CAAA3E,IAAA,WAAAa,MAED,WACE,MAAO,QAAUG,KAAK2D,KAAO,GAC/B,M,gFAACD,CAAA,CA1ByB,G,m0BCMrB,IAAME,GAAUC,IACrB,SAAAD,EAAYE,GAEV,G,4FAFkB/D,CAAA,KAAA6D,QAEHG,IAAXD,GAAmC,OAAXA,EAC1B,KAAM,yBAER9D,KAAK8D,OAASA,EAEd9D,KAAKgE,WAAY,EACjBhE,KAAKiE,MAAQ,IACf,I,grDAKFL,GAAWM,QAAU,EACrBN,GAAWO,MAAQ,EACnBP,GAAWQ,KAAO,EAElBR,GAAWS,UAAY,EACvBT,GAAWU,KAAO,EAClBV,GAAWW,OAAS,EAEpBX,GAAWY,IAAM,EACjBZ,GAAWa,QAAU,EACrBb,GAAWc,SAAW,EACtBd,GAAWe,WAAa,GAExBf,GAAWgB,mBAAqB,CAC9B,UACA,UACA,QACA,OACA,YACA,OACA,SACA,MACA,UACA,WACA,cAGFhB,GAAWiB,mBAAqB,CAC9BC,kBAAmBlB,GAAWM,QAC9Ba,gBAAiBnB,GAAWO,MAC5Ba,eAAgBpB,GAAWQ,KAC3Ba,oBAAqBrB,GAAWS,UAChCa,eAAgBtB,GAAWU,KAC3Ba,iBAAkBvB,GAAWW,OAC7Ba,cAAexB,GAAWY,IAC1Ba,iBAAkBzB,GAAWa,QAC7Ba,mBAAoB1B,GAAWc,SAC/Ba,8BAA+B3B,GAAWe,YChErC,IAAMa,GAA2B,SAAAC,I,uRAAAvD,CAAAsD,EAAS5B,IAAT,I,MAAAzB,EAAAC,GAAAoD,GACtC,SAAAA,EAAY1B,GAAQ,O,4FAAA/D,CAAA,KAAAyF,GAAArD,EAAAzC,KAAA,KACZoE,EACR,CAAC,O,EAAA0B,E,oFAAA,CAHqC,G,otBCIjC,IAAME,GAAK,WAChB,SAAAA,K,4FAAc3F,CAAA,KAAA2F,GACZ1F,KAAK2F,OAAS,KACd3F,KAAK2D,KAAO,KACZ3D,KAAKqC,QAAU,KACfrC,KAAK4F,MAAQ,KACb5F,KAAK6F,KAAO,KACZ7F,KAAK8F,WAAa,KAClB9F,KAAK+F,KAAO,KACZ/F,KAAKgG,OAAS,KACdhG,KAAKiG,MAAQ,IACf,C,UAgBC,O,EAhBAP,G,EAAA,EAAA1G,IAAA,OAAAK,IAED,WACE,OAAOW,KAAKiG,KACd,EAACC,IAED,SAASC,GACPnG,KAAKiG,MAAQE,CACf,GAAC,CAAAnH,IAAA,iBAAAa,MAED,WACE,OAAOG,KAAK2F,OAAO,EACrB,GAAC,CAAA3G,IAAA,iBAAAa,MAED,WACE,OAAOG,KAAK2F,OAAO,EACrB,M,gFAACD,CAAA,CA3Be,GCNX,SAASU,GAAYC,EAAGC,GAC7B,IAAKhG,MAAMC,QAAQ8F,KAAO/F,MAAMC,QAAQ+F,GAAI,OAAO,EACnD,GAAID,IAAMC,EAAG,OAAO,EACpB,GAAID,EAAEhG,SAAWiG,EAAEjG,OAAQ,OAAO,EAClC,IAAK,IAAIF,EAAI,EAAGA,EAAIkG,EAAEhG,OAAQF,IAC5B,GAAIkG,EAAElG,KAAOmG,EAAEnG,MACVkG,EAAElG,GAAGoG,SAAWF,EAAElG,GAAGoG,OAAOD,EAAEnG,KAAK,OAAO,EAEjD,OAAO,CACT,CCTO,SAASqG,GAAyBH,GACvC,OAAOA,EAAIA,EAAEzF,YAAc,CAC7B,CCFO,SAAS6F,GAAuBJ,EAAGC,GACxC,OAAOD,EAAIA,EAAEE,OAAOD,GAAKD,IAAMC,CACjC,CCFO,SAASI,GAAcC,GAC5B,OAAa,OAANA,EAAa,OAASA,CAC/B,CCAO,SAASC,GAAcP,GAC5B,OAAO/F,MAAMC,QAAQ8F,GAAK,IAAMA,EAAEQ,IAAIH,IAAeI,KAAK,MAAQ,IAAM,MAC1E,C,otBLgCApB,GAAMqB,aAAe,EAMrBrB,GAAMxB,SAAW,EAEjBwB,GAAMsB,oBAAsB,EAE5BtB,GAAMuB,KAAO,EAObvB,GAAMwB,gBAAkB,EAMxBxB,GAAMyB,eAAiB,EMvDvB,IAAMC,GAAkB,KAEXC,GAAO,WAClB,SAAAA,EAAYC,EAAcC,I,4FAAgBxH,CAAA,KAAAsH,GACxCrH,KAAKwH,KAAO,CAAC,EACbxH,KAAKsH,aAAeA,GAAgBd,GACpCxG,KAAKuH,eAAiBA,GAAkBd,EAC1C,C,UAmDC,O,EAnDAY,E,EAAA,EAAArI,IAAA,SAAAK,IAED,WAAa,IAAAiD,EAAA,KACX,OAAOpD,OAAOuI,KAAKzH,KAAKwH,MACrBE,QAAO,SAAC1I,GAAG,OAAKA,EAAI2I,WAAWP,GAAgB,IAC/CP,KAAI,SAAC7H,GAAG,OAAKsD,EAAKkF,KAAKxI,GAAKqB,MAAM,GAAEL,MACpC4H,QAAO,SAACC,EAAOC,GAAI,OAAKD,EAAQC,CAAI,GAAE,EAC3C,GAAC,CAAA9I,IAAA,MAAAa,MAED,SAAIA,GACF,IAAMb,EAAMoI,GAAkBpH,KAAKsH,aAAazH,GAChD,GAAIb,KAAOgB,KAAKwH,KAAM,CAEpB,IADA,IAAMO,EAAS/H,KAAKwH,KAAKxI,GAChBmB,EAAI,EAAGA,EAAI4H,EAAO1H,OAAQF,IACjC,GAAIH,KAAKuH,eAAe1H,EAAOkI,EAAO5H,IACpC,OAAO4H,EAAO5H,GAIlB,OADA4H,EAAOC,KAAKnI,GACLA,CACT,CAEE,OADAG,KAAKwH,KAAKxI,GAAO,CAACa,GACXA,CAEX,GAAC,CAAAb,IAAA,MAAAa,MAED,SAAIA,GACF,OAA0B,MAAnBG,KAAKX,IAAIQ,EAClB,GAAC,CAAAb,IAAA,MAAAa,MAED,SAAIA,GACF,IAAMb,EAAMoI,GAAkBpH,KAAKsH,aAAazH,GAChD,GAAIb,KAAOgB,KAAKwH,KAEd,IADA,IAAMO,EAAS/H,KAAKwH,KAAKxI,GAChBmB,EAAI,EAAGA,EAAI4H,EAAO1H,OAAQF,IACjC,GAAIH,KAAKuH,eAAe1H,EAAOkI,EAAO5H,IACpC,OAAO4H,EAAO5H,GAIpB,OAAO,IACT,GAAC,CAAAnB,IAAA,SAAAa,MAED,WAAS,IAAAoI,EAAA,KACP,OAAO/I,OAAOuI,KAAKzH,KAAKwH,MACrBE,QAAO,SAAC1I,GAAG,OAAKA,EAAI2I,WAAWP,GAAgB,IAC/Cc,SAAQ,SAAClJ,GAAG,OAAKiJ,EAAKT,KAAKxI,EAAI,GAAEgB,KACtC,GAAC,CAAAhB,IAAA,WAAAa,MAED,WACE,OAAO+G,GAAc5G,KAAK+H,SAC5B,I,mFAACV,CAAA,CAxDiB,G,wpECOb,IAAMc,GAAe,oBAAAA,IAAApI,GAAA,KAAAoI,EAAA,CAgCzB,OAhCyBtE,GAAAsE,EAAA,EAAAnJ,IAAA,WAAAa,MAkC1B,WACE,IAAMK,EAAO,IAAIJ,EAEjB,OADAE,KAAKa,eAAeX,GACbA,EAAKe,QACd,GAEA,CAAAjC,IAAA,WAAAa,MAaA,SAASuI,EAAQC,GAAe,GAEhC,CAAArJ,IAAA,iBAAAa,MAkBA,SAAeuI,EAAQC,GACrB,OAAOrI,IACT,IAAC,EAAAhB,IAAA,aAAAa,MA1ED,SAAkBwG,EAAGC,GACnB,GAAU,OAAND,GAAcA,IAAM8B,EAAgBG,KACtC,OAAOhC,EAET,GAAU,OAANA,GAAcA,IAAM6B,EAAgBG,KACtC,OAAOjC,EAET,IAAMkC,EAAS,IAAIC,GAAInC,EAAGC,GAC1B,OAA4B,IAAxBiC,EAAOE,MAAMpI,OACRkI,EAAOE,MAAM,GAEbF,CAEX,GAAC,CAAAvJ,IAAA,YAAAa,MAED,SAAiBwG,EAAGC,GAClB,GAAU,OAAND,EACF,OAAOC,EAET,GAAU,OAANA,EACF,OAAOD,EAET,GAAIA,IAAM8B,EAAgBG,MAAQhC,IAAM6B,EAAgBG,KACtD,OAAOH,EAAgBG,KAEzB,IAAMC,EAAS,IAAIG,GAAGrC,EAAGC,GACzB,OAA4B,IAAxBiC,EAAOE,MAAMpI,OACRkI,EAAOE,MAAM,GAEbF,CAEX,KAACJ,CAAA,CAhCyB,GA8EtBK,GAAG,SAAAG,GAAAzG,GAAAsG,EAASL,IAAT,IAAAhG,EAAAC,GAAAoG,GAKP,SAAAA,EAAYnC,EAAGC,GAAG,IAAAhE,EAAAvC,GAAA,KAAAyI,GAChBlG,EAAAH,EAAAzC,KAAA,MACA,IAAMkJ,EAAW,IAAIvB,GACjBhB,aAAamC,EACfnC,EAAEoC,MAAM5B,KAAI,SAAU5H,GACpB2J,EAASC,IAAI5J,EACf,IAEA2J,EAASC,IAAIxC,GAEXC,aAAakC,EACflC,EAAEmC,MAAM5B,KAAI,SAAU5H,GACpB2J,EAASC,IAAI5J,EACf,IAEA2J,EAASC,IAAIvC,GAEf,IAAMwC,EAAuBC,GAA2BH,GACxD,GAAIE,EAAqBzI,OAAS,EAAG,CAEnC,IAAI2I,EAAU,KACdF,EAAqBjC,KAAI,SAAUoC,IACjB,OAAZD,GAAoBC,EAAEC,WAAaF,EAAQE,cAC7CF,EAAUC,EAEd,IACAL,EAASC,IAAIG,EACf,CAC2C,OAA3C1G,EAAKmG,MAAQnI,MAAM6I,KAAKP,EAASb,UAAUzF,CAC7C,CAgEC,OAhEAuB,GAAA2E,EAAA,EAAAxJ,IAAA,SAAAa,MAED,SAAOyB,GACL,OAAItB,OAASsB,GAEAA,aAAiBkH,GAGrBpC,GAAYpG,KAAKyI,MAAOnH,EAAMmH,MAEzC,GAAC,CAAAzJ,IAAA,iBAAAa,MAED,SAAeK,GACbA,EAAKM,OAAOR,KAAKyI,MAAO,MAC1B,GAEA,CAAAzJ,IAAA,WAAAa,MAOA,SAASuI,EAAQC,GACf,IAAK,IAAIlI,EAAI,EAAGA,EAAIH,KAAKyI,MAAMpI,OAAQF,IACrC,IAAKH,KAAKyI,MAAMtI,GAAGiJ,SAAShB,EAAQC,GAClC,OAAO,EAGX,OAAO,CACT,GAAC,CAAArJ,IAAA,iBAAAa,MAED,SAAeuI,EAAQC,GAGrB,IAFA,IAAIgB,GAAU,EACRT,EAAW,GACRzI,EAAI,EAAGA,EAAIH,KAAKyI,MAAMpI,OAAQF,IAAK,CAC1C,IAAMmJ,EAAUtJ,KAAKyI,MAAMtI,GACrBoJ,EAAYD,EAAQE,eAAepB,EAAQC,GAEjD,GADAgB,GAAWE,IAAcD,EACP,OAAdC,EAEF,OAAO,KACEA,IAAcpB,GAAgBG,MAEvCM,EAASZ,KAAKuB,EAElB,CACA,IAAKF,EACH,OAAOrJ,KAET,GAAwB,IAApB4I,EAASvI,OAEX,OAAO8H,GAAgBG,KAEzB,IAAIC,EAAS,KAIb,OAHAK,EAAS/B,KAAI,SAAU5H,GACrBsJ,EAAoB,OAAXA,EAAkBtJ,EAAIkJ,GAAgBsB,WAAWlB,EAAQtJ,EACpE,IACOsJ,CACT,GAAC,CAAAvJ,IAAA,WAAAa,MAED,WACE,IAAM6J,EAAI1J,KAAKyI,MAAM5B,KAAI,SAAC5H,GAAC,OAAKA,EAAE+B,UAAU,IAC5C,OAAQ0I,EAAErJ,OAAS,EAAIqJ,EAAEC,MAAM,GAAKD,GAAG5C,KAAK,KAC9C,KAAC0B,CAAA,CAlGM,GAqGHE,GAAE,SAAAkB,GAAA1H,GAAAwG,EAASP,IAAT,IAAA0B,EAAAzH,GAAAsG,GAKN,SAAAA,EAAYrC,EAAGC,GAAG,IAAA2B,EAAAlI,GAAA,KAAA2I,GAChBT,EAAA4B,EAAAnK,KAAA,MACA,IAAMkJ,EAAW,IAAIvB,GACjBhB,aAAaqC,EACfrC,EAAEoC,MAAM5B,KAAI,SAAU5H,GACpB2J,EAASC,IAAI5J,EACf,IAEA2J,EAASC,IAAIxC,GAEXC,aAAaoC,EACfpC,EAAEmC,MAAM5B,KAAI,SAAU5H,GACpB2J,EAASC,IAAI5J,EACf,IAEA2J,EAASC,IAAIvC,GAGf,IAAMwC,EAAuBC,GAA2BH,GACxD,GAAIE,EAAqBzI,OAAS,EAAG,CAEnC,IAAMqJ,EAAIZ,EAAqBgB,MAAK,SAAUzD,EAAGC,GAC/C,OAAOD,EAAE0D,UAAUzD,EACrB,IACM0C,EAAUU,EAAEA,EAAErJ,OAAS,GAC7BuI,EAASC,IAAIG,EACf,CAC2C,OAA3Cf,EAAKQ,MAAQnI,MAAM6I,KAAKP,EAASb,UAAUE,CAC7C,CA8DC,OA9DApE,GAAA6E,EAAA,EAAA1J,IAAA,SAAAa,MAED,SAAOyB,GACL,OAAItB,OAASsB,GAEAA,aAAiBoH,GAGrBtC,GAAYpG,KAAKyI,MAAOnH,EAAMmH,MAEzC,GAAC,CAAAzJ,IAAA,iBAAAa,MAED,SAAeK,GACbA,EAAKM,OAAOR,KAAKyI,MAAO,KAC1B,GAEA,CAAAzJ,IAAA,WAAAa,MAKA,SAASuI,EAAQC,GACf,IAAK,IAAIlI,EAAI,EAAGA,EAAIH,KAAKyI,MAAMpI,OAAQF,IACrC,GAAIH,KAAKyI,MAAMtI,GAAGiJ,SAAShB,EAAQC,GACjC,OAAO,EAGX,OAAO,CACT,GAAC,CAAArJ,IAAA,iBAAAa,MAED,SAAeuI,EAAQC,GAGrB,IAFA,IAAIgB,GAAU,EACRT,EAAW,GACRzI,EAAI,EAAGA,EAAIH,KAAKyI,MAAMpI,OAAQF,IAAK,CAC1C,IAAMmJ,EAAUtJ,KAAKyI,MAAMtI,GACrBoJ,EAAYD,EAAQE,eAAepB,EAAQC,GAEjD,GADAgB,GAAWE,IAAcD,EACrBC,IAAcpB,GAAgBG,KAEhC,OAAOH,GAAgBG,KACA,OAAdiB,GAETX,EAASZ,KAAKuB,EAElB,CACA,IAAKF,EACH,OAAOrJ,KAET,GAAwB,IAApB4I,EAASvI,OAEX,OAAO,KAET,IAAMkI,EAAS,KAIf,OAHAK,EAAS/B,KAAI,SAAU5H,GACrB,OAAyBA,CAC3B,IACOsJ,CACT,GAAC,CAAAvJ,IAAA,WAAAa,MAED,WACE,IAAM6J,EAAI1J,KAAKyI,MAAM5B,KAAI,SAAC5H,GAAC,OAAKA,EAAE+B,UAAU,IAC5C,OAAQ0I,EAAErJ,OAAS,EAAIqJ,EAAEC,MAAM,GAAKD,GAAG5C,KAAK,KAC9C,KAAC4B,CAAA,CA/FK,GAkGR,SAASK,GAA2B7C,GAClC,IAAMqC,EAAS,GAMf,OALArC,EAAI6B,SAASlB,KAAI,SAAUyC,GACrBA,aAAmBnB,GAAgB6B,qBACrCzB,EAAOP,KAAKsB,EAEhB,IACOf,CACT,C,otBCtSA,SAAS0B,GAAYC,EAAQC,GAC3B,GAAe,OAAXD,EAAiB,CACnB,IAAM3B,EAAS,CAAE6B,MAAO,KAAMC,IAAK,KAAMf,QAAS,KAAMgB,gBAAiB,MAIzE,OAHIH,IACF5B,EAAOgC,wBAA0B,GAE5BhC,CACT,CACE,IAAMiC,EAAQ,CAAC,EASf,OARAA,EAAMJ,MAAQF,EAAOE,OAAS,KAC9BI,EAAMH,SAAqBtG,IAAfmG,EAAOG,IAAoB,KAAOH,EAAOG,IACrDG,EAAMlB,QAAUY,EAAOZ,SAAW,KAClCkB,EAAMF,gBAAkBJ,EAAOI,iBAAmB,KAC9CH,IACFK,EAAMD,wBAA0BL,EAAOK,yBAA2B,EAClEC,EAAMC,2BAA6BP,EAAOO,6BAA8B,GAEnED,CAEX,CAEO,IAAME,GAAS,WASpB,SAAAA,EAAYR,EAAQS,I,4FAAQ5K,CAAA,KAAA2K,GAC1B1K,KAAK4K,aAAaV,EAAQS,GAC1BT,EAASD,GAAYC,GACrBS,EAASV,GAAYU,GAAQ,GAE7B3K,KAAKoK,MAAyB,OAAjBF,EAAOE,MAAiBF,EAAOE,MAAQO,EAAOP,MAE3DpK,KAAKqK,IAAqB,OAAfH,EAAOG,IAAeH,EAAOG,IAAMM,EAAON,IAMrDrK,KAAKsJ,QAA6B,OAAnBY,EAAOZ,QAAmBY,EAAOZ,QAAUqB,EAAOrB,QACjEtJ,KAAKsK,gBACwB,OAA3BJ,EAAOI,gBACHJ,EAAOI,gBACoB,OAA3BK,EAAOL,gBACPK,EAAOL,gBACPnC,GAAgBG,KAYtBtI,KAAKuK,wBAA0BI,EAAOJ,wBACtCvK,KAAKyK,2BAA6BE,EAAOF,0BAC3C,C,UAyEC,O,EAzEAC,G,EAAA,EAAA1L,IAAA,eAAAa,MAED,SAAaqK,EAAQS,GAEG,OAAnBT,EAAOZ,cAAuCvF,IAAnBmG,EAAOZ,SACvB,OAAXqB,GAAsC,OAAnBA,EAAOrB,cAAuCvF,IAAnB4G,EAAOrB,UAEtDtJ,KAAKsJ,QAAU,KAEnB,GAAC,CAAAtK,IAAA,WAAAa,MAED,WACE,IAAMK,EAAO,IAAIJ,EAEjB,OADAE,KAAKa,eAAeX,GACbA,EAAKe,QACd,GAAC,CAAAjC,IAAA,iBAAAa,MAED,SAAeK,GACbA,EAAKM,OAAOR,KAAKoK,MAAMS,YAAa7K,KAAKqK,IAAKrK,KAAKsJ,QAAStJ,KAAKsK,gBACnE,GAEA,CAAAtL,IAAA,SAAAa,MAKA,SAAOyB,GACL,OAAItB,OAASsB,GAEAA,aAAiBoJ,GAI1B1K,KAAKoK,MAAMS,cAAgBvJ,EAAM8I,MAAMS,aACvC7K,KAAKqK,MAAQ/I,EAAM+I,MACD,OAAjBrK,KAAKsJ,QAAqC,OAAlBhI,EAAMgI,QAAmBtJ,KAAKsJ,QAAQ/C,OAAOjF,EAAMgI,WAC5EtJ,KAAKsK,gBAAgB/D,OAAOjF,EAAMgJ,kBAClCtK,KAAKyK,6BAA+BnJ,EAAMmJ,0BAGhD,GAAC,CAAAzL,IAAA,uBAAAa,MAED,WACE,IAAMK,EAAO,IAAIJ,EAEjB,OADAI,EAAKM,OAAOR,KAAKoK,MAAMS,YAAa7K,KAAKqK,IAAKrK,KAAKsK,iBAC5CpK,EAAKe,QACd,GAAC,CAAAjC,IAAA,qBAAAa,MAED,SAAmByB,GACjB,OAAItB,OAASsB,GAEAA,aAAiBoJ,GAI1B1K,KAAKoK,MAAMS,cAAgBvJ,EAAM8I,MAAMS,aACvC7K,KAAKqK,MAAQ/I,EAAM+I,KACnBrK,KAAKsK,gBAAgB/D,OAAOjF,EAAMgJ,gBAGxC,GAAC,CAAAtL,IAAA,WAAAa,MAED,WACE,MACE,IACAG,KAAKoK,MACL,IACApK,KAAKqK,KACa,OAAjBrK,KAAKsJ,QAAmB,KAAOtJ,KAAKsJ,QAAQtI,WAAa,IAAM,KAC/DhB,KAAKsK,kBAAoBnC,GAAgBG,KAAO,IAAMtI,KAAKsK,gBAAgBtJ,WAAa,KACxFhB,KAAKuK,wBAA0B,EAAI,OAASvK,KAAKuK,wBAA0B,IAC5E,GAEJ,M,gFAACG,CAAA,CAnHmB,G,otBCxBf,IAAMI,GAAQ,WACnB,SAAAA,EAAYlF,EAAOC,I,4FAAM9F,CAAA,KAAA+K,GACvB9K,KAAK4F,MAAQA,EACb5F,KAAK6F,KAAOA,CACd,C,UAoBC,O,EApBAiF,G,EAAA,EAAA9L,IAAA,SAAAK,IAED,WACE,OAAOW,KAAK6F,KAAO7F,KAAK4F,KAC1B,GAAC,CAAA5G,IAAA,QAAAa,MAED,WACE,OAAO,IAAIiL,EAAS9K,KAAK4F,MAAO5F,KAAK6F,KACvC,GAAC,CAAA7G,IAAA,WAAAa,MAED,SAASiI,GACP,OAAOA,GAAQ9H,KAAK4F,OAASkC,EAAO9H,KAAK6F,IAC3C,GAAC,CAAA7G,IAAA,WAAAa,MAED,WACE,OAAIG,KAAK4F,QAAU5F,KAAK6F,KAAO,EACtB7F,KAAK4F,MAAM5E,WAEXhB,KAAK4F,MAAM5E,WAAa,MAAQhB,KAAK6F,KAAO,GAAG7E,UAE1D,M,gFAAC8J,CAAA,CAxBkB,G,otBA2BrBA,GAASC,iBAAmB,IAAID,IAAU,GAAI,GCxBvC,IAAME,GAAW,WACtB,SAAAA,K,4FAAcjL,CAAA,KAAAiL,GACZhL,KAAKiL,UAAY,KACjBjL,KAAKkL,UAAW,CAClB,C,UAwPC,O,EAxPAF,E,EAAA,EAAAhM,IAAA,SAAAK,IAED,WACE,OAAOW,KAAKiL,UAAUpE,KAAI,SAACsE,GAAQ,OAAKA,EAAS9K,MAAM,IAAEuH,QAAO,SAACwD,EAAKC,GAAG,OAAKD,EAAMC,CAAG,GACzF,GAAC,CAAArM,IAAA,QAAAa,MAED,SAAM8G,GACJ,OAAuB,OAAnB3G,KAAKiL,WAAgD,IAA1BjL,KAAKiL,UAAU5K,OACrCqF,GAAMqB,aAEN/G,KAAKiL,UAAU,GAAGrF,KAE7B,GAAC,CAAA5G,IAAA,SAAAa,MAED,SAAO8G,GACL3G,KAAKsL,YAAY,IAAIR,GAASnE,EAAGA,EAAI,GACvC,GAAC,CAAA3H,IAAA,WAAAa,MAED,SAAS0L,EAAGC,GACVxL,KAAKsL,YAAY,IAAIR,GAASS,EAAGC,EAAI,GACvC,GAAC,CAAAxM,IAAA,cAAAa,MAED,SAAY4L,GACV,GAAuB,OAAnBzL,KAAKiL,UACPjL,KAAKiL,UAAY,GACjBjL,KAAKiL,UAAUjD,KAAKyD,EAAMC,aACrB,CAEL,IAAK,IAAIC,EAAM,EAAGA,EAAM3L,KAAKiL,UAAU5K,OAAQsL,IAAO,CACpD,IAAMC,EAAW5L,KAAKiL,UAAUU,GAEhC,GAAIF,EAAM5F,KAAO+F,EAAShG,MAExB,YADA5F,KAAKiL,UAAUY,OAAOF,EAAK,EAAGF,GAI3B,GAAIA,EAAM5F,OAAS+F,EAAShG,MAE/B,YADA5F,KAAKiL,UAAUU,GAAO,IAAIb,GAASW,EAAM7F,MAAOgG,EAAS/F,OAItD,GAAI4F,EAAM7F,OAASgG,EAAS/F,KAM/B,OALA7F,KAAKiL,UAAUU,GAAO,IAAIb,GACxBgB,KAAKC,IAAIH,EAAShG,MAAO6F,EAAM7F,OAC/BkG,KAAKE,IAAIJ,EAAS/F,KAAM4F,EAAM5F,YAEhC7F,KAAK4H,OAAO+D,EAGhB,CAEA3L,KAAKiL,UAAUjD,KAAKyD,EAAMC,QAC5B,CACF,GAAC,CAAA1M,IAAA,SAAAa,MAED,SAAOyB,GAAO,IAAAgB,EAAA,KAIZ,OAHwB,OAApBhB,EAAM2J,WACR3J,EAAM2J,UAAUgB,SAAQ,SAACR,GAAK,OAAKnJ,EAAKgJ,YAAYG,EAAM,GAAEzL,MAEvDA,IACT,GAAC,CAAAhB,IAAA,SAAAa,MAED,SAAO8L,GAEL,GAAIA,EAAM3L,KAAKiL,UAAU5K,OAAS,EAAG,CACnC,IAAM6L,EAAUlM,KAAKiL,UAAUU,GACzBQ,EAAOnM,KAAKiL,UAAUU,EAAM,GAE9BO,EAAQrG,MAAQsG,EAAKtG,MACvB7F,KAAKiL,UAAUY,OAAOF,EAAM,EAAG,GAC/B3L,KAAK4H,OAAO+D,IACHO,EAAQrG,MAAQsG,EAAKvG,QAC9B5F,KAAKiL,UAAUU,GAAO,IAAIb,GAASoB,EAAQtG,MAAOuG,EAAKtG,MACvD7F,KAAKiL,UAAUY,OAAOF,EAAM,EAAG,GAEnC,CACF,GAAC,CAAA3M,IAAA,aAAAa,MAED,SAAW+F,EAAOC,GAChB,IAAM0C,EAAS,IAAIyC,EAGnB,OAFAzC,EAAO+C,YAAY,IAAIR,GAASlF,EAAOC,EAAO,IACvB,OAAnB7F,KAAKiL,WAAoBjL,KAAKiL,UAAUgB,SAAQ,SAACG,GAAQ,OAAK7D,EAAO8D,YAAYD,EAAS,IACvF7D,CACT,GAAC,CAAAvJ,IAAA,WAAAa,MAED,SAASiI,GACP,GAAuB,OAAnB9H,KAAKiL,UACP,OAAO,EAEP,IAAK,IAAIvK,EAAI,EAAGA,EAAIV,KAAKiL,UAAU5K,OAAQK,IACzC,GAAIV,KAAKiL,UAAUvK,GAAG4L,SAASxE,GAC7B,OAAO,EAGX,OAAO,CAEX,GAAC,CAAA9I,IAAA,cAAAa,MAED,SAAYuM,GACV,GAAIA,EAASxG,QAAUwG,EAASvG,KAAO,EACrC7F,KAAKuM,UAAUH,EAASxG,YACnB,GAAuB,OAAnB5F,KAAKiL,UAEd,IADA,IAAIU,EAAM,EACDa,EAAI,EAAGA,EAAIxM,KAAKiL,UAAU5K,OAAQmM,IAAK,CAC9C,IAAMZ,EAAW5L,KAAKiL,UAAUU,GAEhC,GAAIS,EAASvG,MAAQ+F,EAAShG,MAC5B,OAGG,GAAIwG,EAASxG,MAAQgG,EAAShG,OAASwG,EAASvG,KAAO+F,EAAS/F,KAAM,CACzE7F,KAAKiL,UAAUU,GAAO,IAAIb,GAASc,EAAShG,MAAOwG,EAASxG,OAC5D,IAAM6G,EAAI,IAAI3B,GAASsB,EAASvG,KAAM+F,EAAS/F,MAE/C,YADA7F,KAAKiL,UAAUY,OAAOF,EAAK,EAAGc,EAEhC,CAESL,EAASxG,OAASgG,EAAShG,OAASwG,EAASvG,MAAQ+F,EAAS/F,MACrE7F,KAAKiL,UAAUY,OAAOF,EAAK,GAC3BA,GAAY,GAGLS,EAASxG,MAAQgG,EAAS/F,KACjC7F,KAAKiL,UAAUU,GAAO,IAAIb,GAASc,EAAShG,MAAOwG,EAASxG,OAGrDwG,EAASvG,KAAO+F,EAAS/F,OAChC7F,KAAKiL,UAAUU,GAAO,IAAIb,GAASsB,EAASvG,KAAM+F,EAAS/F,OAE7D8F,GAAO,CACT,CAEJ,GAAC,CAAA3M,IAAA,YAAAa,MAED,SAAUA,GACR,GAAuB,OAAnBG,KAAKiL,UACP,IAAK,IAAI9K,EAAI,EAAGA,EAAIH,KAAKiL,UAAU5K,OAAQF,IAAK,CAC9C,IAAMyL,EAAW5L,KAAKiL,UAAU9K,GAEhC,GAAIN,EAAQ+L,EAAShG,MACnB,OAGG,GAAI/F,IAAU+L,EAAShG,OAAS/F,IAAU+L,EAAS/F,KAAO,EAE7D,YADA7F,KAAKiL,UAAUY,OAAO1L,EAAG,GAItB,GAAIN,IAAU+L,EAAShG,MAE1B,YADA5F,KAAKiL,UAAU9K,GAAK,IAAI2K,GAASc,EAAShG,MAAQ,EAAGgG,EAAS/F,OAI3D,GAAIhG,IAAU+L,EAAS/F,KAAO,EAEjC,YADA7F,KAAKiL,UAAU9K,GAAK,IAAI2K,GAASc,EAAShG,MAAOgG,EAAS/F,KAAO,IAI9D,GAAIhG,EAAQ+L,EAAS/F,KAAO,EAAG,CAClC,IAAM6G,EAAU,IAAI5B,GAASc,EAAShG,MAAO/F,GAG7C,OAFA+L,EAAShG,MAAQ/F,EAAQ,OACzBG,KAAKiL,UAAUY,OAAO1L,EAAG,EAAGuM,EAE9B,CACF,CAEJ,GAAC,CAAA1N,IAAA,WAAAa,MAED,SAAS8M,EAAcC,EAAeC,GAIpC,OAHAF,EAAeA,GAAgB,KAC/BC,EAAgBA,GAAiB,KACjCC,EAAeA,IAAgB,EACR,OAAnB7M,KAAKiL,UACA,KACmB,OAAjB0B,GAA2C,OAAlBC,EAC3B5M,KAAK8M,cAAcH,EAAcC,GAC/BC,EACF7M,KAAK+M,eAEL/M,KAAKgN,eAEhB,GAAC,CAAAhO,IAAA,eAAAa,MAED,WAEE,IADA,IAAMoN,EAAQ,GACL9M,EAAI,EAAGA,EAAIH,KAAKiL,UAAU5K,OAAQF,IAAK,CAC9C,IAAMyL,EAAW5L,KAAKiL,UAAU9K,GAC5ByL,EAAS/F,OAAS+F,EAAShG,MAAQ,EACjCgG,EAAShG,QAAUF,GAAMuB,IAC3BgG,EAAMjF,KAAK,SAEXiF,EAAMjF,KAAK,IAAMkF,OAAOC,aAAavB,EAAShG,OAAS,KAGzDqH,EAAMjF,KAAK,IAAMkF,OAAOC,aAAavB,EAAShG,OAAS,OAASsH,OAAOC,aAAavB,EAAS/F,KAAO,GAAK,IAE7G,CACA,OAAIoH,EAAM5M,OAAS,EACV,IAAM4M,EAAMnG,KAAK,MAAQ,IAEzBmG,EAAM,EAEjB,GAAC,CAAAjO,IAAA,gBAAAa,MAED,WAEE,IADA,IAAMoN,EAAQ,GACL9M,EAAI,EAAGA,EAAIH,KAAKiL,UAAU5K,OAAQF,IAAK,CAC9C,IAAMyL,EAAW5L,KAAKiL,UAAU9K,GAC5ByL,EAAS/F,OAAS+F,EAAShG,MAAQ,EACjCgG,EAAShG,QAAUF,GAAMuB,IAC3BgG,EAAMjF,KAAK,SAEXiF,EAAMjF,KAAK4D,EAAShG,MAAM5E,YAG5BiM,EAAMjF,KAAK4D,EAAShG,MAAM5E,WAAa,MAAQ4K,EAAS/F,KAAO,GAAG7E,WAEtE,CACA,OAAIiM,EAAM5M,OAAS,EACV,IAAM4M,EAAMnG,KAAK,MAAQ,IAEzBmG,EAAM,EAEjB,GAAC,CAAAjO,IAAA,gBAAAa,MAED,SAAc8M,EAAcC,GAE1B,IADA,IAAMK,EAAQ,GACL9M,EAAI,EAAGA,EAAIH,KAAKiL,UAAU5K,OAAQF,IAEzC,IADA,IAAMyL,EAAW5L,KAAKiL,UAAU9K,GACvBiN,EAAIxB,EAAShG,MAAOwH,EAAIxB,EAAS/F,KAAMuH,IAC9CH,EAAMjF,KAAKhI,KAAKqN,YAAYV,EAAcC,EAAeQ,IAG7D,OAAIH,EAAM5M,OAAS,EACV,IAAM4M,EAAMnG,KAAK,MAAQ,IAEzBmG,EAAM,EAEjB,GAAC,CAAAjO,IAAA,cAAAa,MAED,SAAY8M,EAAcC,EAAeU,GACvC,OAAIA,IAAU5H,GAAMuB,IACX,QACEqG,IAAU5H,GAAMxB,QAClB,YAEAyI,EAAaW,IAAUV,EAAcU,EAEhD,I,mFAACtC,CAAA,CA5PqB,G,otBCyDjB,IAAMuC,GAAQ,WACnB,SAAAA,K,4FAAcxN,CAAA,KAAAwN,GAEZvN,KAAKwN,IAAM,KACXxN,KAAK6K,YAAc0C,EAASE,qBAC5BzN,KAAK0N,UAAY,KACjB1N,KAAK0C,UAAY,EACjB1C,KAAK2N,wBAAyB,EAE9B3N,KAAK4N,YAAc,GAEnB5N,KAAK6N,oBAAsB,IAC7B,C,UAgCC,O,EAhCAN,G,EAAA,EAAAvO,IAAA,WAAAa,MAED,WACE,OAAOG,KAAK6K,WACd,GAAC,CAAA7L,IAAA,SAAAa,MAED,SAAOyB,GACL,OAAIA,aAAiBiM,GACZvN,KAAK6K,cAAgBvJ,EAAMuJ,WAItC,GAAC,CAAA7L,IAAA,uBAAAa,MAED,WACE,OAAO,CACT,GAAC,CAAAb,IAAA,gBAAAa,MAED,SAAciO,EAAOC,QACLhK,IAAVgK,IACFA,GAAS,GAEqB,IAA5B/N,KAAK4N,YAAYvN,OACnBL,KAAK2N,uBAAyBG,EAAM9J,UAC3BhE,KAAK2N,yBAA2BG,EAAM9J,YAC/ChE,KAAK2N,wBAAyB,IAEjB,IAAXI,EACF/N,KAAK4N,YAAY5F,KAAK8F,GAEtB9N,KAAK4N,YAAY/B,OAAOkC,EAAO,EAAGD,EAEtC,M,gFAACP,CAAA,CA5CkB,G,0rDAgDrBA,GAASxG,aAAe,EACxBwG,GAASS,MAAQ,EACjBT,GAASU,WAAa,EACtBV,GAASW,YAAc,EACvBX,GAASY,iBAAmB,EAC5BZ,GAASa,iBAAmB,EAC5Bb,GAASc,YAAc,EACvBd,GAASe,UAAY,EACrBf,GAASgB,UAAY,EACrBhB,GAASiB,eAAiB,EAC1BjB,GAASkB,gBAAkB,GAC3BlB,GAASmB,eAAiB,GAC1BnB,GAASoB,SAAW,GAEpBpB,GAAS3I,mBAAqB,CAC5B,UACA,QACA,aACA,cACA,mBACA,mBACA,cACA,YACA,YACA,iBACA,kBACA,iBACA,YAGF2I,GAASE,sBAAwB,ECnI1B,IAAMmB,GAAa,SAAAC,I,uRAAA3M,CAAA0M,EAASrB,IAAT,I,MAAApL,EAAAC,GAAAwM,GACxB,SAAAA,IAAc,IAAAtM,EAGZ,O,4FAHYvC,CAAA,KAAA6O,IACZtM,EAAAH,EAAAzC,KAAA,OACKgO,UAAYH,GAASe,UAC1BQ,GAAAxM,EAAAyM,GAAAzM,GACF,CAAC,O,EAAAsM,E,oFAAA,CALuB,G,grDCNnB,IAAM5J,GAAc,SAAAS,I,uRAAAvD,CAAA8C,EAASpB,IAAT,I,MAAAzB,EAAAC,GAAA4C,GACzB,SAAAA,EAAYgK,EAAWtM,EAAWwG,EAAY+F,GAAa,IAAA3M,EAQnC,O,4FARmCvC,CAAA,KAAAiF,IACzD1C,EAAAH,EAAAzC,KAAA,KAAMsP,IAEDtM,UAAYA,EACjBJ,EAAK4G,WAAaA,EAElB5G,EAAK2M,YAAcA,EACnB3M,EAAK4M,kBAAoBtL,GAAWQ,KACpC9B,EAAK0B,WAAY,EAAK1B,CACxB,CAIC,O,EAJA0C,G,EAAA,EAAAhG,IAAA,UAAAa,MAED,SAAQsP,EAAQC,EAAgBC,GAC9B,OAAO,CACT,M,gFAACrK,CAAA,CAdwB,G,grDCGpB,IAAMI,GAAa,SAAAK,I,uRAAAvD,CAAAkD,EAASxB,IAAT,I,MAAAzB,EAAAC,GAAAgD,GACxB,SAAAA,EAAYtB,EAAQoC,GAAK,IAAA5D,EAQtB,O,4FARsBvC,CAAA,KAAAqF,IACvB9C,EAAAH,EAAAzC,KAAA,KAAMoE,IACDoL,kBAAoBtL,GAAWY,SACxBT,IAARmC,GAA6B,OAARA,EACvB5D,EAAK2B,MAAQiC,GAEb5D,EAAK2B,MAAQ,IAAI+G,GACjB1I,EAAK2B,MAAMqL,OAAO5J,GAAMqB,eACzBzE,CACH,CAQC,O,EARA8C,G,EAAA,EAAApG,IAAA,UAAAa,MAED,SAAQsP,EAAQC,EAAgBC,GAC9B,OAAOrP,KAAKiE,MAAMqI,SAAS6C,EAC7B,GAAC,CAAAnQ,IAAA,WAAAa,MAED,WACE,OAAOG,KAAKiE,MAAMjD,UACpB,M,gFAACoE,CAAA,CAlBuB,G,ggECFnB,IAAMC,GAAgB,SAAAkK,I,uRAAArN,CAAAmD,EAASD,IAAT,I,MAAAjD,EAAAC,GAAAiD,GAC3B,SAAAA,EAAYvB,EAAQoC,GAAK,IAAA5D,EAEqB,O,4FAFrBvC,CAAA,KAAAsF,IACvB/C,EAAAH,EAAAzC,KAAA,KAAMoE,EAAQoC,IACTgJ,kBAAoBtL,GAAWa,QAAQnC,CAC9C,CAUC,O,EAVA+C,G,EAAA,EAAArG,IAAA,UAAAa,MAED,SAAQsP,EAAQC,EAAgBC,GAC9B,OACEF,GAAUC,GAAkBD,GAAUE,IAAkBG,GAAAC,GAAApK,EAAA7F,WAAA,gBAAAE,KAAA,KAAeyP,EAAQC,EAAgBC,EAEnG,GAAC,CAAArQ,IAAA,WAAAa,MAED,WACE,MAAO,IAAG2P,GAAAC,GAAApK,EAAA7F,WAAA,iBAAAE,KAAA,KACZ,M,gFAAC2F,CAAA,CAd0B,G,grDCDtB,IAAMC,GAAkB,SAAAG,I,uRAAAvD,CAAAoD,EAAS1B,IAAT,I,MAAAzB,EAAAC,GAAAkD,GAC7B,SAAAA,EAAYxB,GAAQ,IAAAxB,EAE2B,O,4FAF3BvC,CAAA,KAAAuF,IAClBhD,EAAAH,EAAAzC,KAAA,KAAMoE,IACDoL,kBAAoBtL,GAAWc,SAASpC,CAC/C,CAQC,O,EARAgD,G,EAAA,EAAAtG,IAAA,UAAAa,MAED,SAAQsP,EAAQC,EAAgBC,GAC9B,OAAOF,GAAUC,GAAkBD,GAAUE,CAC/C,GAAC,CAAArQ,IAAA,WAAAa,MAED,WACE,MAAO,GACT,M,gFAACyF,CAAA,CAZ4B,G,m0BCGxB,IAAMoK,GAAI7L,IAAA,SAAA6L,K,4FAAA3P,CAAA,KAAA2P,EAAA,I,grDCHV,IAAMC,GAAU,SAAAC,I,uRAAA1N,CAAAyN,EAASD,IAAT,I,MAAAvN,EAAAC,GAAAuN,GAAA,SAAAA,IAAA,O,4FAAA5P,CAAA,KAAA4P,GAAAxN,EAAA1B,MAAA,KAAAL,UAAA,Q,EAAAuP,E,oFAAA,I,grDCAhB,IAAME,GAAS,SAAAC,I,uRAAA5N,CAAA2N,EAASF,IAAT,I,MAAAxN,EAAAC,GAAAyN,GAAA,SAAAA,IAAA,O,4FAAA9P,CAAA,KAAA8P,GAAA1N,EAAA1B,MAAA,KAAAL,UAAA,Q,EAAAyP,E,oFAAA,I,grDCAf,IAAME,GAAQ,SAAAC,I,uRAAA9N,CAAA6N,EAASF,IAAT,I,MAAA1N,EAAAC,GAAA2N,GAAA,SAAAA,IAAA,O,4FAAAhQ,CAAA,KAAAgQ,GAAA5N,EAAA1B,MAAA,KAAAL,UAAA,CAGlB,O,EAHkB2P,G,EAAA,EAAA/Q,IAAA,cAAAK,IACnB,WACE,MAAM,IAAI4Q,MAAM,mCAClB,M,gFAACF,CAAA,CAHkB,G,grDCAd,IAAMG,GAAY,SAAAF,I,uRAAA9N,CAAAgO,EAASL,IAAT,I,MAAA1N,EAAAC,GAAA8N,GAAA,SAAAA,IAAA,O,4FAAAnQ,CAAA,KAAAmQ,GAAA/N,EAAA1B,MAAA,KAAAL,UAAA,Q,EAAA8P,E,oFAAA,I,grDCAlB,IAAMC,GAAS,SAAAC,I,uRAAAlO,CAAAiO,EAASD,IAAT,I,MAAA/N,EAAAC,GAAA+N,GAAA,SAAAA,IAAA,O,4FAAApQ,CAAA,KAAAoQ,GAAAhO,EAAA1B,MAAA,KAAAL,UAAA,Q,EAAA+P,E,oFAAA,ICMf,IAAME,GAAQ,CAMnBC,aAAc,SAAUC,EAAMC,EAAWC,GACvCD,EAAYA,GAAa,KAEX,QADdC,EAAQA,GAAS,QAEfD,EAAYC,EAAMD,WAEpB,IAAI9G,EAAI2G,GAAMK,YAAYH,EAAMC,GAChC9G,ECrBG,SAA0BA,EAAGiH,GAKlC,OAJAjH,EAAIA,EAAEgD,QAAQ,MAAO,OAAOA,QAAQ,MAAO,OAAOA,QAAQ,MAAO,OAC7DiE,IACFjH,EAAIA,EAAEgD,QAAQ,KAAM,SAEfhD,CACT,CDeQkH,CAAiBlH,GAAG,GACxB,IAAMmH,EAAIN,EAAKO,gBACf,GAAU,IAAND,EACF,OAAOnH,EAET,IAAIqH,EAAM,IAAMrH,EAAI,IAChBmH,EAAI,IACNnH,EAAI2G,GAAMC,aAAaC,EAAKS,SAAS,GAAIR,GACzCO,EAAMA,EAAIE,OAAOvH,IAEnB,IAAK,IAAIvJ,EAAI,EAAGA,EAAI0Q,EAAG1Q,IACrBuJ,EAAI2G,GAAMC,aAAaC,EAAKS,SAAS7Q,GAAIqQ,GACzCO,EAAMA,EAAIE,OAAO,IAAMvH,GAGzB,OADAqH,EAAMA,EAAIE,OAAO,IAEnB,EAEAP,YAAa,SAAUQ,EAAGV,EAAWC,GAMnC,GALAD,EAAYA,GAAa,KAEX,QADdC,EAAQA,GAAS,QAEfD,EAAYC,EAAMD,WAEF,OAAdA,EAAoB,CACtB,GAAIU,aAAanB,GAAU,CACzB,IACMoB,EADUD,EAAEE,YACQC,eAE1B,OAAiB,GAAbF,EACKX,EAAUU,EAAExO,WAAa,IAAMyO,EAEjCX,EAAUU,EAAExO,UACrB,CAAO,GAAIwO,aAAaf,GACtB,OAAOe,EAAElQ,WACJ,GAAIkQ,aAAahB,IACL,OAAbgB,EAAE/B,OACJ,OAAO+B,EAAE/B,OAAOhJ,IAGtB,CAEA,IAAMmL,EAAUJ,EAAEK,aAClB,OAAID,aAAmB5L,GACd4L,EAAQnL,KAEV+K,EAAEK,aAAavQ,UACxB,EAKAwQ,YAAa,SAAUN,GAErB,IADA,IAAMO,EAAO,GACJtR,EAAI,EAAGA,EAAI+Q,EAAEJ,gBAAiB3Q,IACrCsR,EAAKzJ,KAAKkJ,EAAEF,SAAS7Q,IAEvB,OAAOsR,CACT,EAMAC,aAAc,SAAUR,GACtB,IAAIS,EAAY,GAEhB,IADAT,EAAIA,EAAEU,YACO,OAANV,GACLS,EAAY,CAACT,GAAGD,OAAOU,GACvBT,EAAIA,EAAEU,YAER,OAAOD,CACT,EAEAE,kBAAmB,SAAUX,EAAGY,GAC9B,OAAOzB,GAAM0B,aAAab,EAAGY,GAAO,EACtC,EAEAE,iBAAkB,SAAUd,EAAGxO,GAC7B,OAAO2N,GAAM0B,aAAab,EAAGxO,GAAW,EAC1C,EAEAqP,aAAc,SAAUb,EAAGnD,EAAOkE,GAChC,IAAMC,EAAQ,GAEd,OADA7B,GAAM8B,cAAcjB,EAAGnD,EAAOkE,EAAYC,GACnCA,CACT,EAEAC,cAAe,SAAUjB,EAAGnD,EAAOkE,EAAYC,GAEzCD,GAAcf,aAAahB,GACzBgB,EAAE/B,OAAOxL,OAASoK,GACpBmE,EAAMlK,KAAKkJ,IAEHe,GAAcf,aAAanB,IACjCmB,EAAExO,YAAcqL,GAClBmE,EAAMlK,KAAKkJ,GAIf,IAAK,IAAI/Q,EAAI,EAAGA,EAAI+Q,EAAEJ,gBAAiB3Q,IACrCkQ,GAAM8B,cAAcjB,EAAEF,SAAS7Q,GAAI4N,EAAOkE,EAAYC,EAE1D,EAEAE,YAAa,SAAUlB,GAErB,IADA,IAAIgB,EAAQ,CAAChB,GACJ/Q,EAAI,EAAGA,EAAI+Q,EAAEJ,gBAAiB3Q,IACrC+R,EAAQA,EAAMjB,OAAOZ,GAAM+B,YAAYlB,EAAEF,SAAS7Q,KAEpD,OAAO+R,CACT,G,grDE/HK,IAAMG,GAAW,SAAAC,I,uRAAApQ,CAAAmQ,EAAStC,IAAT,I,MAAA5N,EAAAC,GAAAiQ,GAqBtB,SAAAA,EAAYE,EAAQC,GAAe,IAAAlQ,EASQ,O,4FATRvC,CAAA,KAAAsS,IAEjC/P,EAAAH,EAAAzC,KAAA,OACK+S,UAAYF,GAAU,KAM3BjQ,EAAKkQ,cAAgBA,IAAkB,EAAElQ,CAC3C,CAqHC,O,EArHA+P,G,EAAA,EAAArT,IAAA,cAAAK,IAED,WACE,OAAOW,IACT,GAAC,CAAAhB,IAAA,QAAAa,MAED,WAGE,IAFA,IAAI2M,EAAI,EACJvD,EAAIjJ,KACK,OAANiJ,GACLA,EAAIA,EAAEwJ,UACNjG,GAAK,EAEP,OAAOA,CACT,GAEA,CAAAxN,IAAA,UAAAa,MAIA,WACE,OAA+B,IAAxBG,KAAKwS,aACd,GAEA,CAAAxT,IAAA,oBAAAa,MACA,WACE,OAAOiL,GAASC,gBAClB,GAAC,CAAA/L,IAAA,aAAAa,MAED,WACE,OAAOG,IACT,GAEA,CAAAhB,IAAA,UAAAa,MAQA,WACE,OAA6B,IAAzBG,KAAK8Q,gBACA,GAEA9Q,KAAK0S,SACT7L,KAAI,SAAC8L,GACJ,OAAOA,EAAMC,SACf,IACC9L,KAAK,GAEZ,GAEA,CAAA9H,IAAA,eAAAa,MAQA,WAEE,OAAO,CACT,GAEA,CAAAb,IAAA,eAAAa,MAOA,SAAasR,GAAY,GAAC,CAAAnS,IAAA,WAAAa,MAE1B,SAASM,GACP,OAAO,IACT,GAAC,CAAAnB,IAAA,gBAAAa,MAED,WACE,OAAO,CACT,GAAC,CAAAb,IAAA,SAAAa,MAED,SAAOgT,GACL,OAAOA,EAAQC,cAAc9S,KAC/B,GAEA,CAAAhB,IAAA,eAAAa,MAIA,SAAa2Q,EAAWC,GACtB,OAAOJ,GAAMC,aAAatQ,KAAMwQ,EAAWC,EAC7C,GAAC,CAAAzR,IAAA,WAAAa,MAED,SAAS2Q,EAAW3K,GAClB2K,EAAYA,GAAa,KACzB3K,EAAOA,GAAQ,KAGf,IAFA,IAAIoD,EAAIjJ,KACJ0J,EAAI,IACK,OAANT,GAAcA,IAAMpD,GAAM,CAC/B,GAAkB,OAAd2K,EACGvH,EAAE8J,YACLrJ,GAAKT,EAAEuJ,mBAEJ,CACL,IAAMQ,EAAK/J,EAAEvG,UAEbgH,GADiBsJ,GAAM,GAAKA,EAAKxC,EAAUnQ,OAASmQ,EAAUwC,GAAM9F,OAAO8F,EAE7E,CACoB,OAAhB/J,EAAEwJ,WAAqC,OAAdjC,GAAuBvH,EAAEwJ,UAAUM,YAC9DrJ,GAAK,KAEPT,EAAIA,EAAEwJ,SACR,CAEA,OADA/I,GAAK,GAEP,M,gFAAC2I,CAAA,CApJqB,G,otBCJjB,IAAMY,GAAiB,WAC5B,SAAAA,EAAYC,I,4FAAgBnT,CAAA,KAAAkT,GAC1BjT,KAAKkT,eAAiBA,CACxB,C,UA0CC,O,EAxCDD,G,EAAA,EAAAjU,IAAA,UAAAa,MA0BA,WACE,OAAOG,OAASiT,EAAkBE,KACpC,GAAC,CAAAnU,IAAA,eAAAa,MAED,WACE,OAAOG,KAAKoT,eAAepT,KAAKK,OAAS,KAAO4S,EAAkBI,kBACpE,GAAC,CAAArU,IAAA,WAAAa,MAED,WACE,OAAOG,KAAKkT,cACd,GAAC,CAAAlU,IAAA,iBAAAa,MAED,SAAeK,GACbA,EAAKM,OAAOR,KAAKkT,eACnB,M,gFAACD,CAAA,CA7C2B,G,0rDAoD9BA,GAAkBE,MAAQ,KAO1BF,GAAkBI,mBAAqB,WAEvCJ,GAAkBK,gBAAkB,EACpCL,GAAkBM,GAAKN,GAAkBK,gBACzCL,GAAkBO,eAAgB,EC5D3B,IAAMC,GAAsB,SAAAC,I,uRAAAxR,CAAAuR,EAASR,IAAT,I,MAAA9Q,EAAAC,GAAAqR,GACjC,SAAAA,EAAYE,EAASC,GAAc,IAAAtR,G,4FAAAvC,CAAA,KAAA0T,GAOjC,IAAMjI,EAAI,IAAI1L,EACd0L,EAAEhL,OAAOmT,EAASC,GAClB,IAAMhT,EAAW4K,EAAEvK,SAInB,OAHAqB,EAAAH,EAAAzC,KAAA,KAAMkB,IACD+S,QAAUA,EACfrR,EAAKsR,aAAeA,EACpB9E,GAAAxM,EAAAyM,GAAAzM,GACF,CAsDC,O,EAtDAmR,E,EAAA,EAAAzU,IAAA,SAAAK,IAED,WACE,OAAOW,KAAK4T,aAAavT,MAC3B,GAAC,CAAArB,IAAA,UAAAa,MAED,WAGE,OAAOG,KAAK4T,aAAa,KAAOX,GAAkBI,kBACpD,GAAC,CAAArU,IAAA,YAAAa,MAED,SAAUkO,GACR,OAAO/N,KAAK2T,QAAQ5F,EACtB,GAAC,CAAA/O,IAAA,iBAAAa,MAED,SAAekO,GACb,OAAO/N,KAAK4T,aAAa7F,EAC3B,GAAC,CAAA/O,IAAA,SAAAa,MAED,SAAOyB,GACL,OAAItB,OAASsB,GAEAA,aAAiBmS,GAEnBzT,KAAKY,aAAeU,EAAMV,YAG5BwF,GAAYpG,KAAK4T,aAActS,EAAMsS,eAAiBxN,GAAYpG,KAAK2T,QAASrS,EAAMqS,QAEjG,GAAC,CAAA3U,IAAA,WAAAa,MAED,WACE,GAAIG,KAAK+S,UACP,MAAO,KAGP,IADA,IAAIrJ,EAAI,IACCvJ,EAAI,EAAGA,EAAIH,KAAK4T,aAAavT,OAAQF,IACxCA,EAAI,IACNuJ,GAAQ,MAEN1J,KAAK4T,aAAazT,KAAO8S,GAAkBI,oBAI/C3J,GAAQ1J,KAAK4T,aAAazT,GACF,OAApBH,KAAK2T,QAAQxT,GACfuJ,EAAIA,EAAI,IAAM1J,KAAK2T,QAAQxT,GAE3BuJ,GAAQ,QAPRA,GAAQ,IAUZ,OAAOA,EAAI,GAEf,I,mFAAC+J,CAAA,CArEgC,G,grDCD5B,IAAMI,GAA0B,SAAAH,I,uRAAAxR,CAAA2R,EAASZ,IAAT,I,MAAA9Q,EAAAC,GAAAyR,GACrC,SAAAA,EAAYtB,EAAQuB,GAAa,IAAAxR,G,4FAAAvC,CAAA,KAAA8T,GAC/B,IAAIjT,EACEV,EAAO,IAAIJ,EASc,OARhB,OAAXyS,EACFrS,EAAKM,OAAO+R,EAAQuB,GAEpB5T,EAAKM,OAAO,GAEdI,EAAWV,EAAKe,UAChBqB,EAAAH,EAAAzC,KAAA,KAAMkB,IACD6R,UAAYF,EACjBjQ,EAAKwR,YAAcA,EAAYxR,CACjC,CAaC,O,EAbAuR,E,EAgDA,EAAA7U,IAAA,SAAAa,MA1CD,SAAc0S,EAAQuB,GACpB,OAAIA,IAAgBb,GAAkBI,oBAAiC,OAAXd,EAEnDU,GAAkBE,MAElB,IAAIU,EAA2BtB,EAAQuB,EAElD,K,EAbC,EAAA9U,IAAA,SAAAK,IAED,WACE,OAAO,CACT,GAAC,CAAAL,IAAA,YAAAa,MAWD,SAAUkO,GACR,OAAO/N,KAAKyS,SACd,GAAC,CAAAzT,IAAA,iBAAAa,MAED,SAAekO,GACb,OAAO/N,KAAK8T,WACd,GAAC,CAAA9U,IAAA,SAAAa,MAED,SAAOyB,GACL,OAAItB,OAASsB,GAEAA,aAAiBuS,GAEnB7T,KAAKY,aAAeU,EAAMV,YAG/BZ,KAAK8T,cAAgBxS,EAAMwS,cACJ,MAAlB9T,KAAKyS,UAA6C,MAAnBnR,EAAMmR,UAClCzS,KAAKyS,UAAUlM,OAAOjF,EAAMmR,WAE5C,GAAC,CAAAzT,IAAA,WAAAa,MAED,WACE,IAAMkU,EAAwB,OAAnB/T,KAAKyS,UAAqB,GAAKzS,KAAKyS,UAAUzR,WACzD,OAAkB,IAAd+S,EAAG1T,OACDL,KAAK8T,cAAgBb,GAAkBI,mBAClC,IAEAnG,OAAOlN,KAAK8T,aAGd5G,OAAOlN,KAAK8T,aAAe,IAAMC,CAE5C,M,gFAnCCF,CAAA,CA1BoC,G,grDCAhC,IAAMG,GAAsB,SAAAC,I,uRAAA/R,CAAA8R,EAASH,IAAT,I,MAAA1R,EAAAC,GAAA4R,GACjC,SAAAA,IAAc,O,4FAAAjU,CAAA,KAAAiU,GAAA7R,EAAAzC,KAAA,KACN,KAAMuT,GAAkBI,mBAChC,CAoBC,O,EApBAW,G,EAAA,EAAAhV,IAAA,UAAAa,MAED,WACE,OAAO,CACT,GAAC,CAAAb,IAAA,YAAAa,MAED,SAAUkO,GACR,OAAO,IACT,GAAC,CAAA/O,IAAA,iBAAAa,MAED,SAAekO,GACb,OAAO/N,KAAK8T,WACd,GAAC,CAAA9U,IAAA,SAAAa,MAED,SAAOyB,GACL,OAAOtB,OAASsB,CAClB,GAAC,CAAAtC,IAAA,WAAAa,MAED,WACE,MAAO,GACT,M,gFAACmU,CAAA,CAvBgC,G,otBA0BnCf,GAAkBE,MAAQ,IAAIa,GC1B9B,IAAM5M,GAAkB,KAEX8M,GAAO,WAClB,SAAAA,EAAY5M,EAAcC,I,4FAAgBxH,CAAA,KAAAmU,GACxClU,KAAKwH,KAAO,CAAC,EACbxH,KAAKsH,aAAeA,GAAgBd,GACpCxG,KAAKuH,eAAiBA,GAAkBd,EAC1C,C,UAsEC,O,EAtEAyN,E,EAAA,EAAAlV,IAAA,SAAAK,IAED,WAAa,IAAAiD,EAAA,KACX,OAAOpD,OAAOuI,KAAKzH,KAAKwH,MACrBE,QAAO,SAAC1I,GAAG,OAAKA,EAAI2I,WAAWP,GAAgB,IAC/CP,KAAI,SAAC7H,GAAG,OAAKsD,EAAKkF,KAAKxI,GAAKqB,MAAM,GAAEL,MACpC4H,QAAO,SAACC,EAAOC,GAAI,OAAKD,EAAQC,CAAI,GAAE,EAC3C,GAAC,CAAA9I,IAAA,MAAAa,MAED,SAAIb,EAAKa,GACP,IAAMsU,EAAU/M,GAAkBpH,KAAKsH,aAAatI,GACpD,GAAImV,KAAWnU,KAAKwH,KAAM,CAExB,IADA,IAAM4M,EAAUpU,KAAKwH,KAAK2M,GACjBhU,EAAI,EAAGA,EAAIiU,EAAQ/T,OAAQF,IAAK,CACvC,IAAMkU,EAAQD,EAAQjU,GACtB,GAAIH,KAAKuH,eAAevI,EAAKqV,EAAMrV,KAAM,CACvC,IAAMsV,EAAWD,EAAMxU,MAEvB,OADAwU,EAAMxU,MAAQA,EACPyU,CACT,CACF,CAEA,OADAF,EAAQpM,KAAK,CAAEhJ,IAAKA,EAAKa,MAAOA,IACzBA,CACT,CAEE,OADAG,KAAKwH,KAAK2M,GAAW,CAAC,CAAEnV,IAAKA,EAAKa,MAAOA,IAClCA,CAEX,GAAC,CAAAb,IAAA,cAAAa,MAED,SAAYb,GACV,IAAMmV,EAAU/M,GAAkBpH,KAAKsH,aAAatI,GACpD,GAAImV,KAAWnU,KAAKwH,KAElB,IADA,IAAM4M,EAAUpU,KAAKwH,KAAK2M,GACjBhU,EAAI,EAAGA,EAAIiU,EAAQ/T,OAAQF,IAAK,CACvC,IAAMkU,EAAQD,EAAQjU,GACtB,GAAIH,KAAKuH,eAAevI,EAAKqV,EAAMrV,KAAM,OAAO,CAClD,CAEF,OAAO,CACT,GAAC,CAAAA,IAAA,MAAAa,MAED,SAAIb,GACF,IAAMmV,EAAU/M,GAAkBpH,KAAKsH,aAAatI,GACpD,GAAImV,KAAWnU,KAAKwH,KAElB,IADA,IAAM4M,EAAUpU,KAAKwH,KAAK2M,GACjBhU,EAAI,EAAGA,EAAIiU,EAAQ/T,OAAQF,IAAK,CACvC,IAAMkU,EAAQD,EAAQjU,GACtB,GAAIH,KAAKuH,eAAevI,EAAKqV,EAAMrV,KAAM,OAAOqV,EAAMxU,KACxD,CAEF,OAAO,IACT,GAAC,CAAAb,IAAA,UAAAa,MAED,WAAU,IAAAoI,EAAA,KACR,OAAO/I,OAAOuI,KAAKzH,KAAKwH,MACrBE,QAAO,SAAC1I,GAAG,OAAKA,EAAI2I,WAAWP,GAAgB,IAC/Cc,SAAQ,SAAClJ,GAAG,OAAKiJ,EAAKT,KAAKxI,EAAI,GAAEgB,KACtC,GAAC,CAAAhB,IAAA,UAAAa,MAED,WACE,OAAOG,KAAKoU,UAAUvN,KAAI,SAAC0N,GAAC,OAAKA,EAAEvV,GAAG,GACxC,GAAC,CAAAA,IAAA,YAAAa,MAED,WACE,OAAOG,KAAKoU,UAAUvN,KAAI,SAAC0N,GAAC,OAAKA,EAAE1U,KAAK,GAC1C,GAAC,CAAAb,IAAA,WAAAa,MAED,WAEE,MAAO,IADIG,KAAKoU,UAAUvN,KAAI,SAAC0N,GAAC,MAAK,IAAMA,EAAEvV,IAAM,IAAMuV,EAAE1U,MAAQ,GAAG,IACtDiH,KAAK,MAAQ,GAC/B,I,mFAACoN,CAAA,CA3EiB,GCMb,SAASM,GAAiChH,EAAKnF,GAMpD,QALqBtE,IAAjBsE,GAA+C,OAAjBA,IAChCA,EAAegK,GAAYc,OAIE,OAA3B9K,EAAaoK,WAAsBpK,IAAiBgK,GAAYc,MAClE,OAAOF,GAAkBE,MAG3B,IAAMZ,EAASiC,GAAiChH,EAAKnF,EAAaoK,WAE5DgC,EADQjH,EAAIkH,OAAOrM,EAAamK,eACb5E,YAAY,GACrC,OAAOiG,GAA2Bc,OAAOpC,EAAQkC,EAAWxF,YAAYpE,YAC1E,CAEO,SAAS+J,GAA2BtL,EAASuL,EAAcC,GAChE,GAAIxL,EAAQyJ,UACV,OAAOzJ,EAET,IAAIsC,EAAWkJ,EAAQzV,IAAIiK,IAAY,KACvC,GAAiB,OAAbsC,EACF,OAAOA,EAGT,GAAiB,QADjBA,EAAWiJ,EAAaxV,IAAIiK,IAG1B,OADAwL,EAAQ5O,IAAIoD,EAASsC,GACdA,EAIT,IAFA,IAAImJ,GAAU,EACVpB,EAAU,GACLxT,EAAI,EAAGA,EAAIwT,EAAQtT,OAAQF,IAAK,CACvC,IAAMoS,EAASqC,GAA2BtL,EAAQsI,UAAUzR,GAAI0U,EAAcC,GAC9E,GAAIC,GAAWxC,IAAWjJ,EAAQsI,UAAUzR,GAAI,CAC9C,IAAK4U,EAAS,CACZpB,EAAU,GACV,IAAK,IAAIvG,EAAI,EAAGA,EAAI9D,EAAQjJ,OAAQ+M,IAClCuG,EAAQvG,GAAK9D,EAAQsI,UAAUxE,GAEjC2H,GAAU,CACZ,CACApB,EAAQxT,GAAKoS,CACf,CACF,CACA,IAAKwC,EAGH,OAFAF,EAAahM,IAAIS,GACjBwL,EAAQ5O,IAAIoD,EAASA,GACdA,EAET,IAAI0L,EAAU,KAYd,OAVEA,EADqB,IAAnBrB,EAAQtT,OACA4S,GAAkBE,MACA,IAAnBQ,EAAQtT,OACPwT,GAA2Bc,OAAOhB,EAAQ,GAAIrK,EAAQ8J,eAAe,IAErE,IAAIK,GAAuBE,EAASrK,EAAQsK,cAExDiB,EAAahM,IAAImM,GACjBF,EAAQ5O,IAAI8O,EAASA,GACrBF,EAAQ5O,IAAIoD,EAAS0L,GAEdA,CACT,CAEO,SAASC,GAAM5O,EAAGC,EAAG4O,EAAgBC,GAE1C,GAAI9O,IAAMC,EACR,OAAOD,EAET,GAAIA,aAAawN,IAA8BvN,aAAauN,GAC1D,OA4MJ,SAAyBxN,EAAGC,EAAG4O,EAAgBC,GAC7C,GAAmB,OAAfA,EAAqB,CACvB,IAAIC,EAAWD,EAAW9V,IAAIgH,EAAGC,GACjC,GAAiB,OAAb8O,EACF,OAAOA,EAGT,GAAiB,QADjBA,EAAWD,EAAW9V,IAAIiH,EAAGD,IAE3B,OAAO+O,CAEX,CAEA,IAAMC,EA4GR,SAAmBhP,EAAGC,EAAG4O,GACvB,GAAIA,EAAgB,CAClB,GAAI7O,IAAM4M,GAAkBE,MAC1B,OAAOF,GAAkBE,MAE3B,GAAI7M,IAAM2M,GAAkBE,MAC1B,OAAOF,GAAkBE,KAE7B,KAAO,CACL,GAAI9M,IAAM4M,GAAkBE,OAAS7M,IAAM2M,GAAkBE,MAC3D,OAAOF,GAAkBE,MACpB,GAAI9M,IAAM4M,GAAkBE,MAAO,CAExC,IAAMmC,EAAW,CAAChP,EAAEwN,YAAab,GAAkBI,oBAC7CM,EAAU,CAACrN,EAAEmM,UAAW,MAC9B,OAAO,IAAIgB,GAAuBE,EAAS2B,EAC7C,CAAO,GAAIhP,IAAM2M,GAAkBE,MAAO,CAExC,IAAMmC,EAAW,CAACjP,EAAEyN,YAAab,GAAkBI,oBAC7CM,EAAU,CAACtN,EAAEoM,UAAW,MAC9B,OAAO,IAAIgB,GAAuBE,EAAS2B,EAC7C,CACF,CACA,OAAO,IACT,CApIoBC,CAAUlP,EAAGC,EAAG4O,GAClC,GAAkB,OAAdG,EAIF,OAHmB,OAAfF,GACFA,EAAWjP,IAAIG,EAAGC,EAAG+O,GAEhBA,EAET,GAAIhP,EAAEyN,cAAgBxN,EAAEwN,YAAa,CACnC,IAAMvB,EAAS0C,GAAM5O,EAAEoM,UAAWnM,EAAEmM,UAAWyC,EAAgBC,GAG/D,GAAI5C,IAAWlM,EAAEoM,UACf,OAAOpM,EAET,GAAIkM,IAAWjM,EAAEmM,UACf,OAAOnM,EAMT,IAAMkP,EAAM3B,GAA2Bc,OAAOpC,EAAQlM,EAAEyN,aAIxD,OAHmB,OAAfqB,GACFA,EAAWjP,IAAIG,EAAGC,EAAGkP,GAEhBA,CACT,CAGE,IAAIC,EAAe,KAOnB,IANIpP,IAAMC,GAAsB,OAAhBD,EAAEoM,WAAsBpM,EAAEoM,YAAcnM,EAAEmM,aAIxDgD,EAAepP,EAAEoM,WAEE,OAAjBgD,EAAuB,CAGzB,IAAMH,EAAW,CAACjP,EAAEyN,YAAaxN,EAAEwN,aAC/BzN,EAAEyN,YAAcxN,EAAEwN,cACpBwB,EAAS,GAAKhP,EAAEwN,YAChBwB,EAAS,GAAKjP,EAAEyN,aAElB,IACM4B,EAAM,IAAIjC,GADA,CAACgC,EAAcA,GACiBH,GAIhD,OAHmB,OAAfH,GACFA,EAAWjP,IAAIG,EAAGC,EAAGoP,GAEhBA,CACT,CAIA,IAAMJ,EAAW,CAACjP,EAAEyN,YAAaxN,EAAEwN,aAC/BH,EAAU,CAACtN,EAAEoM,UAAWnM,EAAEmM,WAC1BpM,EAAEyN,YAAcxN,EAAEwN,cAEpBwB,EAAS,GAAKhP,EAAEwN,YAChBwB,EAAS,GAAKjP,EAAEyN,YAChBH,EAAU,CAACrN,EAAEmM,UAAWpM,EAAEoM,YAE5B,IAAMkD,EAAK,IAAIlC,GAAuBE,EAAS2B,GAI/C,OAHmB,OAAfH,GACFA,EAAWjP,IAAIG,EAAGC,EAAGqP,GAEhBA,CAEX,CA5RWC,CAAgBvP,EAAGC,EAAG4O,EAAgBC,GAI/C,GAAID,EAAgB,CAClB,GAAI7O,aAAa2N,GACf,OAAO3N,EAET,GAAIC,aAAa0N,GACf,OAAO1N,CAEX,CAQA,OANID,aAAawN,KACfxN,EAAI,IAAIoN,GAAuB,CAACpN,EAAEuL,aAAc,CAACvL,EAAEyN,eAEjDxN,aAAauN,KACfvN,EAAI,IAAImN,GAAuB,CAACnN,EAAEsL,aAAc,CAACtL,EAAEwN,eAyBvD,SAAqBzN,EAAGC,EAAG4O,EAAgBC,GACzC,GAAmB,OAAfA,EAAqB,CACvB,IAAIC,EAAWD,EAAW9V,IAAIgH,EAAGC,GACjC,GAAiB,OAAb8O,EAEF,OADInC,GAAkBO,eAAe1S,QAAQC,IAAI,iBAAmBsF,EAAI,MAAQC,EAAI,gBAC7E8O,EAGT,GAAiB,QADjBA,EAAWD,EAAW9V,IAAIiH,EAAGD,IAG3B,OADI4M,GAAkBO,eAAe1S,QAAQC,IAAI,iBAAmBsF,EAAI,MAAQC,EAAI,gBAC7E8O,CAEX,CAEA,IAAIjV,EAAI,EACJiN,EAAI,EACJ1M,EAAI,EAEJmV,EAAqB,IAAIvV,MAAM+F,EAAEuN,aAAavT,OAASiG,EAAEsN,aAAavT,QAAQyV,KAAK,GACnFC,EAAgB,IAAIzV,MAAM+F,EAAEuN,aAAavT,OAASiG,EAAEsN,aAAavT,QAAQyV,KAAK,MAElF,KAAO3V,EAAIkG,EAAEuN,aAAavT,QAAU+M,EAAI9G,EAAEsN,aAAavT,QAAQ,CAC7D,IAAM2V,EAAW3P,EAAEsN,QAAQxT,GACrB8V,EAAW3P,EAAEqN,QAAQvG,GAC3B,GAAI/G,EAAEuN,aAAazT,KAAOmG,EAAEsN,aAAaxG,GAAI,CAE3C,IAAMkE,EAAUjL,EAAEuN,aAAazT,GAEXmR,IAAY2B,GAAkBI,oBAAmC,OAAb2C,GAAkC,OAAbC,GAClE,OAAbD,GAAkC,OAAbC,GAAqBD,IAAaC,GAInEF,EAAcrV,GAAKsV,EACnBH,EAAmBnV,GAAK4Q,IAGxByE,EAAcrV,GAAKuU,GAAMe,EAAUC,EAAUf,EAAgBC,GAC7DU,EAAmBnV,GAAK4Q,GAE1BnR,GAAK,EACLiN,GAAK,CACP,MAAW/G,EAAEuN,aAAazT,GAAKmG,EAAEsN,aAAaxG,IAE5C2I,EAAcrV,GAAKsV,EACnBH,EAAmBnV,GAAK2F,EAAEuN,aAAazT,GACvCA,GAAK,IAGL4V,EAAcrV,GAAKuV,EACnBJ,EAAmBnV,GAAK4F,EAAEsN,aAAaxG,GACvCA,GAAK,GAEP1M,GAAK,CACP,CAEA,GAAIP,EAAIkG,EAAEuN,aAAavT,OACrB,IAAK,IAAI4I,EAAI9I,EAAG8I,EAAI5C,EAAEuN,aAAavT,OAAQ4I,IACzC8M,EAAcrV,GAAK2F,EAAEsN,QAAQ1K,GAC7B4M,EAAmBnV,GAAK2F,EAAEuN,aAAa3K,GACvCvI,GAAK,OAGP,IAAK,IAAIuI,EAAImE,EAAGnE,EAAI3C,EAAEsN,aAAavT,OAAQ4I,IACzC8M,EAAcrV,GAAK4F,EAAEqN,QAAQ1K,GAC7B4M,EAAmBnV,GAAK4F,EAAEsN,aAAa3K,GACvCvI,GAAK,EAIT,GAAIA,EAAIqV,EAAc1V,OAAQ,CAE5B,GAAU,IAANK,EAAS,CAEX,IAAMiV,EAAK9B,GAA2Bc,OAAOoB,EAAc,GAAIF,EAAmB,IAIlF,OAHmB,OAAfV,GACFA,EAAWjP,IAAIG,EAAGC,EAAGqP,GAEhBA,CACT,CACAI,EAAgBA,EAAcpM,MAAM,EAAGjJ,GACvCmV,EAAqBA,EAAmBlM,MAAM,EAAGjJ,EACnD,CAEA,IAAMwV,EAAI,IAAIzC,GAAuBsC,EAAeF,GAIpD,GAAIK,EAAE3P,OAAOF,GAKX,OAJmB,OAAf8O,GACFA,EAAWjP,IAAIG,EAAGC,EAAGD,GAEnB4M,GAAkBO,eAAe1S,QAAQC,IAAI,iBAAmBsF,EAAI,MAAQC,EAAI,SAC7ED,EAET,GAAI6P,EAAE3P,OAAOD,GAKX,OAJmB,OAAf6O,GACFA,EAAWjP,IAAIG,EAAGC,EAAGA,GAEnB2M,GAAkBO,eAAe1S,QAAQC,IAAI,iBAAmBsF,EAAI,MAAQC,EAAI,SAC7EA,GAiBX,SAA8BqN,GAG5B,IAFA,IAAMwC,EAAgB,IAAIjC,GAEjBjL,EAAI,EAAGA,EAAI0K,EAAQtT,OAAQ4I,IAAK,CACvC,IAAMsJ,EAASoB,EAAQ1K,GAClBkN,EAAcC,YAAY7D,IAC7B4D,EAAcjQ,IAAIqM,EAAQA,EAE9B,CACA,IAAK,IAAI8D,EAAI,EAAGA,EAAI1C,EAAQtT,OAAQgW,IAClC1C,EAAQ0C,GAAKF,EAAc9W,IAAIsU,EAAQ0C,GAE3C,EA3BEC,CAAqBP,GAEF,OAAfZ,GACFA,EAAWjP,IAAIG,EAAGC,EAAG4P,GAGnBjD,GAAkBO,eAAe1S,QAAQC,IAAI,iBAAmBsF,EAAI,MAAQC,EAAI,OAAS4P,GAE7F,OAAOA,CACT,CAtISK,CAAYlQ,EAAGC,EAAG4O,EAAgBC,EAC3C,CA2UO,SAASqB,GAAmBlN,EAAS4I,EAAO4C,GACjD,GAAc,OAAV5C,EAEF,OAAOsE,GAAmBlN,EAD1B4I,EAAQ,GACkC4C,GACrC,GAAgB,OAAZA,EAET,OAAO0B,GAAmBlN,EAAS4I,EADnC4C,EAAU,IAAIZ,IAGd,GAAgB,OAAZ5K,GAAoBwL,EAAQsB,YAAY9M,GAC1C,OAAO4I,EAET4C,EAAQ5O,IAAIoD,EAASA,GACrB4I,EAAMlK,KAAKsB,GACX,IAAK,IAAInJ,EAAI,EAAGA,EAAImJ,EAAQjJ,OAAQF,IAClCqW,GAAmBlN,EAAQsI,UAAUzR,GAAI+R,EAAO4C,GAElD,OAAO5C,CAEX,C,otBC/bO,IAAMuE,GAAM,WACjB,SAAAA,K,4FAAc1W,CAAA,KAAA0W,GACZzW,KAAKwH,KAAO,EACd,C,UAwCC,O,EAxCAiP,G,EAAA,EAAAzX,IAAA,SAAAK,IAED,WACE,OAAOW,KAAK+H,SAAS1H,MACvB,GAAC,CAAArB,IAAA,MAAAa,MAED,SAAIA,GACFG,KAAKwH,KAAK3H,IAAS,CACrB,GAAC,CAAAb,IAAA,KAAAa,MAED,SAAGqG,GAAK,IAAA5D,EAAA,KACNpD,OAAOuI,KAAKvB,EAAIsB,MAAMX,KAAI,SAACwD,GAAG,OAAK/H,EAAKuG,IAAIwB,EAAI,GAAErK,KACpD,GAAC,CAAAhB,IAAA,SAAAa,MAED,SAAOA,UACEG,KAAKwH,KAAK3H,EACnB,GAAC,CAAAb,IAAA,MAAAa,MAED,SAAIA,GACF,OAA4B,IAArBG,KAAKwH,KAAK3H,EACnB,GAAC,CAAAb,IAAA,SAAAa,MAED,WACE,OAAOX,OAAOuI,KAAKzH,KAAKwH,KAC1B,GAAC,CAAAxI,IAAA,WAAAa,MAED,WACE,OAAOiM,KAAKC,IAAItL,MAAM,KAAMT,KAAK+H,SACnC,GAAC,CAAA/I,IAAA,WAAAa,MAED,WACE,OAAOC,EAAS4W,UAAU1W,KAAK+H,SACjC,GAAC,CAAA/I,IAAA,SAAAa,MAED,SAAOyB,GACL,OAAOA,aAAiBmV,GAAUrQ,GAAYpG,KAAKwH,KAAMlG,EAAMkG,KACjE,GAAC,CAAAxI,IAAA,WAAAa,MAED,WACE,MAAO,IAAMG,KAAK+H,SAASjB,KAAK,MAAQ,GAC1C,M,gFAAC2P,CAAA,CA3CgB,G,otBCYZ,IAAME,GAAW,WACtB,SAAAA,EAAYnJ,I,4FAAKzN,CAAA,KAAA4W,GACf3W,KAAKwN,IAAMA,CACb,C,UA2KC,O,EAzKDmJ,E,EAAA,EAAA3X,IAAA,uBAAAa,MAUA,SAAqB6J,GACnB,GAAU,OAANA,EACF,OAAO,KAIT,IAFA,IAAMzJ,EAAQyJ,EAAEkE,YAAYvN,OACtBuW,EAAO,GACJvM,EAAM,EAAGA,EAAMpK,EAAOoK,IAAO,CACpCuM,EAAKvM,GAAO,IAAIW,GAChB,IAAM6L,EAAW,IAAIxP,GAErBrH,KAAK8W,MACHpN,EAAE+K,WAAWpK,GAAKvG,OAClB,KACAmP,GAAkBE,MAClByD,EAAKvM,GACLwM,EACA,IAAIJ,IAPe,GASnB,IAIuB,IAArBG,EAAKvM,GAAKhK,QAAgBuW,EAAKvM,GAAKiC,SAASqK,EAAYI,aAC3DH,EAAKvM,GAAO,KAEhB,CACA,OAAOuM,CACT,GAEA,CAAA5X,IAAA,OAAAa,MAkBA,SAAK6J,EAAGsN,EAAWC,GACjB,IAAMC,EAAI,IAAIlM,GAGRmM,EAAsB,QAD5BF,EAAMA,GAAO,MACsBzC,GAAiC9K,EAAE8D,IAAKyJ,GAAO,KAElF,OADAjX,KAAK8W,MAAMpN,EAAGsN,EAAWG,EAAaD,EAAG,IAAI7P,GAAW,IAAIoP,IAHvC,GAG+D,GAC7ES,CACT,GAEA,CAAAlY,IAAA,QAAAa,MA8BA,SAAM6J,EAAGsN,EAAWC,EAAKL,EAAMC,EAAUO,EAAiBC,EAAcC,GACtE,IAAMzG,EAAI,IAAInG,GAAU,CAAEN,MAAOV,EAAGW,IAAK,EAAGf,QAAS2N,GAAO,MAC5D,IAAIJ,EAASU,IAAI1G,GAAjB,CAIA,GADAgG,EAAShO,IAAIgI,GACTnH,IAAMsN,EAAW,CACnB,GAAY,OAARC,EAEF,YADAL,EAAKtH,OAAO5J,GAAMxB,SAEb,GAAI+S,EAAIlE,WAAauE,EAE1B,YADAV,EAAKtH,OAAO5J,GAAMuB,IAGtB,CACA,GAAIyC,aAAakF,GAAe,CAC9B,GAAY,OAARqI,EAEF,YADAL,EAAKtH,OAAO5J,GAAMxB,SAEb,GAAI+S,EAAIlE,WAAauE,EAE1B,YADAV,EAAKtH,OAAO5J,GAAMuB,KAGpB,GAAIgQ,IAAQhE,GAAkBE,MAAO,CACnC,IAAMqE,EAAUJ,EAAgBG,IAAI7N,EAAEhH,WACtC,IACE0U,EAAgBK,OAAO/N,EAAEhH,WAEzB,IAAK,IAAIvC,EAAI,EAAGA,EAAI8W,EAAI5W,OAAQF,IAAK,CACnC,IAAM2T,EAAc9T,KAAKwN,IAAIkH,OAAOuC,EAAI7D,eAAejT,IACvDH,KAAK8W,MAAMhD,EAAakD,EAAWC,EAAIrF,UAAUzR,GAAIyW,EAAMC,EAAUO,EAAiBC,EAAcC,EACtG,CACF,CAAE,QACIE,GACFJ,EAAgBvO,IAAIa,EAAEhH,UAE1B,CACA,MACF,CACF,CACA,IAAK,IAAI0K,EAAI,EAAGA,EAAI1D,EAAEkE,YAAYvN,OAAQ+M,IAAK,CAC7C,IAAM8D,EAAIxH,EAAEkE,YAAYR,GACxB,GAAI8D,EAAEwG,cAAgB1S,GAAgB,CACpC,GAAIoS,EAAgBG,IAAIrG,EAAEpN,OAAOpB,WAC/B,SAEF,IAAMiV,EAAa9D,GAA2Bc,OAAOsC,EAAK/F,EAAEjC,YAAYpE,aACxE,IACEuM,EAAgBvO,IAAIqI,EAAEpN,OAAOpB,WAC7B1C,KAAK8W,MAAM5F,EAAEpN,OAAQkT,EAAWW,EAAYf,EAAMC,EAAUO,EAAiBC,EAAcC,EAC7F,CAAE,QACAF,EAAgBK,OAAOvG,EAAEpN,OAAOpB,UAClC,CACF,MAAO,GAAIwO,aAAa1L,GAClB6R,EACFrX,KAAK8W,MAAM5F,EAAEpN,OAAQkT,EAAWC,EAAKL,EAAMC,EAAUO,EAAiBC,EAAcC,GAEpFV,EAAKtH,OAAOqH,EAAYI,eAErB,GAAI7F,EAAElN,UACXhE,KAAK8W,MAAM5F,EAAEpN,OAAQkT,EAAWC,EAAKL,EAAMC,EAAUO,EAAiBC,EAAcC,QAC/E,GAAIpG,EAAEwG,cAAgBpS,GAC3BsR,EAAKgB,SAASlS,GAAMsB,oBAAqBhH,KAAKwN,IAAIqK,kBAC7C,CACL,IAAI3R,EAAMgL,EAAEjN,MACA,OAARiC,IACEgL,aAAa7L,KACfa,EAAMA,EAAI4R,WAAWpS,GAAMsB,oBAAqBhH,KAAKwN,IAAIqK,eAE3DjB,EAAKmB,OAAO7R,GAEhB,CACF,CApEA,CAqEF,I,mFAACyQ,CAAA,CA9KqB,G,otBAqLxBA,GAAYI,SAAWrR,GAAMqB,aC/LtB,IAAMiR,GAAG,WACd,SAAAA,EAAYC,EAAaJ,I,4FAAc9X,CAAA,KAAAiY,GAKrChY,KAAKiY,YAAcA,EAEnBjY,KAAK6X,aAAeA,EACpB7X,KAAK0U,OAAS,GAMd1U,KAAKkY,gBAAkB,GAEvBlY,KAAKmY,iBAAmB,GAExBnY,KAAKoY,gBAAkB,KACvBpY,KAAKqY,qBAAuB,CAAC,EAO7BrY,KAAKsY,gBAAkB,KAKvBtY,KAAKuY,aAAe,KACpBvY,KAAKwY,iBAAmB,EAC1B,C,UA0GC,O,EAxGDR,G,EAAA,EAAAhZ,IAAA,sBAAAa,MAMA,SAAoB6J,EAAGuN,GAErB,OADa,IAAIN,GAAY3W,MACjByY,KAAK/O,EAAG,KAAMuN,EAC5B,GAEA,CAAAjY,IAAA,sBAAAa,MAKA,SAAoB6J,GAClB,OAA8B,OAA1BA,EAAEmE,sBAGNnE,EAAEmE,oBAAsB7N,KAAK0Y,oBAAoBhP,EAAG,MACpDA,EAAEmE,oBAAoB3C,UAAW,GAHxBxB,EAAEmE,mBAKb,GAAC,CAAA7O,IAAA,aAAAa,MAED,SAAW6J,EAAGuN,GACZ,YAAYlT,IAARkT,EACKjX,KAAK2Y,oBAAoBjP,GAEzB1J,KAAK0Y,oBAAoBhP,EAAGuN,EAEvC,GAAC,CAAAjY,IAAA,WAAAa,MAED,SAASuK,GACO,OAAVA,IACFA,EAAMoD,IAAMxN,KACZoK,EAAMS,YAAc7K,KAAK0U,OAAOrU,QAElCL,KAAK0U,OAAO1M,KAAKoC,EACnB,GAAC,CAAApL,IAAA,cAAAa,MAED,SAAYuK,GACVpK,KAAK0U,OAAOtK,EAAMS,aAAe,IACnC,GAAC,CAAA7L,IAAA,sBAAAa,MAED,SAAoB6J,GAGlB,OAFA1J,KAAKkY,gBAAgBlQ,KAAK0B,GAC1BA,EAAEkP,SAAW5Y,KAAKkY,gBAAgB7X,OAAS,EACpCqJ,EAAEkP,QACX,GAAC,CAAA5Z,IAAA,mBAAAa,MAED,SAAiB+Y,GACf,OAAoC,IAAhC5Y,KAAKkY,gBAAgB7X,OAChB,KAEAL,KAAKkY,gBAAgBU,EAEhC,GAEA,CAAA5Z,IAAA,oBAAAa,MAqBA,SAAkBgL,EAAaoM,GAC7B,GAAIpM,EAAc,GAAKA,GAAe7K,KAAK0U,OAAOrU,OAChD,KAAM,wBAER,IAAMqJ,EAAI1J,KAAK0U,OAAO7J,GAClBgO,EAAY7Y,KAAK8Y,WAAWpP,GAChC,IAAKmP,EAAUvM,SAAS5G,GAAMxB,SAC5B,OAAO2U,EAET,IAAME,EAAW,IAAI/N,GAGrB,IAFA+N,EAAShB,OAAOc,GAChBE,EAASxM,UAAU7G,GAAMxB,SACV,OAAR+S,GAAgBA,EAAIzE,eAAiB,GAAKqG,EAAUvM,SAAS5G,GAAMxB,UAAU,CAClF,IACM8U,EADgBhZ,KAAK0U,OAAOuC,EAAIzE,eACb5E,YAAY,GACrCiL,EAAY7Y,KAAK8Y,WAAWE,EAAG/J,aAC/B8J,EAAShB,OAAOc,GAChBE,EAASxM,UAAU7G,GAAMxB,SACzB+S,EAAMA,EAAIxE,SACZ,CAIA,OAHIoG,EAAUvM,SAAS5G,GAAMxB,UAC3B6U,EAASzJ,OAAO5J,GAAMuB,KAEjB8R,CACT,M,gFAACf,CAAA,CA5Ia,G,otBCIhB,SAASiB,GAAcpI,GACrB,OAAOA,EAAEqI,sBACX,CAEA,SAASC,GAAgB9S,EAAGC,GAC1B,OAAID,IAAMC,GAEO,OAAND,GAAoB,OAANC,GAEXD,EAAE+S,mBAAmB9S,EACrC,CDiIA0R,GAAIqB,mBAAqB,EC1HlB,IAAMC,GAAY,WACvB,SAAAA,EAAYC,I,4FAASxZ,CAAA,KAAAuZ,GAanBtZ,KAAKwZ,aAAe,IAAInS,GAAQ4R,GAAeE,IAM/CnZ,KAAKuZ,aAAsBxV,IAAZwV,GAA+BA,EAQ9CvZ,KAAKkL,UAAW,EAEhBlL,KAAKyZ,QAAU,GAMfzZ,KAAK0Z,UAAY,EACjB1Z,KAAK2Z,gBAAkB,KAMvB3Z,KAAK4Z,oBAAqB,EAC1B5Z,KAAK6Z,sBAAuB,EAE5B7Z,KAAKkT,gBAAkB,CACzB,C,UAuKC,O,EAvKAoG,E,EAAA,EAAAta,IAAA,QAAAK,IAED,WACE,OAAOW,KAAKyZ,OACd,GAAC,CAAAza,IAAA,SAAAK,IAED,WACE,OAAOW,KAAKyZ,QAAQpZ,MACtB,GAEA,CAAArB,IAAA,MAAAa,MAUA,SAAI8K,EAAQwK,GAIV,QAHmBpR,IAAfoR,IACFA,EAAa,MAEXnV,KAAKkL,SACP,KAAM,uBAEJP,EAAOL,kBAAoBnC,GAAgBG,OAC7CtI,KAAK4Z,oBAAqB,GAExBjP,EAAOJ,wBAA0B,IACnCvK,KAAK6Z,sBAAuB,GAE9B,IAAMjO,EAAW5L,KAAKwZ,aAAa3Q,IAAI8B,GACvC,GAAIiB,IAAajB,EAGf,OAFA3K,KAAKkT,gBAAkB,EACvBlT,KAAKyZ,QAAQzR,KAAK2C,IACX,EAGT,IAAMuK,GAAkBlV,KAAKuZ,QACvBO,EAAS7E,GAAMrJ,EAAStC,QAASqB,EAAOrB,QAAS4L,EAAgBC,GAYvE,OANAvJ,EAASrB,wBAA0BuB,KAAKE,IAAIJ,EAASrB,wBAAyBI,EAAOJ,yBAEjFI,EAAOF,6BACTmB,EAASnB,4BAA6B,GAExCmB,EAAStC,QAAUwQ,GACZ,CACT,GAAC,CAAA9a,IAAA,YAAAa,MAED,WAEE,IADA,IAAM6U,EAAS,IAAIrN,GACVlH,EAAI,EAAGA,EAAIH,KAAKyZ,QAAQpZ,OAAQF,IACvCuU,EAAO7L,IAAI7I,KAAKyZ,QAAQtZ,GAAGiK,OAE7B,OAAOsK,CACT,GAAC,CAAA1V,IAAA,gBAAAa,MAED,WAEE,IADA,IAAMka,EAAQ,GACL5Z,EAAI,EAAGA,EAAIH,KAAKyZ,QAAQpZ,OAAQF,IAAK,CAC5C,IAAM0Q,EAAI7Q,KAAKyZ,QAAQtZ,GAAGmK,gBACtBuG,IAAM1I,GAAgBG,MACxByR,EAAM/R,KAAK6I,EAAEvG,gBAEjB,CACA,OAAOyP,CACT,GAAC,CAAA/a,IAAA,kBAAAa,MAED,SAAgBma,GACd,GAAIha,KAAKkL,SACP,KAAM,uBAER,GAAiC,IAA7BlL,KAAKwZ,aAAanZ,OAGtB,IAAK,IAAIF,EAAI,EAAGA,EAAIH,KAAKyZ,QAAQpZ,OAAQF,IAAK,CAC5C,IAAMwK,EAAS3K,KAAKyZ,QAAQtZ,GAC5BwK,EAAOrB,QAAU0Q,EAAYC,iBAAiBtP,EAAOrB,QACvD,CACF,GAAC,CAAAtK,IAAA,SAAAa,MAED,SAAOqa,GACL,IAAK,IAAI/Z,EAAI,EAAGA,EAAI+Z,EAAK7Z,OAAQF,IAC/BH,KAAK6I,IAAIqR,EAAK/Z,IAEhB,OAAO,CACT,GAAC,CAAAnB,IAAA,SAAAa,MAED,SAAOyB,GACL,OACEtB,OAASsB,GACRA,aAAiBgY,GAChBlT,GAAYpG,KAAKyZ,QAASnY,EAAMmY,UAChCzZ,KAAKuZ,UAAYjY,EAAMiY,SACvBvZ,KAAK0Z,YAAcpY,EAAMoY,WACzB1Z,KAAK2Z,kBAAoBrY,EAAMqY,iBAC/B3Z,KAAK4Z,qBAAuBtY,EAAMsY,oBAClC5Z,KAAK6Z,uBAAyBvY,EAAMuY,oBAE1C,GAAC,CAAA7a,IAAA,WAAAa,MAED,WACE,IAAMK,EAAO,IAAIJ,EAEjB,OADAI,EAAKM,OAAOR,KAAKyZ,SACVvZ,EAAKe,QACd,GAAC,CAAAjC,IAAA,iBAAAa,MAED,SAAeK,GACTF,KAAKkL,WACsB,IAAzBlL,KAAKkT,iBACPlT,KAAKkT,eAAiBlT,KAAKY,YAE7BV,EAAKM,OAAOR,KAAKkT,iBAEjBhT,EAAKM,OAAOR,KAAKY,WAErB,GAAC,CAAA5B,IAAA,UAAAa,MAED,WACE,OAA+B,IAAxBG,KAAKyZ,QAAQpZ,MACtB,GAAC,CAAArB,IAAA,WAAAa,MAED,SAASiI,GACP,GAA0B,OAAtB9H,KAAKwZ,aACP,KAAM,oDAER,OAAOxZ,KAAKwZ,aAAalN,SAASxE,EACpC,GAAC,CAAA9I,IAAA,eAAAa,MAED,SAAaiI,GACX,GAA0B,OAAtB9H,KAAKwZ,aACP,KAAM,oDAER,OAAOxZ,KAAKwZ,aAAaW,aAAarS,EACxC,GAAC,CAAA9I,IAAA,QAAAa,MAED,WACE,GAAIG,KAAKkL,SACP,KAAM,uBAERlL,KAAKyZ,QAAU,GACfzZ,KAAKkT,gBAAkB,EACvBlT,KAAKwZ,aAAe,IAAInS,EAC1B,GAAC,CAAArI,IAAA,cAAAa,MAED,SAAYqL,GACVlL,KAAKkL,SAAWA,EACZA,IACFlL,KAAKwZ,aAAe,KAExB,GAAC,CAAAxa,IAAA,WAAAa,MAED,WACE,OACE+G,GAAc5G,KAAKyZ,UAClBzZ,KAAK4Z,mBAAqB,uBAAyB5Z,KAAK4Z,mBAAqB,KAC7E5Z,KAAK0Z,YAAc1B,GAAIqB,mBAAqB,cAAgBrZ,KAAK0Z,UAAY,KACpD,OAAzB1Z,KAAK2Z,gBAA2B,oBAAsB3Z,KAAK2Z,gBAAkB,KAC7E3Z,KAAK6Z,qBAAuB,wBAA0B,GAE3D,I,mFAACP,CAAA,CAtNsB,G,m0BCzBlB,IAAMc,GAAyBvW,IACpC,SAAAuW,EAAYC,I,4FAAUta,CAAA,KAAAqa,QACHrW,IAAbsW,IACFA,EAAW,MAEbra,KAAKkL,UAAW,EAChBlL,KAAKsa,UAAyB,OAAbD,GAA2BA,EAASC,UACrDta,KAAKua,8BAA6C,OAAbF,GAA4BA,EAASE,6BAC5E,IAGFH,GAA0BI,eAAiB,IAAIJ,GAC/CA,GAA0BI,eAAetP,UAAW,ECT7C,IAAMuP,GAAU,CACrBC,MAAO,EACPC,OAAQ,G,grDCJH,IAAMC,GAAU,SAAA/L,I,uRAAA3M,CAAA0Y,EAASrN,IAAT,I,MAAApL,EAAAC,GAAAwY,GACrB,SAAAA,IAAc,IAAAtY,EAEoB,O,4FAFpBvC,CAAA,KAAA6a,IACZtY,EAAAH,EAAAzC,KAAA,OACKgO,UAAYH,GAASS,MAAM1L,CAClC,CAAC,O,EAAAsY,E,oFAAA,CAJoB,G,0rDCAhB,IAAMC,GAAa,SAAAhM,I,uRAAA3M,CAAA2Y,EAAStN,IAAT,I,MAAApL,EAAAC,GAAAyY,GACxB,SAAAA,IAAc,IAAAvY,EAIZ,O,4FAJYvC,CAAA,KAAA8a,IACZvY,EAAAH,EAAAzC,KAAA,OACKkZ,UAAY,EACjBtW,EAAKwY,WAAY,EACjBhM,GAAAxM,EAAAyM,GAAAzM,GACF,CAAC,O,EAAAuY,E,oFAAA,CANuB,G,0rDCGnB,IAAME,GAAe,SAAAC,I,uRAAA9Y,CAAA6Y,EAASF,IAAT,I,MAAA1Y,EAAAC,GAAA2Y,GAC1B,SAAAA,IAAc,IAAAzY,EAGZ,O,4FAHYvC,CAAA,KAAAgb,IACZzY,EAAAH,EAAAzC,KAAA,OACKub,SAAW,KAChBnM,GAAAxM,EAAAyM,GAAAzM,GACF,CAAC,O,EAAAyY,E,oFAAA,CALyB,G,0rDCArB,IAAMG,GAAa,SAAArM,I,uRAAA3M,CAAAgZ,EAAS3N,IAAT,I,MAAApL,EAAAC,GAAA8Y,GACxB,SAAAA,IAAc,IAAA5Y,EAIZ,O,4FAJYvC,CAAA,KAAAmb,IACZ5Y,EAAAH,EAAAzC,KAAA,OACKgO,UAAYH,GAASgB,UAC1BjM,EAAK6Y,WAAa,KAClBrM,GAAAxM,EAAAyM,GAAAzM,GACF,CAAC,O,EAAA4Y,E,oFAAA,CANuB,G,0rDCAnB,IAAME,GAAY,SAAAvM,I,uRAAA3M,CAAAkZ,EAAS7N,IAAT,I,MAAApL,EAAAC,GAAAgZ,GACvB,SAAAA,IAAc,IAAA9Y,EAIZ,O,4FAJYvC,CAAA,KAAAqb,IACZ9Y,EAAAH,EAAAzC,KAAA,OACKgO,UAAYH,GAASoB,SAC1BrM,EAAK+Y,cAAgB,KACrBvM,GAAAxM,EAAAyM,GAAAzM,GACF,CAAC,O,EAAA8Y,E,oFAAA,CANsB,G,0rDCHlB,IAAME,GAAc,SAAAzM,I,uRAAA3M,CAAAoZ,EAAS/N,IAAT,I,MAAApL,EAAAC,GAAAkZ,GACzB,SAAAA,IAAc,IAAAhZ,EAKZ,O,4FALYvC,CAAA,KAAAub,IACZhZ,EAAAH,EAAAzC,KAAA,OACKgO,UAAYH,GAASU,WAC1B3L,EAAK0U,UAAY,KACjB1U,EAAKiZ,kBAAmB,EACxBzM,GAAAxM,EAAAyM,GAAAzM,GACF,CAAC,O,EAAAgZ,E,oFAAA,CAPwB,G,0rDCIpB,IAAME,GAAgB,SAAAR,I,uRAAA9Y,CAAAsZ,EAASX,IAAT,I,MAAA1Y,EAAAC,GAAAoZ,GAC3B,SAAAA,IAAc,IAAAlZ,EAGZ,O,4FAHYvC,CAAA,KAAAyb,IACZlZ,EAAAH,EAAAzC,KAAA,OACKgO,UAAYH,GAASc,YAC1BS,GAAAxM,EAAAyM,GAAAzM,GACF,CAAC,O,EAAAkZ,E,oFAAA,CAL0B,G,0rDCCtB,IAAMC,GAAiB,SAAAT,I,uRAAA9Y,CAAAuZ,EAASZ,IAAT,I,MAAA1Y,EAAAC,GAAAqZ,GAC5B,SAAAA,IAAc,IAAAnZ,EAGZ,O,4FAHYvC,CAAA,KAAA0b,IACZnZ,EAAAH,EAAAzC,KAAA,OACKgO,UAAYH,GAASmB,eAC1BI,GAAAxM,EAAAyM,GAAAzM,GACF,CAAC,O,EAAAmZ,E,oFAAA,CAL2B,G,0rDCLvB,IAAMC,GAAiB,SAAA7M,I,uRAAA3M,CAAAwZ,EAASnO,IAAT,I,MAAApL,EAAAC,GAAAsZ,GAC5B,SAAAA,IAAc,IAAApZ,EAGZ,O,4FAHYvC,CAAA,KAAA2b,IACZpZ,EAAAH,EAAAzC,KAAA,OACKgO,UAAYH,GAASiB,eAC1BM,GAAAxM,EAAAyM,GAAAzM,GACF,CAAC,O,EAAAoZ,E,oFAAA,CAL2B,G,0rDCCvB,IAAMC,GAAkB,SAAAX,I,uRAAA9Y,CAAAyZ,EAASd,IAAT,I,MAAA1Y,EAAAC,GAAAuZ,GAC7B,SAAAA,IAAc,IAAArZ,EAMZ,O,4FANYvC,CAAA,KAAA4b,IACZrZ,EAAAH,EAAAzC,KAAA,OACKgO,UAAYH,GAASkB,gBAC1BnM,EAAK+Y,cAAgB,KAErB/Y,EAAKsZ,qBAAuB,KAC5B9M,GAAAxM,EAAAyM,GAAAzM,GACF,CAAC,O,EAAAqZ,E,oFAAA,CAR4B,G,0rDCMxB,IAAME,GAAmB,SAAAC,I,uRAAA5Z,CAAA2Z,EAASd,IAAT,I,MAAA5Y,EAAAC,GAAAyZ,GAC9B,SAAAA,IAAc,IAAAvZ,EAIZ,O,4FAJYvC,CAAA,KAAA8b,IACZvZ,EAAAH,EAAAzC,KAAA,OACKgO,UAAYH,GAASY,iBAC1B7L,EAAK+Y,cAAgB,KACrBvM,GAAAxM,EAAAyM,GAAAzM,GACF,CAAC,O,EAAAuZ,E,oFAAA,CAN6B,G,0rDCHzB,IAAME,GAAmB,SAAAD,I,uRAAA5Z,CAAA6Z,EAAShB,IAAT,I,MAAA5Y,EAAAC,GAAA2Z,GAC9B,SAAAA,IAAc,IAAAzZ,EAGZ,O,4FAHYvC,CAAA,KAAAgc,IACZzZ,EAAAH,EAAAzC,KAAA,OACKgO,UAAYH,GAASa,iBAC1BU,GAAAxM,EAAAyM,GAAAzM,GACF,CAAC,O,EAAAyZ,E,oFAAA,CAL6B,G,0rDCHzB,IAAMC,GAAoB,SAAAF,I,uRAAA5Z,CAAA8Z,EAASjB,IAAT,I,MAAA5Y,EAAAC,GAAA4Z,GAC/B,SAAAA,IAAc,IAAA1Z,EAGZ,O,4FAHYvC,CAAA,KAAAic,IACZ1Z,EAAAH,EAAAzC,KAAA,OACKgO,UAAYH,GAASW,YAC1BY,GAAAxM,EAAAyM,GAAAzM,GACF,CAAC,O,EAAA0Z,E,oFAAA,CAL8B,G,grDCA1B,IAAM9W,GAAc,SAAAO,I,uRAAAvD,CAAAgD,EAAStB,IAAT,I,MAAAzB,EAAAC,GAAA8C,GACzB,SAAAA,EAAYpB,EAAQG,GAAO,IAAA3B,EAKgB,O,4FALhBvC,CAAA,KAAAmF,IACzB5C,EAAAH,EAAAzC,KAAA,KAAMoE,IAEDmY,OAAShY,EACd3B,EAAK2B,MAAQ3B,EAAK4Z,YAClB5Z,EAAK4M,kBAAoBtL,GAAWU,KAAKhC,CAC3C,CAcC,O,EAdA4C,G,EAAA,EAAAlG,IAAA,YAAAa,MAED,WACE,IAAM6J,EAAI,IAAIsB,GAEd,OADAtB,EAAE4F,OAAOtP,KAAKic,QACPvS,CACT,GAAC,CAAA1K,IAAA,UAAAa,MAED,SAAQsP,EAAQC,EAAgBC,GAC9B,OAAOrP,KAAKic,SAAW9M,CACzB,GAAC,CAAAnQ,IAAA,WAAAa,MAED,WACE,OAAOG,KAAKic,MACd,M,gFAAC/W,CAAA,CArBwB,G,grDCApB,IAAMH,GAAe,SAAAU,I,uRAAAvD,CAAA6C,EAASnB,IAAT,I,MAAAzB,EAAAC,GAAA2C,GAC1B,SAAAA,EAAYjB,EAAQ8B,EAAOC,GAAM,IAAAvD,EAKD,O,4FALCvC,CAAA,KAAAgF,IAC/BzC,EAAAH,EAAAzC,KAAA,KAAMoE,IACDoL,kBAAoBtL,GAAWO,MACpC7B,EAAKsD,MAAQA,EACbtD,EAAKuD,KAAOA,EACZvD,EAAK2B,MAAQ3B,EAAK4Z,YAAY5Z,CAChC,CAcC,O,EAdAyC,G,EAAA,EAAA/F,IAAA,YAAAa,MAED,WACE,IAAM6J,EAAI,IAAIsB,GAEd,OADAtB,EAAEkO,SAAS5X,KAAK4F,MAAO5F,KAAK6F,MACrB6D,CACT,GAAC,CAAA1K,IAAA,UAAAa,MAED,SAAQsP,EAAQC,EAAgBC,GAC9B,OAAOF,GAAUnP,KAAK4F,OAASuJ,GAAUnP,KAAK6F,IAChD,GAAC,CAAA7G,IAAA,WAAAa,MAED,WACE,MAAO,IAAMqN,OAAOC,aAAanN,KAAK4F,OAAS,OAASsH,OAAOC,aAAanN,KAAK6F,MAAQ,GAC3F,M,gFAACd,CAAA,CArByB,G,grDCDrB,IAAMI,GAAgB,SAAAM,I,uRAAAvD,CAAAiD,EAASvB,IAAT,I,MAAAzB,EAAAC,GAAA+C,GAC3B,SAAAA,EAAYrB,EAAQpB,EAAWC,EAAawZ,GAAgB,IAAA7Z,EAMpC,O,4FANoCvC,CAAA,KAAAoF,IAC1D7C,EAAAH,EAAAzC,KAAA,KAAMoE,IACDoL,kBAAoBtL,GAAWW,OACpCjC,EAAKI,UAAYA,EACjBJ,EAAKK,iBAA8BoB,IAAhBpB,GAA6B,EAAIA,EACpDL,EAAK6Z,oBAAoCpY,IAAnBoY,GAAuCA,EAC7D7Z,EAAK0B,WAAY,EAAK1B,CACxB,CAQC,O,EARA6C,G,EAAA,EAAAnG,IAAA,UAAAa,MAED,SAAQsP,EAAQC,EAAgBC,GAC9B,OAAO,CACT,GAAC,CAAArQ,IAAA,WAAAa,MAED,WACE,MAAO,UAAYG,KAAK0C,UAAY,IAAM1C,KAAK2C,WACjD,M,gFAACwC,CAAA,CAhB0B,G,grDCAtB,IAAML,GAAiB,SAAAW,I,uRAAAvD,CAAA4C,EAASlB,IAAT,I,MAAAzB,EAAAC,GAAA0C,GAC5B,SAAAA,EAAYhB,EAAQsY,GAA2B,IAAA9Z,EAIc,O,4FAJdvC,CAAA,KAAA+E,IAC7CxC,EAAAH,EAAAzC,KAAA,KAAMoE,IACDoL,kBAAoBtL,GAAWM,QACpC5B,EAAK0B,WAAY,EACjB1B,EAAK8Z,0BAA4BA,EAA0B9Z,CAC7D,CAQC,O,EARAwC,G,EAAA,EAAA9F,IAAA,UAAAa,MAED,SAAQsP,EAAQC,EAAgBC,GAC9B,OAAO,CACT,GAAC,CAAArQ,IAAA,WAAAa,MAED,WACE,MAAO,SACT,M,gFAACiF,CAAA,CAd2B,G,grDCAvB,IAAMuX,GAAS,SAAA1T,I,uRAAAzG,CAAAma,EAASlU,IAAT,I,MAAAhG,EAAAC,GAAAia,GACpB,SAAAA,EAAY3Z,EAAW4Z,EAAWH,GAAgB,IAAA7Z,EAI6B,O,4FAJ7BvC,CAAA,KAAAsc,IAChD/Z,EAAAH,EAAAzC,KAAA,OACKgD,eAA0BqB,IAAdrB,GAA2B,EAAIA,EAChDJ,EAAKga,eAA0BvY,IAAduY,GAA2B,EAAIA,EAChDha,EAAK6Z,oBAAoCpY,IAAnBoY,GAAuCA,EAAgB7Z,CAC/E,CA2BC,O,EA3BA+Z,G,EAAA,EAAArd,IAAA,WAAAa,MAED,SAASuI,EAAQC,GACf,IAAMkU,EAAWvc,KAAKmc,eAAiB9T,EAAe,KACtD,OAAOD,EAAOoU,QAAQD,EAAUvc,KAAK0C,UAAW1C,KAAKsc,UACvD,GAAC,CAAAtd,IAAA,iBAAAa,MAED,SAAeK,GACbA,EAAKM,OAAOR,KAAK0C,UAAW1C,KAAKsc,UAAWtc,KAAKmc,eACnD,GAAC,CAAAnd,IAAA,SAAAa,MAED,SAAOyB,GACL,OAAItB,OAASsB,GAEAA,aAAiB+a,GAI1Brc,KAAK0C,YAAcpB,EAAMoB,WACzB1C,KAAKsc,YAAchb,EAAMgb,WACzBtc,KAAKmc,iBAAmB7a,EAAM6a,cAGpC,GAAC,CAAAnd,IAAA,WAAAa,MAED,WACE,MAAO,IAAMG,KAAK0C,UAAY,IAAM1C,KAAKsc,UAAY,IACvD,M,gFAACD,CAAA,CAjCmB,G,grDAwCtBlU,GAAgBG,KAAO,IAAI+T,GCtCpB,IAAMpX,GAAmB,SAAAwX,I,uRAAAva,CAAA+C,EAASO,IAAT,I,MAAArD,EAAAC,GAAA6C,GAC9B,SAAAA,EAAYnB,EAAQpB,EAAW4Z,EAAWH,GAAgB,IAAA7Z,EAMlC,O,4FANkCvC,CAAA,KAAAkF,IACxD3C,EAAAH,EAAAzC,KAAA,KAAMoE,IACDoL,kBAAoBtL,GAAWS,UACpC/B,EAAKI,UAAYA,EACjBJ,EAAKga,UAAYA,EACjBha,EAAK6Z,eAAiBA,EACtB7Z,EAAK0B,WAAY,EAAK1B,CACxB,CAYC,O,EAZA2C,G,EAAA,EAAAjG,IAAA,UAAAa,MAED,SAAQsP,EAAQC,EAAgBC,GAC9B,OAAO,CACT,GAAC,CAAArQ,IAAA,eAAAa,MAED,WACE,OAAO,IAAIwc,GAAUrc,KAAK0C,UAAW1C,KAAKsc,UAAWtc,KAAKmc,eAC5D,GAAC,CAAAnd,IAAA,WAAAa,MAED,WACE,MAAO,QAAUG,KAAK0C,UAAY,IAAM1C,KAAKsc,SAC/C,M,gFAACrX,CAAA,CApB6B,G,grDCFzB,IAAM+E,GAAmB,SAAArB,I,uRAAAzG,CAAA8H,EAAS7B,IAAT,I,MAAAhG,EAAAC,GAAA4H,GAC9B,SAAAA,EAAYd,GAAY,IAAA5G,EAEsC,O,4FAFtCvC,CAAA,KAAAiK,IACtB1H,EAAAH,EAAAzC,KAAA,OACKwJ,gBAA4BnF,IAAfmF,EAA2B,EAAIA,EAAW5G,CAC9D,CAkCC,O,EAlCA0H,G,EAAA,EAAAhL,IAAA,WAAAa,MAED,SAASuI,EAAQC,GACf,OAAOD,EAAOsU,SAASrU,EAAcrI,KAAKkJ,WAC5C,GAAC,CAAAlK,IAAA,iBAAAa,MAED,SAAeuI,EAAQC,GACrB,OAAID,EAAOsU,SAASrU,EAAcrI,KAAKkJ,YAC9Bf,GAAgBG,KAEhB,IAEX,GAAC,CAAAtJ,IAAA,YAAAa,MAED,SAAUyB,GACR,OAAOtB,KAAKkJ,WAAa5H,EAAM4H,UACjC,GAAC,CAAAlK,IAAA,iBAAAa,MAED,SAAeK,GACbA,EAAKM,OAAOR,KAAKkJ,WACnB,GAAC,CAAAlK,IAAA,SAAAa,MAED,SAAOyB,GACL,OAAItB,OAASsB,GAEAA,aAAiB0I,GAGrBhK,KAAKkJ,aAAe5H,EAAM4H,UAErC,GAAC,CAAAlK,IAAA,WAAAa,MAED,WACE,MAAO,IAAMG,KAAKkJ,WAAa,UACjC,M,gFAACc,CAAA,CAtC6B,G,grDA0ChC7B,GAAgB6B,oBAAsBA,GCxC/B,IAAMzE,GAA6B,SAAAkX,I,uRAAAva,CAAAqD,EAASC,IAAT,I,MAAArD,EAAAC,GAAAmD,GACxC,SAAAA,EAAYzB,EAAQoF,GAAY,IAAA5G,EAIR,O,4FAJQvC,CAAA,KAAAwF,IAC9BjD,EAAAH,EAAAzC,KAAA,KAAMoE,IACDoL,kBAAoBtL,GAAWe,WACpCrC,EAAK4G,WAAaA,EAClB5G,EAAK0B,WAAY,EAAK1B,CACxB,CAYC,O,EAZAiD,G,EAAA,EAAAvG,IAAA,UAAAa,MAED,SAAQsP,EAAQC,EAAgBC,GAC9B,OAAO,CACT,GAAC,CAAArQ,IAAA,eAAAa,MAED,WACE,OAAO,IAAImK,GAAoBhK,KAAKkJ,WACtC,GAAC,CAAAlK,IAAA,WAAAa,MAED,WACE,OAAOG,KAAKkJ,WAAa,QAC3B,M,gFAAC3D,CAAA,CAlBuC,G,otBC4C1C,SAASoX,GAAUtc,EAAQR,GACzB,IAAM+c,EAAM,GAEZ,OADAA,EAAIvc,EAAS,GAAKR,EACX+c,EAAI/V,KAAI,SAAU1G,GACvB,OAAON,CACT,GACF,CAEO,IAAMgd,GAAe,WAC1B,SAAAA,EAAYC,I,4FAAS/c,CAAA,KAAA8c,QACH9Y,IAAZ+Y,GAAqC,OAAZA,IAC3BA,EAAU1C,GAA0BI,gBAEtCxa,KAAK+c,uBAAyBD,EAC9B9c,KAAKgd,eAAiB,KACtBhd,KAAKid,gBAAkB,IACzB,C,UAmhBC,O,EAnhBAJ,E,EAAA,EAAA7d,IAAA,cAAAa,MAED,SAAY2H,GACV,IAAM0V,EAASld,KAAKmd,MAAM3V,GAC1BxH,KAAKod,aAAaF,GACdA,GAAQld,KAAKqd,WACjB,IAAM7P,EAAMxN,KAAKsd,UACjBtd,KAAKud,WAAW/P,EAAK0P,GACrBld,KAAKwd,UAAUhQ,EAAK0P,GACpBld,KAAKyd,UAAUjQ,GACf,IAAMkQ,EAAO,GAab,OAZA1d,KAAK2d,SAASnQ,EAAKkQ,EAAM1d,KAAK4d,QAAQC,KAAK7d,OACvCkd,GAAQld,KAAK2d,SAASnQ,EAAKkQ,EAAM1d,KAAK8d,UAAUD,KAAK7d,OACzDA,KAAK+d,UAAUvQ,EAAKkQ,GACpB1d,KAAKge,cAAcxQ,GACnBxN,KAAKie,iBAAiBzQ,EAAK0P,GAC3Bld,KAAKke,wBAAwB1Q,GAC7BxN,KAAKsa,UAAU9M,GACXxN,KAAK+c,uBAAuBxC,+BAAiC/M,EAAIyK,cAAgBwC,GAAQE,SAC3F3a,KAAKua,8BAA8B/M,GAEnCxN,KAAKsa,UAAU9M,IAEVA,CACT,GAAC,CAAAxO,IAAA,QAAAa,MAED,SAAM2H,GAEJ,GAAgB2W,KADA3W,EAAK4W,WAAa5W,EAAK4W,WAAW,GAAK5W,EAAK,IACpB,CACtC,IAIM6W,EAAO7W,EAAK8W,MAAM,IAAIzX,KAJb,SAAUgK,GACvB,IAAMlK,EAAIkK,EAAEuN,WAAW,GACvB,OAAOzX,EAAI,EAAIA,EAAI,EAAIA,EAAI,KAC7B,IAMA,OAHA0X,EAAK,GAAK7W,EAAK4W,WAAW,GAC1Bpe,KAAKwH,KAAO6W,EACZre,KAAK2L,IAAM,GACJ,CACT,CAGE,OAFA3L,KAAKwH,KAAOA,EACZxH,KAAK2L,IAAM,GACJ,CAEX,GAAC,CAAA3M,IAAA,WAAAa,MAED,WAEE,IADA,IAAII,EAAQ,EACLA,IAAU,GAAGD,KAAK4d,SAC3B,GAAC,CAAA5e,IAAA,eAAAa,MAED,SAAaqd,GACX,IAAMqB,EAAUve,KAAK4d,UACrB,IAAKV,GAvEkB,IAuERqB,EACb,KAAM,0CAA4CA,EAA5C,gBAEV,GAAC,CAAAvf,IAAA,UAAAa,MAED,WACE,IAAMoY,EAAcjY,KAAK4d,UACnB/F,EAAe7X,KAAK4d,UAC1B,OAAO,IAAI5F,GAAIC,EAAaJ,EAC9B,GAAC,CAAA7Y,IAAA,aAAAa,MAED,SAAW2N,EAAK0P,GAKd,IAJA,IAAI9P,EAAGoR,EAAM3T,EACP4T,EAAuB,GACvBC,EAAkB,GAClBC,EAAU3e,KAAK4d,UACZzd,EAAI,EAAGA,EAAIwe,EAASxe,IAAK,CAChC,IAAMye,EAAQ5e,KAAK4d,UAEnB,GAAIgB,IAAUrR,GAASxG,aAAvB,CAIA,IAAIrE,EAAY1C,KAAK4d,UACjBV,GAAwB,QAAdxa,IACZA,GAAa,GAEf,IAAMgH,EAAI1J,KAAK6e,aAAaD,EAAOlc,GACnC,GAAIkc,IAAUrR,GAASoB,SAAU,CAE/B,IAAMmQ,EAAsB9e,KAAK4d,UACjCa,EAAqBzW,KAAK,CAAC0B,EAAGoV,GAChC,MAAO,GAAIpV,aAAaqR,GAAiB,CACvC,IAAMgE,EAAiB/e,KAAK4d,UAC5Bc,EAAgB1W,KAAK,CAAC0B,EAAGqV,GAC3B,CACAvR,EAAIwR,SAAStV,EAdb,MAFE8D,EAAIwR,SAAS,KAiBjB,CAGA,IAAK5R,EAAI,EAAGA,EAAIqR,EAAqBpe,OAAQ+M,KAC3CoR,EAAOC,EAAqBrR,IACvB,GAAGiO,cAAgB7N,EAAIkH,OAAO8J,EAAK,IAG1C,IAAKpR,EAAI,EAAGA,EAAIsR,EAAgBre,OAAQ+M,KACtCoR,EAAOE,EAAgBtR,IAClB,GAAG6N,SAAWzN,EAAIkH,OAAO8J,EAAK,IAGrC,IAAIS,EAAqBjf,KAAK4d,UAC9B,IAAKxQ,EAAI,EAAGA,EAAI6R,EAAoB7R,IAClCvC,EAAc7K,KAAK4d,UACnBpQ,EAAIkH,OAAO7J,GAAaiQ,WAAY,EAGtC,IAAIoE,EAAsBlf,KAAK4d,UAC/B,IAAKxQ,EAAI,EAAGA,EAAI8R,EAAqB9R,IACnCvC,EAAc7K,KAAK4d,UACnBpQ,EAAIkH,OAAO7J,GAAa0Q,kBAAmB,CAE/C,GAAC,CAAAvc,IAAA,YAAAa,MAED,SAAU2N,EAAK0P,GACb,IAAI/c,EACEgf,EAASnf,KAAK4d,UAKpB,IAJIpQ,EAAIyK,cAAgBwC,GAAQC,QAC9BlN,EAAI8K,gBAAkBqE,GAAUwC,EAAQ,IAE1C3R,EAAI2K,iBAAmBwE,GAAUwC,EAAQ,GACpChf,EAAI,EAAGA,EAAIgf,EAAQhf,IAAK,CAC3B,IAAMuJ,EAAI1J,KAAK4d,UAEf,GADApQ,EAAI2K,iBAAiBhY,GAAKqN,EAAIkH,OAAOhL,GACjC8D,EAAIyK,cAAgBwC,GAAQC,MAAO,CACrC,IAAI0E,EAAYpf,KAAK4d,UACjBV,GAAwB,QAAdkC,IACZA,EAAY1Z,GAAMuB,KAEpBuG,EAAI8K,gBAAgBnY,GAAKif,CAC3B,CACF,CAEA,IADA5R,EAAI4K,gBAAkBuE,GAAUwC,EAAQ,GACnChf,EAAI,EAAGA,EAAIqN,EAAIkH,OAAOrU,OAAQF,IAAK,CACtC,IAAMiK,EAAQoD,EAAIkH,OAAOvU,GACnBiK,aAAiBwE,KAGvBpB,EAAI4K,gBAAgBhO,EAAM1H,WAAa0H,EACvCoD,EAAI2K,iBAAiB/N,EAAM1H,WAAWsU,UAAY5M,EACpD,CACF,GAAC,CAAApL,IAAA,YAAAa,MAED,SAAU2N,GAER,IADA,IAAM6R,EAASrf,KAAK4d,UACXzd,EAAI,EAAGA,EAAIkf,EAAQlf,IAAK,CAC/B,IAAIuJ,EAAI1J,KAAK4d,UACbpQ,EAAIgL,iBAAiBxQ,KAAKwF,EAAIkH,OAAOhL,GACvC,CACF,GAAC,CAAA1K,IAAA,WAAAa,MAED,SAAS2N,EAAKkQ,EAAM4B,GAElB,IADA,IAAMC,EAAIvf,KAAK4d,UACNzd,EAAI,EAAGA,EAAIof,EAAGpf,IAAK,CAC1B,IAAMqf,EAAO,IAAIxU,GACjB0S,EAAK1V,KAAKwX,GACV,IAAMhT,EAAIxM,KAAK4d,UAEK,IADA5d,KAAK4d,WAEvB4B,EAAKlQ,QAAQ,GAEf,IAAK,IAAIlC,EAAI,EAAGA,EAAIZ,EAAGY,IAAK,CAC1B,IAAMqS,EAAKH,IACLI,EAAKJ,IACXE,EAAK5H,SAAS6H,EAAIC,EACpB,CACF,CACF,GAAC,CAAA1gB,IAAA,YAAAa,MAED,SAAU2N,EAAKkQ,GACb,IAAIvd,EAAGiN,EAAGhD,EAAO0D,EAAOhK,EAClB6b,EAAS3f,KAAK4d,UACpB,IAAKzd,EAAI,EAAGA,EAAIwf,EAAQxf,IAAK,CAC3B,IAAMyf,EAAM5f,KAAK4d,UACXiC,EAAM7f,KAAK4d,UACX9L,EAAQ9R,KAAK4d,UACbkC,EAAO9f,KAAK4d,UACZmC,EAAO/f,KAAK4d,UACZoC,EAAOhgB,KAAK4d,UAClB9P,EAAQ9N,KAAKigB,YAAYzS,EAAKsE,EAAO8N,EAAKC,EAAKC,EAAMC,EAAMC,EAAMtC,GAChDlQ,EAAIkH,OAAOkL,GACnBM,cAAcpS,EACzB,CAEA,IAAK3N,EAAI,EAAGA,EAAIqN,EAAIkH,OAAOrU,OAAQF,IAEjC,IADAiK,EAAQoD,EAAIkH,OAAOvU,GACdiN,EAAI,EAAGA,EAAIhD,EAAMwD,YAAYvN,OAAQ+M,IAAK,CAC7C,IAAM8D,EAAI9G,EAAMwD,YAAYR,GAC5B,GAAM8D,aAAalM,GAAnB,CAGA,IAAIoX,GAA6B,EAC7B5O,EAAI2K,iBAAiBjH,EAAEpN,OAAOpB,WAAW6Y,kBACtB,IAAjBrK,EAAEhI,aACJkT,EAA4BlL,EAAEpN,OAAOpB,WAIzCoL,EAAQ,IAAIhJ,GAAkBoM,EAAEjC,YAAamN,GAC7C5O,EAAI4K,gBAAgBlH,EAAEpN,OAAOpB,WAAWwd,cAAcpS,EATtD,CAUF,CAGF,IAAK3N,EAAI,EAAGA,EAAIqN,EAAIkH,OAAOrU,OAAQF,IAAK,CAEtC,IADAiK,EAAQoD,EAAIkH,OAAOvU,cACE4a,GAAiB,CAEpC,GAAuB,OAAnB3Q,EAAM6Q,SACR,KAAM,eAIR,GAAkC,OAA9B7Q,EAAM6Q,SAASE,WACjB,KAAM,eAER/Q,EAAM6Q,SAASE,WAAa/Q,CAC9B,CACA,GAAIA,aAAiBqR,GACnB,IAAKrO,EAAI,EAAGA,EAAIhD,EAAMwD,YAAYvN,OAAQ+M,KACxCtJ,EAASsG,EAAMwD,YAAYR,GAAGtJ,kBACR+X,KACpB/X,EAAOuX,cAAgBjR,QAGtB,GAAIA,aAAiBsR,GAC1B,IAAKtO,EAAI,EAAGA,EAAIhD,EAAMwD,YAAYvN,OAAQ+M,KACxCtJ,EAASsG,EAAMwD,YAAYR,GAAGtJ,kBACR6X,KACpB7X,EAAOuX,cAAgBjR,EAI/B,CACF,GAAC,CAAApL,IAAA,gBAAAa,MAED,SAAc2N,GAEZ,IADA,IAAM2S,EAAangB,KAAK4d,UACfzd,EAAI,EAAGA,EAAIggB,EAAYhgB,IAAK,CACnC,IAAMuJ,EAAI1J,KAAK4d,UACTwC,EAAW5S,EAAIkH,OAAOhL,GAC5B8D,EAAI0K,gBAAgBlQ,KAAKoY,GACzBA,EAASxH,SAAWzY,CACtB,CACF,GAAC,CAAAnB,IAAA,mBAAAa,MAED,SAAiB2N,EAAK0P,GACpB,GAAI1P,EAAIyK,cAAgBwC,GAAQC,MAAO,CACrC,IAAMza,EAAQD,KAAK4d,UACnBpQ,EAAI+K,aAAeoE,GAAU1c,EAAO,MACpC,IAAK,IAAIE,EAAI,EAAGA,EAAIF,EAAOE,IAAK,CAC9B,IAAMiB,EAAapB,KAAK4d,UACpByC,EAAQrgB,KAAK4d,UACbV,GAAoB,QAAVmD,IACZA,GAAS,GAEX,IAAIC,EAAQtgB,KAAK4d,UACbV,GAAoB,QAAVoD,IACZA,GAAS,GAEX9S,EAAI+K,aAAapY,GAAKH,KAAKugB,mBAAmBnf,EAAYif,EAAOC,EACnE,CACF,CACF,GAAC,CAAAthB,IAAA,gCAAAa,MAED,SAA8B2N,GAC5B,IAAIrN,EACEF,EAAQuN,EAAI2K,iBAAiB9X,OACnC,IAAKF,EAAI,EAAGA,EAAIF,EAAOE,IACrBqN,EAAI8K,gBAAgBnY,GAAKqN,EAAIqK,aAAe1X,EAAI,EAElD,IAAKA,EAAI,EAAGA,EAAIF,EAAOE,IACrBH,KAAKwgB,6BAA6BhT,EAAKrN,EAE3C,GAAC,CAAAnB,IAAA,+BAAAa,MAED,SAA6B2N,EAAKiT,GAChC,IAAItgB,EAAGiK,EACDsW,EAAc,IAAI1E,GACxB0E,EAAYhe,UAAY+d,EACxBjT,EAAIwR,SAAS0B,GAEb,IAAMC,EAAa,IAAIzF,GACvByF,EAAWje,UAAY+d,EACvBjT,EAAIwR,SAAS2B,GAEbD,EAAYzF,SAAW0F,EACvBnT,EAAIoT,oBAAoBF,GAExBC,EAAWxF,WAAauF,EAExB,IAAIG,EAAoB,KACpB5F,EAAW,KAEf,GAAIzN,EAAI2K,iBAAiBsI,GAAKlF,iBAAkB,CAG9C,IADAN,EAAW,KACN9a,EAAI,EAAGA,EAAIqN,EAAIkH,OAAOrU,OAAQF,IAEjC,GADAiK,EAAQoD,EAAIkH,OAAOvU,GACfH,KAAK8gB,mBAAmB1W,EAAOqW,GAAM,CACvCxF,EAAW7Q,EACXyW,EAAoBzW,EAAMiR,cAAczN,YAAY,GACpD,KACF,CAEF,GAA0B,OAAtBiT,EACF,KAAM,sEAEV,MACE5F,EAAWzN,EAAI4K,gBAAgBqI,GAKjC,IAAKtgB,EAAI,EAAGA,EAAIqN,EAAIkH,OAAOrU,OAAQF,IAAK,CACtCiK,EAAQoD,EAAIkH,OAAOvU,GACnB,IAAK,IAAIiN,EAAI,EAAGA,EAAIhD,EAAMwD,YAAYvN,OAAQ+M,IAAK,CACjD,IAAMqH,EAAarK,EAAMwD,YAAYR,GACjCqH,IAAeoM,GAGfpM,EAAW3Q,SAAWmX,IACxBxG,EAAW3Q,OAAS6c,EAExB,CACF,CAMA,IAFA,IAAMxI,EAAmB3K,EAAI2K,iBAAiBsI,GACxCxgB,EAAQkY,EAAiBvK,YAAYvN,OACpCJ,EAAQ,GACbygB,EAAYR,cAAc/H,EAAiBvK,YAAY3N,EAAQ,IAC/DkY,EAAiBvK,YAAcuK,EAAiBvK,YAAYjE,OAAO,GAGrE6D,EAAI2K,iBAAiBsI,GAAKP,cAAc,IAAIpb,GAAkB4b,IAC9DC,EAAWT,cAAc,IAAIpb,GAAkBmW,IAE/C,IAAM8F,EAAa,IAAInG,GACvBpN,EAAIwR,SAAS+B,GACbA,EAAWb,cAAc,IAAIhb,GAAeyb,EAAYnT,EAAI8K,gBAAgBmI,KAC5EC,EAAYR,cAAc,IAAIpb,GAAkBic,GAClD,GAAC,CAAA/hB,IAAA,qBAAAa,MAED,SAAmBuK,EAAOqW,GACxB,GAAIrW,EAAM1H,YAAc+d,EACtB,OAAO,KAET,KAAMrW,aAAiBuR,IACrB,OAAO,KAET,IAAMqF,EAAoB5W,EAAMwD,YAAYxD,EAAMwD,YAAYvN,OAAS,GAAGyD,OAC1E,OAAMkd,aAA6B5F,IAG/B4F,EAAkBrT,wBAA0BqT,EAAkBpT,YAAY,GAAG9J,kBAAkB8K,GAC1FxE,EAHA,IAOX,GAEA,CAAApL,IAAA,0BAAAa,MAMA,SAAwB2N,GACtB,IAAK,IAAIrN,EAAI,EAAGA,EAAIqN,EAAIkH,OAAOrU,OAAQF,IAAK,CAC1C,IAAMiK,EAAQoD,EAAIkH,OAAOvU,GACzB,GAAMiK,aAAiBuR,IAMnBnO,EAAI2K,iBAAiB/N,EAAM1H,WAAW6Y,iBAAkB,CAC1D,IAAMyF,EAAoB5W,EAAMwD,YAAYxD,EAAMwD,YAAYvN,OAAS,GAAGyD,OACtEkd,aAA6B5F,IAE7B4F,EAAkBrT,wBAClBqT,EAAkBpT,YAAY,GAAG9J,kBAAkB8K,KAEnDxE,EAAMwR,sBAAuB,EAGnC,CACF,CACF,GAAC,CAAA5c,IAAA,YAAAa,MAED,SAAU2N,GACR,GAAKxN,KAAK+c,uBAAuBzC,UAIjC,IAAK,IAAIna,EAAI,EAAGA,EAAIqN,EAAIkH,OAAOrU,OAAQF,IAAK,CAC1C,IAAMiK,EAAQoD,EAAIkH,OAAOvU,GACzB,GAAc,OAAViK,EAIJ,GADApK,KAAKihB,eAAe7W,EAAMuD,wBAA0BvD,EAAMwD,YAAYvN,QAAU,GAC5E+J,aAAiByR,GACnB7b,KAAKihB,eAAuC,OAAxB7W,EAAMiR,oBACrB,GAAIjR,aAAiBuR,GAG1B,GAFA3b,KAAKihB,eAAuC,OAAxB7W,EAAMiR,eAC1Brb,KAAKihB,eAA4C,IAA7B7W,EAAMwD,YAAYvN,QAClC+J,EAAMwD,YAAY,GAAG9J,kBAAkBiY,GACzC/b,KAAKihB,eAAe7W,EAAMwD,YAAY,GAAG9J,kBAAkBsX,IAC3Dpb,KAAKihB,gBAAgB7W,EAAM0Q,eACtB,MAAI1Q,EAAMwD,YAAY,GAAG9J,kBAAkBsX,IAIhD,KAAM,eAHNpb,KAAKihB,eAAe7W,EAAMwD,YAAY,GAAG9J,kBAAkBiY,IAC3D/b,KAAKihB,eAAe7W,EAAM0Q,UAG5B,MACS1Q,aAAiBsR,IAC1B1b,KAAKihB,eAA4C,IAA7B7W,EAAMwD,YAAYvN,QACtCL,KAAKihB,eAAe7W,EAAMwD,YAAY,GAAG9J,kBAAkB6X,KAClDvR,aAAiBgR,GAC1Bpb,KAAKihB,eAAuC,OAAxB7W,EAAMiR,eACjBjR,aAAiBkR,GAC1Btb,KAAKihB,eAAmC,OAApB7W,EAAM4M,WACjB5M,aAAiB2Q,GAC1B/a,KAAKihB,eAAkC,OAAnB7W,EAAM6Q,UACjB7Q,aAAiB8Q,GAC1Blb,KAAKihB,eAAoC,OAArB7W,EAAM+Q,YACjB/Q,aAAiByQ,GAC1B7a,KAAKihB,eAAe7W,EAAMwD,YAAYvN,QAAU,GAAK+J,EAAMwO,UAAY,GAEvE5Y,KAAKihB,eAAe7W,EAAMwD,YAAYvN,QAAU,GAAK+J,aAAiBwE,GAE1E,CACF,GAAC,CAAA5P,IAAA,iBAAAa,MAED,SAAeqhB,EAAWC,GACxB,IAAKD,EAIH,WAHgBnd,IAAZod,GAAqC,OAAZA,IAC3BA,EAAU,gBAENA,CAEV,GAAC,CAAAniB,IAAA,UAAAa,MAED,WACE,OAAOG,KAAKwH,KAAKxH,KAAK2L,MACxB,GAAC,CAAA3M,IAAA,YAAAa,MAED,WAGE,OAFYG,KAAK4d,UACJ5d,KAAK4d,WACI,EACxB,GAAC,CAAA5e,IAAA,cAAAa,MAED,SAAY2N,EAAK7J,EAAMic,EAAKC,EAAKC,EAAMC,EAAMC,EAAMtC,GACjD,IAAM5Z,EAAS0J,EAAIkH,OAAOmL,GAC1B,OAAQlc,GACN,KAAKC,GAAWM,QACd,OAAO,IAAIY,GAAkBhB,GAC/B,KAAKF,GAAWO,MACd,OAAoB,IAAIY,GAAgBjB,EAAxB,IAATkc,EAAyCta,GAAMuB,IAAyC6Y,EAApCC,GAC7D,KAAKnc,GAAWQ,KACd,OAAO,IAAIY,GAAewI,EAAIkH,OAAOoL,GAAOC,EAAMC,EAAMlc,GAC1D,KAAKF,GAAWS,UACd,OAAO,IAAIY,GAAoBnB,EAAQgc,EAAMC,EAAe,IAATC,GACrD,KAAKpc,GAAWe,WACd,OAAO,IAAIY,GAA8BzB,EAAQgc,GACnD,KAAKlc,GAAWU,KACd,OAAoB,IAAIY,GAAepB,EAAvB,IAATkc,EAAwCta,GAAMuB,IAAkC6Y,GACzF,KAAKlc,GAAWW,OACd,OAAO,IAAIY,GAAiBrB,EAAQgc,EAAMC,EAAe,IAATC,GAClD,KAAKpc,GAAWY,IACd,OAAO,IAAIY,GAActB,EAAQ4Z,EAAKoC,IACxC,KAAKlc,GAAWa,QACd,OAAO,IAAIY,GAAiBvB,EAAQ4Z,EAAKoC,IAC3C,KAAKlc,GAAWc,SACd,OAAO,IAAIY,GAAmBxB,GAChC,QACE,KAAM,kCAAoCH,EAAO,iBAEvD,GAAC,CAAA3E,IAAA,eAAAa,MAED,SAAa8D,EAAMjB,GACjB,GAA4B,OAAxB1C,KAAKgd,eAAyB,CAChC,IAAMoE,EAAK,GACXA,EAAG7T,GAASxG,cAAgB,KAC5Bqa,EAAG7T,GAASS,OAAS,kBAAM,IAAI4M,EAAY,EAC3CwG,EAAG7T,GAASU,YAAc,kBAAM,IAAIqN,EAAgB,EACpD8F,EAAG7T,GAASW,aAAe,kBAAM,IAAI8N,EAAsB,EAC3DoF,EAAG7T,GAASY,kBAAoB,kBAAM,IAAI0N,EAAqB,EAC/DuF,EAAG7T,GAASa,kBAAoB,kBAAM,IAAI2N,EAAqB,EAC/DqF,EAAG7T,GAASc,aAAe,kBAAM,IAAImN,EAAkB,EACvD4F,EAAG7T,GAASe,WAAa,kBAAM,IAAIM,EAAe,EAClDwS,EAAG7T,GAASgB,WAAa,kBAAM,IAAI2M,EAAe,EAClDkG,EAAG7T,GAASiB,gBAAkB,kBAAM,IAAIkN,EAAmB,EAC3D0F,EAAG7T,GAASkB,iBAAmB,kBAAM,IAAIkN,EAAoB,EAC7DyF,EAAG7T,GAASmB,gBAAkB,kBAAM,IAAI+M,EAAmB,EAC3D2F,EAAG7T,GAASoB,UAAY,kBAAM,IAAIyM,EAAc,EAChDpb,KAAKgd,eAAiBoE,CACxB,CACA,GAAIzd,EAAO3D,KAAKgd,eAAe3c,QAAwC,OAA9BL,KAAKgd,eAAerZ,GAC3D,KAAM,4BAA8BA,EAAO,iBAE3C,IAAM+F,EAAI1J,KAAKgd,eAAerZ,KAC9B,GAAU,OAAN+F,EAEF,OADAA,EAAEhH,UAAYA,EACPgH,CAGb,GAAC,CAAA1K,IAAA,qBAAAa,MAED,SAAmB8D,EAAM0c,EAAOC,GAC9B,GAA6B,OAAzBtgB,KAAKid,gBAA0B,CACjC,IAAMoE,EAAK,GACXA,EAAG9f,EAAgBC,SAAW,SAAC6e,EAAOC,GAAK,OAAK,IAAIte,EAAmBqe,EAAM,EAC7EgB,EAAG9f,EAAgBE,QAAU,SAAC4e,EAAOC,GAAK,OAAK,IAAI7d,EAAkB4d,EAAOC,EAAM,EAClFe,EAAG9f,EAAgBG,MAAQ,SAAC2e,EAAOC,GAAK,OAAK,IAAIvd,EAAgBsd,EAAM,EACvEgB,EAAG9f,EAAgBI,MAAQ,SAAC0e,EAAOC,GAAK,OAAKrd,EAAgBE,QAAQ,EACrEke,EAAG9f,EAAgBK,UAAY,SAACye,EAAOC,GAAK,OAAKld,EAAmBD,QAAQ,EAC5Eke,EAAG9f,EAAgBM,WAAa,SAACwe,EAAOC,GAAK,OAAK,IAAIhd,EAAoB+c,EAAM,EAChFgB,EAAG9f,EAAgBO,MAAQ,SAACue,EAAOC,GAAK,OAAK9c,GAAgBL,QAAQ,EACrEke,EAAG9f,EAAgBQ,MAAQ,SAACse,EAAOC,GAAK,OAAK,IAAI5c,GAAgB2c,EAAM,EACvErgB,KAAKid,gBAAkBoE,CACzB,CACA,GAAI1d,EAAO3D,KAAKid,gBAAgB5c,QAAyC,OAA/BL,KAAKid,gBAAgBtZ,GAC7D,KAAM,mCAAqCA,EAAO,iBAElD,OAAO3D,KAAKid,gBAAgBtZ,GAAM0c,EAAOC,EAE7C,I,mFAACzD,CAAA,CA3hByB,G,otBC1BrB,IAAMyE,GAAQ,WACnB,SAAAA,EAAYzW,EAAa4O,GA8CvB,O,4FA9CgC1Z,CAAA,KAAAuhB,GACZ,OAAhBzW,IACFA,GAAe,GAED,OAAZ4O,IACFA,EAAU,IAAIH,IAEhBtZ,KAAK6K,YAAcA,EACnB7K,KAAKyZ,QAAUA,EAKfzZ,KAAKuhB,MAAQ,KACbvhB,KAAKwhB,eAAgB,EAMrBxhB,KAAKyhB,WAAa,EAClBzhB,KAAK0hB,oBAAsB,KAO3B1hB,KAAK2hB,qBAAsB,EAiB3B3hB,KAAK4hB,WAAa,KACX5hB,IACT,C,UAqDC,O,EAnDDshB,E,EAAA,EAAAtiB,IAAA,YAAAa,MAIA,WACE,IAAMgiB,EAAO,IAAIxa,GACjB,GAAqB,OAAjBrH,KAAKyZ,QACP,IAAK,IAAItZ,EAAI,EAAGA,EAAIH,KAAKyZ,QAAQpZ,OAAQF,IAAK,CAC5C,IAAM0Q,EAAI7Q,KAAKyZ,QAAQtZ,GACvB0hB,EAAKhZ,IAAIgI,EAAExG,IACb,CAEF,OAAoB,IAAhBwX,EAAKxhB,OACA,KAEAwhB,CAEX,GAEA,CAAA7iB,IAAA,SAAAa,MAaA,SAAOyB,GAEL,OAAOtB,OAASsB,GAAUA,aAAiBggB,GAAYthB,KAAKyZ,QAAQlT,OAAOjF,EAAMmY,QACnF,GAAC,CAAAza,IAAA,WAAAa,MAED,WACE,IAAI6J,EAAS1J,KAAK6K,YAAc,IAAM7K,KAAKyZ,QAM3C,OALIzZ,KAAKwhB,gBACP9X,GAAQ,KACgB,OAApB1J,KAAK4hB,WAAqBlY,GAAQ1J,KAAK4hB,WACtClY,GAAQ1J,KAAKyhB,YAEb/X,CACT,GAAC,CAAA1K,IAAA,WAAAa,MAED,WACE,IAAMK,EAAO,IAAIJ,EAEjB,OADAI,EAAKM,OAAOR,KAAKyZ,SACVvZ,EAAKe,QACd,I,mFAACqgB,CAAA,CArGkB,G,otBCxBd,IAAMQ,GAAY,WACvB,SAAAA,EAAYtU,EAAKuU,GAwBf,O,4FAxBmChiB,CAAA,KAAA+hB,GAsBnC9hB,KAAKwN,IAAMA,EACXxN,KAAK+hB,mBAAqBA,EACnB/hB,IACT,C,UAQC,O,EARA8hB,G,EAAA,EAAA9iB,IAAA,mBAAAa,MAED,SAAiByJ,GACf,GAAgC,OAA5BtJ,KAAK+hB,mBACP,OAAOzY,EAET,IAAMwL,EAAU,IAAIZ,GACpB,OAAOU,GAA2BtL,EAAStJ,KAAK+hB,mBAAoBjN,EACtE,M,gFAACgN,CAAA,CAlCsB,G,otBAsCzBA,GAAaE,MAAQ,IAAIV,GAAS,WAAY,IAAIhI,ICxC3C,IAAM2I,GAAmB,WAS9B,SAAAA,EAAY1J,GAQV,O,4FARwBxY,CAAA,KAAAkiB,GACxBjiB,KAAKuY,aAAgC,OAAjBA,EAAwB,GAAKA,EAKjDvY,KAAKkT,eAAiBpT,EAAS4W,UAAU6B,GAElCvY,IACT,C,UAuBC,O,EArBDiiB,E,EAAA,EAAAjjB,IAAA,uBAAAa,MAoDA,SAAqBgD,GAEnB,IADA,IAAIqf,EAAsB,KACjB/hB,EAAI,EAAGA,EAAIH,KAAKuY,aAAalY,OAAQF,KACxCH,KAAKuY,aAAapY,GAAGkB,qBAAyBrB,KAAKuY,aAAapY,aAAcyC,IACpD,OAAxBsf,IACFA,EAAsBliB,KAAKuY,aAAatH,OAAO,KAEjDiR,EAAoB/hB,GAAK,IAAIyC,EAAyBC,EAAQ7C,KAAKuY,aAAapY,KAGpF,OAA4B,OAAxB+hB,EACKliB,KAEA,IAAIiiB,EAAoBC,EAEnC,GAEA,CAAAljB,IAAA,UAAAa,MAmBA,SAAQ0C,EAAO4f,EAAOC,GACpB,IAAIC,GAAe,EACbC,EAAYH,EAAMpU,MACxB,IACE,IAAK,IAAI5N,EAAI,EAAGA,EAAIH,KAAKuY,aAAalY,OAAQF,IAAK,CACjD,IAAIoiB,EAAcviB,KAAKuY,aAAapY,GACpC,GAAIoiB,aAAuB3f,EAA0B,CACnD,IAAMC,EAAS0f,EAAY1f,OAC3Bsf,EAAMK,KAAKJ,EAAavf,GACxB0f,EAAcA,EAAYphB,OAC1BkhB,EAAeD,EAAavf,IAAWyf,CACzC,MAAWC,EAAYlhB,sBACrB8gB,EAAMK,KAAKF,GACXD,GAAe,GAEjBE,EAAYzf,QAAQP,EACtB,CACF,CAAE,QACI8f,GACFF,EAAMK,KAAKF,EAEf,CACF,GAAC,CAAAtjB,IAAA,WAAAa,MAED,WACE,OAAOG,KAAKkT,cACd,GAAC,CAAAlU,IAAA,iBAAAa,MAED,SAAeK,GACbA,EAAKM,OAAOR,KAAKkT,eACnB,GAAC,CAAAlU,IAAA,SAAAa,MAED,SAAOyB,GACL,GAAItB,OAASsB,EACX,OAAO,EACF,GAAMA,aAAiB2gB,EAEvB,IAAIjiB,KAAKkT,gBAAkB5R,EAAM4R,eACtC,OAAO,EACF,GAAIlT,KAAKuY,aAAalY,QAAUiB,EAAMiX,aAAalY,OACxD,OAAO,EAGP,IADA,IAAMoiB,EAAaziB,KAAKuY,aAAalY,OAC5BogB,EAAM,EAAGA,EAAMgC,IAAchC,EACpC,IAAKzgB,KAAKuY,aAAakI,GAAKla,OAAOjF,EAAMiX,aAAakI,IACpD,OAAO,EAGX,OAAO,CACT,CAbE,OAAO,CAcX,I,EAAC,EAAAzhB,IAAA,SAAAa,MA3HD,SAAc6hB,EAAqBa,GACjC,OACS,IAAIN,EADe,OAAxBP,EAC6B,CAACa,GAEbb,EAAoBnJ,aAAatH,OAAO,CAACsR,IAEhE,I,mFAACN,CAAA,CAzC6B,G,0gECDzB,IAAMS,GAAc,SAAAC,I,uRAAAzgB,CAAAwgB,EAAShY,IAAT,I,MAAAvI,EAAAC,GAAAsgB,GACzB,SAAAA,EAAYxY,EAAQS,GAAQ,IAAArI,G,4FAAAvC,CAAA,KAAA2iB,GAC1BpgB,EAAAH,EAAAzC,KAAA,KAAMwK,EAAQS,GAGd,IAAM+W,EAAsBxX,EAAOwX,qBAAuB,KAK1D,OAJApf,EAAKof,oBAAsBA,IAAmC,OAAX/W,EAAkBA,EAAO+W,oBAAsB,MAClGpf,EAAKsgB,+BAA4C,OAAXjY,GAAkBrI,EAAKugB,uBAAuBlY,EAAQrI,EAAK8H,OACjG9H,EAAK4W,qBAAuBwJ,EAAeljB,UAAUoB,SACrD0B,EAAK8W,mBAAqBsJ,EAAeljB,UAAU+G,OACnDuI,GAAAxM,EAAAyM,GAAAzM,GACF,CA2BC,O,EA3BAogB,G,EAAA,EAAA1jB,IAAA,iBAAAa,MAED,SAAeK,GACbA,EAAKM,OACHR,KAAKoK,MAAMS,YACX7K,KAAKqK,IACLrK,KAAKsJ,QACLtJ,KAAKsK,gBACLtK,KAAK4iB,+BACL5iB,KAAK0hB,oBAET,GAAC,CAAA1iB,IAAA,SAAAa,MAED,SAAOyB,GACL,OACEtB,OAASsB,GACRA,aAAiBohB,GAChB1iB,KAAK4iB,iCAAmCthB,EAAMshB,iCAC7C5iB,KAAK0hB,oBACF1hB,KAAK0hB,oBAAoBnb,OAAOjF,EAAMogB,sBACrCpgB,EAAMogB,sBAAoBlS,GAAAC,GAAAiT,EAAAljB,WAAA,eAAAE,KAAA,KAClB4B,EAEnB,GAAC,CAAAtC,IAAA,yBAAAa,MAED,SAAuB8F,EAAQ7B,GAC7B,OAAO6B,EAAOid,gCAAmC9e,aAAkB+W,IAAiB/W,EAAOgX,SAC7F,M,gFAAC4H,CAAA,CAtCwB,G,otBCGpB,IAAMI,GAAa,oBAAAA,K,4FAAA/iB,CAAA,KAAA+iB,EAAA,C,UAOgE,O,EAPhEA,G,EAAA,EAAA9jB,IAAA,cAAAa,MACxB,SAAYkjB,EAAYC,EAAiBjd,EAAMC,EAAQid,EAAK1O,GAAI,GAAC,CAAAvV,IAAA,kBAAAa,MAEjE,SAAgBkjB,EAAYG,EAAKd,EAAYE,EAAWa,EAAOC,EAAW3J,GAAU,GAAC,CAAAza,IAAA,8BAAAa,MAErF,SAA4BkjB,EAAYG,EAAKd,EAAYE,EAAW3I,EAAiBF,GAAU,GAAC,CAAAza,IAAA,2BAAAa,MAEhG,SAAyBkjB,EAAYG,EAAKd,EAAYE,EAAWb,EAAYhI,GAAU,M,gFAACqJ,CAAA,CAPhE,G,grDCSnB,IAAMO,GAAoB,SAAAC,I,uRAAAphB,CAAAmhB,EAASP,IAAT,I,MAAA3gB,EAAAC,GAAAihB,GAC/B,SAAAA,IAAc,O,4FAAAtjB,CAAA,KAAAsjB,GAAAlhB,EAAAzC,KAAA,KAEd,CAIC,O,EAJA2jB,G,EAAA,EAAArkB,IAAA,cAAAa,MAED,SAAYkjB,EAAYC,EAAiBjd,EAAMC,EAAQid,EAAK1O,GAC1DzT,QAAQyiB,MAAM,QAAUxd,EAAO,IAAMC,EAAS,IAAMid,EACtD,M,gFAACI,CAAA,CAP8B,G,0rDAajCA,GAAqBlgB,SAAW,IAAIkgB,GC1B7B,IAAMG,GAAkB,SAAAF,I,uRAAAphB,CAAAshB,EAASV,IAAT,I,MAAA3gB,EAAAC,GAAAohB,GAC7B,SAAAA,EAAYC,GAAW,IAAAnhB,EAErB,G,4FAFqBvC,CAAA,KAAAyjB,GACrBlhB,EAAAH,EAAAzC,KAAA,MACkB,OAAd+jB,EACF,KAAM,YAGR,OADAnhB,EAAKmhB,UAAYA,EACjB3U,GAAAxM,EAAAyM,GAAAzM,GACF,CAkBC,O,EAlBAkhB,G,EAAA,EAAAxkB,IAAA,cAAAa,MAED,SAAYkjB,EAAYC,EAAiBjd,EAAMC,EAAQid,EAAK1O,GAC1DvU,KAAKyjB,UAAU5c,KAAI,SAAC6c,GAAC,OAAKA,EAAEC,YAAYZ,EAAYC,EAAiBjd,EAAMC,EAAQid,EAAK1O,EAAE,GAC5F,GAAC,CAAAvV,IAAA,kBAAAa,MAED,SAAgBkjB,EAAYG,EAAKd,EAAYE,EAAWa,EAAOC,EAAW3J,GACxEzZ,KAAKyjB,UAAU5c,KAAI,SAAC6c,GAAC,OAAKA,EAAEE,gBAAgBb,EAAYG,EAAKd,EAAYE,EAAWa,EAAOC,EAAW3J,EAAQ,GAChH,GAAC,CAAAza,IAAA,8BAAAa,MAED,SAA4BkjB,EAAYG,EAAKd,EAAYE,EAAW3I,EAAiBF,GACnFzZ,KAAKyjB,UAAU5c,KAAI,SAAC6c,GAAC,OACnBA,EAAEG,4BAA4Bd,EAAYG,EAAKd,EAAYE,EAAW3I,EAAiBF,EAAQ,GAEnG,GAAC,CAAAza,IAAA,2BAAAa,MAED,SAAyBkjB,EAAYG,EAAKd,EAAYE,EAAWb,EAAYhI,GAC3EzZ,KAAKyjB,UAAU5c,KAAI,SAAC6c,GAAC,OAAKA,EAAEI,yBAAyBf,EAAYG,EAAKd,EAAYE,EAAWb,EAAYhI,EAAQ,GACnH,M,gFAAC+J,CAAA,CA1B4B,G,otBCGxB,IAAMO,GAAU,WACrB,SAAAA,K,4FAAchkB,CAAA,KAAAgkB,GACZ/jB,KAAKgkB,WAAa,CAACX,GAAqBlgB,UACxCnD,KAAKikB,QAAU,KACfjkB,KAAKkkB,cAAgB,CACvB,C,UAsJC,O,EAtJAH,E,EAAA,EAAA/kB,IAAA,MAAAK,IAED,WACE,OAAOW,KAAKikB,QAAQzW,GACtB,GAAC,CAAAxO,IAAA,QAAAK,IAED,WACE,OAAOW,KAAKkkB,YACd,EAAChe,IAED,SAAUkE,GACRpK,KAAKkkB,aAAe9Z,CACtB,GAAC,CAAApL,IAAA,eAAAa,MAED,SAAaskB,GACX,IAAMC,EAAiB,SACnBA,IAAmBD,GACrBrjB,QAAQC,IAAI,uDAAyDqjB,EAAiB,KAAOD,EAEjG,GAAC,CAAAnlB,IAAA,mBAAAa,MAED,SAAiBwkB,GACfrkB,KAAKgkB,WAAWhc,KAAKqc,EACvB,GAAC,CAAArlB,IAAA,uBAAAa,MAED,WACEG,KAAKgkB,WAAa,EACpB,GAAC,CAAAhlB,IAAA,kBAAAa,MAED,WACE,OAAOX,OAAOolB,eAAetkB,MAAM0X,YAAY/K,cAAgB,EACjE,GAAC,CAAA3N,IAAA,mBAAAa,MAED,WACE,OAAOX,OAAOolB,eAAetkB,MAAM0X,YAAY9K,eAAiB,EAClE,GAAC,CAAA5N,IAAA,gBAAAa,MAED,WACE,IAAKG,KAAKukB,WAAY,CACpB,IAAM5X,EAAe3M,KAAKwkB,kBACpB5X,EAAgB5M,KAAKykB,mBACrBpkB,EAASsM,EAAatM,OAASuM,EAAcvM,OAASsM,EAAatM,OAASuM,EAAcvM,OAChGL,KAAKukB,WAAa,GAClB,IAAK,IAAIpkB,EAAI,EAAGA,EAAIE,EAAQF,IAC1BH,KAAKukB,WAAWpkB,GAAKwM,EAAaxM,IAAMyM,EAAczM,IAAM,UAEhE,CACA,OAAOH,KAAKukB,UACd,GAAC,CAAAvlB,IAAA,kBAAAa,MAED,WACE,IAAM0kB,EAAavkB,KAAK0kB,gBACxB,GAAmB,OAAfH,EACF,MAAM,IAAItU,MAAM,kEAElB,IAAI1H,EAASvI,KAAK2kB,kBAAkBJ,GASpC,YARexgB,IAAXwE,IAEFA,EAASgc,EAAW3c,QAAO,SAAC3I,EAAGyB,EAAGP,GAChClB,EAAEyB,GAAKP,CACT,IACAoI,EAAOtB,IAAMvB,GAAMuB,IACnBjH,KAAK2kB,kBAAkBJ,GAAchc,GAEhCA,CACT,GAEA,CAAAvJ,IAAA,kBAAAa,MAIA,WACE,IAAM2Q,EAAYxQ,KAAKwQ,UACvB,GAAkB,OAAdA,EACF,MAAM,IAAIP,MAAM,iEAElB,IAAI1H,EAASvI,KAAK4kB,kBAAkBpU,GAQpC,YAPezM,IAAXwE,IAEFA,EAASiI,EAAU5I,QAAO,SAAC3I,EAAGyB,EAAGP,GAC/BlB,EAAEyB,GAAKP,CACT,IACAH,KAAK4kB,kBAAkBpU,GAAajI,GAE/BA,CACT,GAAC,CAAAvJ,IAAA,eAAAa,MAED,SAAaglB,GACX,IAAM/S,EAAQ9R,KAAK8kB,kBAAkBD,GACrC,YAAc9gB,IAAV+N,EACKA,EAEApM,GAAMqB,YAEjB,GAAC,CAAA/H,IAAA,mBAAAa,MAED,WACE,MAAM,IAAIoQ,MAAM,6BAClB,GAEA,CAAAjR,IAAA,iBAAAa,MACA,SAAe0U,GAGb,MAAO,QAFMA,EAAEwQ,oBAAoBhf,KAEX,IADTwO,EAAEwQ,oBAAoB/e,MAEvC,GAEA,CAAAhH,IAAA,uBAAAa,MAaA,SAAqBqR,GACnB,GAAU,OAANA,EACF,MAAO,aAET,IAAIxH,EAAIwH,EAAE/K,KASV,OARU,OAANuD,IAEAA,EADEwH,EAAEvN,OAAS+B,GAAMuB,IACf,QAEA,IAAMiK,EAAEvN,KAAO,KAIhB,KADP+F,EAAIA,EAAEgD,QAAQ,KAAM,OAAOA,QAAQ,KAAM,OAAOA,QAAQ,KAAM,QAC7C,GACnB,GAAC,CAAA1N,IAAA,2BAAAa,MAED,WACE,OAAO,IAAI2jB,GAAmBxjB,KAAKgkB,WACrC,GAEA,CAAAhlB,IAAA,UAAAa,MAIA,SAAQ0c,EAAU7Z,EAAWC,GAC3B,OAAO,CACT,GAAC,CAAA3D,IAAA,WAAAa,MAED,SAAS0c,EAAUrT,GACjB,OAAO,CACT,I,mFAAC6a,CAAA,CA3JoB,G,grDA8JvBA,GAAWY,kBAAoB,CAAC,EAChCZ,GAAWa,kBAAoB,CAAC,ECtKzB,IAAMI,GAAW,SAAAC,I,uRAAA/iB,CAAA8iB,EAAStf,IAAT,I,MAAAvD,EAAAC,GAAA4iB,GACtB,SAAAA,EAAYrf,EAAQhC,EAAMtB,EAASuD,EAAOC,GAAM,IAAAvD,EAa7C,O,4FAb6CvC,CAAA,KAAAilB,IAC9C1iB,EAAAH,EAAAzC,KAAA,OACKiG,YAAoB5B,IAAX4B,EAAuBA,EAASqf,EAAYE,aAC1D5iB,EAAKqB,UAAgBI,IAATJ,EAAqBA,EAAO,KACxCrB,EAAKD,aAAsB0B,IAAZ1B,EAAwBA,EAAUqD,GAAMwB,gBACvD5E,EAAKsD,WAAkB7B,IAAV6B,EAAsBA,GAAS,EAC5CtD,EAAKuD,UAAgB9B,IAAT8B,EAAqBA,GAAQ,EACzCvD,EAAKwD,YAAc,EACI,OAAnBxD,EAAKqD,OAAO,IACdrD,EAAKyD,KAAOJ,EAAO,GAAGI,KACtBzD,EAAK0D,OAASL,EAAO,GAAGK,QAExB1D,EAAK0D,QAAU,EAChB1D,CACH,CA+EC,O,EA/EA0iB,G,EAAA,EAAAhmB,IAAA,OAAAK,IAED,WACE,GAAmB,OAAfW,KAAKiG,MACP,OAAOjG,KAAKiG,MAEd,IAAMkc,EAAQniB,KAAKmlB,iBACnB,GAAc,OAAVhD,EACF,OAAO,KAET,IAAM3V,EAAI2V,EAAMiD,KAChB,OAAIplB,KAAK4F,MAAQ4G,GAAKxM,KAAK6F,KAAO2G,EACzB2V,EAAMvP,QAAQ5S,KAAK4F,MAAO5F,KAAK6F,MAE/B,OAEX,EAACK,IAED,SAASC,GACPnG,KAAKiG,MAAQE,CACf,GAEA,CAAAnH,IAAA,QAAAa,MAaA,WACE,IAAMqR,EAAI,IAAI8T,EAAYhlB,KAAK2F,OAAQ3F,KAAK2D,KAAM3D,KAAKqC,QAASrC,KAAK4F,MAAO5F,KAAK6F,MAKjF,OAJAqL,EAAEpL,WAAa9F,KAAK8F,WACpBoL,EAAEnL,KAAO/F,KAAK+F,KACdmL,EAAElL,OAAShG,KAAKgG,OAChBkL,EAAE/K,KAAOnG,KAAKmG,KACP+K,CACT,GAAC,CAAAlS,IAAA,gBAAAa,MAED,SAAc8D,GACZ,IAAMuN,EAAI,IAAI8T,EAAYhlB,KAAK2F,OAAQhC,EAAM3D,KAAKqC,QAASrC,KAAK4F,MAAO5F,KAAK6F,MAK5E,OAJAqL,EAAEpL,WAAa9F,KAAK8F,WACpBoL,EAAEnL,KAAO/F,KAAK+F,KACdmL,EAAElL,OAAShG,KAAKgG,OACZrC,IAAS+B,GAAMuB,MAAKiK,EAAE/K,KAAO,IAC1B+K,CACT,GAAC,CAAAlS,IAAA,WAAAa,MAED,WACE,IAAIwlB,EAAMrlB,KAAKmG,KAMf,OAJEkf,EADU,OAARA,EACIA,EAAI3Y,QAAQ,MAAO,OAAOA,QAAQ,MAAO,OAAOA,QAAQ,MAAO,OAE/D,YAGN,KACA1M,KAAK8F,WACL,IACA9F,KAAK4F,MACL,IACA5F,KAAK6F,KACL,KACAwf,EACA,MACArlB,KAAK2D,KACL,KACC3D,KAAKqC,QAAU,EAAI,YAAcrC,KAAKqC,QAAU,IACjD,IACArC,KAAK+F,KACL,IACA/F,KAAKgG,OACL,GAEJ,M,gFAACgf,CAAA,CA9FqB,G,83DAqGxBA,GAAYE,aAAe,CAAC,KAAM,MClGa,IAEzCI,GAAYzhB,IAAA,SAAAyhB,IAAAvlB,GAAA,KAAAulB,EAAA,IAMLC,GAAkB,SAAAC,I,uRAAAtjB,CAAAqjB,EAASD,IAAT,IAAAnjB,EAAAC,GAAAmjB,GAC7B,SAAAA,EAAYE,GAAU,IAAAnjB,EAiBsC,OAjBtCvC,GAAA,KAAAwlB,IACpBjjB,EAAAH,EAAAzC,KAAA,OAgBK+lB,cAAwB1hB,IAAb0hB,GAAiCA,EAASnjB,CAC5D,CAkBC,OAlBAuB,GAAA0hB,EAAA,EAAAvmB,IAAA,SAAAa,MAED,SAAO8F,EAAQhC,EAAMwC,EAAM9D,EAASuD,EAAOC,EAAME,EAAMC,GACrD,IAAMkL,EAAI,IAAI8T,GAAYrf,EAAQhC,EAAMtB,EAASuD,EAAOC,GAQxD,OAPAqL,EAAEnL,KAAOA,EACTmL,EAAElL,OAASA,EACE,OAATG,EACF+K,EAAE/K,KAAOA,EACAnG,KAAKylB,UAA0B,OAAd9f,EAAO,KACjCuL,EAAE/K,KAAOR,EAAO,GAAGiN,QAAQhN,EAAOC,IAE7BqL,CACT,GAAC,CAAAlS,IAAA,aAAAa,MAED,SAAW8D,EAAMwC,GACf,IAAM+K,EAAI,IAAI8T,GAAY,KAAMrhB,GAEhC,OADAuN,EAAE/K,KAAOA,EACF+K,CACT,KAACqU,CAAA,CArC4B,G,y4EA+C/BA,GAAmBG,QAAU,IAAIH,GC/C1B,IAAMI,GAAoB,SAAAC,I,uRAAA1jB,CAAAyjB,EAgD9BE,GAhDuC5V,QAAT,I,MAAA9N,EAAAC,GAAAujB,GAC/B,SAAAA,EAAYzb,GAAQ,IAAA5H,EAuBjB,O,4FAvBiBvC,CAAA,KAAA4lB,GAClBrjB,EAAAH,EAAAzC,KAAA,KAAMwK,EAAOiX,SACTlR,MAAM6V,mBAAmB7V,MAAM6V,kBAAiB/W,GAAAzM,GAAOqjB,GAC3DrjB,EAAK6e,QAAUjX,EAAOiX,QACtB7e,EAAKygB,WAAa7Y,EAAO6Y,WACzBzgB,EAAK6f,MAAQjY,EAAOiY,MACpB7f,EAAK2U,IAAM/M,EAAO+M,IAMlB3U,EAAKyjB,eAAiB,KAQtBzjB,EAAK0jB,gBAAkB,EACC,OAApB1jB,EAAKygB,aACPzgB,EAAK0jB,eAAiB1jB,EAAKygB,WAAW3Y,OACvC9H,CACH,CAuBC,O,EArBDqjB,G,EAAA,EAAA3mB,IAAA,oBAAAa,MAUA,WACE,OAAwB,OAApBG,KAAK+iB,WACA/iB,KAAK+iB,WAAWvV,IAAIyY,kBAAkBjmB,KAAKgmB,eAAgBhmB,KAAKiX,KAEhE,IAEX,GAEA,CAAAjY,IAAA,WAAAa,MACA,WACE,OAAOG,KAAKmhB,OACd,M,gFAACwE,CAAA,CAhD8B,G,grDCA1B,IAAMO,GAAoB,SAAAC,I,uRAAAjkB,CAAAgkB,EAASP,IAAT,I,MAAAxjB,EAAAC,GAAA8jB,GAC/B,SAAAA,EAAYnD,EAAYZ,EAAOiE,EAAYL,EAAgBM,EAAgBpP,GAAK,IAAA3U,EAczC,O,4FAdyCvC,CAAA,KAAAmmB,GAC9EjP,EAAMA,GAAO8L,EAAWuD,KACxBP,EAAiBA,GAAkBhD,EAAWwD,kBAC9CH,EAAaA,GAAcrD,EAAWwD,kBACtCpE,EAAQA,GAASY,EAAWoC,kBAC5B7iB,EAAAH,EAAAzC,KAAA,KAAM,CAAEyhB,QAAS,GAAI4B,WAAYA,EAAYZ,MAAOA,EAAOlL,IAAKA,KAG3DoP,eAAiBA,EAKtB/jB,EAAK8jB,WAAaA,EAClB9jB,EAAKyjB,eAAiBA,EAAezjB,CACvC,CAAC,O,EAAA4jB,E,oFAAA,CAhB8B,G,grDCN1B,IAAMM,GAAyB,SAAAL,I,uRAAAjkB,CAAAskB,EAASb,IAAT,I,MAAAxjB,EAAAC,GAAAokB,GACpC,SAAAA,EAAYjkB,EAAO4f,EAAOC,EAAYiE,GAAgB,IAAA/jB,EAGf,O,4FAHevC,CAAA,KAAAymB,IACpDlkB,EAAAH,EAAAzC,KAAA,KAAM,CAAEyhB,QAAS,GAAI4B,WAAYxgB,EAAO4f,MAAOA,EAAOlL,IAAK,QACtDmL,WAAaA,EAClB9f,EAAK+jB,eAAiBA,EAAe/jB,CACvC,CAQC,O,EARAkkB,G,EAAA,EAAAxnB,IAAA,WAAAa,MAED,WACE,IAAIsP,EAAS,GAIb,OAHInP,KAAKoiB,YAAc,GAAKpiB,KAAKoiB,WAAapiB,KAAKmiB,MAAMiD,OACvDjW,EAASnP,KAAKmiB,MAAMvP,QAAQ,IAAI9H,GAAS9K,KAAKoiB,WAAYpiB,KAAKoiB,cAE1D,4BAA8BjT,CACvC,M,gFAACqX,CAAA,CAbmC,G,grDCG/B,IAAMC,GAAsB,SAAAN,I,uRAAAjkB,CAAAukB,EAASd,IAAT,I,MAAAxjB,EAAAC,GAAAqkB,GACjC,SAAAA,EAAY1D,GAAY,IAAAzgB,EAE6B,O,4FAF7BvC,CAAA,KAAA0mB,IACtBnkB,EAAAH,EAAAzC,KAAA,KAAM,CAAEyhB,QAAS,GAAI4B,WAAYA,EAAYZ,MAAOY,EAAWoC,iBAAkBlO,IAAK8L,EAAWuD,QAC5FP,eAAiBhD,EAAWwD,kBAAkBjkB,CACrD,CAAC,O,EAAAmkB,E,oFAAA,CAJgC,G,grDCG5B,IAAMC,GAAwB,SAAAP,I,uRAAAjkB,CAAAwkB,EAASf,IAAT,I,MAAAxjB,EAAAC,GAAAskB,GACnC,SAAAA,EAAY3D,EAAY4D,EAAWxF,GAAS,IAAA7e,G,4FAAAvC,CAAA,KAAA2mB,GAC1CpkB,EAAAH,EAAAzC,KAAA,KAAM,CACJyhB,QAASyF,GAAcD,EAAWxF,GAAW,MAC7C4B,WAAYA,EACZZ,MAAOY,EAAWoC,iBAClBlO,IAAK8L,EAAWuD,OAElB,IACMxY,EADIiV,EAAWkB,QAAQzW,IAAIkH,OAAOqO,EAAW3Y,OACnCwD,YAAY,GASuB,OAR/CE,aAAiB7I,IACnB3C,EAAKI,UAAYoL,EAAMpL,UACvBJ,EAAKukB,eAAiB/Y,EAAMwO,YAE5Bha,EAAKI,UAAY,EACjBJ,EAAKukB,eAAiB,GAExBvkB,EAAKqkB,UAAYA,EACjBrkB,EAAKyjB,eAAiBhD,EAAWwD,kBAAkBjkB,CACrD,CAAC,O,EAAAokB,E,oFAAA,CAnBkC,GAsBrC,SAASE,GAAcD,EAAWxF,GAChC,OAAgB,OAAZA,EACKA,EAEA,sBAAwBwF,EAAY,IAE/C,C,grDCbO,IAAMG,GAAuB,SAAAxD,I,uRAAAphB,CAAA4kB,EAAShE,IAAT,I,MAAA3gB,EAAAC,GAAA0kB,GAClC,SAAAA,EAAYC,GAAW,IAAAzkB,EAIM,O,4FAJNvC,CAAA,KAAA+mB,GAErBC,EAAYA,IAAa,GADzBzkB,EAAAH,EAAAzC,KAAA,OAGKqnB,UAAYA,EAAUzkB,CAC7B,CAwEC,O,EAxEAwkB,E,EAAA,EAAA9nB,IAAA,kBAAAa,MAED,SAAgBkjB,EAAYG,EAAKd,EAAYE,EAAWa,EAAOC,EAAW3J,GACxE,IAAIzZ,KAAK+mB,WAAc5D,EAAvB,CAGA,IAAMF,EACJ,qBACAjjB,KAAKgnB,uBAAuBjE,EAAYG,GACxC,eACAljB,KAAKinB,mBAAmB7D,EAAW3J,GACnC,YACAsJ,EAAWmE,iBAAiBtU,QAAQ,IAAI9H,GAASsX,EAAYE,IAC7D,IACFS,EAAWoE,qBAAqBlE,EAThC,CAUF,GAAC,CAAAjkB,IAAA,8BAAAa,MAED,SAA4BkjB,EAAYG,EAAKd,EAAYE,EAAW3I,EAAiBF,GACnF,IAAMwJ,EACJ,iCACAjjB,KAAKgnB,uBAAuBjE,EAAYG,GACxC,YACAH,EAAWmE,iBAAiBtU,QAAQ,IAAI9H,GAASsX,EAAYE,IAC7D,IACFS,EAAWoE,qBAAqBlE,EAClC,GAAC,CAAAjkB,IAAA,2BAAAa,MAED,SAAyBkjB,EAAYG,EAAKd,EAAYE,EAAWb,EAAYhI,GAC3E,IAAMwJ,EACJ,8BACAjjB,KAAKgnB,uBAAuBjE,EAAYG,GACxC,YACAH,EAAWmE,iBAAiBtU,QAAQ,IAAI9H,GAASsX,EAAYE,IAC7D,IACFS,EAAWoE,qBAAqBlE,EAClC,GAAC,CAAAjkB,IAAA,yBAAAa,MAED,SAAuBkjB,EAAYG,GACjC,IAAMtK,EAAWsK,EAAItK,SACflW,EAAYwgB,EAAIkE,cAAc1kB,UAE9B8N,EAAYuS,EAAWvS,UAC7B,GAAI9N,EAAY,GAAKA,GAAa8N,EAAUnQ,OAC1C,MAAO,GAAKuY,EAEd,IAAMyO,EAAW7W,EAAU9N,IAAc,KACzC,OAAiB,OAAb2kB,GAAyC,IAApBA,EAAShnB,OACzB,GAAKuY,EAEP,GAAP3H,OAAU2H,EAAQ,MAAA3H,OAAKoW,EAAQ,IACjC,GAEA,CAAAroB,IAAA,qBAAAa,MAWA,SAAmBynB,EAAc7N,GAC/B,GAAqB,OAAjB6N,EACF,OAAOA,EAGT,IADA,IAAM/e,EAAS,IAAIkO,GACVtW,EAAI,EAAGA,EAAIsZ,EAAQ8N,MAAMlnB,OAAQF,IACxCoI,EAAOM,IAAI4Q,EAAQ8N,MAAMpnB,GAAGkK,KAE9B,MAAO,IAAP4G,OAAW1I,EAAOR,SAASjB,KAAK,MAAK,IACvC,I,mFAACggB,CAAA,CA9EiC,G,y4ECxB7B,IAAMU,GAA0B,SAAA5B,I,uRAAA1jB,CAAAslB,EAIpC3B,GAJ6C5V,QAAT,I,MAAA9N,EAAAC,GAAAolB,GACrC,SAAAA,IAAc,IAAAllB,EAE8C,O,4FAF9CvC,CAAA,KAAAynB,GACZllB,EAAAH,EAAAzC,KAAA,MACAuQ,MAAM6V,kBAAiB/W,GAAAzM,GAAOklB,GAA4BllB,CAC5D,CAAC,O,EAAAklB,E,oFAAA,CAJoC,G,otBCChC,IAAMC,GAAa,oBAAAA,K,4FAAA1nB,CAAA,KAAA0nB,EAAA,C,UAWE,O,EAXFA,G,EAAA,EAAAzoB,IAAA,QAAAa,MACxB,SAAMkjB,GAAa,GAAC,CAAA/jB,IAAA,gBAAAa,MAEpB,SAAckjB,GAAa,GAAC,CAAA/jB,IAAA,UAAAa,MAE5B,SAAQkjB,EAAYxO,GAAI,GAAC,CAAAvV,IAAA,OAAAa,MAEzB,SAAKkjB,GAAa,GAAC,CAAA/jB,IAAA,sBAAAa,MAEnB,SAAoBkjB,GAAa,GAAC,CAAA/jB,IAAA,cAAAa,MAElC,SAAYkjB,GAAa,M,gFAAC0E,CAAA,CAXF,G,grDCYnB,IAAMC,GAAoB,SAAAC,I,uRAAAzlB,CAAAwlB,EAASD,IAAT,I,MAAAtlB,EAAAC,GAAAslB,GAC/B,SAAAA,IAAc,IAAAplB,EAqBY,O,4FArBZvC,CAAA,KAAA2nB,IACZplB,EAAAH,EAAAzC,KAAA,OAQKkoB,mBAAoB,EASzBtlB,EAAKulB,gBAAkB,EACvBvlB,EAAKwlB,gBAAkB,KACvBxlB,EAAKylB,kBAAoB,KACzBzlB,EAAK0lB,eAAiB,EAAE1lB,CAC1B,CAgqBC,O,EA9pBDolB,G,EAAA,EAAA1oB,IAAA,QAAAa,MAIA,SAAMkjB,GACJ/iB,KAAKioB,kBAAkBlF,EACzB,GAEA,CAAA/jB,IAAA,sBAAAa,MAMA,SAAoBkjB,GAClB/iB,KAAK4nB,mBAAoB,CAC3B,GAAC,CAAA5oB,IAAA,sBAAAa,MAED,SAAoBkjB,GAClB,OAAO/iB,KAAK4nB,iBACd,GAEA,CAAA5oB,IAAA,oBAAAa,MAKA,SAAkBkjB,GAChB/iB,KAAK4nB,mBAAoB,EACzB5nB,KAAK8nB,gBAAkB,KACvB9nB,KAAK6nB,gBAAkB,CACzB,GAEA,CAAA7oB,IAAA,cAAAa,MAIA,SAAYkjB,GACV/iB,KAAKioB,kBAAkBlF,EACzB,GAEA,CAAA/jB,IAAA,cAAAa,MAmBA,SAAYkjB,EAAYxO,GAGlBvU,KAAKkoB,oBAAoBnF,KAG7B/iB,KAAKmoB,oBAAoBpF,GACrBxO,aAAa2R,GACflmB,KAAKooB,0BAA0BrF,EAAYxO,GAClCA,aAAakS,GACtBzmB,KAAKqoB,oBAAoBtF,EAAYxO,GAC5BA,aAAamS,GACtB1mB,KAAKsoB,sBAAsBvF,EAAYxO,IAEvCzT,QAAQC,IAAI,mCAAqCwT,EAAEmD,YAAY6Q,MAC/DznB,QAAQC,IAAIwT,EAAEiU,OACdzF,EAAWoE,qBAAqB5S,EAAEwQ,oBAAqBxQ,EAAEkU,aAAclU,IAE3E,GAEA,CAAAvV,IAAA,UAAAa,MASA,SAAQkjB,EAAYxO,GAEhBvU,KAAK6nB,iBAAmB9E,EAAWoC,iBAAiBpX,OAC3B,OAAzB/N,KAAK8nB,iBACL9nB,KAAK8nB,gBAAgBY,QAAQ3F,EAAW3Y,QAAU,GAMlD2Y,EAAW4F,UAEb3oB,KAAK6nB,eAAiB9E,EAAW6F,OAAO7a,MACX,OAAzB/N,KAAK8nB,kBACP9nB,KAAK8nB,gBAAkB,IAEzB9nB,KAAK8nB,gBAAgB9f,KAAK+a,EAAW3Y,OACrC,IAAMye,EAAY7oB,KAAK8oB,oBAAoB/F,GAC3C/iB,KAAK+oB,aAAahG,EAAY8F,EAChC,GAEA,CAAA7pB,IAAA,OAAAa,MA+CA,SAAKkjB,GAEH,IAAI/iB,KAAKkoB,oBAAoBnF,GAA7B,CAGA,IAAMrZ,EAAIqZ,EAAWkB,QAAQzW,IAAIkH,OAAOqO,EAAW3Y,OAC7C4e,EAAKjG,EAAWmE,iBAAiB+B,GAAG,GAEpCnQ,EAAaiK,EAAWvV,IAAIsL,WAAWpP,GAC7C,GAAIoP,EAAWxM,SAAS0c,GAGtB,OAFAhpB,KAAK+nB,kBAAoB,UACzB/nB,KAAKgoB,eAAiBza,GAASE,sBAE1B,GAAIqL,EAAWxM,SAAS5G,GAAMxB,SACJ,OAA3BlE,KAAK+nB,oBAGP/nB,KAAK+nB,kBAAoBhF,EAAWuD,KACpCtmB,KAAKkpB,gBAAkBnG,EAAWmB,mBAItC,OAAQxa,EAAEgE,WACR,KAAKH,GAASW,YACd,KAAKX,GAASa,iBACd,KAAKb,GAASY,iBACd,KAAKZ,GAASkB,gBAEZ,GAA6C,OAAzCzO,KAAKmpB,oBAAoBpG,GAC3B,OAEA,MAAM,IAAI0D,GAAuB1D,GAErC,KAAKxV,GAASmB,eACd,KAAKnB,GAASiB,eAEVxO,KAAKopB,oBAAoBrG,GACzB,IAAMsG,EAAY,IAAIre,GACtBqe,EAAUtR,OAAOgL,EAAWkD,qBAC5B,IAAMqD,EAAiCD,EAAUtR,OAAO/X,KAAK8oB,oBAAoB/F,IACjF/iB,KAAK+oB,aAAahG,EAAYuG,GApCpC,CA0CF,GAEA,CAAAtqB,IAAA,4BAAAa,MASA,SAA0BkjB,EAAYxO,GACpC,IACI4N,EADEoH,EAASxG,EAAWmE,iBAItB/E,EAFW,OAAXoH,EACEhV,EAAE6R,WAAWziB,OAAS+B,GAAMuB,IACtB,QAEAsiB,EAAO3W,QAAQ,IAAI9H,GAASyJ,EAAE6R,WAAWtgB,WAAYyO,EAAEwR,eAAejgB,aAGxE,kBAEV,IAAMmd,EAAM,kCAAoCjjB,KAAKwpB,iBAAiBrH,GACtEY,EAAWoE,qBAAqBlE,EAAK1O,EAAEwR,eAAgBxR,EACzD,GAEA,CAAAvV,IAAA,sBAAAa,MASA,SAAoBkjB,EAAYxO,GAC9B,IAAM0O,EACJ,oBACAjjB,KAAKypB,qBAAqBlV,EAAEwR,gBAC5B,cACAxR,EAAE0R,oBAAoBjlB,SAAS+hB,EAAWpW,aAAcoW,EAAWnW,eACrEmW,EAAWoE,qBAAqBlE,EAAK1O,EAAEwR,eAAgBxR,EACzD,GAEA,CAAAvV,IAAA,wBAAAa,MASA,SAAsBkjB,EAAYxO,GAChC,IACM0O,EAAM,QADKF,EAAWvS,UAAUuS,EAAWuD,KAAK5jB,WACrB,IAAM6R,EAAE4M,QACzC4B,EAAWoE,qBAAqBlE,EAAK1O,EAAEwR,eAAgBxR,EACzD,GAEA,CAAAvV,IAAA,sBAAAa,MAmBA,SAAoBkjB,GAClB,IAAI/iB,KAAKkoB,oBAAoBnF,GAA7B,CAGA/iB,KAAKmoB,oBAAoBpF,GACzB,IAAM7R,EAAI6R,EAAWwD,kBAGftD,EACJ,oBAHgBjjB,KAAKypB,qBAAqBvY,GAK1C,cAJgBlR,KAAKimB,kBAAkBlD,GAK7B/hB,SAAS+hB,EAAWpW,aAAcoW,EAAWnW,eACzDmW,EAAWoE,qBAAqBlE,EAAK/R,EAAG,KAVxC,CAWF,GAEA,CAAAlS,IAAA,qBAAAa,MAiBA,SAAmBkjB,GACjB,IAAI/iB,KAAKkoB,oBAAoBnF,GAA7B,CAGA/iB,KAAKmoB,oBAAoBpF,GACzB,IAAM7R,EAAI6R,EAAWwD,kBAEftD,EACJ,WAFgBjjB,KAAKimB,kBAAkBlD,GAG7B/hB,SAAS+hB,EAAWpW,aAAcoW,EAAWnW,eACvD,OACA5M,KAAKypB,qBAAqBvY,GAC5B6R,EAAWoE,qBAAqBlE,EAAK/R,EAAG,KATxC,CAUF,GAEA,CAAAlS,IAAA,gBAAAa,MAkDA,SAAckjB,GAEZ,IAAM2G,EAAgB1pB,KAAKmpB,oBAAoBpG,GAC/C,GAAsB,OAAlB2G,EAIF,OADA3G,EAAW4F,UACJe,EAGT,GAAI1pB,KAAK2pB,qBAAqB5G,GAC5B,OAAO/iB,KAAK4pB,iBAAiB7G,GAG/B,MAAM,IAAI0D,GAAuB1D,EACnC,GAEA,CAAA/jB,IAAA,uBAAAa,MAiBA,SAAqBkjB,GACnB,IAAM8G,EAAoB9G,EAAWmE,iBAAiB+B,GAAG,GAInDzb,EAAMuV,EAAWkB,QAAQzW,IAEzBrB,EADeqB,EAAIkH,OAAOqO,EAAW3Y,OACjBwD,YAAY,GAAG9J,OAEzC,QADuB0J,EAAIsL,WAAW3M,EAAM4W,EAAWuD,MACpCha,SAASud,KAC1B7pB,KAAK8pB,mBAAmB/G,IACjB,EAIX,GAEA,CAAA/jB,IAAA,sBAAAa,MAmBA,SAAoBkjB,GAClB,IAAMgH,EAAgBhH,EAAWmE,iBAAiB+B,GAAG,GAErD,GADkBjpB,KAAKimB,kBAAkBlD,GAC3BzW,SAASyd,GAAgB,CACrC/pB,KAAKopB,oBAAoBrG,GAKzBA,EAAW4F,UAEX,IAAMe,EAAgB3G,EAAWwD,kBAEjC,OADAvmB,KAAKgqB,YAAYjH,GACV2G,CACT,CACE,OAAO,IAEX,GAEA,CAAA1qB,IAAA,mBAAAa,MAqBA,SAAiBkjB,GACf,IAGIkH,EAHEC,EAAgBnH,EAAWwD,kBAE3B4D,EADYnqB,KAAKimB,kBAAkBlD,GACLqH,QAGlCH,EADEE,IAAsBzkB,GAAMuB,IAClB,gBAEA,YAAc8b,EAAWpW,aAAawd,GAAqB,IAEzE,IAAIje,EAAUge,EACRG,EAAWtH,EAAWmE,iBAAiBoD,IAAI,GAIjD,OAHIpe,EAAQvI,OAAS+B,GAAMuB,KAAoB,OAAbojB,IAChCne,EAAUme,GAELtH,EACJwH,kBACA5V,OACCzI,EAAQvG,OACRwkB,EACAF,EACAvkB,GAAMwB,iBACL,GACA,EACDgF,EAAQnG,KACRmG,EAAQlG,OAEd,GAAC,CAAAhH,IAAA,oBAAAa,MAED,SAAkBkjB,GAChB,OAAOA,EAAWkD,mBACpB,GAEA,CAAAjnB,IAAA,uBAAAa,MASA,SAAqBqR,GACnB,GAAU,OAANA,EACF,MAAO,aAET,IAAIxH,EAAIwH,EAAE/K,KAQV,OAPU,OAANuD,IAEAA,EADEwH,EAAEvN,OAAS+B,GAAMuB,IACf,QAEA,IAAMiK,EAAEvN,KAAO,KAGhB3D,KAAKwpB,iBAAiB9f,EAC/B,GAAC,CAAA1K,IAAA,mBAAAa,MAED,SAAiB6J,GAIf,MAAO,KADPA,GADAA,GADAA,EAAIA,EAAEgD,QAAQ,MAAO,QACfA,QAAQ,MAAO,QACfA,QAAQ,MAAO,QACJ,GACnB,GAEA,CAAA1N,IAAA,sBAAAa,MA6FA,SAAoBkjB,GAIlB,IAHA,IAAMvV,EAAMuV,EAAWkB,QAAQzW,IAC3ByJ,EAAM8L,EAAWuD,KACfkE,EAAa,IAAIxf,GACR,OAARiM,GAAgBA,EAAIzE,eAAiB,GAAG,CAE7C,IACMwG,EADgBxL,EAAIkH,OAAOuC,EAAIzE,eACZ5E,YAAY,GAC/B6c,EAASjd,EAAIsL,WAAWE,EAAG/J,aACjCub,EAAWzS,OAAO0S,GAClBxT,EAAMA,EAAIxE,SACZ,CAEA,OADA+X,EAAWje,UAAU7G,GAAMxB,SACpBsmB,CACT,GAEA,CAAAxrB,IAAA,eAAAa,MACA,SAAakjB,EAAY7c,GAEvB,IADA,IAAI4L,EAAQiR,EAAWmE,iBAAiB+B,GAAG,GACpCnX,IAAUpM,GAAMuB,MAAQf,EAAIoG,SAASwF,IAC1CiR,EAAW4F,UACX7W,EAAQiR,EAAWmE,iBAAiB+B,GAAG,EAE3C,M,gFAACvB,CAAA,CAvrB8B,G,grDCmB1B,IAAMgD,GAAiB,SAAAC,I,uRAAAzoB,CAAAwoB,EAAShD,IAAT,I,MAAAvlB,EAAAC,GAAAsoB,GAC5B,SAAAA,IAAc,O,4FAAA3qB,CAAA,KAAA2qB,GAAAvoB,EAAAzC,KAAA,KAEd,CA4BC,O,EA1BDgrB,G,EAAA,EAAA1rB,IAAA,UAAAa,MAMA,SAAQkjB,EAAYxO,GAElB,IADA,IAAIjL,EAAUyZ,EAAWuD,KACN,OAAZhd,GACLA,EAAQshB,UAAYrW,EACpBjL,EAAUA,EAAQmJ,UAEpB,MAAM,IAAI+U,GAA2BjT,EACvC,GAEA,CAAAvV,IAAA,gBAAAa,MAIA,SAAckjB,GACZ/iB,KAAK6qB,QAAQ9H,EAAY,IAAI0D,GAAuB1D,GACtD,GAEA,CAAA/jB,IAAA,OAAAa,MACA,SAAKkjB,GACH,M,gFACD2H,CAAA,CA/B2B,G,qrDCpBvB,IAAMI,GAAK,SAAAC,I,uRAAA7oB,CAAA4oB,EAAS/G,IAAT,I,MAAA5hB,EAAAC,GAAA0oB,GAChB,SAAAA,EAAY3I,GAAO,IAAA7f,EAiDC,O,4FAjDDvC,CAAA,KAAA+qB,IACjBxoB,EAAAH,EAAAzC,KAAA,OACKkpB,OAASzG,EACd7f,EAAK0oB,SAAWzF,GAAmBG,QACnCpjB,EAAK2oB,wBAA0B,CAAAlc,GAAAzM,GAAO6f,GAEtC7f,EAAK2hB,QAAU,KAWf3hB,EAAK4oB,OAAS,KAOd5oB,EAAK6oB,sBAAwB,EAG7B7oB,EAAK8oB,iBAAmB,EAGxB9oB,EAAK+oB,mBAAqB,EAI1B/oB,EAAKgpB,SAAU,EAGfhpB,EAAKE,SAAWkD,GAAMwB,gBAGtB5E,EAAKipB,MAAQ7lB,GAAMqB,aAEnBzE,EAAKkpB,WAAa,GAClBlpB,EAAKmpB,MAAQX,EAAMY,aAMnBppB,EAAK2D,MAAQ,KAAK3D,CACpB,CA0SC,O,EA1SAwoB,E,EAAA,EAAA9rB,IAAA,cAAAK,IAED,WACE,OAAOW,KAAK4oB,MACd,EAAC1iB,IAED,SAAgBic,GACdniB,KAAK4oB,OAAS,KACd5oB,KAAKirB,wBAA0B,CAACjrB,KAAMA,KAAK4oB,QAC3C5oB,KAAKmd,QACLnd,KAAK4oB,OAASzG,EACdniB,KAAKirB,wBAA0B,CAACjrB,KAAMA,KAAK4oB,OAC7C,GAAC,CAAA5pB,IAAA,aAAAK,IAED,WACE,OAAOW,KAAK4oB,OAAO+C,UACrB,GAAC,CAAA3sB,IAAA,OAAAK,IAED,WACE,OAAOW,KAAKurB,KACd,EAACrlB,IAED,SAASvC,GACP3D,KAAKurB,MAAQ5nB,CACf,GAAC,CAAA3E,IAAA,OAAAK,IAED,WACE,OAAOW,KAAKikB,QAAQle,IACtB,EAACG,IAED,SAASH,GACP/F,KAAKikB,QAAQle,KAAOA,CACtB,GAAC,CAAA/G,IAAA,SAAAK,IAED,WACE,OAAOW,KAAKikB,QAAQje,MACtB,EAACE,IAED,SAAWF,GACThG,KAAKikB,QAAQje,OAASA,CACxB,GAAC,CAAAhH,IAAA,OAAAK,IAED,WACE,OAAmB,OAAfW,KAAKiG,MACAjG,KAAKiG,MAELjG,KAAKikB,QAAQrR,QAAQ5S,KAAK4oB,OAErC,EAAC1iB,IAED,SAASC,GACPnG,KAAKiG,MAAQE,CACf,GAAC,CAAAnH,IAAA,QAAAa,MAED,WAEsB,OAAhBG,KAAK4oB,QACP5oB,KAAK4oB,OAAOpG,KAAK,GAEnBxiB,KAAKkrB,OAAS,KACdlrB,KAAKurB,MAAQ7lB,GAAMqB,aACnB/G,KAAKwC,SAAWkD,GAAMwB,gBACtBlH,KAAKmrB,sBAAwB,EAC7BnrB,KAAKqrB,mBAAqB,EAC1BrrB,KAAKorB,iBAAmB,EACxBprB,KAAKiG,MAAQ,KAEbjG,KAAKsrB,SAAU,EACftrB,KAAKyrB,MAAQX,EAAMY,aACnB1rB,KAAKwrB,WAAa,GAElBxrB,KAAKikB,QAAQ9G,OACf,GAEA,CAAAne,IAAA,YAAAa,MACA,WACE,GAAoB,OAAhBG,KAAK4oB,OACP,KAAM,8CAOR,IAAMgD,EAAmB5rB,KAAK4oB,OAAOiD,OACrC,IACE,OAAS,CACP,GAAI7rB,KAAKsrB,QAEP,OADAtrB,KAAK8rB,UACE9rB,KAAKkrB,OAEdlrB,KAAKkrB,OAAS,KACdlrB,KAAKwC,SAAWkD,GAAMwB,gBACtBlH,KAAKmrB,qBAAuBnrB,KAAK4oB,OAAO7a,MACxC/N,KAAKqrB,kBAAoBrrB,KAAKikB,QAAQje,OACtChG,KAAKorB,gBAAkBprB,KAAKikB,QAAQle,KACpC/F,KAAKiG,MAAQ,KAEb,IADA,IAAI8lB,GAAgB,IACX,CACP/rB,KAAKurB,MAAQ7lB,GAAMqB,aACnB,IAAI+K,EAAQgZ,EAAMhpB,KAClB,IACEgQ,EAAQ9R,KAAKikB,QAAQ+H,MAAMhsB,KAAK4oB,OAAQ5oB,KAAKyrB,MAC/C,CAAE,MAAOlX,GACP,KAAIA,aAAaoR,IAKf,MADA7kB,QAAQC,IAAIwT,EAAEiU,OACRjU,EAJNvU,KAAKisB,gBAAgB1X,GACrBvU,KAAK6qB,QAAQtW,EAKjB,CAOA,GANIvU,KAAK4oB,OAAOK,GAAG,KAAOvjB,GAAMuB,MAC9BjH,KAAKsrB,SAAU,GAEbtrB,KAAKurB,QAAU7lB,GAAMqB,eACvB/G,KAAKurB,MAAQzZ,GAEX9R,KAAKurB,QAAUT,EAAMhpB,KAAM,CAC7BiqB,GAAgB,EAChB,KACF,CACA,GAAI/rB,KAAKurB,QAAUT,EAAMnpB,KACvB,KAEJ,CACA,IAAIoqB,EAMJ,OAHoB,OAAhB/rB,KAAKkrB,QACPlrB,KAAKksB,OAEAlsB,KAAKkrB,MACd,CACF,CAAE,QAGAlrB,KAAK4oB,OAAOuD,QAAQP,EACtB,CACF,GAEA,CAAA5sB,IAAA,OAAAa,MAOA,WACEG,KAAKurB,MAAQT,EAAMhpB,IACrB,GAAC,CAAA9C,IAAA,OAAAa,MAED,WACEG,KAAKurB,MAAQT,EAAMnpB,IACrB,GAAC,CAAA3C,IAAA,OAAAa,MAED,SAAK0f,GACHvf,KAAKyrB,MAAQlM,CACf,GAAC,CAAAvgB,IAAA,WAAAa,MAED,SAAS0f,GACHvf,KAAKikB,QAAQmI,OACftrB,QAAQC,IAAI,YAAcwe,GAE5Bvf,KAAKwrB,WAAWxjB,KAAKhI,KAAKyrB,OAC1BzrB,KAAKgD,KAAKuc,EACZ,GAAC,CAAAvgB,IAAA,UAAAa,MAED,WACE,GAA+B,IAA3BG,KAAKwrB,WAAWnrB,OAClB,KAAM,cAMR,OAJIL,KAAKikB,QAAQmI,OACftrB,QAAQC,IAAI,mBAAqBf,KAAKwrB,WAAW7hB,MAAM,GAAI,IAE7D3J,KAAKgD,KAAKhD,KAAKwrB,WAAWa,OACnBrsB,KAAKyrB,KACd,GAEA,CAAAzsB,IAAA,YAAAa,MAMA,SAAUyN,GACRtN,KAAKkrB,OAAS5d,CAChB,GAEA,CAAAtO,IAAA,OAAAa,MAOA,WACE,IAAMqR,EAAIlR,KAAKgrB,SAASrW,OACtB3U,KAAKirB,wBACLjrB,KAAKurB,MACLvrB,KAAKiG,MACLjG,KAAKwC,SACLxC,KAAKmrB,qBACLnrB,KAAKssB,eAAiB,EACtBtsB,KAAKorB,gBACLprB,KAAKqrB,mBAGP,OADArrB,KAAKusB,UAAUrb,GACRA,CACT,GAAC,CAAAlS,IAAA,UAAAa,MAED,WACE,IAAM2sB,EAAOxsB,KAAKgG,OACZymB,EAAOzsB,KAAK+F,KACZ2mB,EAAM1sB,KAAKgrB,SAASrW,OACxB3U,KAAKirB,wBACLvlB,GAAMuB,IACN,KACAvB,GAAMwB,gBACNlH,KAAK4oB,OAAO7a,MACZ/N,KAAK4oB,OAAO7a,MAAQ,EACpB0e,EACAD,GAGF,OADAxsB,KAAKusB,UAAUG,GACRA,CACT,GAEA,CAAA1tB,IAAA,eAAAa,MACA,WACE,OAAOG,KAAK4oB,OAAO7a,KACrB,GAEA,CAAA/O,IAAA,eAAAa,MAIA,WAGE,IAFA,IAAM0pB,EAAS,GACXrY,EAAIlR,KAAK2sB,YACNzb,EAAEvN,OAAS+B,GAAMuB,KACtBsiB,EAAOvhB,KAAKkJ,GACZA,EAAIlR,KAAK2sB,YAEX,OAAOpD,CACT,GAAC,CAAAvqB,IAAA,kBAAAa,MAED,SAAgB0U,GACd,IAAM3O,EAAQ5F,KAAKmrB,qBACbtlB,EAAO7F,KAAK4oB,OAAO7a,MACnB5H,EAAOnG,KAAK4oB,OAAOhW,QAAQhN,EAAOC,GAClCod,EAAM,gCAAkCjjB,KAAK4sB,gBAAgBzmB,GAAQ,IAC1DnG,KAAK6sB,2BACblJ,YAAY3jB,KAAM,KAAMA,KAAKorB,gBAAiBprB,KAAKqrB,kBAAmBpI,EAAK1O,EACtF,GAAC,CAAAvV,IAAA,kBAAAa,MAED,SAAgB6J,GAEd,IADA,IAAMga,EAAI,GACDvjB,EAAI,EAAGA,EAAIuJ,EAAErJ,OAAQF,IAC5BujB,EAAE1b,KAAK0B,EAAEvJ,IAEX,OAAOujB,EAAE5c,KAAK,GAChB,GAAC,CAAA9H,IAAA,yBAAAa,MAED,SAAuBgR,GACrB,OAAIA,EAAEuN,WAAW,KAAO1Y,GAAMuB,IACrB,QACQ,OAAN4J,EACF,MACQ,OAANA,EACF,MACQ,OAANA,EACF,MAEAA,CAEX,GAAC,CAAA7R,IAAA,sBAAAa,MAED,SAAoBgR,GAClB,MAAO,IAAM7Q,KAAK8sB,uBAAuBjc,GAAK,GAChD,GAEA,CAAA7R,IAAA,UAAAa,MAMA,SAAQktB,GACF/sB,KAAK4oB,OAAOK,GAAG,KAAOvjB,GAAMuB,MAC1B8lB,aAAcvG,GAEhBxmB,KAAKikB,QAAQ0E,QAAQ3oB,KAAK4oB,QAG1B5oB,KAAK4oB,OAAOD,UAGlB,I,mFAACmC,CAAA,CA7Ve,G,grDAgWlBA,GAAMY,aAAe,EACrBZ,GAAMnpB,MAAQ,EACdmpB,GAAMhpB,MAAQ,EAEdgpB,GAAMkC,sBAAwBtnB,GAAMwB,gBACpC4jB,GAAMmC,OAASvnB,GAAMyB,eACrB2jB,GAAMoC,eAAiB,EACvBpC,GAAMqC,eAAiB,QChXhB,IAAMC,GAAmB,SAAAC,I,uRAAAnrB,CAAAkrB,EAAS9T,IAAT,I,MAAAnX,EAAAC,GAAAgrB,GAC9B,SAAAA,IAAc,IAAA9qB,EAEsB,O,4FAFtBvC,CAAA,KAAAqtB,IACZ9qB,EAAAH,EAAAzC,KAAA,OACK8Z,aAAe,IAAInS,GAAU/E,CACpC,CAAC,O,EAAA8qB,E,oFAAA,CAJ6B,G,83DCYhC,SAASE,GAAcC,GACrBA,EAAIxf,OAAS,EACbwf,EAAIxnB,KAAO,EACXwnB,EAAIvnB,QAAU,EACdunB,EAAIC,SAAW,IACjB,CAAC,IAEKC,GAAQ,WACZ,SAAAA,IAAc1tB,GAAA,KAAA0tB,GACZH,GAActtB,KAChB,CAIC,OAJA6D,GAAA4pB,EAAA,EAAAzuB,IAAA,QAAAa,MAED,WACEytB,GAActtB,KAChB,KAACytB,CAAA,CAPW,GAUDC,GAAiB,SAAAC,I,uRAAAzrB,CAAAwrB,EAAS5L,IAAT,IAAA3f,EAAAC,GAAAsrB,GAiB5B,SAAAA,EAAYjd,EAAOjD,EAAKogB,EAAe7L,GAAoB,IAAAzf,EAuBxB,OAvBwBvC,GAAA,KAAA2tB,IACzDprB,EAAAH,EAAAzC,KAAA,KAAM8N,EAAKuU,IACN6L,cAAgBA,EACrBtrB,EAAKmO,MAAQA,EAObnO,EAAK8f,YAAc,EAEnB9f,EAAKyD,KAAO,EAKZzD,EAAK0D,OAAS,EACd1D,EAAKU,KAAO8nB,GAAMY,aAKlBppB,EAAKurB,WAAa,IAAIJ,GAAWnrB,CACnC,CAyjBC,OAzjBAuB,GAAA6pB,EAAA,EAAA1uB,IAAA,YAAAa,MAED,SAAUiuB,GACR9tB,KAAKgG,OAAS8nB,EAAU9nB,OACxBhG,KAAK+F,KAAO+nB,EAAU/nB,KACtB/F,KAAKgD,KAAO8qB,EAAU9qB,KACtBhD,KAAKoiB,WAAa0L,EAAU1L,UAC9B,GAAC,CAAApjB,IAAA,QAAAa,MAED,SAAMsiB,EAAOnf,GACXhD,KAAKgD,KAAOA,EACZ,IAAM6oB,EAAO1J,EAAM0J,OACnB,IACE7rB,KAAKoiB,WAAaD,EAAMpU,MACxB/N,KAAK6tB,WAAW1Q,QAChB,IAAM+F,EAAMljB,KAAK4tB,cAAc5qB,GAC/B,OAAe,OAAXkgB,EAAI6K,GACC/tB,KAAKguB,SAAS7L,GAEdniB,KAAKiuB,QAAQ9L,EAAOe,EAAI6K,GAEnC,CAAE,QACA5L,EAAMgK,QAAQN,EAChB,CACF,GAAC,CAAA7sB,IAAA,QAAAa,MAED,WACEG,KAAK6tB,WAAW1Q,QAChBnd,KAAKoiB,YAAc,EACnBpiB,KAAK+F,KAAO,EACZ/F,KAAKgG,OAAS,EACdhG,KAAKgD,KAAO8nB,GAAMY,YACpB,GAAC,CAAA1sB,IAAA,WAAAa,MAED,SAASsiB,GACP,IAAMhH,EAAanb,KAAKwN,IAAIgL,iBAAiBxY,KAAKgD,MAE9C0qB,EAAkBtB,OACpBtrB,QAAQC,IAAI,iBAAmBf,KAAKgD,KAAO,WAAamY,GAE1D,IAAM+S,EAAWluB,KAAKgD,KAChBmrB,EAAanuB,KAAKouB,kBAAkBjM,EAAOhH,GAC3CkT,EAAeF,EAAWvU,mBAChCuU,EAAWvU,oBAAqB,EAEhC,IAAMzN,EAAOnM,KAAKsuB,YAAYH,GACzBE,IACHruB,KAAK4tB,cAAc5tB,KAAKgD,MAAM+qB,GAAK5hB,GAGrC,IAAMoiB,EAAUvuB,KAAKiuB,QAAQ9L,EAAOhW,GAKpC,OAHIuhB,EAAkBtB,OACpBtrB,QAAQC,IAAI,uBAAyBf,KAAK4tB,cAAcM,GAAUM,iBAE7DD,CACT,GAAC,CAAAvvB,IAAA,UAAAa,MAED,SAAQsiB,EAAOsM,GACTf,EAAkBtB,OACpBtrB,QAAQC,IAAI,uBAAyB0tB,EAAIhV,SAEvCgV,EAAIjN,eAENxhB,KAAK0uB,gBAAgB1uB,KAAK6tB,WAAY1L,EAAOsM,GAK/C,IAHA,IAAIvd,EAAIiR,EAAM8G,GAAG,GACbvf,EAAI+kB,IAEC,CAEHf,EAAkBtB,OACpBtrB,QAAQC,IAAI,kCAAoC2I,EAAE+P,SAuBpD,IAAI3V,EAAS9D,KAAK2uB,uBAAuBjlB,EAAGwH,GAM5C,GAJe,OAAXpN,IACFA,EAAS9D,KAAK4uB,mBAAmBzM,EAAOzY,EAAGwH,IAGzCpN,IAAWge,GAAaE,MAC1B,MASF,GAHI9Q,IAAMxL,GAAMuB,KACdjH,KAAK2oB,QAAQxG,GAEXre,EAAO0d,gBACTxhB,KAAK0uB,gBAAgB1uB,KAAK6tB,WAAY1L,EAAOre,GACzCoN,IAAMxL,GAAMuB,KACd,MAGJiK,EAAIiR,EAAM8G,GAAG,GACbvf,EAAI5F,CACN,CACA,OAAO9D,KAAK6uB,aAAa7uB,KAAK6tB,WAAY1L,EAAOzY,EAAE+P,QAASvI,EAC9D,GAEA,CAAAlS,IAAA,yBAAAa,MAWA,SAAuB6J,EAAGwH,GACxB,GAAgB,OAAZxH,EAAE6X,OAAkBrQ,EAAIwc,EAAkBoB,cAAgB5d,EAAIwc,EAAkBqB,aAClF,OAAO,KAGT,IAAIjrB,EAAS4F,EAAE6X,MAAMrQ,EAAIwc,EAAkBoB,cAO3C,YANe/qB,IAAXD,IACFA,EAAS,MAEP4pB,EAAkBtB,OAAoB,OAAXtoB,GAC7BhD,QAAQC,IAAI,eAAiB2I,EAAEmB,YAAc,YAAc/G,EAAO+G,aAE7D/G,CACT,GAEA,CAAA9E,IAAA,qBAAAa,MAYA,SAAmBsiB,EAAOzY,EAAGwH,GAC3B,IAAM8d,EAAQ,IAAI5B,GAKlB,OAFAptB,KAAKivB,sBAAsB9M,EAAOzY,EAAE+P,QAASuV,EAAO9d,GAEzB,IAAvB8d,EAAMzH,MAAMlnB,QAET2uB,EAAMpV,oBAGT5Z,KAAKkvB,WAAWxlB,EAAGwH,EAAG4Q,GAAaE,OAG9BF,GAAaE,OAGfhiB,KAAKkvB,WAAWxlB,EAAGwH,EAAG,KAAM8d,EACrC,GAAC,CAAAhwB,IAAA,eAAAa,MAED,SAAaguB,EAAY1L,EAAO6M,EAAO9d,GACrC,GAAiC,OAA7BlR,KAAK6tB,WAAWL,SAAmB,CACrC,IAAM9L,EAAsBmM,EAAWL,SAAS9L,oBAEhD,OADA1hB,KAAKmvB,OAAOhN,EAAOT,EAAqB1hB,KAAKoiB,WAAYyL,EAAW9f,MAAO8f,EAAW9nB,KAAM8nB,EAAW7nB,QAChG6nB,EAAWL,SAAS/L,UAC7B,CAEE,GAAIvQ,IAAMxL,GAAMuB,KAAOkb,EAAMpU,QAAU/N,KAAKoiB,WAC1C,OAAO1c,GAAMuB,IAEf,MAAM,IAAIuf,GAA0BxmB,KAAKyQ,MAAO0R,EAAOniB,KAAKoiB,WAAY4M,EAE5E,GAEA,CAAAhwB,IAAA,wBAAAa,MAKA,SAAsBsiB,EAAOiN,EAASJ,EAAO9d,GAI3C,IADA,IAAIme,EAAUrX,GAAIqB,mBACTlZ,EAAI,EAAGA,EAAIivB,EAAQ7H,MAAMlnB,OAAQF,IAAK,CAC7C,IAAMmvB,EAAMF,EAAQ7H,MAAMpnB,GACpBovB,EAA+BD,EAAIjlB,MAAQglB,EACjD,IAAIE,IAAgCD,EAAI1M,+BAAxC,CAGI8K,EAAkBtB,OACpBtrB,QAAQC,IAAI,qBAAsBf,KAAKwvB,aAAate,GAAIoe,EAAItuB,SAAShB,KAAKyQ,OAAO,IAEnF,IAAK,IAAIrD,EAAI,EAAGA,EAAIkiB,EAAIllB,MAAMwD,YAAYvN,OAAQ+M,IAAK,CACrD,IAAMU,EAAQwhB,EAAIllB,MAAMwD,YAAYR,GAC9BtJ,EAAS9D,KAAKyvB,mBAAmB3hB,EAAOoD,GAC9C,GAAe,OAAXpN,EAAiB,CACnB,IAAI4d,EAAsB4N,EAAI5N,oBACF,OAAxBA,IACFA,EAAsBA,EAAoBgO,qBAAqBvN,EAAMpU,MAAQ/N,KAAKoiB,aAEpF,IAAMuN,EAAoBze,IAAMxL,GAAMuB,IAChC0D,EAAS,IAAI+X,GAAe,CAAEtY,MAAOtG,EAAQ4d,oBAAqBA,GAAuB4N,GAC3FtvB,KAAKovB,QAAQjN,EAAOxX,EAAQqkB,EAAOO,GAA8B,EAAMI,KAGzEN,EAAUC,EAAIjlB,IAElB,CACF,CApBA,CAqBF,CACF,GAAC,CAAArL,IAAA,SAAAa,MAED,SAAOsiB,EAAOT,EAAqBU,EAAYrU,EAAOhI,EAAM6pB,GACtDlC,EAAkBtB,OACpBtrB,QAAQC,IAAI,cAAe2gB,GAG7BS,EAAMK,KAAKzU,GACX/N,KAAK+F,KAAOA,EACZ/F,KAAKgG,OAAS4pB,EACc,OAAxBlO,GAA+C,OAAf1hB,KAAKyQ,OACvCiR,EAAoB5e,QAAQ9C,KAAKyQ,MAAO0R,EAAOC,EAEnD,GAAC,CAAApjB,IAAA,qBAAAa,MAED,SAAmBiO,EAAOoD,GACxB,OAAIpD,EAAM+hB,QAAQ3e,EAAG,EAAG4Z,GAAMqC,gBACrBrf,EAAMhK,OAEN,IAEX,GAAC,CAAA9E,IAAA,oBAAAa,MAED,SAAkBsiB,EAAOlZ,GAGvB,IAFA,IAAM6mB,EAAiB7c,GAAkBE,MACnCsG,EAAU,IAAI2T,GACXjtB,EAAI,EAAGA,EAAI8I,EAAE2E,YAAYvN,OAAQF,IAAK,CAC7C,IAAM2D,EAASmF,EAAE2E,YAAYzN,GAAG2D,OAC1BwrB,EAAM,IAAI5M,GAAe,CAAEtY,MAAOtG,EAAQuG,IAAKlK,EAAI,EAAGmJ,QAASwmB,GAAkB,MACvF9vB,KAAKovB,QAAQjN,EAAOmN,EAAK7V,GAAS,GAAO,GAAO,EAClD,CACA,OAAOA,CACT,GAEA,CAAAza,IAAA,UAAAa,MAUA,SAAQsiB,EAAOxX,EAAQ8O,EAAS8V,EAA8BQ,EAAaJ,GACzE,IAAIL,EAAM,KAIV,GAHI5B,EAAkBtB,OACpBtrB,QAAQC,IAAI,WAAa4J,EAAO3J,SAAShB,KAAKyQ,OAAO,GAAQ,KAE3D9F,EAAOP,iBAAiBwE,GAAe,CAQzC,GAPI8e,EAAkBtB,QACD,OAAfpsB,KAAKyQ,MACP3P,QAAQC,IAAI,+BAAgCf,KAAKyQ,MAAMD,UAAU7F,EAAOP,MAAM1H,WAAYiI,GAE1F7J,QAAQC,IAAI,4BAA6B4J,IAGtB,OAAnBA,EAAOrB,SAAoBqB,EAAOrB,QAAQ0mB,eAAgB,CAC5D,GAAuB,OAAnBrlB,EAAOrB,SAAoBqB,EAAOrB,QAAQyJ,UAE5C,OADA0G,EAAQ5Q,IAAI8B,IACL,EAEP8O,EAAQ5Q,IAAI,IAAI6Z,GAAe,CAAEtY,MAAOO,EAAOP,MAAOd,QAAS2J,GAAkBE,OAASxI,IAC1F4kB,GAA+B,CAEnC,CACA,GAAuB,OAAnB5kB,EAAOrB,UAAqBqB,EAAOrB,QAAQyJ,UAC7C,IAAK,IAAI5S,EAAI,EAAGA,EAAIwK,EAAOrB,QAAQjJ,OAAQF,IACzC,GAAIwK,EAAOrB,QAAQ8J,eAAejT,KAAO8S,GAAkBI,mBAAoB,CAC7E,IAAMsE,EAAahN,EAAOrB,QAAQsI,UAAUzR,GACtC2T,EAAc9T,KAAKwN,IAAIkH,OAAO/J,EAAOrB,QAAQ8J,eAAejT,IAClEmvB,EAAM,IAAI5M,GAAe,CAAEtY,MAAO0J,EAAaxK,QAASqO,GAAchN,GACtE4kB,EAA+BvvB,KAAKovB,QAClCjN,EACAmN,EACA7V,EACA8V,EACAQ,EACAJ,EAEJ,CAGJ,OAAOJ,CACT,CAEK5kB,EAAOP,MAAMuD,wBACX4hB,GAAiC5kB,EAAOiY,gCAC3CnJ,EAAQ5Q,IAAI8B,GAGhB,IAAK,IAAIyC,EAAI,EAAGA,EAAIzC,EAAOP,MAAMwD,YAAYvN,OAAQ+M,IAAK,CACxD,IAAMU,EAAQnD,EAAOP,MAAMwD,YAAYR,GAE3B,QADZkiB,EAAMtvB,KAAKiwB,iBAAiB9N,EAAOxX,EAAQmD,EAAO2L,EAASsW,EAAaJ,MAEtEJ,EAA+BvvB,KAAKovB,QAClCjN,EACAmN,EACA7V,EACA8V,EACAQ,EACAJ,GAGN,CACA,OAAOJ,CACT,GAEA,CAAAvwB,IAAA,mBAAAa,MACA,SAAiBsiB,EAAOxX,EAAQmD,EAAO2L,EAASsW,EAAaJ,GAC3D,IAAIL,EAAM,KACV,GAAIxhB,EAAMoB,oBAAsBtL,GAAWQ,KAAM,CAC/C,IAAMuT,EAAa9D,GAA2Bc,OAAOhK,EAAOrB,QAASwE,EAAMmB,YAAYpE,aACvFykB,EAAM,IAAI5M,GAAe,CAAEtY,MAAO0D,EAAMhK,OAAQwF,QAASqO,GAAchN,EACzE,KAAO,IAAImD,EAAMoB,oBAAsBtL,GAAWe,WAChD,KAAM,qDACD,GAAImJ,EAAMoB,oBAAsBtL,GAAWS,UAmB5CqpB,EAAkBtB,OACpBtrB,QAAQC,IAAI,aAAe+M,EAAMpL,UAAY,IAAMoL,EAAMwO,WAE3D7C,EAAQG,oBAAqB,EACzB5Z,KAAKkwB,kBAAkB/N,EAAOrU,EAAMpL,UAAWoL,EAAMwO,UAAWyT,KAClET,EAAM,IAAI5M,GAAe,CAAEtY,MAAO0D,EAAMhK,QAAU6G,SAE/C,GAAImD,EAAMoB,oBAAsBtL,GAAWW,OAChD,GAAuB,OAAnBoG,EAAOrB,SAAoBqB,EAAOrB,QAAQ0mB,eAAgB,CAa5D,IAAMtO,EAAsBO,GAAoBkO,OAC9CxlB,EAAO+W,oBACP1hB,KAAKwN,IAAI+K,aAAazK,EAAMnL,cAE9B2sB,EAAM,IAAI5M,GAAe,CAAEtY,MAAO0D,EAAMhK,OAAQ4d,oBAAqBA,GAAuB/W,EAC9F,MAEE2kB,EAAM,IAAI5M,GAAe,CAAEtY,MAAO0D,EAAMhK,QAAU6G,QAE3CmD,EAAMoB,oBAAsBtL,GAAWM,QAChDorB,EAAM,IAAI5M,GAAe,CAAEtY,MAAO0D,EAAMhK,QAAU6G,GAElDmD,EAAMoB,oBAAsBtL,GAAWU,MACvCwJ,EAAMoB,oBAAsBtL,GAAWO,OACvC2J,EAAMoB,oBAAsBtL,GAAWY,KAEnCmrB,GACE7hB,EAAM+hB,QAAQnqB,GAAMuB,IAAK,EAAG6jB,GAAMqC,kBACpCmC,EAAM,IAAI5M,GAAe,CAAEtY,MAAO0D,EAAMhK,QAAU6G,GAGxD,CACA,OAAO2kB,CACT,GAEA,CAAAtwB,IAAA,oBAAAa,MAqBA,SAAkBsiB,EAAOzf,EAAW4Z,EAAWyT,GAE7C,GAAmB,OAAf/vB,KAAKyQ,MACP,OAAO,EAET,IAAKsf,EACH,OAAO/vB,KAAKyQ,MAAM+L,QAAQ,KAAM9Z,EAAW4Z,GAE7C,IAAM8T,EAAcpwB,KAAKgG,OACnBqqB,EAAYrwB,KAAK+F,KACjBgI,EAAQoU,EAAMpU,MACduiB,EAASnO,EAAM0J,OACrB,IAEE,OADA7rB,KAAK2oB,QAAQxG,GACNniB,KAAKyQ,MAAM+L,QAAQ,KAAM9Z,EAAW4Z,EAC7C,CAAE,QACAtc,KAAKgG,OAASoqB,EACdpwB,KAAK+F,KAAOsqB,EACZlO,EAAMK,KAAKzU,GACXoU,EAAMgK,QAAQmE,EAChB,CACF,GAAC,CAAAtxB,IAAA,kBAAAa,MAED,SAAgB0wB,EAAUpO,EAAOqL,GAC/B+C,EAASxiB,MAAQoU,EAAMpU,MACvBwiB,EAASxqB,KAAO/F,KAAK+F,KACrBwqB,EAASvqB,OAAShG,KAAKgG,OACvBuqB,EAAS/C,SAAWA,CACtB,GAAC,CAAAxuB,IAAA,aAAAa,MAED,SAAW2wB,EAAOC,EAAIC,EAAIC,GAOxB,QANW5sB,IAAP2sB,IACFA,EAAK,WAEM3sB,IAAT4sB,IACFA,EAAO,MAEE,OAAPD,GAAwB,OAATC,EAAe,CAYhC,IAAMtC,EAAesC,EAAK/W,mBAK1B,GAJA+W,EAAK/W,oBAAqB,EAE1B8W,EAAK1wB,KAAKsuB,YAAYqC,GAElBtC,EACF,OAAOqC,CAEX,CAEA,OAAID,EAAK/C,EAAkBoB,cAAgB2B,EAAK/C,EAAkBqB,eAI9DrB,EAAkBtB,OACpBtrB,QAAQC,IAAI,QAAUyvB,EAAQ,OAASE,EAAK,SAAWD,GAErC,OAAhBD,EAAMjP,QAERiP,EAAMjP,MAAQ,IAEhBiP,EAAMjP,MAAMkP,EAAK/C,EAAkBoB,cAAgB4B,GAT1CA,CAYX,GAEA,CAAA1xB,IAAA,cAAAa,MAMA,SAAY4Z,GAGV,IAFA,IAAMmX,EAAW,IAAItP,GAAS,KAAM7H,GAChCoX,EAA+B,KAC1B1wB,EAAI,EAAGA,EAAIsZ,EAAQ8N,MAAMlnB,OAAQF,IAAK,CAC7C,IAAMmvB,EAAM7V,EAAQ8N,MAAMpnB,GAC1B,GAAImvB,EAAIllB,iBAAiBwE,GAAe,CACtCiiB,EAA+BvB,EAC/B,KACF,CACF,CACqC,OAAjCuB,IACFD,EAASpP,eAAgB,EACzBoP,EAASlP,oBAAsBmP,EAA6BnP,oBAC5DkP,EAASnP,WAAazhB,KAAKwN,IAAI8K,gBAAgBuY,EAA6BzmB,MAAM1H,YAEpF,IAAMwgB,EAAMljB,KAAK4tB,cAAc5tB,KAAKgD,MAC9B4I,EAAWsX,EAAIxO,OAAOrV,IAAIuxB,GAChC,GAAiB,OAAbhlB,EACF,OAAOA,EAET,IAAMklB,EAAWF,EAKjB,OAJAE,EAASjmB,YAAcqY,EAAIxO,OAAOrU,OAClCoZ,EAAQsX,aAAY,GACpBD,EAASrX,QAAUA,EACnByJ,EAAIxO,OAAO7L,IAAIioB,GACRA,CACT,GAAC,CAAA9xB,IAAA,SAAAa,MAED,SAAOmD,GACL,OAAOhD,KAAK4tB,cAAc5qB,EAC5B,GAEA,CAAAhE,IAAA,UAAAa,MACA,SAAQsiB,GAEN,OAAOA,EAAMvP,QAAQ5S,KAAKoiB,WAAYD,EAAMpU,MAAQ,EACtD,GAAC,CAAA/O,IAAA,UAAAa,MAED,SAAQsiB,GACUA,EAAM8G,GAAG,KACT,KAAK7K,WAAW,IAC9Bpe,KAAK+F,MAAQ,EACb/F,KAAKgG,OAAS,GAEdhG,KAAKgG,QAAU,EAEjBmc,EAAMwG,SACR,GAAC,CAAA3pB,IAAA,eAAAa,MAED,SAAamxB,GACX,OAAY,IAARA,EACK,MAEA,IAAM9jB,OAAOC,aAAa6jB,GAAM,GAE3C,KAACtD,CAAA,CAlmB2B,G,otBAqmB9BA,GAAkBtB,OAAQ,EAC1BsB,GAAkBuD,WAAY,EAE9BvD,GAAkBoB,aAAe,EACjCpB,GAAkBqB,aAAe,ICtoB1B,IAAMmC,GAAc,WACzB,SAAAA,EAAYC,EAAM9mB,I,4FAAKtK,CAAA,KAAAmxB,GACrBlxB,KAAKqK,IAAMA,EACXrK,KAAKmxB,KAAOA,CACd,C,UAIC,O,EAJAD,G,EAAA,EAAAlyB,IAAA,WAAAa,MAED,WACE,MAAO,IAAMG,KAAKmxB,KAAO,KAAOnxB,KAAKqK,IAAM,GAC7C,M,gFAAC6mB,CAAA,CARwB,G,otBCHpB,IAAME,GAAO,WAClB,SAAAA,K,4FAAcrxB,CAAA,KAAAqxB,GACZpxB,KAAKwH,KAAO,CAAC,CACf,C,UAcC,O,EAdA4pB,G,EAAA,EAAApyB,IAAA,MAAAa,MAED,SAAIb,GACF,OAAOgB,KAAKwH,KAAK,KAAOxI,IAAQ,IAClC,GAAC,CAAAA,IAAA,MAAAa,MAED,SAAIb,EAAKa,GACPG,KAAKwH,KAAK,KAAOxI,GAAOa,CAC1B,GAAC,CAAAb,IAAA,SAAAa,MAED,WAAS,IAAAyC,EAAA,KACP,OAAOpD,OAAOuI,KAAKzH,KAAKwH,MACrBE,QAAO,SAAC1I,GAAG,OAAKA,EAAI2I,WAAW,KAAK,IACpCd,KAAI,SAAC7H,GAAG,OAAKsD,EAAKkF,KAAKxI,EAAI,GAAEgB,KAClC,M,gFAACoxB,CAAA,CAjBiB,GCgBPC,GAAiB,CAsB5BC,IAAK,EAoBLC,GAAI,EAoBJC,yBAA0B,EA+F1BC,oCAAqC,SAAUzuB,EAAMyW,GAMnD,GAAI4X,GAAeK,2BAA2BjY,GAC5C,OAAO,EAGT,GAAIzW,IAASquB,GAAeC,KAItB7X,EAAQG,mBAAoB,CAG9B,IADA,IAAM+X,EAAM,IAAIrY,GACPnZ,EAAI,EAAGA,EAAIsZ,EAAQ8N,MAAMlnB,OAAQF,IAAK,CAC7C,IAAI0Q,EAAI4I,EAAQ8N,MAAMpnB,GACtB0Q,EAAI,IAAInG,GAAU,CAAEJ,gBAAiBnC,GAAgBG,MAAQuI,GAC7D8gB,EAAI9oB,IAAIgI,EACV,CACA4I,EAAUkY,CACZ,CAIF,IAAMC,EAAUP,GAAeQ,yBAAyBpY,GACxD,OAAO4X,GAAeS,qBAAqBF,KAAaP,GAAeU,6BAA6BtY,EACtG,EAYAuY,yBAA0B,SAAUvY,GAClC,IAAK,IAAItZ,EAAI,EAAGA,EAAIsZ,EAAQ8N,MAAMlnB,OAAQF,IAAK,CAE7C,GADUsZ,EAAQ8N,MAAMpnB,GAClBiK,iBAAiBwE,GACrB,OAAO,CAEX,CACA,OAAO,CACT,EAYA8iB,2BAA4B,SAAUjY,GACpC,IAAK,IAAItZ,EAAI,EAAGA,EAAIsZ,EAAQ8N,MAAMlnB,OAAQF,IAAK,CAE7C,KADUsZ,EAAQ8N,MAAMpnB,GAChBiK,iBAAiBwE,IACvB,OAAO,CAEX,CACA,OAAO,CACT,EAgJAqjB,2BAA4B,SAAUL,GACpC,OAAOP,GAAea,mBAAmBN,EAC3C,EAUAO,mBAAoB,SAAUP,GAC5B,OAAQP,GAAee,wBAAwBR,EACjD,EASAQ,wBAAyB,SAAUR,GACjC,IAAK,IAAIzxB,EAAI,EAAGA,EAAIyxB,EAAQvxB,OAAQF,IAAK,CAEvC,GAAoB,IADPyxB,EAAQzxB,GACZE,OACP,OAAO,CAEX,CACA,OAAO,CACT,EAUAyxB,qBAAsB,SAAUF,GAC9B,IAAK,IAAIzxB,EAAI,EAAGA,EAAIyxB,EAAQvxB,OAAQF,IAAK,CAEvC,GADayxB,EAAQzxB,GACZE,OAAS,EAChB,OAAO,CAEX,CACA,OAAO,CACT,EASAgyB,gBAAiB,SAAUT,GAEzB,IADA,IAAIxH,EAAQ,KACHjqB,EAAI,EAAGA,EAAIyxB,EAAQvxB,OAAQF,IAAK,CACvC,IAAM0hB,EAAO+P,EAAQzxB,GACrB,GAAc,OAAViqB,EACFA,EAAQvI,OACH,GAAIA,IAASuI,EAClB,OAAO,CAEX,CACA,OAAO,CACT,EASAkI,aAAc,SAAUV,GACtB,IAAMW,EAAMlB,GAAemB,QAAQZ,GACnC,OAAmB,IAAfW,EAAIlyB,OACCkyB,EAAIE,WAEJza,GAAIqB,kBAEf,EAUAmZ,QAAS,SAAUZ,GACjB,IAAMW,EAAM,IAAI9b,GAIhB,OAHAmb,EAAQ/qB,KAAI,SAAUgb,GACpB0Q,EAAIG,GAAG7Q,EACT,IACO0Q,CACT,EAWAV,yBAA0B,SAAUpY,GAClC,IAAMkZ,EAAe,IAAIze,GAezB,OAdAye,EAAarrB,aAAe,SAAUgoB,GACpCxvB,EAAS4W,UAAU4Y,EAAIllB,MAAMS,YAAaykB,EAAIhmB,QAChD,EACAqpB,EAAaprB,eAAiB,SAAUqrB,EAAIC,GAC1C,OAAOD,EAAGxoB,MAAMS,cAAgBgoB,EAAGzoB,MAAMS,aAAe+nB,EAAGtpB,QAAQ/C,OAAOssB,EAAGvpB,QAC/E,EACAmQ,EAAQ8N,MAAM1gB,KAAI,SAAUyoB,GAC1B,IAAIzN,EAAO8Q,EAAatzB,IAAIiwB,GACf,OAATzN,IACFA,EAAO,IAAIpL,GACXkc,EAAazsB,IAAIopB,EAAKzN,IAExBA,EAAKhZ,IAAIymB,EAAIjlB,IACf,IACOsoB,EAAaG,WACtB,EAUAC,iBAAkB,SAAUtZ,GAC1B,IAAM8F,EAAI,IAAI6R,GASd,OARA3X,EAAQ8N,MAAM1gB,KAAI,SAAUgK,GAC1B,IAAIgR,EAAOtC,EAAElgB,IAAIwR,EAAEzG,OACN,OAATyX,IACFA,EAAO,IAAIpL,GACX8I,EAAErZ,IAAI2K,EAAEzG,MAAOyX,IAEjBA,EAAKhZ,IAAIgI,EAAExG,IACb,IACOkV,CACT,EAEAwS,6BAA8B,SAAUtY,GAEtC,IADA,IAAM1R,EAASspB,GAAe0B,iBAAiBtZ,GAAS1R,SAC/C5H,EAAI,EAAGA,EAAI4H,EAAO1H,OAAQF,IACjC,GAAyB,IAArB4H,EAAO5H,GAAGE,OACZ,OAAO,EAGX,OAAO,CACT,EAEA6xB,mBAAoB,SAAUN,GAE5B,IADA,IAAIrpB,EAAS,KACJpI,EAAI,EAAGA,EAAIyxB,EAAQvxB,OAAQF,IAAK,CACvC,IACM6yB,EADOpB,EAAQzxB,GACDsyB,WACpB,GAAe,OAAXlqB,EACFA,EAASyqB,OACJ,GAAIzqB,IAAWyqB,EAEpB,OAAOhb,GAAIqB,kBAEf,CACA,OAAO9Q,CACT,G,otBC/iBK,IAAM0qB,GAAU,WACrB,SAAAA,EAAYC,I,4FAAgBnzB,CAAA,KAAAkzB,GAC1BjzB,KAAKkzB,eAAiBA,GAAkBhf,GACxClU,KAAKmzB,SAAW,IAAInzB,KAAKkzB,cAC3B,C,UAcC,O,EAdAD,G,EAAA,EAAAj0B,IAAA,MAAAa,MAED,SAAIwG,EAAGC,GACL,IAAMod,EAAI1jB,KAAKmzB,SAAS9zB,IAAIgH,IAAM,KAClC,OAAa,OAANqd,EAAa,KAAOA,EAAErkB,IAAIiH,IAAM,IACzC,GAAC,CAAAtH,IAAA,MAAAa,MAED,SAAIwG,EAAGC,EAAGrH,GACR,IAAIykB,EAAI1jB,KAAKmzB,SAAS9zB,IAAIgH,IAAM,KACtB,OAANqd,IACFA,EAAI,IAAI1jB,KAAKkzB,eACblzB,KAAKmzB,SAASjtB,IAAIG,EAAGqd,IAEvBA,EAAExd,IAAII,EAAGrH,EACX,M,gFAACg0B,CAAA,CAlBoB,G,grDC8PhB,IAAMG,GAAkB,SAAAzF,I,uRAAAzrB,CAAAkxB,EAAStR,IAAT,I,MAAA3f,EAAAC,GAAAgxB,GAC7B,SAAAA,EAAYhrB,EAAQoF,EAAKogB,EAAe7L,GAAoB,IAAAzf,EA0BjC,O,4FA1BiCvC,CAAA,KAAAqzB,IAC1D9wB,EAAAH,EAAAzC,KAAA,KAAM8N,EAAKuU,IACN3Z,OAASA,EACd9F,EAAKsrB,cAAgBA,EAErBtrB,EAAK+wB,eAAiBhC,GAAeE,GAErCjvB,EAAKsmB,OAAS,KACdtmB,EAAKgxB,YAAc,EACnBhxB,EAAKixB,cAAgB,KACrBjxB,EAAKkxB,KAAO,KAUZlxB,EAAK6S,WAAa,KAClB7S,EAAK8pB,OAAQ,EACb9pB,EAAKmxB,eAAgB,EACrBnxB,EAAKoxB,WAAY,EACjBpxB,EAAKkR,eAAgB,EACrBlR,EAAK2uB,WAAY,EACjB3uB,EAAKqxB,aAAc,EAAMrxB,CAC3B,CAugDC,O,EAvgDA8wB,E,EAAA,EAAAp0B,IAAA,QAAAa,MAED,WAAS,GAAC,CAAAb,IAAA,kBAAAa,MAEV,SAAgBsiB,EAAOvJ,EAAUvQ,IAC3BrI,KAAKosB,OAASpsB,KAAKwT,gBACrB1S,QAAQC,IACN,4BACE6X,EACA,gBACA5Y,KAAK4zB,iBAAiBzR,GACtB,SACAA,EAAMmI,GAAG,GAAGvkB,KACZ,IACAoc,EAAMmI,GAAG,GAAGtkB,QAGlBhG,KAAK4oB,OAASzG,EACdniB,KAAKszB,YAAcnR,EAAMpU,MACzB/N,KAAKuzB,cAAgBlrB,EAErB,IAAM6a,EAAMljB,KAAK4tB,cAAchV,GAC/B5Y,KAAKwzB,KAAOtQ,EACZ,IAAM3D,EAAI4C,EAAM0J,OACV9d,EAAQoU,EAAMpU,MAIpB,IACE,IAAIggB,EASJ,GAAW,QALTA,EAHE7K,EAAI2Q,cAGD3Q,EAAI4Q,wBAAwB9zB,KAAKoI,OAAO2rB,iBAGxC7Q,EAAI6K,IAEM,CACM,OAAjB1lB,IACFA,EAAegK,GAAYc,OAEzBnT,KAAKosB,OACPtrB,QAAQC,IACN,uBACEmiB,EAAItK,SACJ,gBACA5Y,KAAK4zB,iBAAiBzR,GACtB,kBACA9Z,EAAarH,SAAShB,KAAKoI,OAAOoI,YAIxC,IACI2d,EAAanuB,KAAKouB,kBAAkBlL,EAAIkE,cAAe/U,GAAYc,OADvD,GAGZ+P,EAAI2Q,eAON3Q,EAAI6K,GAAGtU,QAAU0U,EACjBA,EAAanuB,KAAKg0B,sBAAsB7F,GACxCJ,EAAK/tB,KAAKsuB,YAAYpL,EAAK,IAAI5B,GAAS,KAAM6M,IAC9CjL,EAAI+Q,wBAAwBj0B,KAAKoI,OAAO2rB,gBAAiBhG,KAEzDA,EAAK/tB,KAAKsuB,YAAYpL,EAAK,IAAI5B,GAAS,KAAM6M,IAC9CjL,EAAI6K,GAAKA,EAEb,CACA,IAAM1jB,EAAMrK,KAAKiuB,QAAQ/K,EAAK6K,EAAI5L,EAAOpU,EAAO1F,GAIhD,OAHIrI,KAAKosB,OACPtrB,QAAQC,IAAI,yBAA2BmiB,EAAIliB,SAAShB,KAAKoI,OAAOuE,aAAc3M,KAAKoI,OAAOwE,gBAErFvC,CACT,CAAE,QACArK,KAAKwzB,KAAO,KACZxzB,KAAKmV,WAAa,KAClBgN,EAAMK,KAAKzU,GACXoU,EAAMgK,QAAQ5M,EAChB,CACF,GAEA,CAAAvgB,IAAA,UAAAa,MAgCA,SAAQqjB,EAAK6K,EAAI5L,EAAOC,EAAY/Z,GAelC,IAAIgC,GAdArK,KAAKosB,OAASpsB,KAAKwT,gBACrB1S,QAAQC,IACN,oBACEmiB,EAAItK,SACJ,eACAmV,EACA,YACA/tB,KAAK4zB,iBAAiBzR,GACtB,SACAA,EAAMmI,GAAG,GAAGvkB,KACZ,IACAoc,EAAMmI,GAAG,GAAGtkB,QAIlB,IAAIkuB,EAAYnG,EAEZ/tB,KAAKosB,OACPtrB,QAAQC,IAAI,QAAUgtB,GAGxB,IADA,IAAI7c,EAAIiR,EAAM8G,GAAG,KACR,CAEP,IAAIkL,EAAIn0B,KAAK2uB,uBAAuBuF,EAAWhjB,GAI/C,GAHU,OAANijB,IACFA,EAAIn0B,KAAK4uB,mBAAmB1L,EAAKgR,EAAWhjB,IAE1CijB,IAAMrS,GAAaE,MAAO,CAU5B,IAAMzN,EAAIvU,KAAKo0B,YAAYjS,EAAO9Z,EAAc6rB,EAAUza,QAAS2I,GAGnE,GAFAD,EAAMK,KAAKJ,IACX/X,EAAMrK,KAAKq0B,wDAAwDH,EAAUza,QAASpR,MAC1E2P,GAAIqB,mBACd,OAAOhP,EAEP,MAAMkK,CAEV,CACA,GAAI4f,EAAExS,qBAAuB3hB,KAAKqzB,iBAAmBhC,GAAeC,IAAK,CAEvE,IAAI3X,EAAkB,KACtB,GAAqB,OAAjBwa,EAAEvS,WAAqB,CACrB5hB,KAAKosB,OACPtrB,QAAQC,IAAI,8CAEd,IAAMuzB,EAAgBnS,EAAMpU,MAK5B,GAJIumB,IAAkBlS,GACpBD,EAAMK,KAAKJ,GAGkB,KAD/BzI,EAAkB3Z,KAAKu0B,oBAAoBJ,EAAEvS,WAAYvZ,GAAc,IACnDhI,OAIlB,OAHIL,KAAKosB,OACPtrB,QAAQC,IAAI,mBAEP4Y,EAAgB8Y,WAErB6B,IAAkBlS,GAGpBD,EAAMK,KAAK8R,EAEf,CACIt0B,KAAKixB,WACPnwB,QAAQC,IAAI,uBAAyBsH,EAAe,OAAS8rB,GAE/D,IACMhG,EAAanuB,KAAKouB,kBAAkBlL,EAAIkE,cAAe/e,GAD7C,GAIhB,OAFArI,KAAK6jB,4BAA4BX,EAAKvJ,EAAiBwa,EAAE1a,QAAS2I,EAAYD,EAAMpU,OACpF1D,EAAMrK,KAAKw0B,uBAAuBtR,EAAKiR,EAAGhG,EAAYhM,EAAOC,EAAY/Z,EAE3E,CACA,GAAI8rB,EAAE3S,cAAe,CACnB,GAAqB,OAAjB2S,EAAEvS,WACJ,OAAOuS,EAAE1S,WAEX,IAAMa,EAAYH,EAAMpU,MACxBoU,EAAMK,KAAKJ,GACX,IAAMP,EAAO7hB,KAAKu0B,oBAAoBJ,EAAEvS,WAAYvZ,GAAc,GAClE,GAAoB,IAAhBwZ,EAAKxhB,OACP,MAAML,KAAKo0B,YAAYjS,EAAO9Z,EAAc8rB,EAAE1a,QAAS2I,GAClD,OAAoB,IAAhBP,EAAKxhB,QAIdL,KAAK4jB,gBAAgBV,EAAKiR,EAAG/R,EAAYE,GAAW,EAAOT,EAAMsS,EAAE1a,SAH5DoI,EAAK4Q,UAMhB,CACAyB,EAAYC,EAERjjB,IAAMxL,GAAMuB,MACdkb,EAAMwG,UACNzX,EAAIiR,EAAM8G,GAAG,GAEjB,CACF,GAEA,CAAAjqB,IAAA,yBAAAa,MAWA,SAAuBq0B,EAAWhjB,GAChC,IAAMqQ,EAAQ2S,EAAU3S,MACxB,OAAc,OAAVA,EACK,KAEAA,EAAMrQ,EAAI,IAAM,IAE3B,GAEA,CAAAlS,IAAA,qBAAAa,MAYA,SAAmBqjB,EAAKgR,EAAWhjB,GACjC,IAAM8d,EAAQhvB,KAAKy0B,gBAAgBP,EAAUza,QAASvI,GAAG,GACzD,GAAc,OAAV8d,EAEF,OADAhvB,KAAKkvB,WAAWhM,EAAKgR,EAAWhjB,EAAG4Q,GAAaE,OACzCF,GAAaE,MAGtB,IAAImS,EAAI,IAAI7S,GAAS,KAAM0N,GAErB0F,EAAe10B,KAAKsyB,aAAatD,GAEvC,GAAIhvB,KAAKosB,MAAO,CACd,IAAMuI,EAAatD,GAAeQ,yBAAyB7C,GAC3DluB,QAAQC,IACN,kBACE6F,GAAc+tB,GAEd,aACA3F,EACA,aACA0F,EACA,wBACArD,GAAec,mBAAmBwC,GAClC,qBACA30B,KAAKinB,mBAAmB+H,GAE9B,CAsBA,OArBI0F,IAAiB1c,GAAIqB,oBAEvB8a,EAAE3S,eAAgB,EAClB2S,EAAE1a,QAAQC,UAAYgb,EACtBP,EAAE1S,WAAaiT,GACNrD,GAAeI,oCAAoCzxB,KAAKqzB,eAAgBrE,KAEjFmF,EAAE1a,QAAQE,gBAAkB3Z,KAAKinB,mBAAmB+H,GACpDmF,EAAExS,qBAAsB,EAExBwS,EAAE3S,eAAgB,EAClB2S,EAAE1S,WAAa0S,EAAE1a,QAAQE,gBAAgB8Y,YAEvC0B,EAAE3S,eAAiB2S,EAAE1a,QAAQG,qBAC/B5Z,KAAK40B,kBAAkBT,EAAGn0B,KAAKwN,IAAIqnB,iBAAiB3R,EAAItK,WACnC,OAAjBub,EAAEvS,aACJuS,EAAE1S,WAAazJ,GAAIqB,qBAIvB8a,EAAIn0B,KAAKkvB,WAAWhM,EAAKgR,EAAWhjB,EAAGijB,EAEzC,GAAC,CAAAn1B,IAAA,oBAAAa,MAED,SAAkB2tB,EAAUsH,GAG1B,IAAMC,EAAQD,EAAclnB,YAAYvN,OAGlC20B,EAAyBh1B,KAAKi1B,8BAA8BzH,EAAS/T,SACrEyb,EAAYl1B,KAAKm1B,qBAAqBH,EAAwBxH,EAAS/T,QAASsb,GACpE,OAAdG,GACF1H,EAAS5L,WAAa5hB,KAAKo1B,wBAAwBJ,EAAwBE,GAC3E1H,EAAS/L,WAAazJ,GAAIqB,oBAK1BmU,EAAS/L,WAAauT,EAAuBvC,UAEjD,GAEA,CAAAzzB,IAAA,yBAAAa,MACA,SACEqjB,EACAiR,EACApG,EACA5L,EACAC,EACA/Z,IAEIrI,KAAKosB,OAASpsB,KAAKwT,gBACrB1S,QAAQC,IAAI,0BAA4BgtB,GAE1C,IAEIiB,EADAqG,GAAkB,EAElBjgB,EAAW2Y,EACf5L,EAAMK,KAAKJ,GAGX,IAFA,IAAIlR,EAAIiR,EAAM8G,GAAG,GACbyL,GAAgB,IACX,CAGP,GAAc,QADd1F,EAAQhvB,KAAKy0B,gBAAgBrf,EAAUlE,GATzB,IAUM,CAUlB,IAAMqD,EAAIvU,KAAKo0B,YAAYjS,EAAO9Z,EAAc+M,EAAUgN,GAC1DD,EAAMK,KAAKJ,GACX,IAAM/X,EAAMrK,KAAKq0B,wDAAwDjf,EAAU/M,GACnF,GAAIgC,IAAQ2N,GAAIqB,mBACd,OAAOhP,EAEP,MAAMkK,CAEV,CACA,IAAMogB,EAAatD,GAAeQ,yBAAyB7C,GAa3D,GAZIhvB,KAAKosB,OACPtrB,QAAQC,IACN,iBACE4zB,EACA,aACAtD,GAAeiB,aAAaqC,GAC5B,gCACAtD,GAAeY,2BAA2B0C,IAGhD3F,EAAMtV,UAAY1Z,KAAKsyB,aAAatD,GAEhCA,EAAMtV,YAAc1B,GAAIqB,mBAAoB,CAC9Cqb,EAAe1F,EAAMtV,UACrB,KACF,CAAO,GAAI1Z,KAAKqzB,iBAAmBhC,GAAeG,0BAEhD,IADAkD,EAAerD,GAAeY,2BAA2B0C,MACpC3c,GAAIqB,mBACvB,WAKF,GAAIgY,GAAec,mBAAmBwC,IAAetD,GAAegB,gBAAgBsC,GAAa,CAC/FU,GAAkB,EAClBX,EAAerD,GAAea,mBAAmByC,GACjD,KACF,CAKFvf,EAAW4Z,EACP9d,IAAMxL,GAAMuB,MACdkb,EAAMwG,UACNzX,EAAIiR,EAAM8G,GAAG,GAEjB,CAIA,OAAI+F,EAAMtV,YAAc1B,GAAIqB,oBAC1BrZ,KAAK8jB,yBAAyBZ,EAAKwR,EAAc1F,EAAO5M,EAAYD,EAAMpU,OACnE2mB,IA6BT10B,KAAK4jB,gBAAgBV,EAAKiR,EAAG/R,EAAYD,EAAMpU,MAAOsnB,EAAiB,KAAMrG,GAEtE0F,EACT,GAAC,CAAA11B,IAAA,kBAAAa,MAED,SAAgBuvB,EAASle,EAAGqI,GACtBvZ,KAAKosB,OACPtrB,QAAQC,IAAI,yCAA2CquB,GAEjC,OAApBpvB,KAAKmV,aACPnV,KAAKmV,WAAa,IAAI8d,IAiBxB,IAfA,IAAMqC,EAAe,IAAIhc,GAAaC,GAYlCgc,EAAoB,KAGfp1B,EAAI,EAAGA,EAAIivB,EAAQ7H,MAAMlnB,OAAQF,IAAK,CAC7C,IAAM0Q,EAAIue,EAAQ7H,MAAMpnB,GAIxB,GAHIH,KAAKosB,OACPtrB,QAAQC,IAAI,WAAaf,KAAKwvB,aAAate,GAAK,OAASL,GAEvDA,EAAEzG,iBAAiBwE,IACjB2K,GAAWrI,IAAMxL,GAAMuB,OACC,OAAtBsuB,IACFA,EAAoB,IAEtBA,EAAkBvtB,KAAK6I,GACnB7Q,KAAK0zB,WACP5yB,QAAQC,IAAI,SAAW8P,EAAI,+BAKjC,IAAK,IAAIzD,EAAI,EAAGA,EAAIyD,EAAEzG,MAAMwD,YAAYvN,OAAQ+M,IAAK,CACnD,IAAMU,EAAQ+C,EAAEzG,MAAMwD,YAAYR,GAC5BtJ,EAAS9D,KAAKyvB,mBAAmB3hB,EAAOoD,GAC9C,GAAe,OAAXpN,EAAiB,CACnB,IAAMwrB,EAAM,IAAI5kB,GAAU,CAAEN,MAAOtG,GAAU+M,GAC7CykB,EAAazsB,IAAIymB,EAAKtvB,KAAKmV,YACvBnV,KAAK0zB,WACP5yB,QAAQC,IAAI,SAAWuuB,EAAM,mBAEjC,CACF,CACF,CAEA,IAAIN,EAAQ,KA2BZ,GAhB0B,OAAtBuG,GAA8BrkB,IAAMxL,GAAMuB,MACV,IAA9BquB,EAAa/N,MAAMlnB,QAMZL,KAAKsyB,aAAagD,KAAkBtd,GAAIqB,sBADjD2V,EAAQsG,GAUE,OAAVtG,EAAgB,CAClBA,EAAQ,IAAI1V,GAAaC,GAGzB,IAFA,IAAMic,EAAc,IAAInuB,GAClBsoB,EAAoBze,IAAMxL,GAAMuB,IAC7BvG,EAAI,EAAGA,EAAI40B,EAAa/N,MAAMlnB,OAAQK,IAC7CV,KAAKovB,QAAQkG,EAAa/N,MAAM7mB,GAAIsuB,EAAOwG,GAAa,EAAOjc,EAASoW,EAE5E,CA6BA,GA5BIze,IAAMxL,GAAMuB,MAkBd+nB,EAAQhvB,KAAKy1B,mCAAmCzG,EAAOA,IAAUsG,IAUzC,OAAtBC,KAAgChc,IAAY8X,GAAeW,yBAAyBhD,IACtF,IAAK,IAAIzjB,EAAI,EAAGA,EAAIgqB,EAAkBl1B,OAAQkL,IAC5CyjB,EAAMnmB,IAAI0sB,EAAkBhqB,GAAIvL,KAAKmV,YAQzC,OAJInV,KAAKwT,eACP1S,QAAQC,IAAI,mBAAqBquB,EAAU,OAASJ,GAG3B,IAAvBA,EAAMzH,MAAMlnB,OACP,KAEA2uB,CAEX,GAEA,CAAAhwB,IAAA,qCAAAa,MAoBA,SAAmC4Z,EAASic,GAC1C,GAAIrE,GAAeK,2BAA2BjY,GAC5C,OAAOA,EAGT,IADA,IAAMlR,EAAS,IAAI+Q,GAAaG,EAAQF,SAC/BpZ,EAAI,EAAGA,EAAIsZ,EAAQ8N,MAAMlnB,OAAQF,IAAK,CAC7C,IAAMwK,EAAS8O,EAAQ8N,MAAMpnB,GAC7B,GAAIwK,EAAOP,iBAAiBwE,GAC1BrG,EAAOM,IAAI8B,EAAQ3K,KAAKmV,iBAG1B,GAAIugB,GAAmB/qB,EAAOP,MAAMuD,wBACf3N,KAAKwN,IAAIsL,WAAWnO,EAAOP,OAC/BkC,SAAS5G,GAAMxB,SAAU,CACtC,IAAMyxB,EAAiB31B,KAAKwN,IAAI4K,gBAAgBzN,EAAOP,MAAM1H,WAC7D6F,EAAOM,IAAI,IAAI6B,GAAU,CAAEN,MAAOurB,GAAkBhrB,GAAS3K,KAAKmV,WACpE,CAEJ,CACA,OAAO5M,CACT,GAAC,CAAAvJ,IAAA,oBAAAa,MAED,SAAkBoJ,EAAGgO,EAAKsC,GAExB,IAAMuW,EAAiBtb,GAAiCxU,KAAKwN,IAAKyJ,GAC5DwC,EAAU,IAAIH,GAAaC,GAE7BvZ,KAAKwT,eACP1S,QAAQC,IAAI,oCAAsCkI,EAAI,mBAAqB6mB,EAAe9uB,SAAShB,KAAKoI,SAG1G,IAAK,IAAIjI,EAAI,EAAGA,EAAI8I,EAAE2E,YAAYvN,OAAQF,IAAK,CAC7C,IAAM2D,EAASmF,EAAE2E,YAAYzN,GAAG2D,OAC1B+M,EAAI,IAAInG,GAAU,CAAEN,MAAOtG,EAAQuG,IAAKlK,EAAI,EAAGmJ,QAASwmB,GAAkB,MAC1E0F,EAAc,IAAInuB,GACxBrH,KAAKovB,QAAQve,EAAG4I,EAAS+b,GAAa,EAAMjc,GAAS,EACvD,CACA,OAAOE,CACT,GAEA,CAAAza,IAAA,wBAAAa,MAwDA,SAAsB4Z,GAIpB,IAHA,IAAI9O,EACEirB,EAAiB,GACjBC,EAAY,IAAIvc,GAAaG,EAAQF,SAClCpZ,EAAI,EAAGA,EAAIsZ,EAAQ8N,MAAMlnB,OAAQF,IAGxC,GAAmB,KAFnBwK,EAAS8O,EAAQ8N,MAAMpnB,IAEZkK,IAAX,CAGA,IAAMyrB,EAAiBnrB,EAAOL,gBAAgBd,eAAexJ,KAAKoI,OAAQpI,KAAKuzB,eACxD,OAAnBuC,IAIJF,EAAejrB,EAAOP,MAAMS,aAAeF,EAAOrB,QAC9CwsB,IAAmBnrB,EAAOL,gBAC5BurB,EAAUhtB,IAAI,IAAI6B,GAAU,CAAEJ,gBAAiBwrB,GAAkBnrB,GAAS3K,KAAKmV,YAE/E0gB,EAAUhtB,IAAI8B,EAAQ3K,KAAKmV,YAV7B,CAaF,IAAK,IAAIhV,EAAI,EAAGA,EAAIsZ,EAAQ8N,MAAMlnB,OAAQF,IAExC,GAAmB,KADnBwK,EAAS8O,EAAQ8N,MAAMpnB,IACZkK,IAAX,CAOA,IAAKM,EAAOF,2BAA4B,CACtC,IAAMnB,EAAUssB,EAAejrB,EAAOP,MAAMS,cAAgB,KAC5D,GAAgB,OAAZvB,GAAoBA,EAAQ/C,OAAOoE,EAAOrB,SAE5C,QAEJ,CACAusB,EAAUhtB,IAAI8B,EAAQ3K,KAAKmV,WAX3B,CAaF,OAAO0gB,CACT,GAAC,CAAA72B,IAAA,qBAAAa,MAED,SAAmBiO,EAAOgE,GACxB,OAAIhE,EAAM+hB,QAAQ/d,EAAO,EAAG9R,KAAKwN,IAAIqK,cAC5B/J,EAAMhK,OAEN,IAEX,GAAC,CAAA9E,IAAA,uBAAAa,MAED,SAAqBujB,EAAW3J,EAASsb,GAcvC,IADA,IAAIG,EAAY,GACP/0B,EAAI,EAAGA,EAAIsZ,EAAQ8N,MAAMlnB,OAAQF,IAAK,CAC7C,IAAM0Q,EAAI4I,EAAQ8N,MAAMpnB,GACpBijB,EAAU7L,IAAI1G,EAAExG,OAClB6qB,EAAUrkB,EAAExG,KAAOlC,GAAgB4tB,UAAUb,EAAUrkB,EAAExG,MAAQ,KAAMwG,EAAEvG,iBAE7E,CAEA,IADA,IAAI0rB,EAAY,EACP71B,EAAI,EAAGA,EAAI40B,EAAQ,EAAG50B,IAAK,CAClC,IAAMgxB,EAAO+D,EAAU/0B,IAAM,KAChB,OAATgxB,EACF+D,EAAU/0B,GAAKgI,GAAgBG,KACtB6oB,IAAShpB,GAAgBG,OAClC0tB,GAAa,EAEjB,CAQA,OANkB,IAAdA,IACFd,EAAY,MAEVl1B,KAAKosB,OACPtrB,QAAQC,IAAI,+BAAiC6F,GAAcsuB,IAEtDA,CACT,GAAC,CAAAl2B,IAAA,0BAAAa,MAED,SAAwBujB,EAAW8R,GAGjC,IAFA,IAAMe,EAAQ,GACVC,GAAoB,EACf/1B,EAAI,EAAGA,EAAI+0B,EAAU70B,OAAQF,IAAK,CACzC,IAAMgxB,EAAO+D,EAAU/0B,GAEL,OAAdijB,GAAsBA,EAAU7L,IAAIpX,IACtC81B,EAAMjuB,KAAK,IAAIkpB,GAAeC,EAAMhxB,IAElCgxB,IAAShpB,GAAgBG,OAC3B4tB,GAAoB,EAExB,CACA,OAAKA,EAGED,EAFE,IAGX,GAEA,CAAAj3B,IAAA,0DAAAa,MA8CA,SAAwD4Z,EAASpR,GAC/D,IAAMsoB,EAAO3wB,KAAKm2B,iCAAiC1c,EAASpR,GACtD+tB,EAAkBzF,EAAK,GACvB0F,EAAoB1F,EAAK,GAC3BtmB,EAAMrK,KAAKs2B,oCAAoCF,GACnD,OAAI/rB,IAAQ2N,GAAIqB,oBAKZgd,EAAkB9O,MAAMlnB,OAAS,IACnCgK,EAAMrK,KAAKs2B,oCAAoCD,MACnCre,GAAIqB,mBALThP,EAUF2N,GAAIqB,kBACb,GAAC,CAAAra,IAAA,sCAAAa,MAED,SAAoC4Z,GAElC,IADA,IAAMoI,EAAO,GACJ1hB,EAAI,EAAGA,EAAIsZ,EAAQ8N,MAAMlnB,OAAQF,IAAK,CAC7C,IAAM0Q,EAAI4I,EAAQ8N,MAAMpnB,IACpB0Q,EAAEtG,wBAA0B,GAAMsG,EAAEzG,iBAAiBwE,IAAiBiC,EAAEvH,QAAQ0mB,iBAC9EnO,EAAK6G,QAAQ7X,EAAExG,KAAO,GACxBwX,EAAK7Z,KAAK6I,EAAExG,IAGlB,CACA,OAAoB,IAAhBwX,EAAKxhB,OACA2X,GAAIqB,mBAEJvN,KAAKC,IAAItL,MAAM,KAAMohB,EAEhC,GAEA,CAAA7iB,IAAA,mCAAAa,MASA,SAAiC4Z,EAASpR,GAGxC,IAFA,IAAMkuB,EAAY,IAAIjd,GAAaG,EAAQF,SACrCid,EAAS,IAAIld,GAAaG,EAAQF,SAC/BpZ,EAAI,EAAGA,EAAIsZ,EAAQ8N,MAAMlnB,OAAQF,IAAK,CAC7C,IAAM0Q,EAAI4I,EAAQ8N,MAAMpnB,GACpB0Q,EAAEvG,kBAAoBnC,GAAgBG,KACNuI,EAAEvG,gBAAgBlB,SAASpJ,KAAKoI,OAAQC,GAExEkuB,EAAU1tB,IAAIgI,GAEd2lB,EAAO3tB,IAAIgI,GAGb0lB,EAAU1tB,IAAIgI,EAElB,CACA,MAAO,CAAC0lB,EAAWC,EACrB,GAEA,CAAAx3B,IAAA,sBAAAa,MAOA,SAAoB42B,EAAiBpuB,EAAcquB,GAEjD,IADA,IAAMC,EAAc,IAAIlgB,GACftW,EAAI,EAAGA,EAAIs2B,EAAgBp2B,OAAQF,IAAK,CAC/C,IAAMqe,EAAOiY,EAAgBt2B,GAC7B,GAAIqe,EAAK2S,OAAShpB,GAAgBG,KAAlC,CAOA,IAAMsuB,EAA4BpY,EAAK2S,KAAK/nB,SAASpJ,KAAKoI,OAAQC,GAIlE,IAHIrI,KAAKosB,OAASpsB,KAAKixB,YACrBnwB,QAAQC,IAAI,aAAeyd,EAAO,IAAMoY,GAEtCA,KACE52B,KAAKosB,OAASpsB,KAAKixB,YACrBnwB,QAAQC,IAAI,WAAayd,EAAKnU,KAEhCssB,EAAY9tB,IAAI2V,EAAKnU,MAChBqsB,GACH,KAXJ,MAJE,GADAC,EAAY9tB,IAAI2V,EAAKnU,MAChBqsB,EACH,KAiBN,CACA,OAAOC,CACT,GAOA,CAAA33B,IAAA,UAAAa,MACA,SAAQ8K,EAAQ8O,EAAS+b,EAAaqB,EAAmBtd,EAASoW,GAEhE3vB,KAAK82B,yBACHnsB,EACA8O,EACA+b,EACAqB,EACAtd,EANmB,EAQnBoW,EAEJ,GAAC,CAAA3wB,IAAA,2BAAAa,MAED,SAAyB8K,EAAQ8O,EAAS+b,EAAaqB,EAAmBtd,EAASwd,EAAOpH,GAIxF,IAHI3vB,KAAKwT,eAAiBxT,KAAKyzB,gBAC7B3yB,QAAQC,IAAI,WAAa4J,EAAO3J,SAAShB,KAAKoI,QAAQ,GAAQ,KAE5DuC,EAAOP,iBAAiBwE,GAAe,CAGzC,IAAKjE,EAAOrB,QAAQyJ,UAAW,CAC7B,IAAK,IAAI5S,EAAI,EAAGA,EAAIwK,EAAOrB,QAAQjJ,OAAQF,IACzC,GAAIwK,EAAOrB,QAAQ8J,eAAejT,KAAO8S,GAAkBI,mBAA3D,CAsBA,IAAMS,EAAc9T,KAAKwN,IAAIkH,OAAO/J,EAAOrB,QAAQ8J,eAAejT,IAC5DwX,EAAahN,EAAOrB,QAAQsI,UAAUzR,GACtC62B,EAAQ,CACZ5sB,MAAO0J,EACPzJ,IAAKM,EAAON,IACZf,QAASqO,EACTrN,gBAAiBK,EAAOL,iBAEpBuG,EAAI,IAAInG,GAAUssB,EAAO,MAI/BnmB,EAAEtG,wBAA0BI,EAAOJ,wBACnCvK,KAAK82B,yBACHjmB,EACA4I,EACA+b,EACAqB,EACAtd,EACAwd,EAAQ,EACRpH,EArBF,KArBA,CACE,GAAIpW,EAAS,CACXE,EAAQ5Q,IACN,IAAI6B,GACF,CACEN,MAAOO,EAAOP,MACdd,QAAS2J,GAAkBE,OAE7BxI,GAEF3K,KAAKmV,YAEP,QACF,CAEMnV,KAAKosB,OACPtrB,QAAQC,IAAI,oBAAsBf,KAAKi3B,YAAYtsB,EAAOP,MAAM1H,YAElE1C,KAAKk3B,SAASvsB,EAAQ8O,EAAS+b,EAAaqB,EAAmBtd,EAASwd,EAAOpH,EAGnF,CAwBF,MACF,CAAO,GAAIpW,EAGT,YADAE,EAAQ5Q,IAAI8B,EAAQ3K,KAAKmV,YAIrBnV,KAAKosB,OACPtrB,QAAQC,IAAI,oBAAsBf,KAAKi3B,YAAYtsB,EAAOP,MAAM1H,WAGtE,CACA1C,KAAKk3B,SAASvsB,EAAQ8O,EAAS+b,EAAaqB,EAAmBtd,EAASwd,EAAOpH,EACjF,GAEA,CAAA3wB,IAAA,WAAAa,MACA,SAAS8K,EAAQ8O,EAAS+b,EAAaqB,EAAmBtd,EAASwd,EAAOpH,GACxE,IAAM1mB,EAAI0B,EAAOP,MAEZnB,EAAE0E,wBACL8L,EAAQ5Q,IAAI8B,EAAQ3K,KAAKmV,YAI3B,IAAK,IAAIhV,EAAI,EAAGA,EAAI8I,EAAE2E,YAAYvN,OAAQF,IACxC,GAAU,IAANA,IAAWH,KAAKm3B,wCAAwCxsB,GAA5D,CAEA,IAAMuG,EAAIjI,EAAE2E,YAAYzN,GAClBi3B,EAAqBP,KAAuB3lB,aAAa/L,IACzD0L,EAAI7Q,KAAKiwB,iBAAiBtlB,EAAQuG,EAAGkmB,EAA8B,IAAVL,EAAaxd,EAASoW,GACrF,GAAU,OAAN9e,EAAY,CACd,IAAIwmB,EAAWN,EACf,GAAIpsB,EAAOP,iBAAiBwE,GAAe,CAazC,GAPkB,OAAd5O,KAAKwzB,MAAiBxzB,KAAKwzB,KAAKK,eAC9B3iB,EAAEkL,4BAA8Bpc,KAAKwzB,KAAKpM,cAAc1kB,YAC1DmO,EAAEpG,4BAA6B,GAInCoG,EAAEtG,yBAA2B,EACzBirB,EAAY3sB,IAAIgI,KAAOA,EAEzB,SAEF4I,EAAQI,sBAAuB,EAC/Bwd,GAAY,EACRr3B,KAAKosB,OACPtrB,QAAQC,IAAI,wBAA0B8P,EAE1C,KAAO,CACL,IAAKK,EAAElN,WAAawxB,EAAY3sB,IAAIgI,KAAOA,EAEzC,SAEEK,aAAalM,IAEXqyB,GAAY,IACdA,GAAY,EAGlB,CACAr3B,KAAK82B,yBACHjmB,EACA4I,EACA+b,EACA4B,EACA7d,EACA8d,EACA1H,EAEJ,CAlD6E,CAoDjF,GAAC,CAAA3wB,IAAA,0CAAAa,MAED,SAAwC8K,GAEtC,IAAM1B,EAAI0B,EAAOP,MAMjB,GAAInB,EAAEyE,YAAcH,GAASkB,gBAAiB,OAAO,EACrD,GACExF,EAAEyE,YAAcH,GAASkB,kBACxBxF,EAAE2S,sBACHjR,EAAOrB,QAAQyJ,WACfpI,EAAOrB,QAAQ0mB,eAEf,OAAO,EAIT,IADA,IAAMsH,EAAU3sB,EAAOrB,QAAQjJ,OACtBF,EAAI,EAAGA,EAAIm3B,EAASn3B,IAG3B,GADoBH,KAAKwN,IAAIkH,OAAO/J,EAAOrB,QAAQ8J,eAAejT,IAClDuC,YAAcuG,EAAEvG,UAAW,OAAO,EASpD,IANA,IACM60B,EADqBtuB,EAAE2E,YAAY,GAAG9J,OACAmX,SAASpQ,YAC/C2sB,EAAgBx3B,KAAKwN,IAAIkH,OAAO6iB,GAI7Bp3B,EAAI,EAAGA,EAAIm3B,EAASn3B,IAAK,CAEhC,IAAMs3B,EAAoB9sB,EAAOrB,QAAQ8J,eAAejT,GAClD2T,EAAc9T,KAAKwN,IAAIkH,OAAO+iB,GAEpC,GAAuC,IAAnC3jB,EAAYlG,YAAYvN,SAAiByT,EAAYlG,YAAY,GAAG5J,UAAW,OAAO,EAG1F,IAAM0zB,EAAoB5jB,EAAYlG,YAAY,GAAG9J,OACrD,IAAIgQ,EAAYpG,YAAcH,GAASgB,WAAampB,IAAsBzuB,IAKtE6K,IAAgB0jB,GAIhBE,IAAsBF,IAKxBE,EAAkBhqB,YAAcH,GAASgB,WACA,IAAzCmpB,EAAkB9pB,YAAYvN,SAC9Bq3B,EAAkB9pB,YAAY,GAAG5J,WACjC0zB,EAAkB9pB,YAAY,GAAG9J,SAAWmF,GAK9C,OAAO,CACT,CACA,OAAO,CACT,GAAC,CAAAjK,IAAA,cAAAa,MAED,SAAYkO,GACV,OAAoB,OAAhB/N,KAAKoI,QAAmB2F,GAAS,EAC5B/N,KAAKoI,OAAOoI,UAAUzC,GAEtB,SAAWA,EAAQ,GAE9B,GAAC,CAAA/O,IAAA,mBAAAa,MAED,SAAiB8K,EAAQuG,EAAG2lB,EAAmBc,EAAWpe,EAASoW,GACjE,OAAQze,EAAEhC,mBACR,KAAKtL,GAAWQ,KACd,OAAOpE,KAAK43B,eAAejtB,EAAQuG,GACrC,KAAKtN,GAAWe,WACd,OAAO3E,KAAK63B,qBAAqBltB,EAAQuG,EAAG2lB,EAAmBc,EAAWpe,GAC5E,KAAK3V,GAAWS,UACd,OAAOrE,KAAK83B,eAAentB,EAAQuG,EAAG2lB,EAAmBc,EAAWpe,GACtE,KAAK3V,GAAWW,OACd,OAAOvE,KAAK+3B,iBAAiBptB,EAAQuG,GACvC,KAAKtN,GAAWM,QACd,OAAO,IAAIwG,GAAU,CAAEN,MAAO8G,EAAEpN,QAAU6G,GAC5C,KAAK/G,GAAWU,KAChB,KAAKV,GAAWO,MAChB,KAAKP,GAAWY,IAGd,OAAImrB,GACEze,EAAE2e,QAAQnqB,GAAMuB,IAAK,EAAG,GACnB,IAAIyD,GAAU,CAAEN,MAAO8G,EAAEpN,QAAU6G,GAGvC,KACT,QACE,OAAO,KAEb,GAAC,CAAA3L,IAAA,mBAAAa,MAED,SAAiB8K,EAAQuG,GACvB,GAAIlR,KAAKosB,MAAO,CACd,IAAMre,GAA2B,IAAnBmD,EAAEvO,YAAqB,MAAQuO,EAAEvO,YAC/C7B,QAAQC,IAAI,eAAiBmQ,EAAExO,UAAY,IAAMqL,EACnD,CACA,OAAO,IAAIrD,GAAU,CAAEN,MAAO8G,EAAEpN,QAAU6G,EAC5C,GAAC,CAAA3L,IAAA,uBAAAa,MAED,SAAqB8K,EAAQqtB,EAAInB,EAAmBc,EAAWpe,GACzDvZ,KAAKosB,QACPtrB,QAAQC,IAAI,2BAA6B81B,EAAoB,KAAOmB,EAAG9uB,WAAa,4BAChE,OAAhBlJ,KAAKoI,QACPtH,QAAQC,IAAI,+BAAiC6F,GAAc5G,KAAKoI,OAAO6vB,4BAG3E,IAAIpnB,EAAI,KACR,GAAIgmB,GAAqBc,EACvB,GAAIpe,EAAS,CAKX,IAAM2e,EAAkBl4B,KAAK4oB,OAAO7a,MACpC/N,KAAK4oB,OAAOpG,KAAKxiB,KAAKszB,aACtB,IAAM6E,EAAeH,EAAGI,eAAehvB,SAASpJ,KAAKoI,OAAQpI,KAAKuzB,eAClEvzB,KAAK4oB,OAAOpG,KAAK0V,GACbC,IACFtnB,EAAI,IAAInG,GAAU,CAAEN,MAAO4tB,EAAGl0B,QAAU6G,GAE5C,KAAO,CACL,IAAM0tB,EAAYlwB,GAAgBsB,WAAWkB,EAAOL,gBAAiB0tB,EAAGI,gBACxEvnB,EAAI,IAAInG,GAAU,CAAEN,MAAO4tB,EAAGl0B,OAAQwG,gBAAiB+tB,GAAa1tB,EACtE,MAEAkG,EAAI,IAAInG,GAAU,CAAEN,MAAO4tB,EAAGl0B,QAAU6G,GAK1C,OAHI3K,KAAKosB,OACPtrB,QAAQC,IAAI,+BAAiC8P,GAExCA,CACT,GAAC,CAAA7R,IAAA,iBAAAa,MAED,SAAe8K,EAAQqtB,EAAInB,EAAmBc,EAAWpe,GACnDvZ,KAAKosB,QACPtrB,QAAQC,IACN,2BACE81B,EACA,KACAmB,EAAGt1B,UACH,IACAs1B,EAAG1b,UACH,mBACA0b,EAAG7b,gBAEa,OAAhBnc,KAAKoI,QACPtH,QAAQC,IAAI,+BAAiC6F,GAAc5G,KAAKoI,OAAO6vB,4BAG3E,IAAIpnB,EAAI,KACR,GAAIgmB,IAAuBmB,EAAG7b,gBAAkBwb,IAAeK,EAAG7b,gBAChE,GAAI5C,EAAS,CAKX,IAAM2e,EAAkBl4B,KAAK4oB,OAAO7a,MACpC/N,KAAK4oB,OAAOpG,KAAKxiB,KAAKszB,aACtB,IAAM6E,EAAeH,EAAGI,eAAehvB,SAASpJ,KAAKoI,OAAQpI,KAAKuzB,eAClEvzB,KAAK4oB,OAAOpG,KAAK0V,GACbC,IACFtnB,EAAI,IAAInG,GAAU,CAAEN,MAAO4tB,EAAGl0B,QAAU6G,GAE5C,KAAO,CACL,IAAM0tB,EAAYlwB,GAAgBsB,WAAWkB,EAAOL,gBAAiB0tB,EAAGI,gBACxEvnB,EAAI,IAAInG,GAAU,CAAEN,MAAO4tB,EAAGl0B,OAAQwG,gBAAiB+tB,GAAa1tB,EACtE,MAEAkG,EAAI,IAAInG,GAAU,CAAEN,MAAO4tB,EAAGl0B,QAAU6G,GAK1C,OAHI3K,KAAKosB,OACPtrB,QAAQC,IAAI,+BAAiC8P,GAExCA,CACT,GAAC,CAAA7R,IAAA,iBAAAa,MAED,SAAe8K,EAAQuG,GACjBlR,KAAKosB,OACPtrB,QAAQC,IAAI,aAAef,KAAKi3B,YAAY/lB,EAAEpN,OAAOpB,WAAa,SAAWiI,EAAOrB,SAEtF,IAAMwK,EAAc5C,EAAEjC,YAChB0I,EAAa9D,GAA2Bc,OAAOhK,EAAOrB,QAASwK,EAAYjJ,aACjF,OAAO,IAAIH,GAAU,CAAEN,MAAO8G,EAAEpN,OAAQwF,QAASqO,GAAchN,EACjE,GAAC,CAAA3L,IAAA,qBAAAa,MAED,SAAmB4Z,GACjB,IAAMmY,EAAUP,GAAeQ,yBAAyBpY,GACxD,OAAO4X,GAAemB,QAAQZ,EAChC,GAEA,CAAA5yB,IAAA,gCAAAa,MAoCA,SAA8B4Z,GAC5B,IAAIE,EAAkB,KAOtB,OANIF,EAAQC,YAAc1B,GAAIqB,oBAC5BM,EAAkB,IAAIlD,IACN5N,IAAI4Q,EAAQC,WAE5BC,EAAkBF,EAAQE,gBAErBA,CACT,GAAC,CAAA3a,IAAA,eAAAa,MAED,SAAaqR,GACX,GAAIA,IAAMxL,GAAMuB,IACd,MAAO,MAET,GAAoB,OAAhBjH,KAAKoI,QAAgD,OAA7BpI,KAAKoI,OAAOuE,aAAuB,CAC7D,KAAIuE,GAAKlR,KAAKoI,OAAOuE,aAAatM,QAAU6Q,GAAKlR,KAAKoI,OAAOwE,cAAcvM,QAKzE,OADaL,KAAKoI,OAAOuE,aAAauE,IAAMlR,KAAKoI,OAAOwE,cAAcsE,IACxD,IAAMA,EAAI,IAJxBpQ,QAAQC,IAASmQ,EAAI,wBAA0BlR,KAAKoI,OAAOuE,cAC3D7L,QAAQC,IAAI,GAAKf,KAAKoI,OAAO+c,iBAAiBmT,YAKlD,CACA,MAAO,GAAKpnB,CACd,GAAC,CAAAlS,IAAA,mBAAAa,MAED,SAAiBsiB,GACf,OAAOniB,KAAKwvB,aAAarN,EAAM8G,GAAG,GACpC,GAEA,CAAAjqB,IAAA,qBAAAa,MAKA,SAAmB04B,GACjBz3B,QAAQC,IAAI,sBAEZ,IADA,IAAMy3B,EAAOD,EAAKE,oBACTt4B,EAAI,EAAGA,EAAIq4B,EAAKn4B,OAAQF,IAAK,CACpC,IAAM0Q,EAAI2nB,EAAKr4B,GACX2N,EAAQ,WACZ,GAAI+C,EAAEzG,MAAMwD,YAAYvN,OAAS,EAAG,CAClC,IAAM6Q,EAAIL,EAAEzG,MAAMwD,YAAY,GAC1BsD,aAAahM,GACf4I,EAAQ,QAAU9N,KAAKwvB,aAAate,EAAEjN,OAC7BiN,aAAa9L,KAEtB0I,GADYoD,aAAa7L,GACV,IAAM,IAAM,OAAS6L,EAAEhL,IAE1C,CACApF,QAAQyiB,MAAM1S,EAAE7P,SAAShB,KAAKoI,QAAQ,GAAQ,IAAM0F,EACtD,CACF,GAAC,CAAA9O,IAAA,cAAAa,MAED,SAAYsiB,EAAO9Z,EAAcoR,EAAS2I,GACxC,OAAO,IAAI8D,GAAqBlmB,KAAKoI,OAAQ+Z,EAAOA,EAAM9iB,IAAI+iB,GAAaD,EAAMmI,GAAG,GAAI7Q,EAASpR,EACnG,GAAC,CAAArJ,IAAA,eAAAa,MAED,SAAa4Z,GAEX,IADA,IAAIpP,EAAM2N,GAAIqB,mBACLlZ,EAAI,EAAGA,EAAIsZ,EAAQ8N,MAAMlnB,OAAQF,IAAK,CAC7C,IAAM0Q,EAAI4I,EAAQ8N,MAAMpnB,GACxB,GAAIkK,IAAQ2N,GAAIqB,mBACdhP,EAAMwG,EAAExG,SACH,GAAIwG,EAAExG,MAAQA,EACnB,OAAO2N,GAAIqB,kBAEf,CACA,OAAOhP,CACT,GAEA,CAAArL,IAAA,aAAAa,MAoBA,SAAWqjB,EAAKsN,EAAOtf,EAAGwf,GAIxB,GAHI1wB,KAAKosB,OACPtrB,QAAQC,IAAI,QAAUyvB,EAAQ,OAASE,EAAK,SAAW1wB,KAAKwvB,aAAate,IAEhE,OAAPwf,EACF,OAAO,KAGT,GADAA,EAAK1wB,KAAKsuB,YAAYpL,EAAKwN,GACb,OAAVF,GAAkBtf,GAAK,GAAKA,EAAIlR,KAAKwN,IAAIqK,aAC3C,OAAO6Y,EAOT,GALoB,OAAhBF,EAAMjP,QACRiP,EAAMjP,MAAQ,IAEhBiP,EAAMjP,MAAMrQ,EAAI,GAAKwf,EAEjB1wB,KAAKosB,MAAO,CACd,IAAMzf,EAA+B,OAAhB3M,KAAKoI,OAAkB,KAAOpI,KAAKoI,OAAOuE,aACzDC,EAAgC,OAAhB5M,KAAKoI,OAAkB,KAAOpI,KAAKoI,OAAOwE,cAChE9L,QAAQC,IAAI,SAAWmiB,EAAIliB,SAAS2L,EAAcC,GACpD,CACA,OAAO8jB,CACT,GAEA,CAAA1xB,IAAA,cAAAa,MAeA,SAAYqjB,EAAKiR,GACf,GAAIA,IAAMrS,GAAaE,MACrB,OAAOmS,EAET,IAAMvoB,EAAWsX,EAAIxO,OAAOrV,IAAI80B,GAChC,OAAiB,OAAbvoB,GACE5L,KAAKwT,eAAe1S,QAAQC,IAAI,eAAiBozB,EAAI,WAClDvoB,IAETuoB,EAAEtpB,YAAcqY,EAAIxO,OAAOrU,OACtB8zB,EAAE1a,QAAQvO,WACbipB,EAAE1a,QAAQif,gBAAgB14B,MAC1Bm0B,EAAE1a,QAAQsX,aAAY,IAGpB/wB,KAAKwT,eAAe1S,QAAQC,IAAI,mBAAqBozB,GAEzDjR,EAAIxO,OAAO7L,IAAIsrB,GACXn0B,KAAKosB,OACPtrB,QAAQC,IAAI,yBAA2BozB,GAElCA,EACT,GAAC,CAAAn1B,IAAA,8BAAAa,MAED,SAA4BqjB,EAAKvJ,EAAiBF,EAAS2I,EAAYE,GACrE,GAAItiB,KAAKosB,OAASpsB,KAAK2zB,YAAa,CAClC,IAAMxoB,EAAW,IAAIL,GAASsX,EAAYE,EAAY,GACtDxhB,QAAQC,IACN,wCACEmiB,EAAItK,SACJ,IACAa,EACA,WACAzZ,KAAKoI,OAAO8e,iBAAiBtU,QAAQzH,GAE3C,CACoB,OAAhBnL,KAAKoI,QACPpI,KAAKoI,OACFykB,2BACAhJ,4BAA4B7jB,KAAKoI,OAAQ8a,EAAKd,EAAYE,EAAW3I,EAAiBF,EAE7F,GAAC,CAAAza,IAAA,2BAAAa,MAED,SAAyBqjB,EAAKzB,EAAYhI,EAAS2I,EAAYE,GAC7D,GAAItiB,KAAKosB,OAASpsB,KAAK2zB,YAAa,CAClC,IAAMxoB,EAAW,IAAIL,GAASsX,EAAYE,EAAY,GACtDxhB,QAAQC,IACN,qCACEmiB,EAAItK,SACJ,IACAa,EACA,WACAzZ,KAAKoI,OAAO8e,iBAAiBtU,QAAQzH,GAE3C,CACoB,OAAhBnL,KAAKoI,QACPpI,KAAKoI,OACFykB,2BACA/I,yBAAyB9jB,KAAKoI,OAAQ8a,EAAKd,EAAYE,EAAWb,EAAYhI,EAErF,GAEA,CAAAza,IAAA,kBAAAa,MACA,SAAgBqjB,EAAKiR,EAAG/R,EAAYE,EAAWa,EAAOC,EAAW3J,GAC/D,GAAIzZ,KAAKosB,OAASpsB,KAAK2zB,YAAa,CAClC,IAAMxoB,EAAW,IAAIL,GAASsX,EAAYE,EAAY,GACtDxhB,QAAQC,IACN,mBAAqBqiB,EAAY,IAAM3J,EAAU,WAAazZ,KAAKoI,OAAO8e,iBAAiBtU,QAAQzH,GAEvG,CACoB,OAAhBnL,KAAKoI,QACPpI,KAAKoI,OACFykB,2BACAjJ,gBAAgB5jB,KAAKoI,OAAQ8a,EAAKd,EAAYE,EAAWa,EAAOC,EAAW3J,EAElF,I,mFAAC2Z,CAAA,CAniD4B,G,otBCxPxB,IAAMuF,GAAsB,WACjC,SAAAA,K,4FAAc54B,CAAA,KAAA44B,GACZ34B,KAAK44B,MAAQ,IAAI1kB,EACnB,C,UAyBC,O,EAzBAykB,G,EAAA,EAAA35B,IAAA,SAAAK,IAED,WACE,OAAOW,KAAK44B,MAAMv4B,MACpB,GAEA,CAAArB,IAAA,MAAAa,MAKA,SAAIoX,GACF,GAAIA,IAAQhE,GAAkBE,MAC5B,OAAOF,GAAkBE,MAE3B,IAAMvH,EAAW5L,KAAK44B,MAAMv5B,IAAI4X,IAAQ,KACxC,OAAiB,OAAbrL,EACKA,GAET5L,KAAK44B,MAAM1yB,IAAI+Q,EAAKA,GACbA,EACT,GAAC,CAAAjY,IAAA,MAAAa,MAED,SAAIoX,GACF,OAAOjX,KAAK44B,MAAMv5B,IAAI4X,IAAQ,IAChC,M,gFAAC0hB,CAAA,CA5BgC,G,otBCR5B,IAAME,GAAiB,oBAAAA,K,4FAAA94B,CAAA,KAAA84B,EAAA,C,UAON,O,EAPMA,G,EAAA,EAAA75B,IAAA,gBAAAa,MAC5B,SAAci5B,GAAO,GAAC,CAAA95B,IAAA,iBAAAa,MAEtB,SAAei5B,GAAO,GAAC,CAAA95B,IAAA,iBAAAa,MAEvB,SAAei5B,GAAO,GAAC,CAAA95B,IAAA,gBAAAa,MAEvB,SAAci5B,GAAO,M,gFAACD,CAAA,CAPM,G,otBCAvB,IAAME,GAAgB,oBAAAA,K,4FAAAh5B,CAAA,KAAAg5B,EAAA,C,UAqBJ,O,EArBIA,G,EAAA,EAAA/5B,IAAA,QAAAa,MAC3B,SAAMoX,GACJ,OAAI3W,MAAMC,QAAQ0W,GACTA,EAAIpQ,KAAI,SAAU8L,GACvB,OAAOA,EAAMwc,OAAOnvB,KACtB,GAAGA,MAEIiX,EAAIkY,OAAOnvB,KAEtB,GAAC,CAAAhB,IAAA,gBAAAa,MAED,SAAcoX,GACZ,OAAIA,EAAIvE,SACC1S,KAAKg5B,MAAM/hB,EAAIvE,UAEf,IAEX,GAAC,CAAA1T,IAAA,gBAAAa,MAED,SAAci5B,GAAO,GAAC,CAAA95B,IAAA,iBAAAa,MAEtB,SAAei5B,GAAO,M,gFAACC,CAAA,CArBI,G,otBCGtB,IAAME,GAAe,oBAAAA,K,4FAAAl5B,CAAA,KAAAk5B,EAAA,C,UA+CzB,O,EA/CyBA,E,EAAA,EAAAj6B,IAAA,OAAAa,MAS1B,SAAKwkB,EAAUnT,GAEb,GADkBA,aAAaf,SAAgCpM,IAAlBmN,EAAEgoB,aAA6BhoB,EAAEgoB,cAE5E7U,EAAS8U,eAAejoB,QACnB,GAAIA,aAAahB,GACtBmU,EAAS+U,cAAcloB,OAClB,CACLlR,KAAKq5B,UAAUhV,EAAUnT,GACzB,IAAK,IAAI/Q,EAAI,EAAGA,EAAI+Q,EAAEJ,gBAAiB3Q,IAAK,CAC1C,IAAMwS,EAAQzB,EAAEF,SAAS7Q,GACzBH,KAAKs5B,KAAKjV,EAAU1R,EACtB,CACA3S,KAAKu5B,SAASlV,EAAUnT,EAC1B,CACF,GAEA,CAAAlS,IAAA,YAAAa,MAMA,SAAUwkB,EAAUnN,GAClB,IAAMD,EAAMC,EAAE9F,YACdiT,EAASmV,eAAeviB,GACxBA,EAAIoiB,UAAUhV,EAChB,GAEA,CAAArlB,IAAA,WAAAa,MAMA,SAASwkB,EAAUnN,GACjB,IAAMD,EAAMC,EAAE9F,YACd6F,EAAIsiB,SAASlV,GACbA,EAASoV,cAAcxiB,EACzB,I,mFAACgiB,CAAA,CA/CyB,G,grDAkD5BA,GAAgBvT,QAAU,IAAIuT,GCjDvB,IAAMS,GAAgB,SAAAtpB,I,uRAAAlO,CAAAw3B,EAASxpB,IAAT,I,MAAA/N,EAAAC,GAAAs3B,GAC3B,SAAAA,EAAYvqB,GAAQ,IAAA7M,EAGG,O,4FAHHvC,CAAA,KAAA25B,IAClBp3B,EAAAH,EAAAzC,KAAA,OACK+S,UAAY,KACjBnQ,EAAK6M,OAASA,EAAO7M,CACvB,CA4CC,O,EA5CAo3B,G,EAAA,EAAA16B,IAAA,WAAAa,MAED,SAASM,GACP,OAAO,IACT,GAAC,CAAAnB,IAAA,YAAAa,MAED,WACE,OAAOG,KAAKmP,MACd,GAAC,CAAAnQ,IAAA,YAAAa,MAED,WACE,OAAOG,KAAKyS,SACd,GAAC,CAAAzT,IAAA,aAAAa,MAED,WACE,OAAOG,KAAKmP,MACd,GAAC,CAAAnQ,IAAA,oBAAAa,MAED,WACE,GAAoB,OAAhBG,KAAKmP,OACP,OAAOrE,GAASC,iBAElB,IAAMjF,EAAa9F,KAAKmP,OAAOrJ,WAC/B,OAAO,IAAIgF,GAAShF,EAAYA,EAClC,GAAC,CAAA9G,IAAA,gBAAAa,MAED,WACE,OAAO,CACT,GAAC,CAAAb,IAAA,SAAAa,MAED,SAAOgT,GACL,OAAOA,EAAQumB,cAAcp5B,KAC/B,GAAC,CAAAhB,IAAA,UAAAa,MAED,WACE,OAAOG,KAAKmP,OAAOhJ,IACrB,GAAC,CAAAnH,IAAA,WAAAa,MAED,WACE,OAAIG,KAAKmP,OAAOxL,OAAS+B,GAAMuB,IACtB,QAEAjH,KAAKmP,OAAOhJ,IAEvB,M,gFAACuzB,CAAA,CAjD0B,G,grDCKtB,IAAMC,GAAa,SAAAC,I,uRAAA13B,CAAAy3B,EAASD,IAAT,I,MAAAv3B,EAAAC,GAAAu3B,GACxB,SAAAA,EAAYrsB,GAAO,O,4FAAAvN,CAAA,KAAA45B,GAAAx3B,EAAAzC,KAAA,KACX4N,EACR,CAQC,O,EARAqsB,G,EAAA,EAAA36B,IAAA,cAAAa,MAED,WACE,OAAO,CACT,GAAC,CAAAb,IAAA,SAAAa,MAED,SAAOgT,GACL,OAAOA,EAAQsmB,eAAen5B,KAChC,M,gFAAC25B,CAAA,CAXuB,G,grDCsBnB,IAAME,GAAiB,SAAAC,I,uRAAA53B,CAAA23B,EAASxnB,IAAT,I,MAAAlQ,EAAAC,GAAAy3B,GAC5B,SAAAA,EAAYtnB,EAAQwnB,GAAqB,IAAAz3B,EAgBjB,O,4FAhBiBvC,CAAA,KAAA85B,IACvCv3B,EAAAH,EAAAzC,KAAA,KAAM6S,EAAQwnB,IAQTrnB,SAAW,KAChBpQ,EAAKsD,MAAQ,KACbtD,EAAKuD,KAAO,KAKZvD,EAAKsoB,UAAY,KAAKtoB,CACxB,CAwJC,O,EAtJDu3B,E,EAAA,EAAA76B,IAAA,WAAAa,MACA,SAASoX,GAEPjX,KAAKyS,UAAYwE,EAAIxE,UACrBzS,KAAKwS,cAAgByE,EAAIzE,cACzBxS,KAAK0S,SAAW,KAChB1S,KAAK4F,MAAQqR,EAAIrR,MACjB5F,KAAK6F,KAAOoR,EAAIpR,KAEZoR,EAAIvE,WACN1S,KAAK0S,SAAW,GAEhBuE,EAAIvE,SAAS7L,KAAI,SAAU8L,GACrBA,aAAiBgnB,KACnB35B,KAAK0S,SAAS1K,KAAK2K,GACnBA,EAAMF,UAAYzS,KAEtB,GAAGA,MAEP,GAEA,CAAAhB,IAAA,YAAAa,MACA,SAAUwkB,GAAW,GAAC,CAAArlB,IAAA,WAAAa,MAEtB,SAASwkB,GAAW,GAEpB,CAAArlB,IAAA,WAAAa,MACA,SAAS8S,GAKP,OAJsB,OAAlB3S,KAAK0S,WACP1S,KAAK0S,SAAW,IAElB1S,KAAK0S,SAAS1K,KAAK2K,GACZA,CACT,GAEA,CAAA3T,IAAA,kBAAAa,MAIA,WACwB,OAAlBG,KAAK0S,UACP1S,KAAK0S,SAAS2Z,KAElB,GAAC,CAAArtB,IAAA,eAAAa,MAED,SAAayN,GACX,IAAMwrB,EAAO,IAAIY,GAAiBpsB,GAGlC,OAFAtN,KAAKg6B,SAASlB,GACdA,EAAKrmB,UAAYzS,KACV84B,CACT,GAAC,CAAA95B,IAAA,eAAAa,MAED,SAAao6B,GACX,IAAMnB,EAAO,IAAIa,GAAcM,GAG/B,OAFAj6B,KAAKg6B,SAASlB,GACdA,EAAKrmB,UAAYzS,KACV84B,CACT,GAAC,CAAA95B,IAAA,WAAAa,MAED,SAASM,EAAGwD,GAEV,GADAA,EAAOA,GAAQ,KACO,OAAlB3D,KAAK0S,UAAqBvS,EAAI,GAAKA,GAAKH,KAAK0S,SAASrS,OACxD,OAAO,KAET,GAAa,OAATsD,EACF,OAAO3D,KAAK0S,SAASvS,GAErB,IAAK,IAAIiN,EAAI,EAAGA,EAAIpN,KAAK0S,SAASrS,OAAQ+M,IAAK,CAC7C,IAAMuF,EAAQ3S,KAAK0S,SAAStF,GAC5B,GAAIuF,aAAiBhP,EAAM,CACzB,GAAU,IAANxD,EACF,OAAOwS,EAEPxS,GAAK,CAET,CACF,CACA,OAAO,IAEX,GAAC,CAAAnB,IAAA,WAAAa,MAED,SAASiS,EAAO3R,GACd,GAAsB,OAAlBH,KAAK0S,UAAqBvS,EAAI,GAAKA,GAAKH,KAAK0S,SAASrS,OACxD,OAAO,KAET,IAAK,IAAI+M,EAAI,EAAGA,EAAIpN,KAAK0S,SAASrS,OAAQ+M,IAAK,CAC7C,IAAMuF,EAAQ3S,KAAK0S,SAAStF,GAC5B,GAAIuF,aAAiBzC,IACfyC,EAAMxD,OAAOxL,OAASmO,EAAO,CAC/B,GAAU,IAAN3R,EACF,OAAOwS,EAEPxS,GAAK,CAET,CAEJ,CACA,OAAO,IACT,GAAC,CAAAnB,IAAA,YAAAa,MAED,SAAUiS,GACR,GAAsB,OAAlB9R,KAAK0S,SACP,MAAO,GAGP,IADA,IAAM6W,EAAS,GACNnc,EAAI,EAAGA,EAAIpN,KAAK0S,SAASrS,OAAQ+M,IAAK,CAC7C,IAAMuF,EAAQ3S,KAAK0S,SAAStF,GACxBuF,aAAiBzC,IACfyC,EAAMxD,OAAOxL,OAASmO,GACxByX,EAAOvhB,KAAK2K,EAGlB,CACA,OAAO4W,CAEX,GAAC,CAAAvqB,IAAA,sBAAAa,MAED,SAAoBq6B,EAAS/5B,GAC3B,OAAOH,KAAKgR,SAAS7Q,EAAG+5B,EAC1B,GAAC,CAAAl7B,IAAA,uBAAAa,MAED,SAAqBq6B,GACnB,GAAsB,OAAlBl6B,KAAK0S,SACP,MAAO,GAGP,IADA,IAAMynB,EAAW,GACR/sB,EAAI,EAAGA,EAAIpN,KAAK0S,SAASrS,OAAQ+M,IAAK,CAC7C,IAAMuF,EAAQ3S,KAAK0S,SAAStF,GACxBuF,aAAiBunB,GACnBC,EAASnyB,KAAK2K,EAElB,CACA,OAAOwnB,CAEX,GAAC,CAAAn7B,IAAA,gBAAAa,MAED,WACE,OAAsB,OAAlBG,KAAK0S,SACA,EAEA1S,KAAK0S,SAASrS,MAEzB,GAAC,CAAArB,IAAA,oBAAAa,MAED,WACE,OAAmB,OAAfG,KAAK4F,OAAgC,OAAd5F,KAAK6F,KACvBiF,GAASC,iBAET,IAAID,GAAS9K,KAAK4F,MAAME,WAAY9F,KAAK6F,KAAKC,WAEzD,I,mFAAC+zB,CAAA,CA1K2B,G,grDA6K9BxnB,GAAYc,MAAQ,IAAI0mB,GC1MjB,IAAMO,GAAsB,SAAAC,I,uRAAAn4B,CAAAk4B,EAASP,IAAT,I,MAAA13B,EAAAC,GAAAg4B,GACjC,SAAAA,EAAY7nB,EAAQwnB,EAAqBr3B,GAAW,IAAAJ,EAEvB,O,4FAFuBvC,CAAA,KAAAq6B,IAClD93B,EAAAH,EAAAzC,KAAA,KAAM6S,EAAQwnB,IACTr3B,UAAYA,EAAUJ,CAC7B,CAAC,O,EAAA83B,E,oFAAA,CAJgC,G,otBCI5B,IAAME,GAAa,WACxB,SAAAA,EAAYpX,EAAKvW,EAAcC,I,4FAAe7M,CAAA,KAAAu6B,GAC5Ct6B,KAAKkjB,IAAMA,EACXljB,KAAK2M,aAAeA,GAAgB,GACpC3M,KAAK4M,cAAgBA,GAAiB,EACxC,C,UAiDC,O,EAjDA0tB,E,EAAA,EAAAt7B,IAAA,WAAAa,MAED,WACE,GAAoB,OAAhBG,KAAKkjB,IAAI6K,GACX,OAAO,KAIT,IAFA,IAAIwM,EAAM,GACJ7lB,EAAS1U,KAAKkjB,IAAIsX,eACfr6B,EAAI,EAAGA,EAAIuU,EAAOrU,OAAQF,IAAK,CACtC,IAAMuJ,EAAIgL,EAAOvU,GACjB,GAAgB,OAAZuJ,EAAE6X,MAEJ,IADA,IAAM/U,EAAI9C,EAAE6X,MAAMlhB,OACT+M,EAAI,EAAGA,EAAIZ,EAAGY,IAAK,CAC1B,IAAM8D,EAAIxH,EAAE6X,MAAMnU,IAAM,KACd,OAAN8D,GAAgC,aAAlBA,EAAErG,cAMlB0vB,GADAA,GADAA,GADAA,GADAA,GADAA,EAAMA,EAAItpB,OAAOjR,KAAKy6B,eAAe/wB,KAC3BuH,OAAO,MACPA,OAAOjR,KAAK06B,aAAattB,KACzB6D,OAAO,OACPA,OAAOjR,KAAKy6B,eAAevpB,KAC3BD,OAAO,MAErB,CAEJ,CACA,OAAsB,IAAfspB,EAAIl6B,OAAe,KAAOk6B,CACnC,GAAC,CAAAv7B,IAAA,eAAAa,MAED,SAAaM,GACX,OAAU,IAANA,EACK,MACwB,OAAtBH,KAAK2M,cAAgD,OAAvB3M,KAAK4M,cACrC5M,KAAK2M,aAAaxM,EAAI,IAAMH,KAAK4M,cAAczM,EAAI,GAEnD+M,OAAOC,aAAahN,EAAI,EAEnC,GAAC,CAAAnB,IAAA,iBAAAa,MAED,SAAe6J,GACb,IAAMixB,GAAgBjxB,EAAE8X,cAAgB,IAAM,IAAM,IAAM9X,EAAEmB,aAAenB,EAAEiY,oBAAsB,IAAM,IACzG,OAAIjY,EAAE8X,cACiB,OAAjB9X,EAAEkY,WACG+Y,EAAe,KAAO/zB,GAAc8C,EAAEkY,YAEtC+Y,EAAe,KAAOjxB,EAAE+X,WAAWzgB,WAGrC25B,CAEX,I,mFAACL,CAAA,CAtDuB,G,grDCJnB,IAAMM,GAAkB,SAAAC,I,uRAAA34B,CAAA04B,EAASN,IAAT,I,MAAAn4B,EAAAC,GAAAw4B,GAC7B,SAAAA,EAAY1X,GAAK,O,4FAAAnjB,CAAA,KAAA66B,GAAAz4B,EAAAzC,KAAA,KACTwjB,EAAK,KACb,CAIC,O,EAJA0X,E,EAAA,EAAA57B,IAAA,eAAAa,MAED,SAAaM,GACX,MAAO,IAAM+M,OAAOC,aAAahN,GAAK,GACxC,I,mFAACy6B,CAAA,CAP4B,G,otBCMxB,IAAME,GAAG,WACd,SAAAA,EAAY1T,EAAexO,GAqBzB,G,4FArBmC7Y,CAAA,KAAA+6B,QAClB/2B,IAAb6U,IACFA,EAAW,GAKb5Y,KAAKonB,cAAgBA,EACrBpnB,KAAK4Y,SAAWA,EAKhB5Y,KAAK+6B,QAAU,IAAI1zB,GACnBrH,KAAK+tB,GAAK,KAMV/tB,KAAK6zB,eAAgB,EACjBzM,aAAyBzL,IACvByL,EAAcxL,qBAAsB,CACtC5b,KAAK6zB,eAAgB,EACrB,IAAMmH,EAAkB,IAAI1Z,GAAS,KAAM,IAAIhI,IAC/C0hB,EAAgBzZ,MAAQ,GACxByZ,EAAgBxZ,eAAgB,EAChCwZ,EAAgBrZ,qBAAsB,EACtC3hB,KAAK+tB,GAAKiN,CACZ,CAEJ,C,UAgHC,O,EAhHAF,G,EAAA,EAAA97B,IAAA,SAAAK,IAED,WACE,OAAOW,KAAK+6B,OACd,GAEA,CAAA/7B,IAAA,0BAAAa,MAUA,SAAwBqJ,GACtB,IAAKlJ,KAAK6zB,cACR,KAAM,6DAGR,OAAI3qB,EAAa,GAAKA,GAAclJ,KAAK+tB,GAAGxM,MAAMlhB,OACzC,KAEFL,KAAK+tB,GAAGxM,MAAMrY,IAAe,IACtC,GAEA,CAAAlK,IAAA,0BAAAa,MAUA,SAAwBqJ,EAAYiS,GAClC,IAAKnb,KAAK6zB,cACR,KAAM,6DAEJ3qB,EAAa,IASjBlJ,KAAK+tB,GAAGxM,MAAMrY,GAAciS,EAC9B,GAEA,CAAAnc,IAAA,mBAAAa,MAiBA,SAAiBg0B,GACf,GAAI7zB,KAAK6zB,gBAAkBA,EAAe,CAExC,GADA7zB,KAAK+6B,QAAU,IAAI1zB,GACfwsB,EAAe,CACjB,IAAMmH,EAAkB,IAAI1Z,GAAS,KAAM,IAAIhI,IAC/C0hB,EAAgBzZ,MAAQ,GACxByZ,EAAgBxZ,eAAgB,EAChCwZ,EAAgBrZ,qBAAsB,EACtC3hB,KAAK+tB,GAAKiN,CACZ,MACEh7B,KAAK+tB,GAAK,KAEZ/tB,KAAK6zB,cAAgBA,CACvB,CACF,GAEA,CAAA70B,IAAA,eAAAa,MAGA,WAEE,OADaG,KAAK+6B,QAAQhzB,SACd+B,MAAK,SAAUzD,EAAGC,GAC5B,OAAOD,EAAEwE,YAAcvE,EAAEuE,WAC3B,GACF,GAAC,CAAA7L,IAAA,WAAAa,MAED,SAAS8M,EAAcC,GAGrB,OAFAD,EAAeA,GAAgB,KAC/BC,EAAgBA,GAAiB,KACjB,OAAZ5M,KAAK+tB,GACA,GAEU,IAAIuM,GAAct6B,KAAM2M,EAAcC,GACvC5L,UACpB,GAAC,CAAAhC,IAAA,gBAAAa,MAED,WACE,OAAgB,OAAZG,KAAK+tB,GACA,GAEU,IAAI6M,GAAmB56B,MACxBgB,UACpB,M,gFAAC85B,CAAA,CAhJa,GCZT,SAASG,GAAkBC,GAEhC,IADA,IAAI3yB,EAAS,IAAI4yB,YAAYD,EAAI76B,QACxBF,EAAI,EAAGA,EAAI+6B,EAAI76B,OAAQF,IAC9BoI,EAAOpI,GAAK+6B,EAAI9c,WAAWje,GAE7B,OAAOoI,CACT,C,m0BCDO,IAAM6yB,GAAWv3B,IAAA,SAAAu3B,K,4FAAAr7B,CAAA,KAAAq7B,EAAA,I,grDCiBjB,ICdCj8B,GAYEk8B,GDEGC,GAAmB,SAAAC,I,uRAAAr5B,CAAAo5B,EAASF,IAAT,I,MAAAj5B,EAAAC,GAAAk5B,GAC9B,SAAAA,EAAYE,GAAa,IAAAl5B,EAyCC,O,4FAzCDvC,CAAA,KAAAu7B,IACvBh5B,EAAAH,EAAAzC,KAAA,OAEK87B,YAAcA,EAMnBl5B,EAAKinB,OAAS,GAcdjnB,EAAKyL,OAAS,EAkBdzL,EAAKm5B,YAAa,EAAMn5B,CAC1B,CAuTC,O,EAvTAg5B,E,EAAA,EAAAt8B,IAAA,OAAAa,MAED,WACE,OAAO,CACT,GAAC,CAAAb,IAAA,UAAAa,MAED,SAAQywB,GACN,GACD,CAAAtxB,IAAA,QAAAa,MAED,WACEG,KAAKwiB,KAAK,EACZ,GAAC,CAAAxjB,IAAA,OAAAa,MAED,SAAKkO,GACH/N,KAAK07B,WACL17B,KAAK+N,MAAQ/N,KAAK27B,gBAAgB5tB,EACpC,GAAC,CAAA/O,IAAA,MAAAa,MAED,SAAIkO,GAEF,OADA/N,KAAK07B,WACE17B,KAAKupB,OAAOxb,EACrB,GAAC,CAAA/O,IAAA,UAAAa,MAED,WAeE,KAbIG,KAAK+N,OAAS,IACZ/N,KAAKy7B,WAGQz7B,KAAK+N,MAAQ/N,KAAKupB,OAAOlpB,OAAS,EAGlCL,KAAK+N,MAAQ/N,KAAKupB,OAAOlpB,UAMvBL,KAAKipB,GAAG,KAAOvjB,GAAMuB,IACxC,MAAM,IAAIgJ,MAAM,sBAEdjQ,KAAK47B,KAAK57B,KAAK+N,MAAQ,KACzB/N,KAAK+N,MAAQ/N,KAAK27B,gBAAgB37B,KAAK+N,MAAQ,GAEnD,GAEA,CAAA/O,IAAA,OAAAa,MAOA,SAAKM,GACH,IAAMqM,EAAIrM,EAAIH,KAAKupB,OAAOlpB,OAAS,EACnC,QAAImM,EAAI,IACUxM,KAAK67B,MAAMrvB,IACTA,CAGtB,GAEA,CAAAxN,IAAA,QAAAa,MAKA,SAAM2M,GACJ,GAAIxM,KAAKy7B,WACP,OAAO,EAET,IAAK,IAAIt7B,EAAI,EAAGA,EAAIqM,EAAGrM,IAAK,CAC1B,IAAM+Q,EAAIlR,KAAKw7B,YAAY7O,YAG3B,GAFAzb,EAAEpL,WAAa9F,KAAKupB,OAAOlpB,OAC3BL,KAAKupB,OAAOvhB,KAAKkJ,GACbA,EAAEvN,OAAS+B,GAAMuB,IAEnB,OADAjH,KAAKy7B,YAAa,EACXt7B,EAAI,CAEf,CACA,OAAOqM,CACT,GAEA,CAAAxN,IAAA,YAAAa,MACA,SAAU+F,EAAOC,EAAMi2B,GAIrB,QAHc/3B,IAAV+3B,IACFA,EAAQ,MAENl2B,EAAQ,GAAKC,EAAO,EACtB,OAAO,KAET7F,KAAK07B,WACL,IAAMK,EAAS,GACXl2B,GAAQ7F,KAAKupB,OAAOlpB,SACtBwF,EAAO7F,KAAKupB,OAAOlpB,OAAS,GAE9B,IAAK,IAAIF,EAAIyF,EAAOzF,EAAI0F,EAAM1F,IAAK,CACjC,IAAM+Q,EAAIlR,KAAKupB,OAAOppB,GACtB,GAAI+Q,EAAEvN,OAAS+B,GAAMuB,IACnB,OAEY,OAAV60B,GAAkBA,EAAMxvB,SAAS4E,EAAEvN,QACrCo4B,EAAO/zB,KAAKkJ,EAEhB,CACA,OAAO6qB,CACT,GAAC,CAAA/8B,IAAA,KAAAa,MAED,SAAGM,GACD,OAAOH,KAAKsqB,GAAGnqB,GAAGwD,IACpB,GAAC,CAAA3E,IAAA,KAAAa,MAED,SAAGa,GACD,OAAIV,KAAK+N,MAAQrN,EAAI,EACZ,KAEFV,KAAKupB,OAAOvpB,KAAK+N,MAAQrN,EAClC,GAAC,CAAA1B,IAAA,KAAAa,MAED,SAAGa,GAED,GADAV,KAAK07B,WACK,IAANh7B,EACF,OAAO,KAET,GAAIA,EAAI,EACN,OAAOV,KAAKg8B,IAAIt7B,GAElB,IAAMP,EAAIH,KAAK+N,MAAQrN,EAAI,EAE3B,OADAV,KAAK47B,KAAKz7B,GACNA,GAAKH,KAAKupB,OAAOlpB,OAGZL,KAAKupB,OAAOvpB,KAAKupB,OAAOlpB,OAAS,GAEnCL,KAAKupB,OAAOppB,EACrB,GAEA,CAAAnB,IAAA,kBAAAa,MAcA,SAAgBM,GACd,OAAOA,CACT,GAAC,CAAAnB,IAAA,WAAAa,MAED,YACsB,IAAhBG,KAAK+N,OACP/N,KAAKi8B,OAET,GAAC,CAAAj9B,IAAA,QAAAa,MAED,WACEG,KAAK47B,KAAK,GACV57B,KAAK+N,MAAQ/N,KAAK27B,gBAAgB,EACpC,GAEA,CAAA38B,IAAA,iBAAAa,MACA,SAAe27B,GACbx7B,KAAKw7B,YAAcA,EACnBx7B,KAAKupB,OAAS,GACdvpB,KAAK+N,OAAS,EACd/N,KAAKy7B,YAAa,CACpB,GAEA,CAAAz8B,IAAA,qBAAAa,MAKA,SAAmBM,EAAGkC,GAEpB,GADArC,KAAK47B,KAAKz7B,GACNA,GAAKH,KAAKupB,OAAOlpB,OACnB,OAAQ,EAGV,IADA,IAAIiN,EAAQtN,KAAKupB,OAAOppB,GACjBmN,EAAMjL,UAAYrC,KAAKqC,SAAS,CACrC,GAAIiL,EAAM3J,OAAS+B,GAAMuB,IACvB,OAAQ,EAEV9G,GAAK,EACLH,KAAK47B,KAAKz7B,GACVmN,EAAQtN,KAAKupB,OAAOppB,EACtB,CACA,OAAOA,CACT,GAEA,CAAAnB,IAAA,yBAAAa,MAKA,SAAuBM,EAAGkC,GACxB,KAAOlC,GAAK,GAAKH,KAAKupB,OAAOppB,GAAGkC,UAAYA,GAC1ClC,GAAK,EAEP,OAAOA,CACT,GAEA,CAAAnB,IAAA,yBAAAa,MAKA,SAAuBiG,EAAYzD,GAKjC,QAJgB0B,IAAZ1B,IACFA,GAAW,GAEbrC,KAAK07B,WACD51B,EAAa,GAAKA,GAAc9F,KAAKupB,OAAOlpB,OAC9C,MAAM6M,OAAOpH,GAAc,cAAgB9F,KAAKupB,OAAOlpB,OAAS,EAElE,IAAM67B,EAAgBl8B,KAAKm8B,mBAAmBr2B,EAAa,EAAGglB,GAAMkC,uBAC9DwD,EAAQ1qB,EAAa,EAErB4qB,GAAwB,IAAnBwL,EAAuBl8B,KAAKupB,OAAOlpB,OAAS,EAAI67B,EAC3D,OAAOl8B,KAAKo8B,iBAAiB5L,EAAOE,EAAIruB,EAC1C,GAEA,CAAArD,IAAA,wBAAAa,MAKA,SAAsBiG,EAAYzD,GAKhC,QAJgB0B,IAAZ1B,IACFA,GAAW,GAEbrC,KAAK07B,WACD51B,EAAa,GAAKA,GAAc9F,KAAKupB,OAAOlpB,OAC9C,MAAM6M,OAAOpH,GAAc,cAAgB9F,KAAKupB,OAAOlpB,OAAS,EAElE,IAAMg8B,EAAgBr8B,KAAKs8B,uBAAuBx2B,EAAa,EAAGglB,GAAMkC,uBACxE,GAAIqP,IAAkBv2B,EAAa,EACjC,OAAO,KAGT,IAAM0qB,EAAQ6L,EAAgB,EACxB3L,EAAK5qB,EAAa,EACxB,OAAO9F,KAAKo8B,iBAAiB5L,EAAOE,EAAIruB,EAC1C,GAAC,CAAArD,IAAA,mBAAAa,MAED,SAAiB08B,EAAMC,EAAOn6B,GAE5B,IADA,IAAMo6B,EAAS,GACNt8B,EAAIo8B,EAAMp8B,EAAIq8B,EAAQ,EAAGr8B,IAAK,CACrC,IAAM+Q,EAAIlR,KAAKupB,OAAOppB,IACL,IAAbkC,EACE6O,EAAE7O,UAAYyoB,GAAMkC,uBACtByP,EAAOz0B,KAAKkJ,GAELA,EAAE7O,UAAYA,GACvBo6B,EAAOz0B,KAAKkJ,EAEhB,CACA,OAAsB,IAAlBurB,EAAOp8B,OACF,KAEFo8B,CACT,GAAC,CAAAz9B,IAAA,gBAAAa,MAED,WACE,OAAOG,KAAKw7B,YAAYkB,eAC1B,GAEA,CAAA19B,IAAA,UAAAa,MACA,SAAQsL,GACNnL,KAAK07B,WACL17B,KAAK8V,OACA3K,IACHA,EAAW,IAAIL,GAAS,EAAG9K,KAAKupB,OAAOlpB,OAAS,IAElD,IAAIuF,EAAQuF,EAASvF,MACjBA,aAAiBF,KACnBE,EAAQA,EAAME,YAEhB,IAAID,EAAOsF,EAAStF,KAIpB,GAHIA,aAAgBH,KAClBG,EAAOA,EAAKC,YAEA,OAAVF,GAA2B,OAATC,GAAiBD,EAAQ,GAAKC,EAAO,EACzD,MAAO,GAELA,GAAQ7F,KAAKupB,OAAOlpB,SACtBwF,EAAO7F,KAAKupB,OAAOlpB,OAAS,GAG9B,IADA,IAAIqJ,EAAI,GACCvJ,EAAIyF,EAAOzF,EAAI0F,EAAO,EAAG1F,IAAK,CACrC,IAAM+Q,EAAIlR,KAAKupB,OAAOppB,GACtB,GAAI+Q,EAAEvN,OAAS+B,GAAMuB,IACnB,MAEFyC,GAAQwH,EAAE/K,IACZ,CACA,OAAOuD,CACT,GAEA,CAAA1K,IAAA,OAAAa,MACA,WAGE,IAFAG,KAAK07B,WAEuB,MAArB17B,KAAK67B,MAAM,OACpB,I,mFAACP,CAAA,CAlW6B,GAqWhCp8B,OAAOC,eAAem8B,GAAqB,OAAQ,CACjDj8B,IAAK,WACH,OAAOW,KAAKupB,OAAOlpB,MACrB,ICzXG6M,OAAO1N,UAAU67B,cAGdl8B,GAAkB,WAEpB,IAAIoJ,EACJ,IACE,IAAMo0B,EAAS,CAAC,EACVC,EAAkB19B,OAAOC,eAC/BoJ,EAASq0B,EAAgBD,EAAQA,EAAQA,IAAWC,CACtD,CAAE,MAAOrZ,GACP,CAEF,OAAOhb,CACT,CAXsB,GAYhB8yB,GAAc,SAAUwB,GAC5B,GAAY,MAAR78B,KACF,MAAM88B,YAER,IAAMC,EAAS7vB,OAAOlN,MAChBolB,EAAO2X,EAAO18B,OAEhB0N,EAAQ8uB,EAAWG,OAAOH,GAAY,EAM1C,GALI9uB,IAAUA,IAEZA,EAAQ,KAGNA,EAAQ,GAAKA,GAASqX,GAA1B,CAIA,IACI6X,EADE7S,EAAQ2S,EAAO3e,WAAWrQ,GAEhC,OAEEqc,GAAS,OACTA,GAAS,OACThF,EAAOrX,EAAQ,IAEfkvB,EAASF,EAAO3e,WAAWrQ,EAAQ,KACrB,OAAUkvB,GAAU,MAGN,MAAlB7S,EAAQ,OAAkB6S,EAAS,MAAS,MAGjD7S,CAjBP,CAkBF,EACIjrB,GACFA,GAAe+N,OAAO1N,UAAW,cAAe,CAC9CK,MAAOw7B,GACP6B,cAAc,EACdC,UAAU,IAGZjwB,OAAO1N,UAAU67B,YAAcA,IAKVnuB,OAAO1N,UAAU67B,YC7DvCnuB,OAAOkwB,eACV,WACE,IAAMj+B,EAAkB,WAEtB,IAAIoJ,EACJ,IACE,IAAMo0B,EAAS,CAAC,EACVC,EAAkB19B,OAAOC,eAC/BoJ,EAASq0B,EAAgBD,EAAQA,EAAQA,IAAWC,CACtD,CAAE,MAAOrZ,GACP,CAEF,OAAOhb,CACT,CAXwB,GAYlB80B,EAAqBnwB,OAAOC,aAC5BmwB,EAAQxxB,KAAKwxB,MACbF,EAAgB,SAAUG,GAC9B,IAEIC,EACAC,EAFEC,EAAY,GAGd3vB,GAAS,EACP1N,EAASD,UAAUC,OACzB,IAAKA,EACH,MAAO,GAGT,IADA,IAAIkI,EAAS,KACJwF,EAAQ1N,GAAQ,CACvB,IAAIs9B,EAAYX,OAAO58B,UAAU2N,IACjC,IACG6vB,SAASD,IACVA,EAAY,GACZA,EAAY,SACZL,EAAMK,KAAeA,EAErB,MAAME,WAAW,uBAAyBF,GAExCA,GAAa,MAEfD,EAAU11B,KAAK21B,IAKfH,EAAoC,QADpCG,GAAa,QACiB,IAC9BF,EAAgBE,EAAY,KAAS,MACrCD,EAAU11B,KAAKw1B,EAAeC,KAE5B1vB,EAAQ,IAAM1N,GAAUq9B,EAAUr9B,OA/BvB,SAgCbkI,GAAU80B,EAAmB58B,MAAM,KAAMi9B,GACzCA,EAAUr9B,OAAS,EAEvB,CACA,OAAOkI,CACT,EACIpJ,EACFA,EAAe+N,OAAQ,gBAAiB,CACtCrN,MAAOu9B,EACPF,cAAc,EACdC,UAAU,IAGZjwB,OAAOkwB,cAAgBA,CAE1B,CA/DD,GAkE2BlwB,OAAO1N,UAAU49B,c,otBCxDvC,IAAMU,GAAU,WACrB,SAAAA,EAAYt2B,EAAMu2B,GAOhB,G,4FAP2Ch+B,CAAA,KAAA+9B,GAC3C99B,KAAKuoB,KAAO,UACZvoB,KAAKg+B,QAAUx2B,EACfxH,KAAK+9B,0BAA4BA,IAA6B,EAE9D/9B,KAAKi+B,OAAS,EACdj+B,KAAKwH,KAAO,GACRxH,KAAK+9B,0BACP,IAAK,IAAI59B,EAAI,EAAGA,EAAIH,KAAKg+B,QAAQ39B,QAAU,CACzC,IAAMs9B,EAAY39B,KAAKg+B,QAAQ3C,YAAYl7B,GAC3CH,KAAKwH,KAAKQ,KAAK21B,GACfx9B,GAAKw9B,GAAa,MAAS,EAAI,CACjC,KACK,CACL39B,KAAKwH,KAAO,IAAIlH,MAAMN,KAAKg+B,QAAQ39B,QACnC,IAAK,IAAIF,EAAI,EAAGA,EAAIH,KAAKg+B,QAAQ39B,OAAQF,IACvCH,KAAKwH,KAAKrH,GAAKH,KAAKg+B,QAAQ5f,WAAWje,EAE3C,CACAH,KAAKk+B,MAAQl+B,KAAKwH,KAAKnH,MACzB,C,UAwFC,O,EAxFAy9B,E,EAAA,EAAA9+B,IAAA,QAAAK,IAED,WACE,OAAOW,KAAKi+B,MACd,GAAC,CAAAj/B,IAAA,OAAAK,IAED,WACE,OAAOW,KAAKk+B,KACd,GAEA,CAAAl/B,IAAA,QAAAa,MAKA,WACEG,KAAKi+B,OAAS,CAChB,GAAC,CAAAj/B,IAAA,UAAAa,MAED,WACE,GAAIG,KAAKi+B,QAAUj+B,KAAKk+B,MAEtB,KAAM,qBAERl+B,KAAKi+B,QAAU,CACjB,GAAC,CAAAj/B,IAAA,KAAAa,MAED,SAAGgD,GACD,GAAe,IAAXA,EACF,OAAO,EAELA,EAAS,IACXA,GAAU,GAEZ,IAAM8I,EAAM3L,KAAKi+B,OAASp7B,EAAS,EACnC,OAAI8I,EAAM,GAAKA,GAAO3L,KAAKk+B,MAElBx4B,GAAMuB,IAERjH,KAAKwH,KAAKmE,EACnB,GAAC,CAAA3M,IAAA,KAAAa,MAED,SAAGgD,GACD,OAAO7C,KAAKipB,GAAGpmB,EACjB,GAEA,CAAA7D,IAAA,OAAAa,MACA,WACE,OAAQ,CACV,GAAC,CAAAb,IAAA,UAAAa,MAED,SAAQywB,GAAS,GAEjB,CAAAtxB,IAAA,OAAAa,MAIA,SAAKo+B,GACCA,GAAUj+B,KAAKi+B,OACjBj+B,KAAKi+B,OAASA,EAKhBj+B,KAAKi+B,OAASnyB,KAAKC,IAAIkyB,EAAQj+B,KAAKk+B,MACtC,GAAC,CAAAl/B,IAAA,UAAAa,MAED,SAAQ+F,EAAOC,GAIb,GAHIA,GAAQ7F,KAAKk+B,QACfr4B,EAAO7F,KAAKk+B,MAAQ,GAElBt4B,GAAS5F,KAAKk+B,MAChB,MAAO,GAEP,GAAIl+B,KAAK+9B,0BAA2B,CAElC,IADA,IAAIx1B,EAAS,GACJpI,EAAIyF,EAAOzF,GAAK0F,EAAM1F,IAC7BoI,GAAU2E,OAAOkwB,cAAcp9B,KAAKwH,KAAKrH,IAE3C,OAAOoI,CACT,CACE,OAAOvI,KAAKg+B,QAAQr0B,MAAM/D,EAAOC,EAAO,EAG9C,GAAC,CAAA7G,IAAA,WAAAa,MAED,WACE,OAAOG,KAAKg+B,OACd,I,mFAACF,CAAA,CA7GoB,G,grDCNhB,IAAMK,GAAW,SAAAC,I,uRAAAl8B,CAAAi8B,EAASL,IAAT,I,MAAA37B,EAAAC,GAAA+7B,GACtB,SAAAA,EAAY32B,EAAMu2B,GAA2B,O,4FAAAh+B,CAAA,KAAAo+B,GAAAh8B,EAAAzC,KAAA,KACrC8H,EAAMu2B,EACd,CAAC,O,EAAAI,E,oFAAA,CAHqB,G,grDCCjB,IAAME,GAAU,SAAAC,I,uRAAAp8B,CAAAm8B,EAASF,IAAT,I,MAAAh8B,EAAAC,GAAAi8B,GACrB,SAAAA,EAAYE,EAAUC,EAAUT,GAE9B,M,4FAFyDh+B,CAAA,KAAAs+B,GACzDl8B,EAAAzC,KAAA,KAAM,KAAMq+B,GACN,IAAI9tB,MAAM,qDAClB,CAIC,O,EAJAouB,E,EAAA,EAAAr/B,IAAA,WAAAa,MAED,SAAgB4+B,EAAMD,EAAUE,GAC9B,MAAM,IAAIzuB,MAAM,qDAClB,K,EAJC,O,gFAIAouB,CAAA,CARoB,G,otBCIhB,IAAMM,GAAW,oBAAAA,K,4FAAA5+B,CAAA,KAAA4+B,EAAA,C,UAkDrB,O,EAlDqBA,E,EAAA,EAAA3/B,IAAA,aAAAa,MAEtB,SAAkBq7B,GAChB,OAAO,IAAI4C,GAAW5C,GAAK,EAC7B,GAEA,CAAAl8B,IAAA,WAAAa,MAQA,SAAgB++B,EAAMJ,EAAUK,EAAQC,GACtC,IAAMxf,EAAS,IAAIyf,OAAOC,WAC1B1f,EAAO2f,OAAS,SAAU1qB,GACxB,IAAM2qB,EAAK,IAAIpB,GAAWvpB,EAAEzQ,OAAOyE,QAAQ,GAC3Cs2B,EAAOK,EACT,EACA5f,EAAO6f,QAAUL,EACjBxf,EAAO8f,WAAWR,EAAMJ,EAC1B,GAEA,CAAAx/B,IAAA,aAAAa,MAKA,SAAkBw/B,EAAQb,GACxB,OAAO,IAAIV,GAAWuB,EAAOr+B,SAASw9B,IAAW,EACnD,GAEA,CAAAx/B,IAAA,WAAAa,MAMA,SAAgB4+B,EAAMD,EAAUE,GAC9BL,GAAWiB,SAASb,EAAMD,EAAUE,EACtC,GAEA,CAAA1/B,IAAA,eAAAa,MAKA,SAAoB4+B,EAAMD,GACxB,OAAO,IAAIH,GAAWI,EAAMD,EAC9B,K,EAlDsB,O,gFAkDrBG,CAAA,CAlDqB,G,grDCiBjB,IAAMY,GAAiB,SAAAC,I,uRAAAt9B,CAAAq9B,EAASjE,IAAT,I,MAAAn5B,EAAAC,GAAAm9B,GAC5B,SAAAA,EAAYh9B,EAAOF,GAAS,IAAAC,EAE6C,O,4FAF7CvC,CAAA,KAAAw/B,IAC1Bj9B,EAAAH,EAAAzC,KAAA,KAAM6C,IACDF,aAAsB0B,IAAZ1B,EAAwBqD,GAAMwB,gBAAkB7E,EAAQC,CACzE,CA2DC,O,EA3DAi9B,E,EAAA,EAAAvgC,IAAA,kBAAAa,MAED,SAAgBM,GACd,OAAOH,KAAKm8B,mBAAmBh8B,EAAGH,KAAKqC,QACzC,GAAC,CAAArD,IAAA,KAAAa,MAED,SAAGa,GACD,GAAU,IAANA,GAAWV,KAAK+N,MAAQrN,EAAI,EAC9B,OAAO,KAKT,IAHA,IAAIP,EAAIH,KAAK+N,MACTvB,EAAI,EAEDA,GAAK9L,GAEVP,EAAIH,KAAKs8B,uBAAuBn8B,EAAI,EAAGH,KAAKqC,SAC5CmK,GAAK,EAEP,OAAIrM,EAAI,EACC,KAEFH,KAAKupB,OAAOppB,EACrB,GAAC,CAAAnB,IAAA,KAAAa,MAED,SAAGa,GAED,GADAV,KAAK07B,WACK,IAANh7B,EACF,OAAO,KAET,GAAIA,EAAI,EACN,OAAOV,KAAKg8B,IAAIt7B,GAKlB,IAHA,IAAIP,EAAIH,KAAK+N,MACTvB,EAAI,EAEDA,EAAI9L,GAELV,KAAK47B,KAAKz7B,EAAI,KAChBA,EAAIH,KAAKm8B,mBAAmBh8B,EAAI,EAAGH,KAAKqC,UAE1CmK,GAAK,EAEP,OAAOxM,KAAKupB,OAAOppB,EACrB,GAEA,CAAAnB,IAAA,6BAAAa,MACA,WACE,IAAI2M,EAAI,EACRxM,KAAK8V,OACL,IAAK,IAAI3V,EAAI,EAAGA,EAAIH,KAAKupB,OAAOlpB,OAAQF,IAAK,CAC3C,IAAM+Q,EAAIlR,KAAKupB,OAAOppB,GAItB,GAHI+Q,EAAE7O,UAAYrC,KAAKqC,UACrBmK,GAAK,GAEH0E,EAAEvN,OAAS+B,GAAMuB,IACnB,KAEJ,CACA,OAAOuF,CACT,I,mFAAC+yB,CAAA,CA/D2B,G,grDC1BvB,IAAME,GAAa,SAAAC,I,uRAAAx9B,CAAAu9B,EAAS5G,IAAT,I,MAAA12B,EAAAC,GAAAq9B,GACxB,SAAAA,EAAYr3B,GAAQ,IAAA9F,EAEG,O,4FAFHvC,CAAA,KAAA0/B,IAClBn9B,EAAAH,EAAAzC,KAAA,OACK0I,OAASA,EAAO9F,CACvB,CAYC,O,EAZAm9B,G,EAAA,EAAAzgC,IAAA,iBAAAa,MAED,SAAeoX,GACbnW,QAAQC,IAAI,WAAaf,KAAKoI,OAAOoI,UAAUyG,EAAIvU,WAAa,WAAa1C,KAAKoI,OAAOwgB,OAAO0B,GAAG,GAAGnkB,KACxG,GAAC,CAAAnH,IAAA,gBAAAa,MAED,SAAci5B,GACZh4B,QAAQC,IAAI,WAAa+3B,EAAK3pB,OAAS,SAAWnP,KAAKoI,OAAOoI,UAAUxQ,KAAKoI,OAAOke,KAAK5jB,WAC3F,GAAC,CAAA1D,IAAA,gBAAAa,MAED,SAAcoX,GACZnW,QAAQC,IAAI,WAAaf,KAAKoI,OAAOoI,UAAUyG,EAAIvU,WAAa,WAAa1C,KAAKoI,OAAOwgB,OAAO0B,GAAG,GAAGnkB,KACxG,M,gFAACs5B,CAAA,CAhBuB,G,grDCQnB,IAAME,GAAM,SAAA5U,I,uRAAA7oB,CAAAy9B,EAAS5b,IAAT,I,MAAA5hB,EAAAC,GAAAu9B,GAKjB,SAAAA,EAAYxd,GAAO,IAAA7f,EAuCU,O,4FAvCVvC,CAAA,KAAA4/B,IACjBr9B,EAAAH,EAAAzC,KAAA,OAEKkpB,OAAS,KAKdtmB,EAAKs9B,YAAc,IAAIlY,GACvBplB,EAAKu9B,iBAAmB,GACxBv9B,EAAKu9B,iBAAiB73B,KAAK,GAK3B1F,EAAKgkB,KAAO,KAKZhkB,EAAKw9B,iBAAkB,EAQvBx9B,EAAKy9B,QAAU,KAKfz9B,EAAK09B,gBAAkB,KAKvB19B,EAAK29B,cAAgB,EACrB39B,EAAK49B,eAAe/d,GAAO7f,CAC7B,CAqjBC,O,EAnjBDq9B,E,EAAA,EAAA3gC,IAAA,QAAAa,MACA,WACsB,OAAhBG,KAAK4oB,QACP5oB,KAAK4oB,OAAOpG,KAAK,GAEnBxiB,KAAK4/B,YAAYziB,MAAMnd,MACvBA,KAAKsmB,KAAO,KACZtmB,KAAKigC,cAAgB,EACrBjgC,KAAKmgC,UAAS,GACdngC,KAAK6/B,iBAAmB,GACxB7/B,KAAK6/B,iBAAiB73B,KAAK,GACN,OAAjBhI,KAAKikB,SACPjkB,KAAKikB,QAAQ9G,OAEjB,GAEA,CAAAne,IAAA,QAAAa,MAkBA,SAAMiS,GACJ,IAAIZ,EAAIlR,KAAKumB,kBAab,OAZIrV,EAAEvN,OAASmO,GACb9R,KAAK4/B,YAAY5V,YAAYhqB,MAC7BA,KAAK2oB,YAELzX,EAAIlR,KAAK4/B,YAAYQ,cAAcpgC,MAC/BA,KAAK8/B,kBAAqC,IAAlB5uB,EAAEpL,YAI5B9F,KAAKsmB,KAAK+Z,aAAanvB,IAGpBA,CACT,GAEA,CAAAlS,IAAA,gBAAAa,MAiBA,WACE,IAAIqR,EAAIlR,KAAKumB,kBAab,OAZIrV,EAAEvN,KAAO,GACX3D,KAAK4/B,YAAY5V,YAAYhqB,MAC7BA,KAAK2oB,YAELzX,EAAIlR,KAAK4/B,YAAYQ,cAAcpgC,MAC/BA,KAAK8/B,kBAAqC,IAAlB5uB,EAAEpL,YAI5B9F,KAAKsmB,KAAK+Z,aAAanvB,IAGpBA,CACT,GAAC,CAAAlS,IAAA,oBAAAa,MAED,WACE,OAAOG,KAAKggC,iBAAmB,EACjC,GAEA,CAAAhhC,IAAA,mBAAAa,MA6BA,SAAiBwkB,GACf,GAAiB,OAAbA,EACF,MAAM,IAAIpU,MAAM,YAEW,OAAzBjQ,KAAKggC,kBACPhgC,KAAKggC,gBAAkB,IAEzBhgC,KAAKggC,gBAAgBh4B,KAAKqc,EAC5B,GAEA,CAAArlB,IAAA,sBAAAa,MAOA,SAAoBwkB,GAClB,GAA6B,OAAzBrkB,KAAKggC,gBAA0B,CACjC,IAAMvf,EAAMzgB,KAAKggC,gBAAgBtX,QAAQrE,GACrC5D,GAAO,GACTzgB,KAAKggC,gBAAgBn0B,OAAO4U,EAAK,GAEC,IAAhCzgB,KAAKggC,gBAAgB3/B,SACvBL,KAAKggC,gBAAkB,KAE3B,CACF,GAEA,CAAAhhC,IAAA,uBAAAa,MACA,WACEG,KAAKggC,gBAAkB,IACzB,GAEA,CAAAhhC,IAAA,wBAAAa,MACA,WACE,GAA6B,OAAzBG,KAAKggC,gBAA0B,CACjC,IAAM/oB,EAAMjX,KAAKsmB,KACjBtmB,KAAKggC,gBAAgB/zB,SAAQ,SAACoY,GAC5BA,EAASmV,eAAeviB,GACxBA,EAAIoiB,UAAUhV,EAChB,GACF,CACF,GAEA,CAAArlB,IAAA,uBAAAa,MAIA,WACE,GAA6B,OAAzBG,KAAKggC,gBAA0B,CAEjC,IAAM/oB,EAAMjX,KAAKsmB,KACjBtmB,KAAKggC,gBACFr2B,MAAM,GACN22B,UACAr0B,SAAQ,SAACoY,GACRpN,EAAIsiB,SAASlV,GACbA,EAASoV,cAAcxiB,EACzB,GACJ,CACF,GAAC,CAAAjY,IAAA,kBAAAa,MAED,WACE,OAAOG,KAAK4oB,OAAO4S,YAAYxQ,QACjC,GAEA,CAAAhsB,IAAA,kBAAAa,MACA,SAAgB0gC,GACdvgC,KAAK4oB,OAAO4S,YAAYxQ,SAAWuV,CACrC,GAEA,CAAAvhC,IAAA,uBAAAa,MAOA,WACE,IAAM2gC,EAAgBxgC,KAAKygC,mBAC3B,GAAsB,OAAlBD,EACF,MAAM,IAAIvwB,MAAM,wEAElB,IAAI1H,EAASvI,KAAK0gC,mBAAmBF,GACrC,GAAe,OAAXj4B,EAAiB,CACnB,IAAMwU,EAAyB,IAAI3C,GACnC2C,EAAuBxC,+BAAgC,EACvDhS,EAAS,IAAIsU,GAAgBE,GAAwB4jB,YAAYH,GACjExgC,KAAK0gC,mBAAmBF,GAAiBj4B,CAC3C,CACA,OAAOA,CACT,GAAC,CAAAvJ,IAAA,iBAAAa,MAED,WACE,OAAOG,KAAKknB,gBACd,GAAC,CAAAloB,IAAA,iBAAAa,MAED,SAAesiB,GACbniB,KAAK4gC,eAAeze,EACtB,GAAC,CAAAnjB,IAAA,iBAAAa,MAED,WACE,OAAOG,KAAK4oB,MACd,GAEA,CAAA5pB,IAAA,iBAAAa,MACA,SAAesiB,GACbniB,KAAK4oB,OAAS,KACd5oB,KAAKmd,QACLnd,KAAK4oB,OAASzG,CAChB,GAEA,CAAAnjB,IAAA,kBAAAa,MAIA,WACE,OAAOG,KAAK4oB,OAAO0B,GAAG,EACxB,GAAC,CAAAtrB,IAAA,uBAAAa,MAED,SAAqBojB,EAAK8C,EAAgB8a,GAExCA,EAAMA,GAAO,KACU,QAFvB9a,EAAiBA,GAAkB,QAGjCA,EAAiB/lB,KAAKumB,mBAExBvmB,KAAKigC,eAAiB,EACtB,IAAMl6B,EAAOggB,EAAehgB,KACtBC,EAAS+f,EAAe/f,OACbhG,KAAK6sB,2BACblJ,YAAY3jB,KAAM+lB,EAAgBhgB,EAAMC,EAAQid,EAAK4d,EAChE,GAEA,CAAA7hC,IAAA,UAAAa,MAqBA,WACE,IAAMZ,EAAIe,KAAKumB,kBACXtnB,EAAE0E,OAAS+B,GAAMuB,KACnBjH,KAAKmlB,iBAAiBwD,UAExB,IAEMmQ,EAFAgI,EAAuC,OAAzB9gC,KAAKggC,iBAA4BhgC,KAAKggC,gBAAgB3/B,OAAS,EAmBnF,OAlBIL,KAAK8/B,iBAAmBgB,MAGxBhI,EADE94B,KAAK4/B,YAAY1X,oBAAoBloB,MAChCA,KAAKsmB,KAAK+Z,aAAaphC,GAEvBe,KAAKsmB,KAAKya,aAAa9hC,IAE3BuT,cAAgBxS,KAAKoK,MACtB02B,GACF9gC,KAAKggC,gBAAgB/zB,SAAQ,SAACoY,GACxByU,aAAgB3oB,SAAmCpM,IAArB+0B,EAAKI,aAA6BJ,EAAKI,cACvE7U,EAAS8U,eAAeL,GACfA,aAAgB5oB,IACzBmU,EAAS+U,cAAcN,EAE3B,KAGG75B,CACT,GAAC,CAAAD,IAAA,wBAAAa,MAED,WAE8B,OAAxBG,KAAKsmB,KAAK7T,WACZzS,KAAKsmB,KAAK7T,UAAUunB,SAASh6B,KAAKsmB,KAEtC,GAEA,CAAAtnB,IAAA,YAAAa,MAIA,SAAU0c,EAAUnS,EAAO1H,GACzB1C,KAAKoK,MAAQA,EACbpK,KAAKsmB,KAAO/J,EACZvc,KAAKsmB,KAAK1gB,MAAQ5F,KAAK4oB,OAAO0B,GAAG,GAC7BtqB,KAAK8/B,iBACP9/B,KAAKghC,wBAEPhhC,KAAKihC,uBACP,GAAC,CAAAjiC,IAAA,WAAAa,MAED,WACEG,KAAKsmB,KAAKzgB,KAAO7F,KAAK4oB,OAAO0B,IAAI,GAEjCtqB,KAAKkhC,uBACLlhC,KAAKoK,MAAQpK,KAAKsmB,KAAK9T,cACvBxS,KAAKsmB,KAAOtmB,KAAKsmB,KAAK7T,SACxB,GAAC,CAAAzT,IAAA,gBAAAa,MAED,SAAc0c,EAAU4kB,GACtB5kB,EAAS6kB,aAAaD,GAGlBnhC,KAAK8/B,iBAAmB9/B,KAAKsmB,OAAS/J,GACZ,OAAxBvc,KAAKsmB,KAAK7T,YACZzS,KAAKsmB,KAAK7T,UAAU4uB,kBACpBrhC,KAAKsmB,KAAK7T,UAAUunB,SAASzd,IAGjCvc,KAAKsmB,KAAO/J,CACd,GAEA,CAAAvd,IAAA,gBAAAa,MAMA,WACE,OAAqC,IAAjCG,KAAK6/B,iBAAiBx/B,QAChB,EAEDL,KAAK6/B,iBAAiB7/B,KAAK6/B,iBAAiBx/B,OAAS,EAEhE,GAEA,CAAArB,IAAA,qBAAAa,MACA,SAAmB0c,EAAUnS,EAAO1H,EAAWwG,GAC7ClJ,KAAKoK,MAAQA,EACbpK,KAAK6/B,iBAAiB73B,KAAKkB,GAC3BlJ,KAAKsmB,KAAO/J,EACZvc,KAAKsmB,KAAK1gB,MAAQ5F,KAAK4oB,OAAO0B,GAAG,GACjCtqB,KAAKihC,uBACP,GAEA,CAAAjiC,IAAA,0BAAAa,MACA,SAAwB0c,EAAUnS,EAAO1H,GACvC,IAAM0S,EAAWpV,KAAKsmB,KACtBlR,EAAS3C,UAAY8J,EACrBnH,EAAS5C,cAAgBpI,EACzBgL,EAASvP,KAAO7F,KAAK4oB,OAAO0B,IAAI,GAEhCtqB,KAAKsmB,KAAO/J,EACZvc,KAAKsmB,KAAK1gB,MAAQwP,EAASxP,MACvB5F,KAAK8/B,iBACP9/B,KAAKsmB,KAAK0T,SAAS5kB,GAErBpV,KAAKihC,uBACP,GAAC,CAAAjiC,IAAA,0BAAAa,MAED,SAAwB4S,GACtBzS,KAAK6/B,iBAAiBxT,MACtBrsB,KAAKsmB,KAAKzgB,KAAO7F,KAAK4oB,OAAO0B,IAAI,GACjC,IAAMgX,EAASthC,KAAKsmB,KAEdib,EAAiBvhC,KAAKwhC,oBAC5B,GAAuB,OAAnBD,GAA2BA,EAAelhC,OAAS,EACrD,KAAOL,KAAKsmB,OAAS7T,GACnBzS,KAAKkhC,uBACLlhC,KAAKsmB,KAAOtmB,KAAKsmB,KAAK7T,eAGxBzS,KAAKsmB,KAAO7T,EAGd6uB,EAAO7uB,UAAYA,EACfzS,KAAK8/B,iBAAiC,OAAdrtB,GAE1BA,EAAUunB,SAASsH,EAEvB,GAAC,CAAAtiC,IAAA,qBAAAa,MAED,SAAmB6C,GAEjB,IADA,IAAIuU,EAAMjX,KAAKsmB,KACA,OAARrP,GAAc,CACnB,GAAIA,EAAIvU,YAAcA,EACpB,OAAOuU,EAETA,EAAMA,EAAIxE,SACZ,CACA,OAAO,IACT,GAAC,CAAAzT,IAAA,WAAAa,MAED,SAAS0c,EAAUrT,GACjB,OAAOA,GAAclJ,KAAK6/B,iBAAiB7/B,KAAK6/B,iBAAiBx/B,OAAS,EAC5E,GAAC,CAAArB,IAAA,YAAAa,MAED,SAAUyJ,GAER,OAAO,CACT,GAEA,CAAAtK,IAAA,kBAAAa,MAcA,SAAgBsP,GACd,IAAM3B,EAAMxN,KAAKikB,QAAQzW,IACrByJ,EAAMjX,KAAKsmB,KACT5c,EAAI8D,EAAIkH,OAAO1U,KAAKoK,OACtByO,EAAYrL,EAAIsL,WAAWpP,GAC/B,GAAImP,EAAUvM,SAAS6C,GACrB,OAAO,EAET,IAAK0J,EAAUvM,SAAS5G,GAAMxB,SAC5B,OAAO,EAET,KAAe,OAAR+S,GAAgBA,EAAIzE,eAAiB,GAAKqG,EAAUvM,SAAS5G,GAAMxB,UAAU,CAClF,IACM8U,EADgBxL,EAAIkH,OAAOuC,EAAIzE,eACZ5E,YAAY,GAErC,IADAiL,EAAYrL,EAAIsL,WAAWE,EAAG/J,cAChB3C,SAAS6C,GACrB,OAAO,EAET8H,EAAMA,EAAIxE,SACZ,CACA,SAAIoG,EAAUvM,SAAS5G,GAAMxB,UAAYiL,IAAWzJ,GAAMuB,IAK5D,GAEA,CAAAjI,IAAA,oBAAAa,MAOA,WACE,OAAOG,KAAKikB,QAAQzW,IAAIyY,kBAAkBjmB,KAAKoK,MAAOpK,KAAKsmB,KAC7D,GAAC,CAAAtnB,IAAA,qCAAAa,MAED,WACE,IAAM2N,EAAMxN,KAAKikB,QAAQzW,IACnB9D,EAAI8D,EAAIkH,OAAO1U,KAAKoK,OAC1B,OAAOoD,EAAIsL,WAAWpP,EACxB,GAEA,CAAA1K,IAAA,eAAAa,MACA,SAAawnB,GACX,IAAM3kB,EAAY1C,KAAKyhC,kBAAkBpa,GACzC,OAAkB,OAAd3kB,EACKA,GAEC,CAEZ,GAEA,CAAA1D,IAAA,yBAAAa,MAQA,SAAuBoJ,GAEX,QADVA,EAAIA,GAAK,QAEPA,EAAIjJ,KAAKsmB,MAGX,IADA,IAAMkC,EAAQ,GACD,OAANvf,GAAY,CAEjB,IAAMvG,EAAYuG,EAAEvG,UAChBA,EAAY,EACd8lB,EAAMxgB,KAAK,OAEXwgB,EAAMxgB,KAAKhI,KAAKwQ,UAAU9N,IAE5BuG,EAAIA,EAAEwJ,SACR,CACA,OAAO+V,CACT,GAEA,CAAAxpB,IAAA,gBAAAa,MACA,WACE,OAAOG,KAAKikB,QAAQ2J,cAAc5sB,UACpC,GAEA,CAAAhC,IAAA,UAAAa,MACA,WAEE,IADA,IAAI6hC,GAAU,EACLvhC,EAAI,EAAGA,EAAIH,KAAKikB,QAAQ2J,cAAcvtB,OAAQF,IAAK,CAC1D,IAAM+iB,EAAMljB,KAAKikB,QAAQ2J,cAAcztB,GACnC+iB,EAAIxO,OAAOrU,OAAS,IAClBqhC,GACF5gC,QAAQC,MAEVf,KAAK2hC,QAAQC,QAAQ,YAAc1e,EAAItK,SAAW,KAClD5Y,KAAK2hC,QAAQE,MAAM3e,EAAIliB,SAAShB,KAAK2M,aAAc3M,KAAK4M,gBACxD80B,GAAU,EAEd,CACF,GAEA,CAAA1iC,IAAA,gBAAAa,MAMA,WACE,OAAOG,KAAK4oB,OAAO+C,UACrB,GAEA,CAAA3sB,IAAA,WAAAa,MAIA,SAASiiC,GACFA,GAIkB,OAAjB9hC,KAAK+/B,SACP//B,KAAK+hC,oBAAoB/hC,KAAK+/B,SAEhC//B,KAAK+/B,QAAU,IAAIN,GAAcz/B,MACjCA,KAAKgiC,iBAAiBhiC,KAAK+/B,WAP3B//B,KAAK+hC,oBAAoB/hC,KAAK+/B,SAC9B//B,KAAK+/B,QAAU,KAQnB,I,mFAACJ,CAAA,CAlmBgB,G,m0BA4mBnBA,GAAOe,mBAAqB,CAAC,ECtnBtB,IAAMuB,GAAWp+B,IAAA,SAAAo+B,K,4FAAAliC,CAAA,KAAAkiC,EAAA,I","sources":["webpack://@gql-grammar/antlr4/webpack/bootstrap","webpack://@gql-grammar/antlr4/webpack/runtime/define property getters","webpack://@gql-grammar/antlr4/webpack/runtime/hasOwnProperty shorthand","webpack://@gql-grammar/antlr4/webpack/runtime/make namespace object","webpack://@gql-grammar/antlr4/./src/misc/HashCode.js","webpack://@gql-grammar/antlr4/./src/action/LexerAction.js","webpack://@gql-grammar/antlr4/./src/atn/LexerActionType.js","webpack://@gql-grammar/antlr4/./src/action/LexerChannelAction.js","webpack://@gql-grammar/antlr4/./src/action/LexerCustomAction.js","webpack://@gql-grammar/antlr4/./src/action/LexerIndexedCustomAction.js","webpack://@gql-grammar/antlr4/./src/action/LexerModeAction.js","webpack://@gql-grammar/antlr4/./src/action/LexerMoreAction.js","webpack://@gql-grammar/antlr4/./src/action/LexerPopModeAction.js","webpack://@gql-grammar/antlr4/./src/action/LexerPushModeAction.js","webpack://@gql-grammar/antlr4/./src/action/LexerSkipAction.js","webpack://@gql-grammar/antlr4/./src/action/LexerTypeAction.js","webpack://@gql-grammar/antlr4/./src/transition/Transition.js","webpack://@gql-grammar/antlr4/./src/atn/AbstractPredicateTransition.js","webpack://@gql-grammar/antlr4/./src/Token.js","webpack://@gql-grammar/antlr4/./src/utils/equalArrays.js","webpack://@gql-grammar/antlr4/./src/utils/standardHashCodeFunction.js","webpack://@gql-grammar/antlr4/./src/utils/standardEqualsFunction.js","webpack://@gql-grammar/antlr4/./src/utils/valueToString.js","webpack://@gql-grammar/antlr4/./src/utils/arrayToString.js","webpack://@gql-grammar/antlr4/./src/misc/HashSet.js","webpack://@gql-grammar/antlr4/./src/atn/SemanticContext.js","webpack://@gql-grammar/antlr4/./src/atn/ATNConfig.js","webpack://@gql-grammar/antlr4/./src/misc/Interval.js","webpack://@gql-grammar/antlr4/./src/misc/IntervalSet.js","webpack://@gql-grammar/antlr4/./src/state/ATNState.js","webpack://@gql-grammar/antlr4/./src/state/RuleStopState.js","webpack://@gql-grammar/antlr4/./src/transition/RuleTransition.js","webpack://@gql-grammar/antlr4/./src/transition/SetTransition.js","webpack://@gql-grammar/antlr4/./src/transition/NotSetTransition.js","webpack://@gql-grammar/antlr4/./src/transition/WildcardTransition.js","webpack://@gql-grammar/antlr4/./src/tree/Tree.js","webpack://@gql-grammar/antlr4/./src/tree/SyntaxTree.js","webpack://@gql-grammar/antlr4/./src/tree/ParseTree.js","webpack://@gql-grammar/antlr4/./src/tree/RuleNode.js","webpack://@gql-grammar/antlr4/./src/tree/TerminalNode.js","webpack://@gql-grammar/antlr4/./src/tree/ErrorNode.js","webpack://@gql-grammar/antlr4/./src/tree/Trees.js","webpack://@gql-grammar/antlr4/./src/utils/escapeWhitespace.js","webpack://@gql-grammar/antlr4/./src/context/RuleContext.js","webpack://@gql-grammar/antlr4/./src/context/PredictionContext.js","webpack://@gql-grammar/antlr4/./src/context/ArrayPredictionContext.js","webpack://@gql-grammar/antlr4/./src/context/SingletonPredictionContext.js","webpack://@gql-grammar/antlr4/./src/context/EmptyPredictionContext.js","webpack://@gql-grammar/antlr4/./src/misc/HashMap.js","webpack://@gql-grammar/antlr4/./src/context/PredictionContextUtils.js","webpack://@gql-grammar/antlr4/./src/misc/BitSet.js","webpack://@gql-grammar/antlr4/./src/atn/LL1Analyzer.js","webpack://@gql-grammar/antlr4/./src/atn/ATN.js","webpack://@gql-grammar/antlr4/./src/atn/ATNConfigSet.js","webpack://@gql-grammar/antlr4/./src/atn/ATNDeserializationOptions.js","webpack://@gql-grammar/antlr4/./src/atn/ATNType.js","webpack://@gql-grammar/antlr4/./src/state/BasicState.js","webpack://@gql-grammar/antlr4/./src/state/DecisionState.js","webpack://@gql-grammar/antlr4/./src/state/BlockStartState.js","webpack://@gql-grammar/antlr4/./src/state/BlockEndState.js","webpack://@gql-grammar/antlr4/./src/state/LoopEndState.js","webpack://@gql-grammar/antlr4/./src/state/RuleStartState.js","webpack://@gql-grammar/antlr4/./src/state/TokensStartState.js","webpack://@gql-grammar/antlr4/./src/state/PlusLoopbackState.js","webpack://@gql-grammar/antlr4/./src/state/StarLoopbackState.js","webpack://@gql-grammar/antlr4/./src/state/StarLoopEntryState.js","webpack://@gql-grammar/antlr4/./src/state/PlusBlockStartState.js","webpack://@gql-grammar/antlr4/./src/state/StarBlockStartState.js","webpack://@gql-grammar/antlr4/./src/state/BasicBlockStartState.js","webpack://@gql-grammar/antlr4/./src/transition/AtomTransition.js","webpack://@gql-grammar/antlr4/./src/transition/RangeTransition.js","webpack://@gql-grammar/antlr4/./src/transition/ActionTransition.js","webpack://@gql-grammar/antlr4/./src/transition/EpsilonTransition.js","webpack://@gql-grammar/antlr4/./src/atn/Predicate.js","webpack://@gql-grammar/antlr4/./src/transition/PredicateTransition.js","webpack://@gql-grammar/antlr4/./src/atn/PrecedencePredicate.js","webpack://@gql-grammar/antlr4/./src/transition/PrecedencePredicateTransition.js","webpack://@gql-grammar/antlr4/./src/atn/ATNDeserializer.js","webpack://@gql-grammar/antlr4/./src/dfa/DFAState.js","webpack://@gql-grammar/antlr4/./src/atn/ATNSimulator.js","webpack://@gql-grammar/antlr4/./src/atn/LexerActionExecutor.js","webpack://@gql-grammar/antlr4/./src/atn/LexerATNConfig.js","webpack://@gql-grammar/antlr4/./src/error/ErrorListener.js","webpack://@gql-grammar/antlr4/./src/error/ConsoleErrorListener.js","webpack://@gql-grammar/antlr4/./src/error/ProxyErrorListener.js","webpack://@gql-grammar/antlr4/./src/Recognizer.js","webpack://@gql-grammar/antlr4/./src/CommonToken.js","webpack://@gql-grammar/antlr4/./src/CommonTokenFactory.js","webpack://@gql-grammar/antlr4/./src/error/RecognitionException.js","webpack://@gql-grammar/antlr4/./src/error/NoViableAltException.js","webpack://@gql-grammar/antlr4/./src/error/LexerNoViableAltException.js","webpack://@gql-grammar/antlr4/./src/error/InputMismatchException.js","webpack://@gql-grammar/antlr4/./src/error/FailedPredicateException.js","webpack://@gql-grammar/antlr4/./src/error/DiagnosticErrorListener.js","webpack://@gql-grammar/antlr4/./src/error/ParseCancellationException.js","webpack://@gql-grammar/antlr4/./src/error/ErrorStrategy.js","webpack://@gql-grammar/antlr4/./src/error/DefaultErrorStrategy.js","webpack://@gql-grammar/antlr4/./src/error/BailErrorStrategy.js","webpack://@gql-grammar/antlr4/./src/Lexer.js","webpack://@gql-grammar/antlr4/./src/atn/OrderedATNConfigSet.js","webpack://@gql-grammar/antlr4/./src/atn/LexerATNSimulator.js","webpack://@gql-grammar/antlr4/./src/dfa/PredPrediction.js","webpack://@gql-grammar/antlr4/./src/misc/AltDict.js","webpack://@gql-grammar/antlr4/./src/atn/PredictionMode.js","webpack://@gql-grammar/antlr4/./src/utils/DoubleDict.js","webpack://@gql-grammar/antlr4/./src/atn/ParserATNSimulator.js","webpack://@gql-grammar/antlr4/./src/atn/PredictionContextCache.js","webpack://@gql-grammar/antlr4/./src/tree/ParseTreeListener.js","webpack://@gql-grammar/antlr4/./src/tree/ParseTreeVisitor.js","webpack://@gql-grammar/antlr4/./src/tree/ParseTreeWalker.js","webpack://@gql-grammar/antlr4/./src/tree/TerminalNodeImpl.js","webpack://@gql-grammar/antlr4/./src/tree/ErrorNodeImpl.js","webpack://@gql-grammar/antlr4/./src/context/ParserRuleContext.js","webpack://@gql-grammar/antlr4/./src/context/InterpreterRuleContext.js","webpack://@gql-grammar/antlr4/./src/dfa/DFASerializer.js","webpack://@gql-grammar/antlr4/./src/dfa/LexerDFASerializer.js","webpack://@gql-grammar/antlr4/./src/dfa/DFA.js","webpack://@gql-grammar/antlr4/./src/utils/stringToCharArray.js","webpack://@gql-grammar/antlr4/./src/TokenStream.js","webpack://@gql-grammar/antlr4/./src/BufferedTokenStream.js","webpack://@gql-grammar/antlr4/./src/polyfills/codepointat.js","webpack://@gql-grammar/antlr4/./src/polyfills/fromcodepoint.js","webpack://@gql-grammar/antlr4/./src/CharStream.js","webpack://@gql-grammar/antlr4/./src/InputStream.js","webpack://@gql-grammar/antlr4/./src/FileStream.js","webpack://@gql-grammar/antlr4/./src/CharStreams.js","webpack://@gql-grammar/antlr4/./src/CommonTokenStream.js","webpack://@gql-grammar/antlr4/./src/TraceListener.js","webpack://@gql-grammar/antlr4/./src/Parser.js","webpack://@gql-grammar/antlr4/./src/TokenSource.js"],"sourcesContent":["// The require scope\nvar __webpack_require__ = {};\n\n","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexport class HashCode {\n  constructor() {\n    this.count = 0;\n    this.hash = 0;\n  }\n\n  static hashStuff() {\n    const hash = new HashCode();\n    hash.update.apply(hash, arguments);\n    return hash.finish();\n  }\n\n  update() {\n    for (let i = 0; i < arguments.length; i++) {\n      const value = arguments[i];\n      if (value == null) continue;\n      if (Array.isArray(value)) this.update.apply(this, value);\n      else {\n        let k = 0;\n        switch (typeof value) {\n          case 'undefined':\n          case 'function':\n            continue;\n          case 'number':\n          case 'boolean':\n            k = value;\n            break;\n          case 'string':\n            k = value.hashCode();\n            break;\n          default:\n            if (value.updateHashCode) value.updateHashCode(this);\n            else console.log('No updateHashCode for ' + value.toString());\n            continue;\n        }\n        k = k * 0xcc9e2d51;\n        k = (k << 15) | (k >>> (32 - 15));\n        k = k * 0x1b873593;\n        this.count = this.count + 1;\n        let hash = this.hash ^ k;\n        hash = (hash << 13) | (hash >>> (32 - 13));\n        hash = hash * 5 + 0xe6546b64;\n        this.hash = hash;\n      }\n    }\n  }\n\n  finish() {\n    let hash = this.hash ^ (this.count * 4);\n    hash = hash ^ (hash >>> 16);\n    hash = hash * 0x85ebca6b;\n    hash = hash ^ (hash >>> 13);\n    hash = hash * 0xc2b2ae35;\n    hash = hash ^ (hash >>> 16);\n    return hash;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { HashCode } from '../misc/HashCode.js';\n\n/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nexport class LexerAction {\n  constructor(action) {\n    this.actionType = action;\n    this.isPositionDependent = false;\n  }\n\n  hashCode() {\n    const hash = new HashCode();\n    this.updateHashCode(hash);\n    return hash.finish();\n  }\n\n  updateHashCode(hash) {\n    hash.update(this.actionType);\n  }\n\n  equals(other) {\n    return this === other;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexport const LexerActionType = {\n  // The type of a {@link LexerChannelAction} action.\n  CHANNEL: 0,\n  // The type of a {@link LexerCustomAction} action\n  CUSTOM: 1,\n  // The type of a {@link LexerModeAction} action.\n  MODE: 2,\n  //The type of a {@link LexerMoreAction} action.\n  MORE: 3,\n  //The type of a {@link LexerPopModeAction} action.\n  POP_MODE: 4,\n  //The type of a {@link LexerPushModeAction} action.\n  PUSH_MODE: 5,\n  //The type of a {@link LexerSkipAction} action.\n  SKIP: 6,\n  //The type of a {@link LexerTypeAction} action.\n  TYPE: 7,\n};\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { LexerActionType } from '../atn/LexerActionType.js';\nimport { LexerAction } from './LexerAction.js';\n\n/**\n * Implements the {@code channel} lexer action by calling\n * {@link Lexer//setChannel} with the assigned channel.\n * Constructs a new {@code channel} action with the specified channel value.\n * @param channel The channel value to pass to {@link Lexer//setChannel}\n */\nexport class LexerChannelAction extends LexerAction {\n  constructor(channel) {\n    super(LexerActionType.CHANNEL);\n    this.channel = channel;\n  }\n\n  /**\n   * <p>This action is implemented by calling {@link Lexer//setChannel} with the\n   * value provided by {@link //getChannel}.</p>\n   */\n  execute(lexer) {\n    lexer._channel = this.channel;\n  }\n\n  updateHashCode(hash) {\n    hash.update(this.actionType, this.channel);\n  }\n\n  equals(other) {\n    if (this === other) {\n      return true;\n    } else if (!(other instanceof LexerChannelAction)) {\n      return false;\n    } else {\n      return this.channel === other.channel;\n    }\n  }\n\n  toString() {\n    return 'channel(' + this.channel + ')';\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { LexerActionType } from '../atn/LexerActionType.js';\nimport { LexerAction } from './LexerAction.js';\n\n/**\n * Executes a custom lexer action by calling {@link Recognizer//action} with the\n * rule and action indexes assigned to the custom action. The implementation of\n * a custom action is added to the generated code for the lexer in an override\n * of {@link Recognizer//action} when the grammar is compiled.\n *\n * <p>This class may represent embedded actions created with the <code>{...}</code>\n * syntax in ANTLR 4, as well as actions created for lexer commands where the\n * command argument could not be evaluated when the grammar was compiled.</p>\n */\nexport class LexerCustomAction extends LexerAction {\n  /**\n   * Constructs a custom lexer action with the specified rule and action\n   * indexes.\n   *\n   * @param ruleIndex The rule index to use for calls to\n   * {@link Recognizer//action}.\n   * @param actionIndex The action index to use for calls to\n   * {@link Recognizer//action}.\n   */\n  constructor(ruleIndex, actionIndex) {\n    super(LexerActionType.CUSTOM);\n    this.ruleIndex = ruleIndex;\n    this.actionIndex = actionIndex;\n    this.isPositionDependent = true;\n  }\n\n  /**\n   * <p>Custom actions are implemented by calling {@link Lexer//action} with the\n   * appropriate rule and action indexes.</p>\n   */\n  execute(lexer) {\n    lexer.action(null, this.ruleIndex, this.actionIndex);\n  }\n\n  updateHashCode(hash) {\n    hash.update(this.actionType, this.ruleIndex, this.actionIndex);\n  }\n\n  equals(other) {\n    if (this === other) {\n      return true;\n    } else if (!(other instanceof LexerCustomAction)) {\n      return false;\n    } else {\n      return this.ruleIndex === other.ruleIndex && this.actionIndex === other.actionIndex;\n    }\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n/**\n * This implementation of {@link LexerAction} is used for tracking input offsets\n * for position-dependent actions within a {@link LexerActionExecutor}.\n *\n * <p>This action is not serialized as part of the ATN, and is only required for\n * position-dependent lexer actions which appear at a location other than the\n * end of a rule. For more information about DFA optimizations employed for\n * lexer actions, see {@link LexerActionExecutor//append} and\n * {@link LexerActionExecutor//fixOffsetBeforeMatch}.</p>\n *\n * Constructs a new indexed custom action by associating a character offset\n * with a {@link LexerAction}.\n *\n * <p>Note: This class is only required for lexer actions for which\n * {@link LexerAction//isPositionDependent} returns {@code true}.</p>\n *\n * @param offset The offset into the input {@link CharStream}, relative to\n * the token start index, at which the specified lexer action should be\n * executed.\n * @param action The lexer action to execute at a particular offset in the\n * input {@link CharStream}.\n */\nimport { LexerAction } from './LexerAction.js';\n\nexport class LexerIndexedCustomAction extends LexerAction {\n  constructor(offset, action) {\n    super(action.actionType);\n    this.offset = offset;\n    this.action = action;\n    this.isPositionDependent = true;\n  }\n\n  /**\n   * <p>This method calls {@link //execute} on the result of {@link //getAction}\n   * using the provided {@code lexer}.</p>\n   */\n  execute(lexer) {\n    // assume the input stream position was properly set by the calling code\n    this.action.execute(lexer);\n  }\n\n  updateHashCode(hash) {\n    hash.update(this.actionType, this.offset, this.action);\n  }\n\n  equals(other) {\n    if (this === other) {\n      return true;\n    } else if (!(other instanceof LexerIndexedCustomAction)) {\n      return false;\n    } else {\n      return this.offset === other.offset && this.action === other.action;\n    }\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { LexerActionType } from '../atn/LexerActionType.js';\nimport { LexerAction } from './LexerAction.js';\n\n/**\n * Implements the {@code mode} lexer action by calling {@link Lexer//mode} with\n * the assigned mode\n */\nexport class LexerModeAction extends LexerAction {\n  constructor(mode) {\n    super(LexerActionType.MODE);\n    this.mode = mode;\n  }\n\n  /**\n   * <p>This action is implemented by calling {@link Lexer//mode} with the\n   * value provided by {@link //getMode}.</p>\n   */\n  execute(lexer) {\n    lexer.mode(this.mode);\n  }\n\n  updateHashCode(hash) {\n    hash.update(this.actionType, this.mode);\n  }\n\n  equals(other) {\n    if (this === other) {\n      return true;\n    } else if (!(other instanceof LexerModeAction)) {\n      return false;\n    } else {\n      return this.mode === other.mode;\n    }\n  }\n\n  toString() {\n    return 'mode(' + this.mode + ')';\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { LexerActionType } from '../atn/LexerActionType.js';\nimport { LexerAction } from './LexerAction.js';\n\n/**\n * Implements the {@code more} lexer action by calling {@link Lexer//more}.\n *\n * <p>The {@code more} command does not have any parameters, so this action is\n * implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\n */\nexport class LexerMoreAction extends LexerAction {\n  constructor() {\n    super(LexerActionType.MORE);\n  }\n\n  /**\n   * <p>This action is implemented by calling {@link Lexer//popMode}.</p>\n   */\n  execute(lexer) {\n    lexer.more();\n  }\n\n  toString() {\n    return 'more';\n  }\n}\n\nLexerMoreAction.INSTANCE = new LexerMoreAction();\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { LexerActionType } from '../atn/LexerActionType.js';\nimport { LexerAction } from './LexerAction.js';\n\n/**\n * Implements the {@code popMode} lexer action by calling {@link Lexer//popMode}.\n *\n * <p>The {@code popMode} command does not have any parameters, so this action is\n * implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\n */\nexport class LexerPopModeAction extends LexerAction {\n  constructor() {\n    super(LexerActionType.POP_MODE);\n  }\n\n  /**\n   * <p>This action is implemented by calling {@link Lexer//popMode}.</p>\n   */\n  execute(lexer) {\n    lexer.popMode();\n  }\n\n  toString() {\n    return 'popMode';\n  }\n}\n\nLexerPopModeAction.INSTANCE = new LexerPopModeAction();\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { LexerActionType } from '../atn/LexerActionType.js';\nimport { LexerAction } from './LexerAction.js';\n\n/**\n * Implements the {@code pushMode} lexer action by calling\n * {@link Lexer//pushMode} with the assigned mode\n */\nexport class LexerPushModeAction extends LexerAction {\n  constructor(mode) {\n    super(LexerActionType.PUSH_MODE);\n    this.mode = mode;\n  }\n\n  /**\n   * <p>This action is implemented by calling {@link Lexer//pushMode} with the\n   * value provided by {@link //getMode}.</p>\n   */\n  execute(lexer) {\n    lexer.pushMode(this.mode);\n  }\n\n  updateHashCode(hash) {\n    hash.update(this.actionType, this.mode);\n  }\n\n  equals(other) {\n    if (this === other) {\n      return true;\n    } else if (!(other instanceof LexerPushModeAction)) {\n      return false;\n    } else {\n      return this.mode === other.mode;\n    }\n  }\n\n  toString() {\n    return 'pushMode(' + this.mode + ')';\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { LexerActionType } from '../atn/LexerActionType.js';\nimport { LexerAction } from './LexerAction.js';\n\n/**\n * Implements the {@code skip} lexer action by calling {@link Lexer//skip}.\n *\n * <p>The {@code skip} command does not have any parameters, so this action is\n * implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\n */\nexport class LexerSkipAction extends LexerAction {\n  constructor() {\n    super(LexerActionType.SKIP);\n  }\n\n  execute(lexer) {\n    lexer.skip();\n  }\n\n  toString() {\n    return 'skip';\n  }\n}\n\n// Provides a singleton instance of this parameterless lexer action.\nLexerSkipAction.INSTANCE = new LexerSkipAction();\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { LexerActionType } from '../atn/LexerActionType.js';\nimport { LexerAction } from './LexerAction.js';\n\n/**\n * Implements the {@code type} lexer action by calling {@link Lexer//setType}\n * with the assigned type\n */\n\nexport class LexerTypeAction extends LexerAction {\n  constructor(type) {\n    super(LexerActionType.TYPE);\n    this.type = type;\n  }\n\n  execute(lexer) {\n    lexer.type = this.type;\n  }\n\n  updateHashCode(hash) {\n    hash.update(this.actionType, this.type);\n  }\n\n  equals(other) {\n    if (this === other) {\n      return true;\n    } else if (!(other instanceof LexerTypeAction)) {\n      return false;\n    } else {\n      return this.type === other.type;\n    }\n  }\n\n  toString() {\n    return 'type(' + this.type + ')';\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * An ATN transition between any two ATN states.  Subclasses define\n * atom, set, epsilon, action, predicate, rule transitions.\n *\n * <p>This is a one way link.  It emanates from a state (usually via a list of\n * transitions) and has a target state.</p>\n *\n * <p>Since we never have to change the ATN transitions once we construct it,\n * we can fix these transitions as specific classes. The DFA transitions\n * on the other hand need to update the labels as it adds transitions to\n * the states. We'll use the term Edge for the DFA to distinguish them from\n * ATN transitions.</p>\n */\nexport class Transition {\n  constructor(target) {\n    // The target of this transition.\n    if (target === undefined || target === null) {\n      throw 'target cannot be null.';\n    }\n    this.target = target;\n    // Are we epsilon, action, sempred?\n    this.isEpsilon = false;\n    this.label = null;\n  }\n}\n\n// constants for serialization\n\nTransition.EPSILON = 1;\nTransition.RANGE = 2;\nTransition.RULE = 3;\n// e.g., {isType(input.LT(1))}?\nTransition.PREDICATE = 4;\nTransition.ATOM = 5;\nTransition.ACTION = 6;\n// ~(A|B) or ~atom, wildcard, which convert to next 2\nTransition.SET = 7;\nTransition.NOT_SET = 8;\nTransition.WILDCARD = 9;\nTransition.PRECEDENCE = 10;\n\nTransition.serializationNames = [\n  'INVALID',\n  'EPSILON',\n  'RANGE',\n  'RULE',\n  'PREDICATE',\n  'ATOM',\n  'ACTION',\n  'SET',\n  'NOT_SET',\n  'WILDCARD',\n  'PRECEDENCE',\n];\n\nTransition.serializationTypes = {\n  EpsilonTransition: Transition.EPSILON,\n  RangeTransition: Transition.RANGE,\n  RuleTransition: Transition.RULE,\n  PredicateTransition: Transition.PREDICATE,\n  AtomTransition: Transition.ATOM,\n  ActionTransition: Transition.ACTION,\n  SetTransition: Transition.SET,\n  NotSetTransition: Transition.NOT_SET,\n  WildcardTransition: Transition.WILDCARD,\n  PrecedencePredicateTransition: Transition.PRECEDENCE,\n};\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { Transition } from '../transition/Transition.js';\n\nexport class AbstractPredicateTransition extends Transition {\n  constructor(target) {\n    super(target);\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * A token has properties: text, type, line, character position in the line\n * (so we can ignore tabs), token channel, index, and source from which\n * we obtained this token.\n */\nexport class Token {\n  constructor() {\n    this.source = null;\n    this.type = null; // token type of the token\n    this.channel = null; // The parser ignores everything not on DEFAULT_CHANNEL\n    this.start = null; // optional; return -1 if not implemented.\n    this.stop = null; // optional; return -1 if not implemented.\n    this.tokenIndex = null; // from 0..n-1 of the token object in the input stream\n    this.line = null; // line=1..n of the 1st character\n    this.column = null; // beginning of the line at which it occurs, 0..n-1\n    this._text = null; // text of the token.\n  }\n\n  get text() {\n    return this._text;\n  }\n\n  set text(text) {\n    this._text = text;\n  }\n\n  getTokenSource() {\n    return this.source[0];\n  }\n\n  getInputStream() {\n    return this.source[1];\n  }\n}\n\nToken.INVALID_TYPE = 0;\n\n/**\n * During lookahead operations, this \"token\" signifies we hit rule end ATN state\n * and did not follow it despite needing to.\n */\nToken.EPSILON = -2;\n\nToken.MIN_USER_TOKEN_TYPE = 1;\n\nToken.EOF = -1;\n\n/**\n * All tokens go to the parser (unless skip() is called in that rule)\n * on a particular \"channel\". The parser tunes to a particular channel\n * so that whitespace etc... can go to the parser on a \"hidden\" channel.\n */\nToken.DEFAULT_CHANNEL = 0;\n\n/**\n * Anything on different channel than DEFAULT_CHANNEL is not parsed\n * by parser.\n */\nToken.HIDDEN_CHANNEL = 1;\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexport function equalArrays(a, b) {\n  if (!Array.isArray(a) || !Array.isArray(b)) return false;\n  if (a === b) return true;\n  if (a.length !== b.length) return false;\n  for (let i = 0; i < a.length; i++) {\n    if (a[i] === b[i]) continue;\n    if (!a[i].equals || !a[i].equals(b[i])) return false;\n  }\n  return true;\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexport function standardHashCodeFunction(a) {\n  return a ? a.hashCode() : -1;\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexport function standardEqualsFunction(a, b) {\n  return a ? a.equals(b) : a === b;\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexport function valueToString(v) {\n  return v === null ? 'null' : v;\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { valueToString } from './valueToString.js';\n\nexport function arrayToString(a) {\n  return Array.isArray(a) ? '[' + a.map(valueToString).join(', ') + ']' : 'null';\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { standardHashCodeFunction } from '../utils/standardHashCodeFunction.js';\nimport { standardEqualsFunction } from '../utils/standardEqualsFunction.js';\nimport { arrayToString } from '../utils/arrayToString.js';\n\nconst HASH_KEY_PREFIX = 'h-';\n\nexport class HashSet {\n  constructor(hashFunction, equalsFunction) {\n    this.data = {};\n    this.hashFunction = hashFunction || standardHashCodeFunction;\n    this.equalsFunction = equalsFunction || standardEqualsFunction;\n  }\n\n  get length() {\n    return Object.keys(this.data)\n      .filter((key) => key.startsWith(HASH_KEY_PREFIX))\n      .map((key) => this.data[key].length, this)\n      .reduce((accum, item) => accum + item, 0);\n  }\n\n  add(value) {\n    const key = HASH_KEY_PREFIX + this.hashFunction(value);\n    if (key in this.data) {\n      const values = this.data[key];\n      for (let i = 0; i < values.length; i++) {\n        if (this.equalsFunction(value, values[i])) {\n          return values[i];\n        }\n      }\n      values.push(value);\n      return value;\n    } else {\n      this.data[key] = [value];\n      return value;\n    }\n  }\n\n  has(value) {\n    return this.get(value) != null;\n  }\n\n  get(value) {\n    const key = HASH_KEY_PREFIX + this.hashFunction(value);\n    if (key in this.data) {\n      const values = this.data[key];\n      for (let i = 0; i < values.length; i++) {\n        if (this.equalsFunction(value, values[i])) {\n          return values[i];\n        }\n      }\n    }\n    return null;\n  }\n\n  values() {\n    return Object.keys(this.data)\n      .filter((key) => key.startsWith(HASH_KEY_PREFIX))\n      .flatMap((key) => this.data[key], this);\n  }\n\n  toString() {\n    return arrayToString(this.values());\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { equalArrays } from '../utils/equalArrays.js';\nimport { HashCode } from '../misc/HashCode.js';\nimport { HashSet } from '../misc/HashSet.js';\n\n/**\n * A tree structure used to record the semantic context in which\n * an ATN configuration is valid.  It's either a single predicate,\n * a conjunction {@code p1&&p2}, or a sum of products {@code p1||p2}.\n *\n * <p>I have scoped the {@link AND}, {@link OR}, and {@link Predicate} subclasses of\n * {@link SemanticContext} within the scope of this outer class.</p>\n */\nexport class SemanticContext {\n  static andContext(a, b) {\n    if (a === null || a === SemanticContext.NONE) {\n      return b;\n    }\n    if (b === null || b === SemanticContext.NONE) {\n      return a;\n    }\n    const result = new AND(a, b);\n    if (result.opnds.length === 1) {\n      return result.opnds[0];\n    } else {\n      return result;\n    }\n  }\n\n  static orContext(a, b) {\n    if (a === null) {\n      return b;\n    }\n    if (b === null) {\n      return a;\n    }\n    if (a === SemanticContext.NONE || b === SemanticContext.NONE) {\n      return SemanticContext.NONE;\n    }\n    const result = new OR(a, b);\n    if (result.opnds.length === 1) {\n      return result.opnds[0];\n    } else {\n      return result;\n    }\n  }\n\n  hashCode() {\n    const hash = new HashCode();\n    this.updateHashCode(hash);\n    return hash.finish();\n  }\n\n  /**\n   * For context independent predicates, we evaluate them without a local\n   * context (i.e., null context). That way, we can evaluate them without\n   * having to create proper rule-specific context during prediction (as\n   * opposed to the parser, which creates them naturally). In a practical\n   * sense, this avoids a cast exception from RuleContext to myruleContext.\n   *\n   * <p>For context dependent predicates, we must pass in a local context so that\n   * references such as $arg evaluate properly as _localctx.arg. We only\n   * capture context dependent predicates in the context in which we begin\n   * prediction, so we passed in the outer context here in case of context\n   * dependent predicate evaluation.</p>\n   */\n  evaluate(parser, outerContext) {}\n\n  /**\n   * Evaluate the precedence predicates for the context and reduce the result.\n   *\n   * @param parser The parser instance.\n   * @param outerContext The current parser context object.\n   * @return The simplified semantic context after precedence predicates are\n   * evaluated, which will be one of the following values.\n   * <ul>\n   * <li>{@link //NONE}: if the predicate simplifies to {@code true} after\n   * precedence predicates are evaluated.</li>\n   * <li>{@code null}: if the predicate simplifies to {@code false} after\n   * precedence predicates are evaluated.</li>\n   * <li>{@code this}: if the semantic context is not changed as a result of\n   * precedence predicate evaluation.</li>\n   * <li>A non-{@code null} {@link SemanticContext}: the new simplified\n   * semantic context after precedence predicates are evaluated.</li>\n   * </ul>\n   */\n  evalPrecedence(parser, outerContext) {\n    return this;\n  }\n}\n\nclass AND extends SemanticContext {\n  /**\n   * A semantic context which is true whenever none of the contained contexts\n   * is false\n   */\n  constructor(a, b) {\n    super();\n    const operands = new HashSet();\n    if (a instanceof AND) {\n      a.opnds.map(function (o) {\n        operands.add(o);\n      });\n    } else {\n      operands.add(a);\n    }\n    if (b instanceof AND) {\n      b.opnds.map(function (o) {\n        operands.add(o);\n      });\n    } else {\n      operands.add(b);\n    }\n    const precedencePredicates = filterPrecedencePredicates(operands);\n    if (precedencePredicates.length > 0) {\n      // interested in the transition with the lowest precedence\n      let reduced = null;\n      precedencePredicates.map(function (p) {\n        if (reduced === null || p.precedence < reduced.precedence) {\n          reduced = p;\n        }\n      });\n      operands.add(reduced);\n    }\n    this.opnds = Array.from(operands.values());\n  }\n\n  equals(other) {\n    if (this === other) {\n      return true;\n    } else if (!(other instanceof AND)) {\n      return false;\n    } else {\n      return equalArrays(this.opnds, other.opnds);\n    }\n  }\n\n  updateHashCode(hash) {\n    hash.update(this.opnds, 'AND');\n  }\n\n  /**\n   * {@inheritDoc}\n   *\n   * <p>\n   * The evaluation of predicates by this context is short-circuiting, but\n   * unordered.</p>\n   */\n  evaluate(parser, outerContext) {\n    for (let i = 0; i < this.opnds.length; i++) {\n      if (!this.opnds[i].evaluate(parser, outerContext)) {\n        return false;\n      }\n    }\n    return true;\n  }\n\n  evalPrecedence(parser, outerContext) {\n    let differs = false;\n    const operands = [];\n    for (let i = 0; i < this.opnds.length; i++) {\n      const context = this.opnds[i];\n      const evaluated = context.evalPrecedence(parser, outerContext);\n      differs |= evaluated !== context;\n      if (evaluated === null) {\n        // The AND context is false if any element is false\n        return null;\n      } else if (evaluated !== SemanticContext.NONE) {\n        // Reduce the result by skipping true elements\n        operands.push(evaluated);\n      }\n    }\n    if (!differs) {\n      return this;\n    }\n    if (operands.length === 0) {\n      // all elements were true, so the AND context is true\n      return SemanticContext.NONE;\n    }\n    let result = null;\n    operands.map(function (o) {\n      result = result === null ? o : SemanticContext.andContext(result, o);\n    });\n    return result;\n  }\n\n  toString() {\n    const s = this.opnds.map((o) => o.toString());\n    return (s.length > 3 ? s.slice(3) : s).join('&&');\n  }\n}\n\nclass OR extends SemanticContext {\n  /**\n   * A semantic context which is true whenever at least one of the contained\n   * contexts is true\n   */\n  constructor(a, b) {\n    super();\n    const operands = new HashSet();\n    if (a instanceof OR) {\n      a.opnds.map(function (o) {\n        operands.add(o);\n      });\n    } else {\n      operands.add(a);\n    }\n    if (b instanceof OR) {\n      b.opnds.map(function (o) {\n        operands.add(o);\n      });\n    } else {\n      operands.add(b);\n    }\n\n    const precedencePredicates = filterPrecedencePredicates(operands);\n    if (precedencePredicates.length > 0) {\n      // interested in the transition with the highest precedence\n      const s = precedencePredicates.sort(function (a, b) {\n        return a.compareTo(b);\n      });\n      const reduced = s[s.length - 1];\n      operands.add(reduced);\n    }\n    this.opnds = Array.from(operands.values());\n  }\n\n  equals(other) {\n    if (this === other) {\n      return true;\n    } else if (!(other instanceof OR)) {\n      return false;\n    } else {\n      return equalArrays(this.opnds, other.opnds);\n    }\n  }\n\n  updateHashCode(hash) {\n    hash.update(this.opnds, 'OR');\n  }\n\n  /**\n   * <p>\n   * The evaluation of predicates by this context is short-circuiting, but\n   * unordered.</p>\n   */\n  evaluate(parser, outerContext) {\n    for (let i = 0; i < this.opnds.length; i++) {\n      if (this.opnds[i].evaluate(parser, outerContext)) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  evalPrecedence(parser, outerContext) {\n    let differs = false;\n    const operands = [];\n    for (let i = 0; i < this.opnds.length; i++) {\n      const context = this.opnds[i];\n      const evaluated = context.evalPrecedence(parser, outerContext);\n      differs |= evaluated !== context;\n      if (evaluated === SemanticContext.NONE) {\n        // The OR context is true if any element is true\n        return SemanticContext.NONE;\n      } else if (evaluated !== null) {\n        // Reduce the result by skipping false elements\n        operands.push(evaluated);\n      }\n    }\n    if (!differs) {\n      return this;\n    }\n    if (operands.length === 0) {\n      // all elements were false, so the OR context is false\n      return null;\n    }\n    const result = null;\n    operands.map(function (o) {\n      return result === null ? o : SemanticContext.orContext(result, o);\n    });\n    return result;\n  }\n\n  toString() {\n    const s = this.opnds.map((o) => o.toString());\n    return (s.length > 3 ? s.slice(3) : s).join('||');\n  }\n}\n\nfunction filterPrecedencePredicates(set) {\n  const result = [];\n  set.values().map(function (context) {\n    if (context instanceof SemanticContext.PrecedencePredicate) {\n      result.push(context);\n    }\n  });\n  return result;\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { SemanticContext } from './SemanticContext.js';\nimport { HashCode } from '../misc/HashCode.js';\n\nfunction checkParams(params, isCfg) {\n  if (params === null) {\n    const result = { state: null, alt: null, context: null, semanticContext: null };\n    if (isCfg) {\n      result.reachesIntoOuterContext = 0;\n    }\n    return result;\n  } else {\n    const props = {};\n    props.state = params.state || null;\n    props.alt = params.alt === undefined ? null : params.alt;\n    props.context = params.context || null;\n    props.semanticContext = params.semanticContext || null;\n    if (isCfg) {\n      props.reachesIntoOuterContext = params.reachesIntoOuterContext || 0;\n      props.precedenceFilterSuppressed = params.precedenceFilterSuppressed || false;\n    }\n    return props;\n  }\n}\n\nexport class ATNConfig {\n  /**\n   * @param {Object} params A tuple: (ATN state, predicted alt, syntactic, semantic context).\n   * The syntactic context is a graph-structured stack node whose\n   * path(s) to the root is the rule invocation(s)\n   * chain used to arrive at the state.  The semantic context is\n   * the tree of semantic predicates encountered before reaching\n   * an ATN state\n   */\n  constructor(params, config) {\n    this.checkContext(params, config);\n    params = checkParams(params);\n    config = checkParams(config, true);\n    // The ATN state associated with this configuration///\n    this.state = params.state !== null ? params.state : config.state;\n    // What alt (or lexer rule) is predicted by this configuration///\n    this.alt = params.alt !== null ? params.alt : config.alt;\n    /**\n     * The stack of invoking states leading to the rule/states associated\n     * with this config.  We track only those contexts pushed during\n     * execution of the ATN simulator\n     */\n    this.context = params.context !== null ? params.context : config.context;\n    this.semanticContext =\n      params.semanticContext !== null\n        ? params.semanticContext\n        : config.semanticContext !== null\n        ? config.semanticContext\n        : SemanticContext.NONE;\n    // TODO: make it a boolean then\n    /**\n     * We cannot execute predicates dependent upon local context unless\n     * we know for sure we are in the correct context. Because there is\n     * no way to do this efficiently, we simply cannot evaluate\n     * dependent predicates unless we are in the rule that initially\n     * invokes the ATN simulator.\n     * closure() tracks the depth of how far we dip into the\n     * outer context: depth &gt; 0.  Note that it may not be totally\n     * accurate depth since I don't ever decrement\n     */\n    this.reachesIntoOuterContext = config.reachesIntoOuterContext;\n    this.precedenceFilterSuppressed = config.precedenceFilterSuppressed;\n  }\n\n  checkContext(params, config) {\n    if (\n      (params.context === null || params.context === undefined) &&\n      (config === null || config.context === null || config.context === undefined)\n    ) {\n      this.context = null;\n    }\n  }\n\n  hashCode() {\n    const hash = new HashCode();\n    this.updateHashCode(hash);\n    return hash.finish();\n  }\n\n  updateHashCode(hash) {\n    hash.update(this.state.stateNumber, this.alt, this.context, this.semanticContext);\n  }\n\n  /**\n   * An ATN configuration is equal to another if both have\n   * the same state, they predict the same alternative, and\n   * syntactic/semantic contexts are the same\n   */\n  equals(other) {\n    if (this === other) {\n      return true;\n    } else if (!(other instanceof ATNConfig)) {\n      return false;\n    } else {\n      return (\n        this.state.stateNumber === other.state.stateNumber &&\n        this.alt === other.alt &&\n        (this.context === null ? other.context === null : this.context.equals(other.context)) &&\n        this.semanticContext.equals(other.semanticContext) &&\n        this.precedenceFilterSuppressed === other.precedenceFilterSuppressed\n      );\n    }\n  }\n\n  hashCodeForConfigSet() {\n    const hash = new HashCode();\n    hash.update(this.state.stateNumber, this.alt, this.semanticContext);\n    return hash.finish();\n  }\n\n  equalsForConfigSet(other) {\n    if (this === other) {\n      return true;\n    } else if (!(other instanceof ATNConfig)) {\n      return false;\n    } else {\n      return (\n        this.state.stateNumber === other.state.stateNumber &&\n        this.alt === other.alt &&\n        this.semanticContext.equals(other.semanticContext)\n      );\n    }\n  }\n\n  toString() {\n    return (\n      '(' +\n      this.state +\n      ',' +\n      this.alt +\n      (this.context !== null ? ',[' + this.context.toString() + ']' : '') +\n      (this.semanticContext !== SemanticContext.NONE ? ',' + this.semanticContext.toString() : '') +\n      (this.reachesIntoOuterContext > 0 ? ',up=' + this.reachesIntoOuterContext : '') +\n      ')'\n    );\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n/* stop is not included! */\nexport class Interval {\n  constructor(start, stop) {\n    this.start = start;\n    this.stop = stop;\n  }\n\n  get length() {\n    return this.stop - this.start;\n  }\n\n  clone() {\n    return new Interval(this.start, this.stop);\n  }\n\n  contains(item) {\n    return item >= this.start && item < this.stop;\n  }\n\n  toString() {\n    if (this.start === this.stop - 1) {\n      return this.start.toString();\n    } else {\n      return this.start.toString() + '..' + (this.stop - 1).toString();\n    }\n  }\n}\n\nInterval.INVALID_INTERVAL = new Interval(-1, -2);\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { Token } from '../Token.js';\nimport { Interval } from './Interval.js';\n\nexport class IntervalSet {\n  constructor() {\n    this.intervals = null;\n    this.readOnly = false;\n  }\n\n  get length() {\n    return this.intervals.map((interval) => interval.length).reduce((acc, val) => acc + val);\n  }\n\n  first(v) {\n    if (this.intervals === null || this.intervals.length === 0) {\n      return Token.INVALID_TYPE;\n    } else {\n      return this.intervals[0].start;\n    }\n  }\n\n  addOne(v) {\n    this.addInterval(new Interval(v, v + 1));\n  }\n\n  addRange(l, h) {\n    this.addInterval(new Interval(l, h + 1));\n  }\n\n  addInterval(toAdd) {\n    if (this.intervals === null) {\n      this.intervals = [];\n      this.intervals.push(toAdd.clone());\n    } else {\n      // find insert pos\n      for (let pos = 0; pos < this.intervals.length; pos++) {\n        const existing = this.intervals[pos];\n        // distinct range -> insert\n        if (toAdd.stop < existing.start) {\n          this.intervals.splice(pos, 0, toAdd);\n          return;\n        }\n        // contiguous range -> adjust\n        else if (toAdd.stop === existing.start) {\n          this.intervals[pos] = new Interval(toAdd.start, existing.stop);\n          return;\n        }\n        // overlapping range -> adjust and reduce\n        else if (toAdd.start <= existing.stop) {\n          this.intervals[pos] = new Interval(\n            Math.min(existing.start, toAdd.start),\n            Math.max(existing.stop, toAdd.stop),\n          );\n          this.reduce(pos);\n          return;\n        }\n      }\n      // greater than any existing\n      this.intervals.push(toAdd.clone());\n    }\n  }\n\n  addSet(other) {\n    if (other.intervals !== null) {\n      other.intervals.forEach((toAdd) => this.addInterval(toAdd), this);\n    }\n    return this;\n  }\n\n  reduce(pos) {\n    // only need to reduce if pos is not the last\n    if (pos < this.intervals.length - 1) {\n      const current = this.intervals[pos];\n      const next = this.intervals[pos + 1];\n      // if next contained in current\n      if (current.stop >= next.stop) {\n        this.intervals.splice(pos + 1, 1);\n        this.reduce(pos);\n      } else if (current.stop >= next.start) {\n        this.intervals[pos] = new Interval(current.start, next.stop);\n        this.intervals.splice(pos + 1, 1);\n      }\n    }\n  }\n\n  complement(start, stop) {\n    const result = new IntervalSet();\n    result.addInterval(new Interval(start, stop + 1));\n    if (this.intervals !== null) this.intervals.forEach((toRemove) => result.removeRange(toRemove));\n    return result;\n  }\n\n  contains(item) {\n    if (this.intervals === null) {\n      return false;\n    } else {\n      for (let k = 0; k < this.intervals.length; k++) {\n        if (this.intervals[k].contains(item)) {\n          return true;\n        }\n      }\n      return false;\n    }\n  }\n\n  removeRange(toRemove) {\n    if (toRemove.start === toRemove.stop - 1) {\n      this.removeOne(toRemove.start);\n    } else if (this.intervals !== null) {\n      let pos = 0;\n      for (let n = 0; n < this.intervals.length; n++) {\n        const existing = this.intervals[pos];\n        // intervals are ordered\n        if (toRemove.stop <= existing.start) {\n          return;\n        }\n        // check for including range, split it\n        else if (toRemove.start > existing.start && toRemove.stop < existing.stop) {\n          this.intervals[pos] = new Interval(existing.start, toRemove.start);\n          const x = new Interval(toRemove.stop, existing.stop);\n          this.intervals.splice(pos, 0, x);\n          return;\n        }\n        // check for included range, remove it\n        else if (toRemove.start <= existing.start && toRemove.stop >= existing.stop) {\n          this.intervals.splice(pos, 1);\n          pos = pos - 1; // need another pass\n        }\n        // check for lower boundary\n        else if (toRemove.start < existing.stop) {\n          this.intervals[pos] = new Interval(existing.start, toRemove.start);\n        }\n        // check for upper boundary\n        else if (toRemove.stop < existing.stop) {\n          this.intervals[pos] = new Interval(toRemove.stop, existing.stop);\n        }\n        pos += 1;\n      }\n    }\n  }\n\n  removeOne(value) {\n    if (this.intervals !== null) {\n      for (let i = 0; i < this.intervals.length; i++) {\n        const existing = this.intervals[i];\n        // intervals are ordered\n        if (value < existing.start) {\n          return;\n        }\n        // check for single value range\n        else if (value === existing.start && value === existing.stop - 1) {\n          this.intervals.splice(i, 1);\n          return;\n        }\n        // check for lower boundary\n        else if (value === existing.start) {\n          this.intervals[i] = new Interval(existing.start + 1, existing.stop);\n          return;\n        }\n        // check for upper boundary\n        else if (value === existing.stop - 1) {\n          this.intervals[i] = new Interval(existing.start, existing.stop - 1);\n          return;\n        }\n        // split existing range\n        else if (value < existing.stop - 1) {\n          const replace = new Interval(existing.start, value);\n          existing.start = value + 1;\n          this.intervals.splice(i, 0, replace);\n          return;\n        }\n      }\n    }\n  }\n\n  toString(literalNames, symbolicNames, elemsAreChar) {\n    literalNames = literalNames || null;\n    symbolicNames = symbolicNames || null;\n    elemsAreChar = elemsAreChar || false;\n    if (this.intervals === null) {\n      return '{}';\n    } else if (literalNames !== null || symbolicNames !== null) {\n      return this.toTokenString(literalNames, symbolicNames);\n    } else if (elemsAreChar) {\n      return this.toCharString();\n    } else {\n      return this.toIndexString();\n    }\n  }\n\n  toCharString() {\n    const names = [];\n    for (let i = 0; i < this.intervals.length; i++) {\n      const existing = this.intervals[i];\n      if (existing.stop === existing.start + 1) {\n        if (existing.start === Token.EOF) {\n          names.push('<EOF>');\n        } else {\n          names.push(\"'\" + String.fromCharCode(existing.start) + \"'\");\n        }\n      } else {\n        names.push(\"'\" + String.fromCharCode(existing.start) + \"'..'\" + String.fromCharCode(existing.stop - 1) + \"'\");\n      }\n    }\n    if (names.length > 1) {\n      return '{' + names.join(', ') + '}';\n    } else {\n      return names[0];\n    }\n  }\n\n  toIndexString() {\n    const names = [];\n    for (let i = 0; i < this.intervals.length; i++) {\n      const existing = this.intervals[i];\n      if (existing.stop === existing.start + 1) {\n        if (existing.start === Token.EOF) {\n          names.push('<EOF>');\n        } else {\n          names.push(existing.start.toString());\n        }\n      } else {\n        names.push(existing.start.toString() + '..' + (existing.stop - 1).toString());\n      }\n    }\n    if (names.length > 1) {\n      return '{' + names.join(', ') + '}';\n    } else {\n      return names[0];\n    }\n  }\n\n  toTokenString(literalNames, symbolicNames) {\n    const names = [];\n    for (let i = 0; i < this.intervals.length; i++) {\n      const existing = this.intervals[i];\n      for (let j = existing.start; j < existing.stop; j++) {\n        names.push(this.elementName(literalNames, symbolicNames, j));\n      }\n    }\n    if (names.length > 1) {\n      return '{' + names.join(', ') + '}';\n    } else {\n      return names[0];\n    }\n  }\n\n  elementName(literalNames, symbolicNames, token) {\n    if (token === Token.EOF) {\n      return '<EOF>';\n    } else if (token === Token.EPSILON) {\n      return '<EPSILON>';\n    } else {\n      return literalNames[token] || symbolicNames[token];\n    }\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * The following images show the relation of states and\n * {@link ATNState//transitions} for various grammar constructs.\n *\n * <ul>\n *\n * <li>Solid edges marked with an &//0949; indicate a required\n * {@link EpsilonTransition}.</li>\n *\n * <li>Dashed edges indicate locations where any transition derived from\n * {@link Transition} might appear.</li>\n *\n * <li>Dashed nodes are place holders for either a sequence of linked\n * {@link BasicState} states or the inclusion of a block representing a nested\n * construct in one of the forms below.</li>\n *\n * <li>Nodes showing multiple outgoing alternatives with a {@code ...} support\n * any number of alternatives (one or more). Nodes without the {@code ...} only\n * support the exact number of alternatives shown in the diagram.</li>\n *\n * </ul>\n *\n * <h2>Basic Blocks</h2>\n *\n * <h3>Rule</h3>\n *\n * <embed src=\"images/Rule.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Block of 1 or more alternatives</h3>\n *\n * <embed src=\"images/Block.svg\" type=\"image/svg+xml\"/>\n *\n * <h2>Greedy Loops</h2>\n *\n * <h3>Greedy Closure: {@code (...)*}</h3>\n *\n * <embed src=\"images/ClosureGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Greedy Positive Closure: {@code (...)+}</h3>\n *\n * <embed src=\"images/PositiveClosureGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Greedy Optional: {@code (...)?}</h3>\n *\n * <embed src=\"images/OptionalGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h2>Non-Greedy Loops</h2>\n *\n * <h3>Non-Greedy Closure: {@code (...)*?}</h3>\n *\n * <embed src=\"images/ClosureNonGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Non-Greedy Positive Closure: {@code (...)+?}</h3>\n *\n * <embed src=\"images/PositiveClosureNonGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Non-Greedy Optional: {@code (...)??}</h3>\n *\n * <embed src=\"images/OptionalNonGreedy.svg\" type=\"image/svg+xml\"/>\n */\nexport class ATNState {\n  constructor() {\n    // Which ATN are we in?\n    this.atn = null;\n    this.stateNumber = ATNState.INVALID_STATE_NUMBER;\n    this.stateType = null;\n    this.ruleIndex = 0; // at runtime, we don't have Rule objects\n    this.epsilonOnlyTransitions = false;\n    // Track the transitions emanating from this ATN state.\n    this.transitions = [];\n    // Used to cache lookahead during parsing, not used during construction\n    this.nextTokenWithinRule = null;\n  }\n\n  toString() {\n    return this.stateNumber;\n  }\n\n  equals(other) {\n    if (other instanceof ATNState) {\n      return this.stateNumber === other.stateNumber;\n    } else {\n      return false;\n    }\n  }\n\n  isNonGreedyExitState() {\n    return false;\n  }\n\n  addTransition(trans, index) {\n    if (index === undefined) {\n      index = -1;\n    }\n    if (this.transitions.length === 0) {\n      this.epsilonOnlyTransitions = trans.isEpsilon;\n    } else if (this.epsilonOnlyTransitions !== trans.isEpsilon) {\n      this.epsilonOnlyTransitions = false;\n    }\n    if (index === -1) {\n      this.transitions.push(trans);\n    } else {\n      this.transitions.splice(index, 1, trans);\n    }\n  }\n}\n\n// constants for serialization\nATNState.INVALID_TYPE = 0;\nATNState.BASIC = 1;\nATNState.RULE_START = 2;\nATNState.BLOCK_START = 3;\nATNState.PLUS_BLOCK_START = 4;\nATNState.STAR_BLOCK_START = 5;\nATNState.TOKEN_START = 6;\nATNState.RULE_STOP = 7;\nATNState.BLOCK_END = 8;\nATNState.STAR_LOOP_BACK = 9;\nATNState.STAR_LOOP_ENTRY = 10;\nATNState.PLUS_LOOP_BACK = 11;\nATNState.LOOP_END = 12;\n\nATNState.serializationNames = [\n  'INVALID',\n  'BASIC',\n  'RULE_START',\n  'BLOCK_START',\n  'PLUS_BLOCK_START',\n  'STAR_BLOCK_START',\n  'TOKEN_START',\n  'RULE_STOP',\n  'BLOCK_END',\n  'STAR_LOOP_BACK',\n  'STAR_LOOP_ENTRY',\n  'PLUS_LOOP_BACK',\n  'LOOP_END',\n];\n\nATNState.INVALID_STATE_NUMBER = -1;\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { ATNState } from './ATNState.js';\n\n/**\n * The last node in the ATN for a rule, unless that rule is the start symbol.\n * In that case, there is one transition to EOF. Later, we might encode\n * references to all calls to this rule to compute FOLLOW sets for\n * error handling\n */\nexport class RuleStopState extends ATNState {\n  constructor() {\n    super();\n    this.stateType = ATNState.RULE_STOP;\n    return this;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { Transition } from './Transition.js';\n\nexport class RuleTransition extends Transition {\n  constructor(ruleStart, ruleIndex, precedence, followState) {\n    super(ruleStart);\n    // ptr to the rule definition object for this rule ref\n    this.ruleIndex = ruleIndex;\n    this.precedence = precedence;\n    // what node to begin computations following ref to rule\n    this.followState = followState;\n    this.serializationType = Transition.RULE;\n    this.isEpsilon = true;\n  }\n\n  matches(symbol, minVocabSymbol, maxVocabSymbol) {\n    return false;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n// A transition containing a set of values.\nimport { IntervalSet } from '../misc/IntervalSet.js';\nimport { Token } from '../Token.js';\nimport { Transition } from './Transition.js';\n\nexport class SetTransition extends Transition {\n  constructor(target, set) {\n    super(target);\n    this.serializationType = Transition.SET;\n    if (set !== undefined && set !== null) {\n      this.label = set;\n    } else {\n      this.label = new IntervalSet();\n      this.label.addOne(Token.INVALID_TYPE);\n    }\n  }\n\n  matches(symbol, minVocabSymbol, maxVocabSymbol) {\n    return this.label.contains(symbol);\n  }\n\n  toString() {\n    return this.label.toString();\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { Transition } from './Transition.js';\nimport { SetTransition } from './SetTransition.js';\n\nexport class NotSetTransition extends SetTransition {\n  constructor(target, set) {\n    super(target, set);\n    this.serializationType = Transition.NOT_SET;\n  }\n\n  matches(symbol, minVocabSymbol, maxVocabSymbol) {\n    return (\n      symbol >= minVocabSymbol && symbol <= maxVocabSymbol && !super.matches(symbol, minVocabSymbol, maxVocabSymbol)\n    );\n  }\n\n  toString() {\n    return '~' + super.toString();\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { Transition } from './Transition.js';\n\nexport class WildcardTransition extends Transition {\n  constructor(target) {\n    super(target);\n    this.serializationType = Transition.WILDCARD;\n  }\n\n  matches(symbol, minVocabSymbol, maxVocabSymbol) {\n    return symbol >= minVocabSymbol && symbol <= maxVocabSymbol;\n  }\n\n  toString() {\n    return '.';\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * The basic notion of a tree has a parent, a payload, and a list of children.\n * It is the most abstract interface for all the trees used by ANTLR.\n */\nexport class Tree {}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { Tree } from './Tree.js';\n\nexport class SyntaxTree extends Tree {}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { SyntaxTree } from './SyntaxTree.js';\n\nexport class ParseTree extends SyntaxTree {}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { ParseTree } from './ParseTree.js';\n\nexport class RuleNode extends ParseTree {\n  get ruleContext() {\n    throw new Error('missing interface implementation');\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { ParseTree } from './ParseTree.js';\n\nexport class TerminalNode extends ParseTree {}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { TerminalNode } from './TerminalNode.js';\n\nexport class ErrorNode extends TerminalNode {}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { Token } from '../Token.js';\nimport { ErrorNode } from './ErrorNode.js';\nimport { TerminalNode } from './TerminalNode.js';\nimport { RuleNode } from './RuleNode.js';\nimport { escapeWhitespace } from '../utils/escapeWhitespace.js';\n\n/** A set of utility routines useful for all kinds of ANTLR trees. */\nexport const Trees = {\n  /**\n   * Print out a whole tree in LISP form. {@link //getNodeText} is used on the\n   *  node payloads to get the text for the nodes.  Detect\n   *  parse trees and extract data appropriately.\n   */\n  toStringTree: function (tree, ruleNames, recog) {\n    ruleNames = ruleNames || null;\n    recog = recog || null;\n    if (recog !== null) {\n      ruleNames = recog.ruleNames;\n    }\n    let s = Trees.getNodeText(tree, ruleNames);\n    s = escapeWhitespace(s, false);\n    const c = tree.getChildCount();\n    if (c === 0) {\n      return s;\n    }\n    let res = '(' + s + ' ';\n    if (c > 0) {\n      s = Trees.toStringTree(tree.getChild(0), ruleNames);\n      res = res.concat(s);\n    }\n    for (let i = 1; i < c; i++) {\n      s = Trees.toStringTree(tree.getChild(i), ruleNames);\n      res = res.concat(' ' + s);\n    }\n    res = res.concat(')');\n    return res;\n  },\n\n  getNodeText: function (t, ruleNames, recog) {\n    ruleNames = ruleNames || null;\n    recog = recog || null;\n    if (recog !== null) {\n      ruleNames = recog.ruleNames;\n    }\n    if (ruleNames !== null) {\n      if (t instanceof RuleNode) {\n        const context = t.ruleContext;\n        const altNumber = context.getAltNumber();\n        // use const value of ATN.INVALID_ALT_NUMBER to avoid circular dependency\n        if (altNumber != 0) {\n          return ruleNames[t.ruleIndex] + ':' + altNumber;\n        }\n        return ruleNames[t.ruleIndex];\n      } else if (t instanceof ErrorNode) {\n        return t.toString();\n      } else if (t instanceof TerminalNode) {\n        if (t.symbol !== null) {\n          return t.symbol.text;\n        }\n      }\n    }\n    // no recog for rule names\n    const payload = t.getPayload();\n    if (payload instanceof Token) {\n      return payload.text;\n    }\n    return t.getPayload().toString();\n  },\n\n  /**\n   * Return ordered list of all children of this node\n   */\n  getChildren: function (t) {\n    const list = [];\n    for (let i = 0; i < t.getChildCount(); i++) {\n      list.push(t.getChild(i));\n    }\n    return list;\n  },\n\n  /**\n   * Return a list of all ancestors of this node.  The first node of\n   * list is the root and the last is the parent of this node.\n   */\n  getAncestors: function (t) {\n    let ancestors = [];\n    t = t.getParent();\n    while (t !== null) {\n      ancestors = [t].concat(ancestors);\n      t = t.getParent();\n    }\n    return ancestors;\n  },\n\n  findAllTokenNodes: function (t, ttype) {\n    return Trees.findAllNodes(t, ttype, true);\n  },\n\n  findAllRuleNodes: function (t, ruleIndex) {\n    return Trees.findAllNodes(t, ruleIndex, false);\n  },\n\n  findAllNodes: function (t, index, findTokens) {\n    const nodes = [];\n    Trees._findAllNodes(t, index, findTokens, nodes);\n    return nodes;\n  },\n\n  _findAllNodes: function (t, index, findTokens, nodes) {\n    // check this node (the root) first\n    if (findTokens && t instanceof TerminalNode) {\n      if (t.symbol.type === index) {\n        nodes.push(t);\n      }\n    } else if (!findTokens && t instanceof RuleNode) {\n      if (t.ruleIndex === index) {\n        nodes.push(t);\n      }\n    }\n    // check children\n    for (let i = 0; i < t.getChildCount(); i++) {\n      Trees._findAllNodes(t.getChild(i), index, findTokens, nodes);\n    }\n  },\n\n  descendants: function (t) {\n    let nodes = [t];\n    for (let i = 0; i < t.getChildCount(); i++) {\n      nodes = nodes.concat(Trees.descendants(t.getChild(i)));\n    }\n    return nodes;\n  },\n};\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexport function escapeWhitespace(s, escapeSpaces) {\n  s = s.replace(/\\t/g, '\\\\t').replace(/\\n/g, '\\\\n').replace(/\\r/g, '\\\\r');\n  if (escapeSpaces) {\n    s = s.replace(/ /g, '\\u00B7');\n  }\n  return s;\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { RuleNode } from '../tree/RuleNode.js';\nimport { Interval } from '../misc/Interval.js';\nimport { Trees } from '../tree/Trees.js';\n\nexport class RuleContext extends RuleNode {\n  /** A rule context is a record of a single rule invocation. It knows\n   * which context invoked it, if any. If there is no parent context, then\n   * naturally the invoking state is not valid.  The parent link\n   * provides a chain upwards from the current rule invocation to the root\n   * of the invocation tree, forming a stack. We actually carry no\n   * information about the rule associated with this context (except\n   * when parsing). We keep only the state number of the invoking state from\n   * the ATN submachine that invoked this. Contrast this with the s\n   * pointer inside ParserRuleContext that tracks the current state\n   * being \"executed\" for the current rule.\n   *\n   * The parent contexts are useful for computing lookahead sets and\n   * getting error information.\n   *\n   * These objects are used during parsing and prediction.\n   * For the special case of parsers, we use the subclass\n   * ParserRuleContext.\n   *\n   * @see ParserRuleContext\n   */\n  constructor(parent, invokingState) {\n    // What context invoked this rule?\n    super();\n    this.parentCtx = parent || null;\n    /**\n     * What state invoked the rule associated with this context?\n     * The \"return address\" is the followState of invokingState\n     * If parent is null, this should be -1.\n     */\n    this.invokingState = invokingState || -1;\n  }\n\n  get ruleContext() {\n    return this;\n  }\n\n  depth() {\n    let n = 0;\n    let p = this;\n    while (p !== null) {\n      p = p.parentCtx;\n      n += 1;\n    }\n    return n;\n  }\n\n  /**\n   * A context is empty if there is no invoking state; meaning nobody call\n   * current context.\n   */\n  isEmpty() {\n    return this.invokingState === -1;\n  }\n\n  // satisfy the ParseTree / SyntaxTree interface\n  getSourceInterval() {\n    return Interval.INVALID_INTERVAL;\n  }\n\n  getPayload() {\n    return this;\n  }\n\n  /**\n   * Return the combined text of all child nodes. This method only considers\n   * tokens which have been added to the parse tree.\n   * <p>\n   * Since tokens on hidden channels (e.g. whitespace or comments) are not\n   * added to the parse trees, they will not appear in the output of this\n   * method.\n   */\n  getText() {\n    if (this.getChildCount() === 0) {\n      return '';\n    } else {\n      return this.children\n        .map((child) => {\n          return child.getText();\n        })\n        .join('');\n    }\n  }\n\n  /**\n   * For rule associated with this parse tree internal node, return\n   * the outer alternative number used to match the input. Default\n   * implementation does not compute nor store this alt num. Create\n   * a subclass of ParserRuleContext with backing field and set\n   * option contextSuperClass.\n   * to set it.\n   */\n  getAltNumber() {\n    // use constant value of ATN.INVALID_ALT_NUMBER to avoid circular dependency\n    return 0;\n  }\n\n  /**\n   * Set the outer alternative number for this context node. Default\n   * implementation does nothing to avoid backing field overhead for\n   * trees that don't need it.  Create\n   * a subclass of ParserRuleContext with backing field and set\n   * option contextSuperClass.\n   */\n  setAltNumber(altNumber) {}\n\n  getChild(i) {\n    return null;\n  }\n\n  getChildCount() {\n    return 0;\n  }\n\n  accept(visitor) {\n    return visitor.visitChildren(this);\n  }\n\n  /**\n   * Print out a whole tree, not just a node, in LISP format\n   * (root child1 .. childN). Print just a node if this is a leaf.\n   */\n  toStringTree(ruleNames, recog) {\n    return Trees.toStringTree(this, ruleNames, recog);\n  }\n\n  toString(ruleNames, stop) {\n    ruleNames = ruleNames || null;\n    stop = stop || null;\n    let p = this;\n    let s = '[';\n    while (p !== null && p !== stop) {\n      if (ruleNames === null) {\n        if (!p.isEmpty()) {\n          s += p.invokingState;\n        }\n      } else {\n        const ri = p.ruleIndex;\n        const ruleName = ri >= 0 && ri < ruleNames.length ? ruleNames[ri] : String(ri);\n        s += ruleName;\n      }\n      if (p.parentCtx !== null && (ruleNames !== null || !p.parentCtx.isEmpty())) {\n        s += ' ';\n      }\n      p = p.parentCtx;\n    }\n    s += ']';\n    return s;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nexport class PredictionContext {\n  constructor(cachedHashCode) {\n    this.cachedHashCode = cachedHashCode;\n  }\n\n  /**\n   * Stores the computed hash code of this {@link PredictionContext}. The hash\n   * code is computed in parts to match the following reference algorithm.\n   *\n   * <pre>\n   * private int referenceHashCode() {\n   * int hash = {@link MurmurHash//initialize MurmurHash.initialize}({@link\n   * //INITIAL_HASH});\n   *\n   * for (int i = 0; i &lt; {@link //size()}; i++) {\n   * hash = {@link MurmurHash//update MurmurHash.update}(hash, {@link //getParent\n   * getParent}(i));\n   * }\n   *\n   * for (int i = 0; i &lt; {@link //size()}; i++) {\n   * hash = {@link MurmurHash//update MurmurHash.update}(hash, {@link\n   * //getReturnState getReturnState}(i));\n   * }\n   *\n   * hash = {@link MurmurHash//finish MurmurHash.finish}(hash, 2// {@link\n   * //size()});\n   * return hash;\n   * }\n   * </pre>\n   * This means only the {@link //EMPTY} context is in set.\n   */\n  isEmpty() {\n    return this === PredictionContext.EMPTY;\n  }\n\n  hasEmptyPath() {\n    return this.getReturnState(this.length - 1) === PredictionContext.EMPTY_RETURN_STATE;\n  }\n\n  hashCode() {\n    return this.cachedHashCode;\n  }\n\n  updateHashCode(hash) {\n    hash.update(this.cachedHashCode);\n  }\n}\n\n/**\n * Represents {@code $} in local context prediction, which means wildcard.\n * {@code//+x =//}.\n */\nPredictionContext.EMPTY = null;\n\n/**\n * Represents {@code $} in an array in full context mode, when {@code $}\n * doesn't mean wildcard: {@code $ + x = [$,x]}. Here,\n * {@code $} = {@link //EMPTY_RETURN_STATE}.\n */\nPredictionContext.EMPTY_RETURN_STATE = 0x7fffffff;\n\nPredictionContext.globalNodeCount = 1;\nPredictionContext.id = PredictionContext.globalNodeCount;\nPredictionContext.trace_atn_sim = false;\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { PredictionContext } from './PredictionContext.js';\nimport { equalArrays } from '../utils/equalArrays.js';\nimport { HashCode } from '../misc/HashCode.js';\n\nexport class ArrayPredictionContext extends PredictionContext {\n  constructor(parents, returnStates) {\n    /**\n     * Parent can be null only if full ctx mode and we make an array\n     * from {@link //EMPTY} and non-empty. We merge {@link //EMPTY} by using\n     * null parent and\n     * returnState == {@link //EMPTY_RETURN_STATE}.\n     */\n    const h = new HashCode();\n    h.update(parents, returnStates);\n    const hashCode = h.finish();\n    super(hashCode);\n    this.parents = parents;\n    this.returnStates = returnStates;\n    return this;\n  }\n\n  get length() {\n    return this.returnStates.length;\n  }\n\n  isEmpty() {\n    // since EMPTY_RETURN_STATE can only appear in the last position, we\n    // don't need to verify that size==1\n    return this.returnStates[0] === PredictionContext.EMPTY_RETURN_STATE;\n  }\n\n  getParent(index) {\n    return this.parents[index];\n  }\n\n  getReturnState(index) {\n    return this.returnStates[index];\n  }\n\n  equals(other) {\n    if (this === other) {\n      return true;\n    } else if (!(other instanceof ArrayPredictionContext)) {\n      return false;\n    } else if (this.hashCode() !== other.hashCode()) {\n      return false; // can't be same if hash is different\n    } else {\n      return equalArrays(this.returnStates, other.returnStates) && equalArrays(this.parents, other.parents);\n    }\n  }\n\n  toString() {\n    if (this.isEmpty()) {\n      return '[]';\n    } else {\n      let s = '[';\n      for (let i = 0; i < this.returnStates.length; i++) {\n        if (i > 0) {\n          s = s + ', ';\n        }\n        if (this.returnStates[i] === PredictionContext.EMPTY_RETURN_STATE) {\n          s = s + '$';\n          continue;\n        }\n        s = s + this.returnStates[i];\n        if (this.parents[i] !== null) {\n          s = s + ' ' + this.parents[i];\n        } else {\n          s = s + 'null';\n        }\n      }\n      return s + ']';\n    }\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { PredictionContext } from './PredictionContext.js';\nimport { HashCode } from '../misc/HashCode.js';\n\nexport class SingletonPredictionContext extends PredictionContext {\n  constructor(parent, returnState) {\n    let hashCode = 0;\n    const hash = new HashCode();\n    if (parent !== null) {\n      hash.update(parent, returnState);\n    } else {\n      hash.update(1);\n    }\n    hashCode = hash.finish();\n    super(hashCode);\n    this.parentCtx = parent;\n    this.returnState = returnState;\n  }\n\n  get length() {\n    return 1;\n  }\n\n  static create(parent, returnState) {\n    if (returnState === PredictionContext.EMPTY_RETURN_STATE && parent === null) {\n      // someone can pass in the bits of an array ctx that mean $\n      return PredictionContext.EMPTY;\n    } else {\n      return new SingletonPredictionContext(parent, returnState);\n    }\n  }\n\n  getParent(index) {\n    return this.parentCtx;\n  }\n\n  getReturnState(index) {\n    return this.returnState;\n  }\n\n  equals(other) {\n    if (this === other) {\n      return true;\n    } else if (!(other instanceof SingletonPredictionContext)) {\n      return false;\n    } else if (this.hashCode() !== other.hashCode()) {\n      return false; // can't be same if hash is different\n    } else {\n      if (this.returnState !== other.returnState) return false;\n      else if (this.parentCtx == null) return other.parentCtx == null;\n      else return this.parentCtx.equals(other.parentCtx);\n    }\n  }\n\n  toString() {\n    const up = this.parentCtx === null ? '' : this.parentCtx.toString();\n    if (up.length === 0) {\n      if (this.returnState === PredictionContext.EMPTY_RETURN_STATE) {\n        return '$';\n      } else {\n        return String(this.returnState);\n      }\n    } else {\n      return String(this.returnState) + ' ' + up;\n    }\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { PredictionContext } from './PredictionContext.js';\nimport { SingletonPredictionContext } from './SingletonPredictionContext.js';\n\nexport class EmptyPredictionContext extends SingletonPredictionContext {\n  constructor() {\n    super(null, PredictionContext.EMPTY_RETURN_STATE);\n  }\n\n  isEmpty() {\n    return true;\n  }\n\n  getParent(index) {\n    return null;\n  }\n\n  getReturnState(index) {\n    return this.returnState;\n  }\n\n  equals(other) {\n    return this === other;\n  }\n\n  toString() {\n    return '$';\n  }\n}\n\nPredictionContext.EMPTY = new EmptyPredictionContext();\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { standardEqualsFunction } from '../utils/standardEqualsFunction.js';\nimport { standardHashCodeFunction } from '../utils/standardHashCodeFunction.js';\n\nconst HASH_KEY_PREFIX = 'h-';\n\nexport class HashMap {\n  constructor(hashFunction, equalsFunction) {\n    this.data = {};\n    this.hashFunction = hashFunction || standardHashCodeFunction;\n    this.equalsFunction = equalsFunction || standardEqualsFunction;\n  }\n\n  get length() {\n    return Object.keys(this.data)\n      .filter((key) => key.startsWith(HASH_KEY_PREFIX))\n      .map((key) => this.data[key].length, this)\n      .reduce((accum, item) => accum + item, 0);\n  }\n\n  set(key, value) {\n    const hashKey = HASH_KEY_PREFIX + this.hashFunction(key);\n    if (hashKey in this.data) {\n      const entries = this.data[hashKey];\n      for (let i = 0; i < entries.length; i++) {\n        const entry = entries[i];\n        if (this.equalsFunction(key, entry.key)) {\n          const oldValue = entry.value;\n          entry.value = value;\n          return oldValue;\n        }\n      }\n      entries.push({ key: key, value: value });\n      return value;\n    } else {\n      this.data[hashKey] = [{ key: key, value: value }];\n      return value;\n    }\n  }\n\n  containsKey(key) {\n    const hashKey = HASH_KEY_PREFIX + this.hashFunction(key);\n    if (hashKey in this.data) {\n      const entries = this.data[hashKey];\n      for (let i = 0; i < entries.length; i++) {\n        const entry = entries[i];\n        if (this.equalsFunction(key, entry.key)) return true;\n      }\n    }\n    return false;\n  }\n\n  get(key) {\n    const hashKey = HASH_KEY_PREFIX + this.hashFunction(key);\n    if (hashKey in this.data) {\n      const entries = this.data[hashKey];\n      for (let i = 0; i < entries.length; i++) {\n        const entry = entries[i];\n        if (this.equalsFunction(key, entry.key)) return entry.value;\n      }\n    }\n    return null;\n  }\n\n  entries() {\n    return Object.keys(this.data)\n      .filter((key) => key.startsWith(HASH_KEY_PREFIX))\n      .flatMap((key) => this.data[key], this);\n  }\n\n  getKeys() {\n    return this.entries().map((e) => e.key);\n  }\n\n  getValues() {\n    return this.entries().map((e) => e.value);\n  }\n\n  toString() {\n    const ss = this.entries().map((e) => '{' + e.key + ':' + e.value + '}');\n    return '[' + ss.join(', ') + ']';\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { RuleContext } from './RuleContext.js';\nimport { PredictionContext } from './PredictionContext.js';\nimport { ArrayPredictionContext } from './ArrayPredictionContext.js';\nimport { SingletonPredictionContext } from './SingletonPredictionContext.js';\nimport { EmptyPredictionContext } from './EmptyPredictionContext.js';\nimport { HashMap } from '../misc/HashMap.js';\n\n/**\n * Convert a {@link RuleContext} tree to a {@link PredictionContext} graph.\n * Return {@link //EMPTY} if {@code outerContext} is empty or null.\n */\nexport function predictionContextFromRuleContext(atn, outerContext) {\n  if (outerContext === undefined || outerContext === null) {\n    outerContext = RuleContext.EMPTY;\n  }\n  // if we are in RuleContext of start rule, s, then PredictionContext\n  // is EMPTY. Nobody called us. (if we are empty, return empty)\n  if (outerContext.parentCtx === null || outerContext === RuleContext.EMPTY) {\n    return PredictionContext.EMPTY;\n  }\n  // If we have a parent, convert it to a PredictionContext graph\n  const parent = predictionContextFromRuleContext(atn, outerContext.parentCtx);\n  const state = atn.states[outerContext.invokingState];\n  const transition = state.transitions[0];\n  return SingletonPredictionContext.create(parent, transition.followState.stateNumber);\n}\n\nexport function getCachedPredictionContext(context, contextCache, visited) {\n  if (context.isEmpty()) {\n    return context;\n  }\n  let existing = visited.get(context) || null;\n  if (existing !== null) {\n    return existing;\n  }\n  existing = contextCache.get(context);\n  if (existing !== null) {\n    visited.set(context, existing);\n    return existing;\n  }\n  let changed = false;\n  let parents = [];\n  for (let i = 0; i < parents.length; i++) {\n    const parent = getCachedPredictionContext(context.getParent(i), contextCache, visited);\n    if (changed || parent !== context.getParent(i)) {\n      if (!changed) {\n        parents = [];\n        for (let j = 0; j < context.length; j++) {\n          parents[j] = context.getParent(j);\n        }\n        changed = true;\n      }\n      parents[i] = parent;\n    }\n  }\n  if (!changed) {\n    contextCache.add(context);\n    visited.set(context, context);\n    return context;\n  }\n  let updated = null;\n  if (parents.length === 0) {\n    updated = PredictionContext.EMPTY;\n  } else if (parents.length === 1) {\n    updated = SingletonPredictionContext.create(parents[0], context.getReturnState(0));\n  } else {\n    updated = new ArrayPredictionContext(parents, context.returnStates);\n  }\n  contextCache.add(updated);\n  visited.set(updated, updated);\n  visited.set(context, updated);\n\n  return updated;\n}\n\nexport function merge(a, b, rootIsWildcard, mergeCache) {\n  // share same graph if both same\n  if (a === b) {\n    return a;\n  }\n  if (a instanceof SingletonPredictionContext && b instanceof SingletonPredictionContext) {\n    return mergeSingletons(a, b, rootIsWildcard, mergeCache);\n  }\n  // At least one of a or b is array\n  // If one is $ and rootIsWildcard, return $ as * wildcard\n  if (rootIsWildcard) {\n    if (a instanceof EmptyPredictionContext) {\n      return a;\n    }\n    if (b instanceof EmptyPredictionContext) {\n      return b;\n    }\n  }\n  // convert singleton so both are arrays to normalize\n  if (a instanceof SingletonPredictionContext) {\n    a = new ArrayPredictionContext([a.getParent()], [a.returnState]);\n  }\n  if (b instanceof SingletonPredictionContext) {\n    b = new ArrayPredictionContext([b.getParent()], [b.returnState]);\n  }\n  return mergeArrays(a, b, rootIsWildcard, mergeCache);\n}\n\n/**\n * Merge two {@link ArrayPredictionContext} instances.\n *\n * <p>Different tops, different parents.<br>\n * <embed src=\"images/ArrayMerge_DiffTopDiffPar.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Shared top, same parents.<br>\n * <embed src=\"images/ArrayMerge_ShareTopSamePar.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Shared top, different parents.<br>\n * <embed src=\"images/ArrayMerge_ShareTopDiffPar.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Shared top, all shared parents.<br>\n * <embed src=\"images/ArrayMerge_ShareTopSharePar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * <p>Equal tops, merge parents and reduce top to\n * {@link SingletonPredictionContext}.<br>\n * <embed src=\"images/ArrayMerge_EqualTop.svg\" type=\"image/svg+xml\"/></p>\n */\nfunction mergeArrays(a, b, rootIsWildcard, mergeCache) {\n  if (mergeCache !== null) {\n    let previous = mergeCache.get(a, b);\n    if (previous !== null) {\n      if (PredictionContext.trace_atn_sim) console.log('mergeArrays a=' + a + ',b=' + b + ' -> previous');\n      return previous;\n    }\n    previous = mergeCache.get(b, a);\n    if (previous !== null) {\n      if (PredictionContext.trace_atn_sim) console.log('mergeArrays a=' + a + ',b=' + b + ' -> previous');\n      return previous;\n    }\n  }\n  // merge sorted payloads a + b => M\n  let i = 0; // walks a\n  let j = 0; // walks b\n  let k = 0; // walks target M array\n\n  let mergedReturnStates = new Array(a.returnStates.length + b.returnStates.length).fill(0);\n  let mergedParents = new Array(a.returnStates.length + b.returnStates.length).fill(null);\n  // walk and merge to yield mergedParents, mergedReturnStates\n  while (i < a.returnStates.length && j < b.returnStates.length) {\n    const a_parent = a.parents[i];\n    const b_parent = b.parents[j];\n    if (a.returnStates[i] === b.returnStates[j]) {\n      // same payload (stack tops are equal), must yield merged singleton\n      const payload = a.returnStates[i];\n      // $+$ = $\n      const bothDollars = payload === PredictionContext.EMPTY_RETURN_STATE && a_parent === null && b_parent === null;\n      const ax_ax = a_parent !== null && b_parent !== null && a_parent === b_parent; // ax+ax\n      // ->\n      // ax\n      if (bothDollars || ax_ax) {\n        mergedParents[k] = a_parent; // choose left\n        mergedReturnStates[k] = payload;\n      } else {\n        // ax+ay -> a'[x,y]\n        mergedParents[k] = merge(a_parent, b_parent, rootIsWildcard, mergeCache);\n        mergedReturnStates[k] = payload;\n      }\n      i += 1; // hop over left one as usual\n      j += 1; // but also skip one in right side since we merge\n    } else if (a.returnStates[i] < b.returnStates[j]) {\n      // copy a[i] to M\n      mergedParents[k] = a_parent;\n      mergedReturnStates[k] = a.returnStates[i];\n      i += 1;\n    } else {\n      // b > a, copy b[j] to M\n      mergedParents[k] = b_parent;\n      mergedReturnStates[k] = b.returnStates[j];\n      j += 1;\n    }\n    k += 1;\n  }\n  // copy over any payloads remaining in either array\n  if (i < a.returnStates.length) {\n    for (let p = i; p < a.returnStates.length; p++) {\n      mergedParents[k] = a.parents[p];\n      mergedReturnStates[k] = a.returnStates[p];\n      k += 1;\n    }\n  } else {\n    for (let p = j; p < b.returnStates.length; p++) {\n      mergedParents[k] = b.parents[p];\n      mergedReturnStates[k] = b.returnStates[p];\n      k += 1;\n    }\n  }\n  // trim merged if we combined a few that had same stack tops\n  if (k < mergedParents.length) {\n    // write index < last position; trim\n    if (k === 1) {\n      // for just one merged element, return singleton top\n      const a_ = SingletonPredictionContext.create(mergedParents[0], mergedReturnStates[0]);\n      if (mergeCache !== null) {\n        mergeCache.set(a, b, a_);\n      }\n      return a_;\n    }\n    mergedParents = mergedParents.slice(0, k);\n    mergedReturnStates = mergedReturnStates.slice(0, k);\n  }\n\n  const M = new ArrayPredictionContext(mergedParents, mergedReturnStates);\n\n  // if we created same array as a or b, return that instead\n  // TODO: track whether this is possible above during merge sort for speed\n  if (M.equals(a)) {\n    if (mergeCache !== null) {\n      mergeCache.set(a, b, a);\n    }\n    if (PredictionContext.trace_atn_sim) console.log('mergeArrays a=' + a + ',b=' + b + ' -> a');\n    return a;\n  }\n  if (M.equals(b)) {\n    if (mergeCache !== null) {\n      mergeCache.set(a, b, b);\n    }\n    if (PredictionContext.trace_atn_sim) console.log('mergeArrays a=' + a + ',b=' + b + ' -> b');\n    return b;\n  }\n  combineCommonParents(mergedParents);\n\n  if (mergeCache !== null) {\n    mergeCache.set(a, b, M);\n  }\n\n  if (PredictionContext.trace_atn_sim) console.log('mergeArrays a=' + a + ',b=' + b + ' -> ' + M);\n\n  return M;\n}\n\n/**\n * Make pass over all <em>M</em> {@code parents}; merge any {@code equals()}\n * ones.\n */\nfunction combineCommonParents(parents) {\n  const uniqueParents = new HashMap();\n\n  for (let p = 0; p < parents.length; p++) {\n    const parent = parents[p];\n    if (!uniqueParents.containsKey(parent)) {\n      uniqueParents.set(parent, parent);\n    }\n  }\n  for (let q = 0; q < parents.length; q++) {\n    parents[q] = uniqueParents.get(parents[q]);\n  }\n}\n\n/**\n * Merge two {@link SingletonPredictionContext} instances.\n *\n * <p>Stack tops equal, parents merge is same; return left graph.<br>\n * <embed src=\"images/SingletonMerge_SameRootSamePar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * <p>Same stack top, parents differ; merge parents giving array node, then\n * remainders of those graphs. A new root node is created to point to the\n * merged parents.<br>\n * <embed src=\"images/SingletonMerge_SameRootDiffPar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * <p>Different stack tops pointing to same parent. Make array node for the\n * root where both element in the root point to the same (original)\n * parent.<br>\n * <embed src=\"images/SingletonMerge_DiffRootSamePar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * <p>Different stack tops pointing to different parents. Make array node for\n * the root where each element points to the corresponding original\n * parent.<br>\n * <embed src=\"images/SingletonMerge_DiffRootDiffPar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * @param a the first {@link SingletonPredictionContext}\n * @param b the second {@link SingletonPredictionContext}\n * @param rootIsWildcard {@code true} if this is a local-context merge,\n * otherwise false to indicate a full-context merge\n * @param mergeCache\n */\nfunction mergeSingletons(a, b, rootIsWildcard, mergeCache) {\n  if (mergeCache !== null) {\n    let previous = mergeCache.get(a, b);\n    if (previous !== null) {\n      return previous;\n    }\n    previous = mergeCache.get(b, a);\n    if (previous !== null) {\n      return previous;\n    }\n  }\n\n  const rootMerge = mergeRoot(a, b, rootIsWildcard);\n  if (rootMerge !== null) {\n    if (mergeCache !== null) {\n      mergeCache.set(a, b, rootMerge);\n    }\n    return rootMerge;\n  }\n  if (a.returnState === b.returnState) {\n    const parent = merge(a.parentCtx, b.parentCtx, rootIsWildcard, mergeCache);\n    // if parent is same as existing a or b parent or reduced to a parent,\n    // return it\n    if (parent === a.parentCtx) {\n      return a; // ax + bx = ax, if a=b\n    }\n    if (parent === b.parentCtx) {\n      return b; // ax + bx = bx, if a=b\n    }\n    // else: ax + ay = a'[x,y]\n    // merge parents x and y, giving array node with x,y then remainders\n    // of those graphs. dup a, a' points at merged array\n    // new joined parent so create new singleton pointing to it, a'\n    const spc = SingletonPredictionContext.create(parent, a.returnState);\n    if (mergeCache !== null) {\n      mergeCache.set(a, b, spc);\n    }\n    return spc;\n  } else {\n    // a != b payloads differ\n    // see if we can collapse parents due to $+x parents if local ctx\n    let singleParent = null;\n    if (a === b || (a.parentCtx !== null && a.parentCtx === b.parentCtx)) {\n      // ax +\n      // bx =\n      // [a,b]x\n      singleParent = a.parentCtx;\n    }\n    if (singleParent !== null) {\n      // parents are same\n      // sort payloads and use same parent\n      const payloads = [a.returnState, b.returnState];\n      if (a.returnState > b.returnState) {\n        payloads[0] = b.returnState;\n        payloads[1] = a.returnState;\n      }\n      const parents = [singleParent, singleParent];\n      const apc = new ArrayPredictionContext(parents, payloads);\n      if (mergeCache !== null) {\n        mergeCache.set(a, b, apc);\n      }\n      return apc;\n    }\n    // parents differ and can't merge them. Just pack together\n    // into array; can't merge.\n    // ax + by = [ax,by]\n    const payloads = [a.returnState, b.returnState];\n    let parents = [a.parentCtx, b.parentCtx];\n    if (a.returnState > b.returnState) {\n      // sort by payload\n      payloads[0] = b.returnState;\n      payloads[1] = a.returnState;\n      parents = [b.parentCtx, a.parentCtx];\n    }\n    const a_ = new ArrayPredictionContext(parents, payloads);\n    if (mergeCache !== null) {\n      mergeCache.set(a, b, a_);\n    }\n    return a_;\n  }\n}\n\n/**\n * Handle case where at least one of {@code a} or {@code b} is\n * {@link //EMPTY}. In the following diagrams, the symbol {@code $} is used\n * to represent {@link //EMPTY}.\n *\n * <h2>Local-Context Merges</h2>\n *\n * <p>These local-context merge operations are used when {@code rootIsWildcard}\n * is true.</p>\n *\n * <p>{@link //EMPTY} is superset of any graph; return {@link //EMPTY}.<br>\n * <embed src=\"images/LocalMerge_EmptyRoot.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>{@link //EMPTY} and anything is {@code //EMPTY}, so merged parent is\n * {@code //EMPTY}; return left graph.<br>\n * <embed src=\"images/LocalMerge_EmptyParent.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Special case of last merge if local context.<br>\n * <embed src=\"images/LocalMerge_DiffRoots.svg\" type=\"image/svg+xml\"/></p>\n *\n * <h2>Full-Context Merges</h2>\n *\n * <p>These full-context merge operations are used when {@code rootIsWildcard}\n * is false.</p>\n *\n * <p><embed src=\"images/FullMerge_EmptyRoots.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Must keep all contexts; {@link //EMPTY} in array is a special value (and\n * null parent).<br>\n * <embed src=\"images/FullMerge_EmptyRoot.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p><embed src=\"images/FullMerge_SameRoot.svg\" type=\"image/svg+xml\"/></p>\n *\n * @param a the first {@link SingletonPredictionContext}\n * @param b the second {@link SingletonPredictionContext}\n * @param rootIsWildcard {@code true} if this is a local-context merge,\n * otherwise false to indicate a full-context merge\n */\nfunction mergeRoot(a, b, rootIsWildcard) {\n  if (rootIsWildcard) {\n    if (a === PredictionContext.EMPTY) {\n      return PredictionContext.EMPTY; // // + b =//\n    }\n    if (b === PredictionContext.EMPTY) {\n      return PredictionContext.EMPTY; // a +// =//\n    }\n  } else {\n    if (a === PredictionContext.EMPTY && b === PredictionContext.EMPTY) {\n      return PredictionContext.EMPTY; // $ + $ = $\n    } else if (a === PredictionContext.EMPTY) {\n      // $ + x = [$,x]\n      const payloads = [b.returnState, PredictionContext.EMPTY_RETURN_STATE];\n      const parents = [b.parentCtx, null];\n      return new ArrayPredictionContext(parents, payloads);\n    } else if (b === PredictionContext.EMPTY) {\n      // x + $ = [$,x] ($ is always first if present)\n      const payloads = [a.returnState, PredictionContext.EMPTY_RETURN_STATE];\n      const parents = [a.parentCtx, null];\n      return new ArrayPredictionContext(parents, payloads);\n    }\n  }\n  return null;\n}\n\n// ter's recursive version of Sam's getAllNodes()\nexport function getAllContextNodes(context, nodes, visited) {\n  if (nodes === null) {\n    nodes = [];\n    return getAllContextNodes(context, nodes, visited);\n  } else if (visited === null) {\n    visited = new HashMap();\n    return getAllContextNodes(context, nodes, visited);\n  } else {\n    if (context === null || visited.containsKey(context)) {\n      return nodes;\n    }\n    visited.set(context, context);\n    nodes.push(context);\n    for (let i = 0; i < context.length; i++) {\n      getAllContextNodes(context.getParent(i), nodes, visited);\n    }\n    return nodes;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { HashCode } from './HashCode.js';\nimport { equalArrays } from '../utils/equalArrays.js';\n\nexport class BitSet {\n  constructor() {\n    this.data = [];\n  }\n\n  get length() {\n    return this.values().length;\n  }\n\n  add(value) {\n    this.data[value] = true;\n  }\n\n  or(set) {\n    Object.keys(set.data).map((alt) => this.add(alt), this);\n  }\n\n  remove(value) {\n    delete this.data[value];\n  }\n\n  has(value) {\n    return this.data[value] === true;\n  }\n\n  values() {\n    return Object.keys(this.data);\n  }\n\n  minValue() {\n    return Math.min.apply(null, this.values());\n  }\n\n  hashCode() {\n    return HashCode.hashStuff(this.values());\n  }\n\n  equals(other) {\n    return other instanceof BitSet && equalArrays(this.data, other.data);\n  }\n\n  toString() {\n    return '{' + this.values().join(', ') + '}';\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { Token } from '../Token.js';\nimport { ATNConfig } from './ATNConfig.js';\nimport { IntervalSet } from '../misc/IntervalSet.js';\nimport { RuleStopState } from '../state/RuleStopState.js';\nimport { RuleTransition } from '../transition/RuleTransition.js';\nimport { NotSetTransition } from '../transition/NotSetTransition.js';\nimport { WildcardTransition } from '../transition/WildcardTransition.js';\nimport { AbstractPredicateTransition } from './AbstractPredicateTransition.js';\nimport { predictionContextFromRuleContext } from '../context/PredictionContextUtils.js';\nimport { PredictionContext } from '../context/PredictionContext.js';\nimport { SingletonPredictionContext } from '../context/SingletonPredictionContext.js';\nimport { BitSet } from '../misc/BitSet.js';\nimport { HashSet } from '../misc/HashSet.js';\n\nexport class LL1Analyzer {\n  constructor(atn) {\n    this.atn = atn;\n  }\n\n  /**\n   * Calculates the SLL(1) expected lookahead set for each outgoing transition\n   * of an {@link ATNState}. The returned array has one element for each\n   * outgoing transition in {@code s}. If the closure from transition\n   * <em>i</em> leads to a semantic predicate before matching a symbol, the\n   * element at index <em>i</em> of the result will be {@code null}.\n   *\n   * @param s the ATN state\n   * @return the expected symbols for each outgoing transition of {@code s}.\n   */\n  getDecisionLookahead(s) {\n    if (s === null) {\n      return null;\n    }\n    const count = s.transitions.length;\n    const look = [];\n    for (let alt = 0; alt < count; alt++) {\n      look[alt] = new IntervalSet();\n      const lookBusy = new HashSet();\n      const seeThruPreds = false; // fail to get lookahead upon pred\n      this._LOOK(\n        s.transition(alt).target,\n        null,\n        PredictionContext.EMPTY,\n        look[alt],\n        lookBusy,\n        new BitSet(),\n        seeThruPreds,\n        false,\n      );\n      // Wipe out lookahead for this alternative if we found nothing\n      // or we had a predicate when we !seeThruPreds\n      if (look[alt].length === 0 || look[alt].contains(LL1Analyzer.HIT_PRED)) {\n        look[alt] = null;\n      }\n    }\n    return look;\n  }\n\n  /**\n   * Compute set of tokens that can follow {@code s} in the ATN in the\n   * specified {@code ctx}.\n   *\n   * <p>If {@code ctx} is {@code null} and the end of the rule containing\n   * {@code s} is reached, {@link Token//EPSILON} is added to the result set.\n   * If {@code ctx} is not {@code null} and the end of the outermost rule is\n   * reached, {@link Token//EOF} is added to the result set.</p>\n   *\n   * @param s the ATN state\n   * @param stopState the ATN state to stop at. This can be a\n   * {@link BlockEndState} to detect epsilon paths through a closure.\n   * @param ctx the complete parser context, or {@code null} if the context\n   * should be ignored\n   *\n   * @return The set of tokens that can follow {@code s} in the ATN in the\n   * specified {@code ctx}.\n   */\n  LOOK(s, stopState, ctx) {\n    const r = new IntervalSet();\n    const seeThruPreds = true; // ignore preds; get all lookahead\n    ctx = ctx || null;\n    const lookContext = ctx !== null ? predictionContextFromRuleContext(s.atn, ctx) : null;\n    this._LOOK(s, stopState, lookContext, r, new HashSet(), new BitSet(), seeThruPreds, true);\n    return r;\n  }\n\n  /**\n   * Compute set of tokens that can follow {@code s} in the ATN in the\n   * specified {@code ctx}.\n   *\n   * <p>If {@code ctx} is {@code null} and {@code stopState} or the end of the\n   * rule containing {@code s} is reached, {@link Token//EPSILON} is added to\n   * the result set. If {@code ctx} is not {@code null} and {@code addEOF} is\n   * {@code true} and {@code stopState} or the end of the outermost rule is\n   * reached, {@link Token//EOF} is added to the result set.</p>\n   *\n   * @param s the ATN state.\n   * @param stopState the ATN state to stop at. This can be a\n   * {@link BlockEndState} to detect epsilon paths through a closure.\n   * @param ctx The outer context, or {@code null} if the outer context should\n   * not be used.\n   * @param look The result lookahead set.\n   * @param lookBusy A set used for preventing epsilon closures in the ATN\n   * from causing a stack overflow. Outside code should pass\n   * {@code new CustomizedSet<ATNConfig>} for this argument.\n   * @param calledRuleStack A set used for preventing left recursion in the\n   * ATN from causing a stack overflow. Outside code should pass\n   * {@code new BitSet()} for this argument.\n   * @param seeThruPreds {@code true} to true semantic predicates as\n   * implicitly {@code true} and \"see through them\", otherwise {@code false}\n   * to treat semantic predicates as opaque and add {@link //HIT_PRED} to the\n   * result if one is encountered.\n   * @param addEOF Add {@link Token//EOF} to the result if the end of the\n   * outermost context is reached. This parameter has no effect if {@code ctx}\n   * is {@code null}.\n   */\n  _LOOK(s, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF) {\n    const c = new ATNConfig({ state: s, alt: 0, context: ctx }, null);\n    if (lookBusy.has(c)) {\n      return;\n    }\n    lookBusy.add(c);\n    if (s === stopState) {\n      if (ctx === null) {\n        look.addOne(Token.EPSILON);\n        return;\n      } else if (ctx.isEmpty() && addEOF) {\n        look.addOne(Token.EOF);\n        return;\n      }\n    }\n    if (s instanceof RuleStopState) {\n      if (ctx === null) {\n        look.addOne(Token.EPSILON);\n        return;\n      } else if (ctx.isEmpty() && addEOF) {\n        look.addOne(Token.EOF);\n        return;\n      }\n      if (ctx !== PredictionContext.EMPTY) {\n        const removed = calledRuleStack.has(s.ruleIndex);\n        try {\n          calledRuleStack.remove(s.ruleIndex);\n          // run thru all possible stack tops in ctx\n          for (let i = 0; i < ctx.length; i++) {\n            const returnState = this.atn.states[ctx.getReturnState(i)];\n            this._LOOK(returnState, stopState, ctx.getParent(i), look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n          }\n        } finally {\n          if (removed) {\n            calledRuleStack.add(s.ruleIndex);\n          }\n        }\n        return;\n      }\n    }\n    for (let j = 0; j < s.transitions.length; j++) {\n      const t = s.transitions[j];\n      if (t.constructor === RuleTransition) {\n        if (calledRuleStack.has(t.target.ruleIndex)) {\n          continue;\n        }\n        const newContext = SingletonPredictionContext.create(ctx, t.followState.stateNumber);\n        try {\n          calledRuleStack.add(t.target.ruleIndex);\n          this._LOOK(t.target, stopState, newContext, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n        } finally {\n          calledRuleStack.remove(t.target.ruleIndex);\n        }\n      } else if (t instanceof AbstractPredicateTransition) {\n        if (seeThruPreds) {\n          this._LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n        } else {\n          look.addOne(LL1Analyzer.HIT_PRED);\n        }\n      } else if (t.isEpsilon) {\n        this._LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n      } else if (t.constructor === WildcardTransition) {\n        look.addRange(Token.MIN_USER_TOKEN_TYPE, this.atn.maxTokenType);\n      } else {\n        let set = t.label;\n        if (set !== null) {\n          if (t instanceof NotSetTransition) {\n            set = set.complement(Token.MIN_USER_TOKEN_TYPE, this.atn.maxTokenType);\n          }\n          look.addSet(set);\n        }\n      }\n    }\n  }\n}\n\n/**\n * Special value added to the lookahead sets to indicate that we hit\n * a predicate during analysis if {@code seeThruPreds==false}.\n */\nLL1Analyzer.HIT_PRED = Token.INVALID_TYPE;\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { LL1Analyzer } from './LL1Analyzer.js';\nimport { IntervalSet } from '../misc/IntervalSet.js';\nimport { Token } from '../Token.js';\n\nexport class ATN {\n  constructor(grammarType, maxTokenType) {\n    /**\n     * Used for runtime deserialization of ATNs from strings\n     * The type of the ATN.\n     */\n    this.grammarType = grammarType;\n    // The maximum value for any symbol recognized by a transition in the ATN.\n    this.maxTokenType = maxTokenType;\n    this.states = [];\n    /**\n     * Each subrule/rule is a decision point and we must track them so we\n     * can go back later and build DFA predictors for them.  This includes\n     * all the rules, subrules, optional blocks, ()+, ()* etc...\n     */\n    this.decisionToState = [];\n    // Maps from rule index to starting state number.\n    this.ruleToStartState = [];\n    // Maps from rule index to stop state number.\n    this.ruleToStopState = null;\n    this.modeNameToStartState = {};\n    /**\n     * For lexer ATNs, this maps the rule index to the resulting token type.\n     * For parser ATNs, this maps the rule index to the generated bypass token\n     * type if the {@link ATNDeserializationOptions//isGenerateRuleBypassTransitions}\n     * deserialization option was specified; otherwise, this is {@code null}\n     */\n    this.ruleToTokenType = null;\n    /**\n     * For lexer ATNs, this is an array of {@link LexerAction} objects which may\n     * be referenced by action transitions in the ATN\n     */\n    this.lexerActions = null;\n    this.modeToStartState = [];\n  }\n\n  /**\n   * Compute the set of valid tokens that can occur starting in state {@code s}.\n   * If {@code ctx} is null, the set of tokens will not include what can follow\n   * the rule surrounding {@code s}. In other words, the set will be\n   * restricted to tokens reachable staying within {@code s}'s rule\n   */\n  nextTokensInContext(s, ctx) {\n    const anal = new LL1Analyzer(this);\n    return anal.LOOK(s, null, ctx);\n  }\n\n  /**\n   * Compute the set of valid tokens that can occur starting in {@code s} and\n   * staying in same rule. {@link Token//EPSILON} is in set if we reach end of\n   * rule\n   */\n  nextTokensNoContext(s) {\n    if (s.nextTokenWithinRule !== null) {\n      return s.nextTokenWithinRule;\n    }\n    s.nextTokenWithinRule = this.nextTokensInContext(s, null);\n    s.nextTokenWithinRule.readOnly = true;\n    return s.nextTokenWithinRule;\n  }\n\n  nextTokens(s, ctx) {\n    if (ctx === undefined) {\n      return this.nextTokensNoContext(s);\n    } else {\n      return this.nextTokensInContext(s, ctx);\n    }\n  }\n\n  addState(state) {\n    if (state !== null) {\n      state.atn = this;\n      state.stateNumber = this.states.length;\n    }\n    this.states.push(state);\n  }\n\n  removeState(state) {\n    this.states[state.stateNumber] = null; // just free mem, don't shift states in list\n  }\n\n  defineDecisionState(s) {\n    this.decisionToState.push(s);\n    s.decision = this.decisionToState.length - 1;\n    return s.decision;\n  }\n\n  getDecisionState(decision) {\n    if (this.decisionToState.length === 0) {\n      return null;\n    } else {\n      return this.decisionToState[decision];\n    }\n  }\n\n  /**\n   * Computes the set of input symbols which could follow ATN state number\n   * {@code stateNumber} in the specified full {@code context}. This method\n   * considers the complete parser context, but does not evaluate semantic\n   * predicates (i.e. all predicates encountered during the calculation are\n   * assumed true). If a path in the ATN exists from the starting state to the\n   * {@link RuleStopState} of the outermost context without matching any\n   * symbols, {@link Token//EOF} is added to the returned set.\n   *\n   * <p>If {@code context} is {@code null}, it is treated as\n   * {@link ParserRuleContext//EMPTY}.</p>\n   *\n   * @param stateNumber the ATN state number\n   * @param ctx the full parse context\n   *\n   * @return {IntervalSet} The set of potentially valid input symbols which could follow the\n   * specified state in the specified context.\n   *\n   * @throws IllegalArgumentException if the ATN does not contain a state with\n   * number {@code stateNumber}\n   */\n  getExpectedTokens(stateNumber, ctx) {\n    if (stateNumber < 0 || stateNumber >= this.states.length) {\n      throw 'Invalid state number.';\n    }\n    const s = this.states[stateNumber];\n    let following = this.nextTokens(s);\n    if (!following.contains(Token.EPSILON)) {\n      return following;\n    }\n    const expected = new IntervalSet();\n    expected.addSet(following);\n    expected.removeOne(Token.EPSILON);\n    while (ctx !== null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {\n      const invokingState = this.states[ctx.invokingState];\n      const rt = invokingState.transitions[0];\n      following = this.nextTokens(rt.followState);\n      expected.addSet(following);\n      expected.removeOne(Token.EPSILON);\n      ctx = ctx.parentCtx;\n    }\n    if (following.contains(Token.EPSILON)) {\n      expected.addOne(Token.EOF);\n    }\n    return expected;\n  }\n}\n\nATN.INVALID_ALT_NUMBER = 0;\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { ATN } from './ATN.js';\nimport { SemanticContext } from './SemanticContext.js';\nimport { merge } from '../context/PredictionContextUtils.js';\nimport { arrayToString } from '../utils/index.js';\nimport { HashSet } from '../misc/HashSet.js';\nimport { equalArrays } from '../utils/equalArrays.js';\nimport { HashCode } from '../misc/HashCode.js';\n\nfunction hashATNConfig(c) {\n  return c.hashCodeForConfigSet();\n}\n\nfunction equalATNConfigs(a, b) {\n  if (a === b) {\n    return true;\n  } else if (a === null || b === null) {\n    return false;\n  } else return a.equalsForConfigSet(b);\n}\n\n/**\n * Specialized {@link Set}{@code <}{@link ATNConfig}{@code >} that can track\n * info about the set, with support for combining similar configurations using a\n * graph-structured stack\n */\nexport class ATNConfigSet {\n  constructor(fullCtx) {\n    /**\n     * The reason that we need this is because we don't want the hash map to use\n     * the standard hash code and equals. We need all configurations with the\n     * same\n     * {@code (s,i,_,semctx)} to be equal. Unfortunately, this key effectively\n     * doubles\n     * the number of objects associated with ATNConfigs. The other solution is\n     * to\n     * use a hash table that lets us specify the equals/hashcode operation.\n     * All configs but hashed by (s, i, _, pi) not including context. Wiped out\n     * when we go readonly as this set becomes a DFA state\n     */\n    this.configLookup = new HashSet(hashATNConfig, equalATNConfigs);\n    /**\n     * Indicates that this configuration set is part of a full context\n     * LL prediction. It will be used to determine how to merge $. With SLL\n     * it's a wildcard whereas it is not for LL context merge\n     */\n    this.fullCtx = fullCtx === undefined ? true : fullCtx;\n    /**\n     * Indicates that the set of configurations is read-only. Do not\n     * allow any code to manipulate the set; DFA states will point at\n     * the sets and they must not change. This does not protect the other\n     * fields; in particular, conflictingAlts is set after\n     * we've made this readonly\n     */\n    this.readOnly = false;\n    // Track the elements as they are added to the set; supports get(i)///\n    this.configs = [];\n\n    // TODO: these fields make me pretty uncomfortable but nice to pack up info\n    // together, saves recomputation\n    // TODO: can we track conflicts as they are added to save scanning configs\n    // later?\n    this.uniqueAlt = 0;\n    this.conflictingAlts = null;\n\n    /**\n     * Used in parser and lexer. In lexer, it indicates we hit a pred\n     * while computing a closure operation. Don't make a DFA state from this\n     */\n    this.hasSemanticContext = false;\n    this.dipsIntoOuterContext = false;\n\n    this.cachedHashCode = -1;\n  }\n\n  get items() {\n    return this.configs;\n  }\n\n  get length() {\n    return this.configs.length;\n  }\n\n  /**\n   * Adding a new config means merging contexts with existing configs for\n   * {@code (s, i, pi, _)}, where {@code s} is the\n   * {@link ATNConfig//state}, {@code i} is the {@link ATNConfig//alt}, and\n   * {@code pi} is the {@link ATNConfig//semanticContext}. We use\n   * {@code (s,i,pi)} as key.\n   *\n   * <p>This method updates {@link //dipsIntoOuterContext} and\n   * {@link //hasSemanticContext} when necessary.</p>\n   */\n  add(config, mergeCache) {\n    if (mergeCache === undefined) {\n      mergeCache = null;\n    }\n    if (this.readOnly) {\n      throw 'This set is readonly';\n    }\n    if (config.semanticContext !== SemanticContext.NONE) {\n      this.hasSemanticContext = true;\n    }\n    if (config.reachesIntoOuterContext > 0) {\n      this.dipsIntoOuterContext = true;\n    }\n    const existing = this.configLookup.add(config);\n    if (existing === config) {\n      this.cachedHashCode = -1;\n      this.configs.push(config); // track order here\n      return true;\n    }\n    // a previous (s,i,pi,_), merge with it and save result\n    const rootIsWildcard = !this.fullCtx;\n    const merged = merge(existing.context, config.context, rootIsWildcard, mergeCache);\n    /**\n     * no need to check for existing.context, config.context in cache\n     * since only way to create new graphs is \"call rule\" and here. We\n     * cache at both places\n     */\n    existing.reachesIntoOuterContext = Math.max(existing.reachesIntoOuterContext, config.reachesIntoOuterContext);\n    // make sure to preserve the precedence filter suppression during the merge\n    if (config.precedenceFilterSuppressed) {\n      existing.precedenceFilterSuppressed = true;\n    }\n    existing.context = merged; // replace context; no need to alt mapping\n    return true;\n  }\n\n  getStates() {\n    const states = new HashSet();\n    for (let i = 0; i < this.configs.length; i++) {\n      states.add(this.configs[i].state);\n    }\n    return states;\n  }\n\n  getPredicates() {\n    const preds = [];\n    for (let i = 0; i < this.configs.length; i++) {\n      const c = this.configs[i].semanticContext;\n      if (c !== SemanticContext.NONE) {\n        preds.push(c.semanticContext);\n      }\n    }\n    return preds;\n  }\n\n  optimizeConfigs(interpreter) {\n    if (this.readOnly) {\n      throw 'This set is readonly';\n    }\n    if (this.configLookup.length === 0) {\n      return;\n    }\n    for (let i = 0; i < this.configs.length; i++) {\n      const config = this.configs[i];\n      config.context = interpreter.getCachedContext(config.context);\n    }\n  }\n\n  addAll(coll) {\n    for (let i = 0; i < coll.length; i++) {\n      this.add(coll[i]);\n    }\n    return false;\n  }\n\n  equals(other) {\n    return (\n      this === other ||\n      (other instanceof ATNConfigSet &&\n        equalArrays(this.configs, other.configs) &&\n        this.fullCtx === other.fullCtx &&\n        this.uniqueAlt === other.uniqueAlt &&\n        this.conflictingAlts === other.conflictingAlts &&\n        this.hasSemanticContext === other.hasSemanticContext &&\n        this.dipsIntoOuterContext === other.dipsIntoOuterContext)\n    );\n  }\n\n  hashCode() {\n    const hash = new HashCode();\n    hash.update(this.configs);\n    return hash.finish();\n  }\n\n  updateHashCode(hash) {\n    if (this.readOnly) {\n      if (this.cachedHashCode === -1) {\n        this.cachedHashCode = this.hashCode();\n      }\n      hash.update(this.cachedHashCode);\n    } else {\n      hash.update(this.hashCode());\n    }\n  }\n\n  isEmpty() {\n    return this.configs.length === 0;\n  }\n\n  contains(item) {\n    if (this.configLookup === null) {\n      throw 'This method is not implemented for readonly sets.';\n    }\n    return this.configLookup.contains(item);\n  }\n\n  containsFast(item) {\n    if (this.configLookup === null) {\n      throw 'This method is not implemented for readonly sets.';\n    }\n    return this.configLookup.containsFast(item);\n  }\n\n  clear() {\n    if (this.readOnly) {\n      throw 'This set is readonly';\n    }\n    this.configs = [];\n    this.cachedHashCode = -1;\n    this.configLookup = new HashSet();\n  }\n\n  setReadonly(readOnly) {\n    this.readOnly = readOnly;\n    if (readOnly) {\n      this.configLookup = null; // can't mod, no need for lookup cache\n    }\n  }\n\n  toString() {\n    return (\n      arrayToString(this.configs) +\n      (this.hasSemanticContext ? ',hasSemanticContext=' + this.hasSemanticContext : '') +\n      (this.uniqueAlt !== ATN.INVALID_ALT_NUMBER ? ',uniqueAlt=' + this.uniqueAlt : '') +\n      (this.conflictingAlts !== null ? ',conflictingAlts=' + this.conflictingAlts : '') +\n      (this.dipsIntoOuterContext ? ',dipsIntoOuterContext' : '')\n    );\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nexport class ATNDeserializationOptions {\n  constructor(copyFrom) {\n    if (copyFrom === undefined) {\n      copyFrom = null;\n    }\n    this.readOnly = false;\n    this.verifyATN = copyFrom === null ? true : copyFrom.verifyATN;\n    this.generateRuleBypassTransitions = copyFrom === null ? false : copyFrom.generateRuleBypassTransitions;\n  }\n}\n\nATNDeserializationOptions.defaultOptions = new ATNDeserializationOptions();\nATNDeserializationOptions.defaultOptions.readOnly = true;\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * Represents the type of recognizer an ATN applies to\n */\nexport const ATNType = {\n  LEXER: 0,\n  PARSER: 1,\n};\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { ATNState } from './ATNState.js';\n\nexport class BasicState extends ATNState {\n  constructor() {\n    super();\n    this.stateType = ATNState.BASIC;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { ATNState } from './ATNState.js';\n\nexport class DecisionState extends ATNState {\n  constructor() {\n    super();\n    this.decision = -1;\n    this.nonGreedy = false;\n    return this;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { DecisionState } from './DecisionState.js';\n\n/**\n *  The start of a regular {@code (...)} block\n */\nexport class BlockStartState extends DecisionState {\n  constructor() {\n    super();\n    this.endState = null;\n    return this;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { ATNState } from './ATNState.js';\n\n/**\n * Terminal node of a simple {@code (a|b|c)} block\n */\nexport class BlockEndState extends ATNState {\n  constructor() {\n    super();\n    this.stateType = ATNState.BLOCK_END;\n    this.startState = null;\n    return this;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { ATNState } from './ATNState.js';\n\n/**\n * Mark the end of a * or + loop\n */\nexport class LoopEndState extends ATNState {\n  constructor() {\n    super();\n    this.stateType = ATNState.LOOP_END;\n    this.loopBackState = null;\n    return this;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { ATNState } from './ATNState.js';\n\nexport class RuleStartState extends ATNState {\n  constructor() {\n    super();\n    this.stateType = ATNState.RULE_START;\n    this.stopState = null;\n    this.isPrecedenceRule = false;\n    return this;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { DecisionState } from './DecisionState.js';\nimport { ATNState } from './ATNState.js';\n\n/**\n * The Tokens rule start state linking to each lexer rule start state\n */\nexport class TokensStartState extends DecisionState {\n  constructor() {\n    super();\n    this.stateType = ATNState.TOKEN_START;\n    return this;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { DecisionState } from './DecisionState.js';\nimport { ATNState } from './ATNState.js';\n\n/**\n * Decision state for {@code A+} and {@code (A|B)+}.  It has two transitions:\n * one to the loop back to start of the block and one to exit.\n */\nexport class PlusLoopbackState extends DecisionState {\n  constructor() {\n    super();\n    this.stateType = ATNState.PLUS_LOOP_BACK;\n    return this;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { ATNState } from './ATNState.js';\n\nexport class StarLoopbackState extends ATNState {\n  constructor() {\n    super();\n    this.stateType = ATNState.STAR_LOOP_BACK;\n    return this;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { DecisionState } from './DecisionState.js';\nimport { ATNState } from './ATNState.js';\n\nexport class StarLoopEntryState extends DecisionState {\n  constructor() {\n    super();\n    this.stateType = ATNState.STAR_LOOP_ENTRY;\n    this.loopBackState = null;\n    // Indicates whether this state can benefit from a precedence DFA during SLL decision making.\n    this.isPrecedenceDecision = null;\n    return this;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { BlockStartState } from './BlockStartState.js';\nimport { ATNState } from './ATNState.js';\n\n/**\n * Start of {@code (A|B|...)+} loop. Technically a decision state, but\n * we don't use for code generation; somebody might need it, so I'm defining\n * it for completeness. In reality, the {@link PlusLoopbackState} node is the\n * real decision-making note for {@code A+}\n */\nexport class PlusBlockStartState extends BlockStartState {\n  constructor() {\n    super();\n    this.stateType = ATNState.PLUS_BLOCK_START;\n    this.loopBackState = null;\n    return this;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { BlockStartState } from './BlockStartState.js';\nimport { ATNState } from './ATNState.js';\n\n/**\n * The block that begins a closure loop\n */\nexport class StarBlockStartState extends BlockStartState {\n  constructor() {\n    super();\n    this.stateType = ATNState.STAR_BLOCK_START;\n    return this;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { ATNState } from './ATNState.js';\nimport { BlockStartState } from './BlockStartState.js';\n\nexport class BasicBlockStartState extends BlockStartState {\n  constructor() {\n    super();\n    this.stateType = ATNState.BLOCK_START;\n    return this;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { IntervalSet } from '../misc/IntervalSet.js';\nimport { Transition } from './Transition.js';\n\nexport class AtomTransition extends Transition {\n  constructor(target, label) {\n    super(target);\n    // The token type or character value; or, signifies special label.\n    this.label_ = label;\n    this.label = this.makeLabel();\n    this.serializationType = Transition.ATOM;\n  }\n\n  makeLabel() {\n    const s = new IntervalSet();\n    s.addOne(this.label_);\n    return s;\n  }\n\n  matches(symbol, minVocabSymbol, maxVocabSymbol) {\n    return this.label_ === symbol;\n  }\n\n  toString() {\n    return this.label_;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { IntervalSet } from '../misc/IntervalSet.js';\nimport { Transition } from './Transition.js';\n\nexport class RangeTransition extends Transition {\n  constructor(target, start, stop) {\n    super(target);\n    this.serializationType = Transition.RANGE;\n    this.start = start;\n    this.stop = stop;\n    this.label = this.makeLabel();\n  }\n\n  makeLabel() {\n    const s = new IntervalSet();\n    s.addRange(this.start, this.stop);\n    return s;\n  }\n\n  matches(symbol, minVocabSymbol, maxVocabSymbol) {\n    return symbol >= this.start && symbol <= this.stop;\n  }\n\n  toString() {\n    return \"'\" + String.fromCharCode(this.start) + \"'..'\" + String.fromCharCode(this.stop) + \"'\";\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { Transition } from './Transition.js';\n\nexport class ActionTransition extends Transition {\n  constructor(target, ruleIndex, actionIndex, isCtxDependent) {\n    super(target);\n    this.serializationType = Transition.ACTION;\n    this.ruleIndex = ruleIndex;\n    this.actionIndex = actionIndex === undefined ? -1 : actionIndex;\n    this.isCtxDependent = isCtxDependent === undefined ? false : isCtxDependent; // e.g., $i ref in pred\n    this.isEpsilon = true;\n  }\n\n  matches(symbol, minVocabSymbol, maxVocabSymbol) {\n    return false;\n  }\n\n  toString() {\n    return 'action_' + this.ruleIndex + ':' + this.actionIndex;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { Transition } from './Transition.js';\n\nexport class EpsilonTransition extends Transition {\n  constructor(target, outermostPrecedenceReturn) {\n    super(target);\n    this.serializationType = Transition.EPSILON;\n    this.isEpsilon = true;\n    this.outermostPrecedenceReturn = outermostPrecedenceReturn;\n  }\n\n  matches(symbol, minVocabSymbol, maxVocabSymbol) {\n    return false;\n  }\n\n  toString() {\n    return 'epsilon';\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { SemanticContext } from './SemanticContext.js';\n\nexport class Predicate extends SemanticContext {\n  constructor(ruleIndex, predIndex, isCtxDependent) {\n    super();\n    this.ruleIndex = ruleIndex === undefined ? -1 : ruleIndex;\n    this.predIndex = predIndex === undefined ? -1 : predIndex;\n    this.isCtxDependent = isCtxDependent === undefined ? false : isCtxDependent; // e.g., $i ref in pred\n  }\n\n  evaluate(parser, outerContext) {\n    const localctx = this.isCtxDependent ? outerContext : null;\n    return parser.sempred(localctx, this.ruleIndex, this.predIndex);\n  }\n\n  updateHashCode(hash) {\n    hash.update(this.ruleIndex, this.predIndex, this.isCtxDependent);\n  }\n\n  equals(other) {\n    if (this === other) {\n      return true;\n    } else if (!(other instanceof Predicate)) {\n      return false;\n    } else {\n      return (\n        this.ruleIndex === other.ruleIndex &&\n        this.predIndex === other.predIndex &&\n        this.isCtxDependent === other.isCtxDependent\n      );\n    }\n  }\n\n  toString() {\n    return '{' + this.ruleIndex + ':' + this.predIndex + '}?';\n  }\n}\n\n/**\n * The default {@link SemanticContext}, which is semantically equivalent to\n * a predicate of the form {@code {true}?}\n */\nSemanticContext.NONE = new Predicate();\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { Predicate } from '../atn/Predicate.js';\nimport { Transition } from './Transition.js';\nimport { AbstractPredicateTransition } from '../atn/AbstractPredicateTransition.js';\n\nexport class PredicateTransition extends AbstractPredicateTransition {\n  constructor(target, ruleIndex, predIndex, isCtxDependent) {\n    super(target);\n    this.serializationType = Transition.PREDICATE;\n    this.ruleIndex = ruleIndex;\n    this.predIndex = predIndex;\n    this.isCtxDependent = isCtxDependent; // e.g., $i ref in pred\n    this.isEpsilon = true;\n  }\n\n  matches(symbol, minVocabSymbol, maxVocabSymbol) {\n    return false;\n  }\n\n  getPredicate() {\n    return new Predicate(this.ruleIndex, this.predIndex, this.isCtxDependent);\n  }\n\n  toString() {\n    return 'pred_' + this.ruleIndex + ':' + this.predIndex;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { SemanticContext } from './SemanticContext.js';\n\nexport class PrecedencePredicate extends SemanticContext {\n  constructor(precedence) {\n    super();\n    this.precedence = precedence === undefined ? 0 : precedence;\n  }\n\n  evaluate(parser, outerContext) {\n    return parser.precpred(outerContext, this.precedence);\n  }\n\n  evalPrecedence(parser, outerContext) {\n    if (parser.precpred(outerContext, this.precedence)) {\n      return SemanticContext.NONE;\n    } else {\n      return null;\n    }\n  }\n\n  compareTo(other) {\n    return this.precedence - other.precedence;\n  }\n\n  updateHashCode(hash) {\n    hash.update(this.precedence);\n  }\n\n  equals(other) {\n    if (this === other) {\n      return true;\n    } else if (!(other instanceof PrecedencePredicate)) {\n      return false;\n    } else {\n      return this.precedence === other.precedence;\n    }\n  }\n\n  toString() {\n    return '{' + this.precedence + '>=prec}?';\n  }\n}\n\n// HORRIBLE workaround circular import, avoiding dynamic import\nSemanticContext.PrecedencePredicate = PrecedencePredicate;\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { PrecedencePredicate } from '../atn/PrecedencePredicate.js';\nimport { Transition } from './Transition.js';\nimport { AbstractPredicateTransition } from '../atn/AbstractPredicateTransition.js';\n\nexport class PrecedencePredicateTransition extends AbstractPredicateTransition {\n  constructor(target, precedence) {\n    super(target);\n    this.serializationType = Transition.PRECEDENCE;\n    this.precedence = precedence;\n    this.isEpsilon = true;\n  }\n\n  matches(symbol, minVocabSymbol, maxVocabSymbol) {\n    return false;\n  }\n\n  getPredicate() {\n    return new PrecedencePredicate(this.precedence);\n  }\n\n  toString() {\n    return this.precedence + ' >= _p';\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { Token } from '../Token.js';\nimport { ATN } from './ATN.js';\nimport { ATNType } from './ATNType.js';\n\nimport { ATNState } from '../state/ATNState.js';\nimport { BasicState } from '../state/BasicState.js';\nimport { DecisionState } from '../state/DecisionState.js';\nimport { BlockStartState } from '../state/BlockStartState.js';\nimport { BlockEndState } from '../state/BlockEndState.js';\nimport { LoopEndState } from '../state/LoopEndState.js';\nimport { RuleStartState } from '../state/RuleStartState.js';\nimport { RuleStopState } from '../state/RuleStopState.js';\nimport { TokensStartState } from '../state/TokensStartState.js';\nimport { PlusLoopbackState } from '../state/PlusLoopbackState.js';\nimport { StarLoopbackState } from '../state/StarLoopbackState.js';\nimport { StarLoopEntryState } from '../state/StarLoopEntryState.js';\nimport { PlusBlockStartState } from '../state/PlusBlockStartState.js';\nimport { StarBlockStartState } from '../state/StarBlockStartState.js';\nimport { BasicBlockStartState } from '../state/BasicBlockStartState.js';\n\nimport { Transition } from '../transition/Transition.js';\nimport { AtomTransition } from '../transition/AtomTransition.js';\nimport { SetTransition } from '../transition/SetTransition.js';\nimport { NotSetTransition } from '../transition/NotSetTransition.js';\nimport { RuleTransition } from '../transition/RuleTransition.js';\nimport { RangeTransition } from '../transition/RangeTransition.js';\nimport { ActionTransition } from '../transition/ActionTransition.js';\nimport { EpsilonTransition } from '../transition/EpsilonTransition.js';\nimport { WildcardTransition } from '../transition/WildcardTransition.js';\nimport { PredicateTransition } from '../transition/PredicateTransition.js';\nimport { PrecedencePredicateTransition } from '../transition/PrecedencePredicateTransition.js';\n\nimport { IntervalSet } from '../misc/IntervalSet.js';\nimport { ATNDeserializationOptions } from './ATNDeserializationOptions.js';\n\nimport { LexerActionType } from './LexerActionType.js';\nimport { LexerSkipAction } from '../action/LexerSkipAction.js';\nimport { LexerChannelAction } from '../action/LexerChannelAction.js';\nimport { LexerCustomAction } from '../action/LexerCustomAction.js';\nimport { LexerMoreAction } from '../action/LexerMoreAction.js';\nimport { LexerTypeAction } from '../action/LexerTypeAction.js';\nimport { LexerPushModeAction } from '../action/LexerPushModeAction.js';\nimport { LexerPopModeAction } from '../action/LexerPopModeAction.js';\nimport { LexerModeAction } from '../action/LexerModeAction.js';\n\nconst SERIALIZED_VERSION = 4;\n\nfunction initArray(length, value) {\n  const tmp = [];\n  tmp[length - 1] = value;\n  return tmp.map(function (i) {\n    return value;\n  });\n}\n\nexport class ATNDeserializer {\n  constructor(options) {\n    if (options === undefined || options === null) {\n      options = ATNDeserializationOptions.defaultOptions;\n    }\n    this.deserializationOptions = options;\n    this.stateFactories = null;\n    this.actionFactories = null;\n  }\n\n  deserialize(data) {\n    const legacy = this.reset(data);\n    this.checkVersion(legacy);\n    if (legacy) this.skipUUID();\n    const atn = this.readATN();\n    this.readStates(atn, legacy);\n    this.readRules(atn, legacy);\n    this.readModes(atn);\n    const sets = [];\n    this.readSets(atn, sets, this.readInt.bind(this));\n    if (legacy) this.readSets(atn, sets, this.readInt32.bind(this));\n    this.readEdges(atn, sets);\n    this.readDecisions(atn);\n    this.readLexerActions(atn, legacy);\n    this.markPrecedenceDecisions(atn);\n    this.verifyATN(atn);\n    if (this.deserializationOptions.generateRuleBypassTransitions && atn.grammarType === ATNType.PARSER) {\n      this.generateRuleBypassTransitions(atn);\n      // re-verify after modification\n      this.verifyATN(atn);\n    }\n    return atn;\n  }\n\n  reset(data) {\n    const version = data.charCodeAt ? data.charCodeAt(0) : data[0];\n    if (version === SERIALIZED_VERSION - 1) {\n      const adjust = function (c) {\n        const v = c.charCodeAt(0);\n        return v > 1 ? v - 2 : v + 65534;\n      };\n      const temp = data.split('').map(adjust);\n      // don't adjust the first value since that's the version number\n      temp[0] = data.charCodeAt(0);\n      this.data = temp;\n      this.pos = 0;\n      return true;\n    } else {\n      this.data = data;\n      this.pos = 0;\n      return false;\n    }\n  }\n\n  skipUUID() {\n    let count = 0;\n    while (count++ < 8) this.readInt();\n  }\n\n  checkVersion(legacy) {\n    const version = this.readInt();\n    if (!legacy && version !== SERIALIZED_VERSION) {\n      throw 'Could not deserialize ATN with version ' + version + ' (expected ' + SERIALIZED_VERSION + ').';\n    }\n  }\n\n  readATN() {\n    const grammarType = this.readInt();\n    const maxTokenType = this.readInt();\n    return new ATN(grammarType, maxTokenType);\n  }\n\n  readStates(atn, legacy) {\n    let j, pair, stateNumber;\n    const loopBackStateNumbers = [];\n    const endStateNumbers = [];\n    const nstates = this.readInt();\n    for (let i = 0; i < nstates; i++) {\n      const stype = this.readInt();\n      // ignore bad type of states\n      if (stype === ATNState.INVALID_TYPE) {\n        atn.addState(null);\n        continue;\n      }\n      let ruleIndex = this.readInt();\n      if (legacy && ruleIndex === 0xffff) {\n        ruleIndex = -1;\n      }\n      const s = this.stateFactory(stype, ruleIndex);\n      if (stype === ATNState.LOOP_END) {\n        // special case\n        const loopBackStateNumber = this.readInt();\n        loopBackStateNumbers.push([s, loopBackStateNumber]);\n      } else if (s instanceof BlockStartState) {\n        const endStateNumber = this.readInt();\n        endStateNumbers.push([s, endStateNumber]);\n      }\n      atn.addState(s);\n    }\n    // delay the assignment of loop back and end states until we know all the\n    // state instances have been initialized\n    for (j = 0; j < loopBackStateNumbers.length; j++) {\n      pair = loopBackStateNumbers[j];\n      pair[0].loopBackState = atn.states[pair[1]];\n    }\n\n    for (j = 0; j < endStateNumbers.length; j++) {\n      pair = endStateNumbers[j];\n      pair[0].endState = atn.states[pair[1]];\n    }\n\n    let numNonGreedyStates = this.readInt();\n    for (j = 0; j < numNonGreedyStates; j++) {\n      stateNumber = this.readInt();\n      atn.states[stateNumber].nonGreedy = true;\n    }\n\n    let numPrecedenceStates = this.readInt();\n    for (j = 0; j < numPrecedenceStates; j++) {\n      stateNumber = this.readInt();\n      atn.states[stateNumber].isPrecedenceRule = true;\n    }\n  }\n\n  readRules(atn, legacy) {\n    let i;\n    const nrules = this.readInt();\n    if (atn.grammarType === ATNType.LEXER) {\n      atn.ruleToTokenType = initArray(nrules, 0);\n    }\n    atn.ruleToStartState = initArray(nrules, 0);\n    for (i = 0; i < nrules; i++) {\n      const s = this.readInt();\n      atn.ruleToStartState[i] = atn.states[s];\n      if (atn.grammarType === ATNType.LEXER) {\n        let tokenType = this.readInt();\n        if (legacy && tokenType === 0xffff) {\n          tokenType = Token.EOF;\n        }\n        atn.ruleToTokenType[i] = tokenType;\n      }\n    }\n    atn.ruleToStopState = initArray(nrules, 0);\n    for (i = 0; i < atn.states.length; i++) {\n      const state = atn.states[i];\n      if (!(state instanceof RuleStopState)) {\n        continue;\n      }\n      atn.ruleToStopState[state.ruleIndex] = state;\n      atn.ruleToStartState[state.ruleIndex].stopState = state;\n    }\n  }\n\n  readModes(atn) {\n    const nmodes = this.readInt();\n    for (let i = 0; i < nmodes; i++) {\n      let s = this.readInt();\n      atn.modeToStartState.push(atn.states[s]);\n    }\n  }\n\n  readSets(atn, sets, reader) {\n    const m = this.readInt();\n    for (let i = 0; i < m; i++) {\n      const iset = new IntervalSet();\n      sets.push(iset);\n      const n = this.readInt();\n      const containsEof = this.readInt();\n      if (containsEof !== 0) {\n        iset.addOne(-1);\n      }\n      for (let j = 0; j < n; j++) {\n        const i1 = reader();\n        const i2 = reader();\n        iset.addRange(i1, i2);\n      }\n    }\n  }\n\n  readEdges(atn, sets) {\n    let i, j, state, trans, target;\n    const nedges = this.readInt();\n    for (i = 0; i < nedges; i++) {\n      const src = this.readInt();\n      const trg = this.readInt();\n      const ttype = this.readInt();\n      const arg1 = this.readInt();\n      const arg2 = this.readInt();\n      const arg3 = this.readInt();\n      trans = this.edgeFactory(atn, ttype, src, trg, arg1, arg2, arg3, sets);\n      const srcState = atn.states[src];\n      srcState.addTransition(trans);\n    }\n    // edges for rule stop states can be derived, so they aren't serialized\n    for (i = 0; i < atn.states.length; i++) {\n      state = atn.states[i];\n      for (j = 0; j < state.transitions.length; j++) {\n        const t = state.transitions[j];\n        if (!(t instanceof RuleTransition)) {\n          continue;\n        }\n        let outermostPrecedenceReturn = -1;\n        if (atn.ruleToStartState[t.target.ruleIndex].isPrecedenceRule) {\n          if (t.precedence === 0) {\n            outermostPrecedenceReturn = t.target.ruleIndex;\n          }\n        }\n\n        trans = new EpsilonTransition(t.followState, outermostPrecedenceReturn);\n        atn.ruleToStopState[t.target.ruleIndex].addTransition(trans);\n      }\n    }\n\n    for (i = 0; i < atn.states.length; i++) {\n      state = atn.states[i];\n      if (state instanceof BlockStartState) {\n        // we need to know the end state to set its start state\n        if (state.endState === null) {\n          throw 'IllegalState';\n        }\n        // block end states can only be associated to a single block start\n        // state\n        if (state.endState.startState !== null) {\n          throw 'IllegalState';\n        }\n        state.endState.startState = state;\n      }\n      if (state instanceof PlusLoopbackState) {\n        for (j = 0; j < state.transitions.length; j++) {\n          target = state.transitions[j].target;\n          if (target instanceof PlusBlockStartState) {\n            target.loopBackState = state;\n          }\n        }\n      } else if (state instanceof StarLoopbackState) {\n        for (j = 0; j < state.transitions.length; j++) {\n          target = state.transitions[j].target;\n          if (target instanceof StarLoopEntryState) {\n            target.loopBackState = state;\n          }\n        }\n      }\n    }\n  }\n\n  readDecisions(atn) {\n    const ndecisions = this.readInt();\n    for (let i = 0; i < ndecisions; i++) {\n      const s = this.readInt();\n      const decState = atn.states[s];\n      atn.decisionToState.push(decState);\n      decState.decision = i;\n    }\n  }\n\n  readLexerActions(atn, legacy) {\n    if (atn.grammarType === ATNType.LEXER) {\n      const count = this.readInt();\n      atn.lexerActions = initArray(count, null);\n      for (let i = 0; i < count; i++) {\n        const actionType = this.readInt();\n        let data1 = this.readInt();\n        if (legacy && data1 === 0xffff) {\n          data1 = -1;\n        }\n        let data2 = this.readInt();\n        if (legacy && data2 === 0xffff) {\n          data2 = -1;\n        }\n        atn.lexerActions[i] = this.lexerActionFactory(actionType, data1, data2);\n      }\n    }\n  }\n\n  generateRuleBypassTransitions(atn) {\n    let i;\n    const count = atn.ruleToStartState.length;\n    for (i = 0; i < count; i++) {\n      atn.ruleToTokenType[i] = atn.maxTokenType + i + 1;\n    }\n    for (i = 0; i < count; i++) {\n      this.generateRuleBypassTransition(atn, i);\n    }\n  }\n\n  generateRuleBypassTransition(atn, idx) {\n    let i, state;\n    const bypassStart = new BasicBlockStartState();\n    bypassStart.ruleIndex = idx;\n    atn.addState(bypassStart);\n\n    const bypassStop = new BlockEndState();\n    bypassStop.ruleIndex = idx;\n    atn.addState(bypassStop);\n\n    bypassStart.endState = bypassStop;\n    atn.defineDecisionState(bypassStart);\n\n    bypassStop.startState = bypassStart;\n\n    let excludeTransition = null;\n    let endState = null;\n\n    if (atn.ruleToStartState[idx].isPrecedenceRule) {\n      // wrap from the beginning of the rule to the StarLoopEntryState\n      endState = null;\n      for (i = 0; i < atn.states.length; i++) {\n        state = atn.states[i];\n        if (this.stateIsEndStateFor(state, idx)) {\n          endState = state;\n          excludeTransition = state.loopBackState.transitions[0];\n          break;\n        }\n      }\n      if (excludeTransition === null) {\n        throw \"Couldn't identify final state of the precedence rule prefix section.\";\n      }\n    } else {\n      endState = atn.ruleToStopState[idx];\n    }\n\n    // all non-excluded transitions that currently target end state need to\n    // target blockEnd instead\n    for (i = 0; i < atn.states.length; i++) {\n      state = atn.states[i];\n      for (let j = 0; j < state.transitions.length; j++) {\n        const transition = state.transitions[j];\n        if (transition === excludeTransition) {\n          continue;\n        }\n        if (transition.target === endState) {\n          transition.target = bypassStop;\n        }\n      }\n    }\n\n    // all transitions leaving the rule start state need to leave blockStart\n    // instead\n    const ruleToStartState = atn.ruleToStartState[idx];\n    const count = ruleToStartState.transitions.length;\n    while (count > 0) {\n      bypassStart.addTransition(ruleToStartState.transitions[count - 1]);\n      ruleToStartState.transitions = ruleToStartState.transitions.slice(-1);\n    }\n    // link the new states\n    atn.ruleToStartState[idx].addTransition(new EpsilonTransition(bypassStart));\n    bypassStop.addTransition(new EpsilonTransition(endState));\n\n    const matchState = new BasicState();\n    atn.addState(matchState);\n    matchState.addTransition(new AtomTransition(bypassStop, atn.ruleToTokenType[idx]));\n    bypassStart.addTransition(new EpsilonTransition(matchState));\n  }\n\n  stateIsEndStateFor(state, idx) {\n    if (state.ruleIndex !== idx) {\n      return null;\n    }\n    if (!(state instanceof StarLoopEntryState)) {\n      return null;\n    }\n    const maybeLoopEndState = state.transitions[state.transitions.length - 1].target;\n    if (!(maybeLoopEndState instanceof LoopEndState)) {\n      return null;\n    }\n    if (maybeLoopEndState.epsilonOnlyTransitions && maybeLoopEndState.transitions[0].target instanceof RuleStopState) {\n      return state;\n    } else {\n      return null;\n    }\n  }\n\n  /**\n   * Analyze the {@link StarLoopEntryState} states in the specified ATN to set\n   * the {@link StarLoopEntryState//isPrecedenceDecision} field to the\n   * correct value.\n   * @param atn The ATN.\n   */\n  markPrecedenceDecisions(atn) {\n    for (let i = 0; i < atn.states.length; i++) {\n      const state = atn.states[i];\n      if (!(state instanceof StarLoopEntryState)) {\n        continue;\n      }\n      // We analyze the ATN to determine if this ATN decision state is the\n      // decision for the closure block that determines whether a\n      // precedence rule should continue or complete.\n      if (atn.ruleToStartState[state.ruleIndex].isPrecedenceRule) {\n        const maybeLoopEndState = state.transitions[state.transitions.length - 1].target;\n        if (maybeLoopEndState instanceof LoopEndState) {\n          if (\n            maybeLoopEndState.epsilonOnlyTransitions &&\n            maybeLoopEndState.transitions[0].target instanceof RuleStopState\n          ) {\n            state.isPrecedenceDecision = true;\n          }\n        }\n      }\n    }\n  }\n\n  verifyATN(atn) {\n    if (!this.deserializationOptions.verifyATN) {\n      return;\n    }\n    // verify assumptions\n    for (let i = 0; i < atn.states.length; i++) {\n      const state = atn.states[i];\n      if (state === null) {\n        continue;\n      }\n      this.checkCondition(state.epsilonOnlyTransitions || state.transitions.length <= 1);\n      if (state instanceof PlusBlockStartState) {\n        this.checkCondition(state.loopBackState !== null);\n      } else if (state instanceof StarLoopEntryState) {\n        this.checkCondition(state.loopBackState !== null);\n        this.checkCondition(state.transitions.length === 2);\n        if (state.transitions[0].target instanceof StarBlockStartState) {\n          this.checkCondition(state.transitions[1].target instanceof LoopEndState);\n          this.checkCondition(!state.nonGreedy);\n        } else if (state.transitions[0].target instanceof LoopEndState) {\n          this.checkCondition(state.transitions[1].target instanceof StarBlockStartState);\n          this.checkCondition(state.nonGreedy);\n        } else {\n          throw 'IllegalState';\n        }\n      } else if (state instanceof StarLoopbackState) {\n        this.checkCondition(state.transitions.length === 1);\n        this.checkCondition(state.transitions[0].target instanceof StarLoopEntryState);\n      } else if (state instanceof LoopEndState) {\n        this.checkCondition(state.loopBackState !== null);\n      } else if (state instanceof RuleStartState) {\n        this.checkCondition(state.stopState !== null);\n      } else if (state instanceof BlockStartState) {\n        this.checkCondition(state.endState !== null);\n      } else if (state instanceof BlockEndState) {\n        this.checkCondition(state.startState !== null);\n      } else if (state instanceof DecisionState) {\n        this.checkCondition(state.transitions.length <= 1 || state.decision >= 0);\n      } else {\n        this.checkCondition(state.transitions.length <= 1 || state instanceof RuleStopState);\n      }\n    }\n  }\n\n  checkCondition(condition, message) {\n    if (!condition) {\n      if (message === undefined || message === null) {\n        message = 'IllegalState';\n      }\n      throw message;\n    }\n  }\n\n  readInt() {\n    return this.data[this.pos++];\n  }\n\n  readInt32() {\n    const low = this.readInt();\n    const high = this.readInt();\n    return low | (high << 16);\n  }\n\n  edgeFactory(atn, type, src, trg, arg1, arg2, arg3, sets) {\n    const target = atn.states[trg];\n    switch (type) {\n      case Transition.EPSILON:\n        return new EpsilonTransition(target);\n      case Transition.RANGE:\n        return arg3 !== 0 ? new RangeTransition(target, Token.EOF, arg2) : new RangeTransition(target, arg1, arg2);\n      case Transition.RULE:\n        return new RuleTransition(atn.states[arg1], arg2, arg3, target);\n      case Transition.PREDICATE:\n        return new PredicateTransition(target, arg1, arg2, arg3 !== 0);\n      case Transition.PRECEDENCE:\n        return new PrecedencePredicateTransition(target, arg1);\n      case Transition.ATOM:\n        return arg3 !== 0 ? new AtomTransition(target, Token.EOF) : new AtomTransition(target, arg1);\n      case Transition.ACTION:\n        return new ActionTransition(target, arg1, arg2, arg3 !== 0);\n      case Transition.SET:\n        return new SetTransition(target, sets[arg1]);\n      case Transition.NOT_SET:\n        return new NotSetTransition(target, sets[arg1]);\n      case Transition.WILDCARD:\n        return new WildcardTransition(target);\n      default:\n        throw 'The specified transition type: ' + type + ' is not valid.';\n    }\n  }\n\n  stateFactory(type, ruleIndex) {\n    if (this.stateFactories === null) {\n      const sf = [];\n      sf[ATNState.INVALID_TYPE] = null;\n      sf[ATNState.BASIC] = () => new BasicState();\n      sf[ATNState.RULE_START] = () => new RuleStartState();\n      sf[ATNState.BLOCK_START] = () => new BasicBlockStartState();\n      sf[ATNState.PLUS_BLOCK_START] = () => new PlusBlockStartState();\n      sf[ATNState.STAR_BLOCK_START] = () => new StarBlockStartState();\n      sf[ATNState.TOKEN_START] = () => new TokensStartState();\n      sf[ATNState.RULE_STOP] = () => new RuleStopState();\n      sf[ATNState.BLOCK_END] = () => new BlockEndState();\n      sf[ATNState.STAR_LOOP_BACK] = () => new StarLoopbackState();\n      sf[ATNState.STAR_LOOP_ENTRY] = () => new StarLoopEntryState();\n      sf[ATNState.PLUS_LOOP_BACK] = () => new PlusLoopbackState();\n      sf[ATNState.LOOP_END] = () => new LoopEndState();\n      this.stateFactories = sf;\n    }\n    if (type > this.stateFactories.length || this.stateFactories[type] === null) {\n      throw 'The specified state type ' + type + ' is not valid.';\n    } else {\n      const s = this.stateFactories[type]();\n      if (s !== null) {\n        s.ruleIndex = ruleIndex;\n        return s;\n      }\n    }\n  }\n\n  lexerActionFactory(type, data1, data2) {\n    if (this.actionFactories === null) {\n      const af = [];\n      af[LexerActionType.CHANNEL] = (data1, data2) => new LexerChannelAction(data1);\n      af[LexerActionType.CUSTOM] = (data1, data2) => new LexerCustomAction(data1, data2);\n      af[LexerActionType.MODE] = (data1, data2) => new LexerModeAction(data1);\n      af[LexerActionType.MORE] = (data1, data2) => LexerMoreAction.INSTANCE;\n      af[LexerActionType.POP_MODE] = (data1, data2) => LexerPopModeAction.INSTANCE;\n      af[LexerActionType.PUSH_MODE] = (data1, data2) => new LexerPushModeAction(data1);\n      af[LexerActionType.SKIP] = (data1, data2) => LexerSkipAction.INSTANCE;\n      af[LexerActionType.TYPE] = (data1, data2) => new LexerTypeAction(data1);\n      this.actionFactories = af;\n    }\n    if (type > this.actionFactories.length || this.actionFactories[type] === null) {\n      throw 'The specified lexer action type ' + type + ' is not valid.';\n    } else {\n      return this.actionFactories[type](data1, data2);\n    }\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { ATNConfigSet } from '../atn/ATNConfigSet.js';\nimport { HashCode } from '../misc/HashCode.js';\nimport { HashSet } from '../misc/HashSet.js';\n\n/**\n * A DFA state represents a set of possible ATN configurations.\n * As Aho, Sethi, Ullman p. 117 says \"The DFA uses its state\n * to keep track of all possible states the ATN can be in after\n * reading each input symbol. That is to say, after reading\n * input a1a2..an, the DFA is in a state that represents the\n * subset T of the states of the ATN that are reachable from the\n * ATN's start state along some path labeled a1a2..an.\"\n * In conventional NFA&rarr;DFA conversion, therefore, the subset T\n * would be a bitset representing the set of states the\n * ATN could be in. We need to track the alt predicted by each\n * state as well, however. More importantly, we need to maintain\n * a stack of states, tracking the closure operations as they\n * jump from rule to rule, emulating rule invocations (method calls).\n * I have to add a stack to simulate the proper lookahead sequences for\n * the underlying LL grammar from which the ATN was derived.\n *\n * <p>I use a set of ATNConfig objects not simple states. An ATNConfig\n * is both a state (ala normal conversion) and a RuleContext describing\n * the chain of rules (if any) followed to arrive at that state.</p>\n *\n * <p>A DFA state may have multiple references to a particular state,\n * but with different ATN contexts (with same or different alts)\n * meaning that state was reached via a different set of rule invocations.</p>\n */\nexport class DFAState {\n  constructor(stateNumber, configs) {\n    if (stateNumber === null) {\n      stateNumber = -1;\n    }\n    if (configs === null) {\n      configs = new ATNConfigSet();\n    }\n    this.stateNumber = stateNumber;\n    this.configs = configs;\n    /**\n     * {@code edges[symbol]} points to target of symbol. Shift up by 1 so (-1)\n     * {@link Token//EOF} maps to {@code edges[0]}.\n     */\n    this.edges = null;\n    this.isAcceptState = false;\n    /**\n     * if accept state, what ttype do we match or alt do we predict?\n     * This is set to {@link ATN//INVALID_ALT_NUMBER} when {@link//predicates}\n     * {@code !=null} or {@link //requiresFullContext}.\n     */\n    this.prediction = 0;\n    this.lexerActionExecutor = null;\n    /**\n     * Indicates that this state was created during SLL prediction that\n     * discovered a conflict between the configurations in the state. Future\n     * {@link ParserATNSimulator//execATN} invocations immediately jumped doing\n     * full context prediction if this field is true.\n     */\n    this.requiresFullContext = false;\n    /**\n     * During SLL parsing, this is a list of predicates associated with the\n     * ATN configurations of the DFA state. When we have predicates,\n     * {@link //requiresFullContext} is {@code false} since full context\n     * prediction evaluates predicates\n     * on-the-fly. If this is not null, then {@link //prediction} is\n     * {@link ATN//INVALID_ALT_NUMBER}.\n     *\n     * <p>We only use these for non-{@link //requiresFullContext} but\n     * conflicting states. That\n     * means we know from the context (it's $ or we don't dip into outer\n     * context) that it's an ambiguity not a conflict.</p>\n     *\n     * <p>This list is computed by {@link\n     * ParserATNSimulator//predicateDFAState}.</p>\n     */\n    this.predicates = null;\n    return this;\n  }\n\n  /**\n   * Get the set of all alts mentioned by all ATN configurations in this\n   * DFA state.\n   */\n  getAltSet() {\n    const alts = new HashSet();\n    if (this.configs !== null) {\n      for (let i = 0; i < this.configs.length; i++) {\n        const c = this.configs[i];\n        alts.add(c.alt);\n      }\n    }\n    if (alts.length === 0) {\n      return null;\n    } else {\n      return alts;\n    }\n  }\n\n  /**\n   * Two {@link DFAState} instances are equal if their ATN configuration sets\n   * are the same. This method is used to see if a state already exists.\n   *\n   * <p>Because the number of alternatives and number of ATN configurations are\n   * finite, there is a finite number of DFA states that can be processed.\n   * This is necessary to show that the algorithm terminates.</p>\n   *\n   * <p>Cannot test the DFA state numbers here because in\n   * {@link ParserATNSimulator//addDFAState} we need to know if any other state\n   * exists that has this exact set of ATN configurations. The\n   * {@link //stateNumber} is irrelevant.</p>\n   */\n  equals(other) {\n    // compare set of ATN configurations in this set with other\n    return this === other || (other instanceof DFAState && this.configs.equals(other.configs));\n  }\n\n  toString() {\n    let s = '' + this.stateNumber + ':' + this.configs;\n    if (this.isAcceptState) {\n      s = s + '=>';\n      if (this.predicates !== null) s = s + this.predicates;\n      else s = s + this.prediction;\n    }\n    return s;\n  }\n\n  hashCode() {\n    const hash = new HashCode();\n    hash.update(this.configs);\n    return hash.finish();\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { DFAState } from '../dfa/DFAState.js';\nimport { ATNConfigSet } from './ATNConfigSet.js';\nimport { getCachedPredictionContext } from '../context/PredictionContextUtils.js';\nimport { HashMap } from '../misc/HashMap.js';\n\nexport class ATNSimulator {\n  constructor(atn, sharedContextCache) {\n    /**\n     * The context cache maps all PredictionContext objects that are ==\n     * to a single cached copy. This cache is shared across all contexts\n     * in all ATNConfigs in all DFA states.  We rebuild each ATNConfigSet\n     * to use only cached nodes/graphs in addDFAState(). We don't want to\n     * fill this during closure() since there are lots of contexts that\n     * pop up but are not used ever again. It also greatly slows down closure().\n     *\n     * <p>This cache makes a huge difference in memory and a little bit in speed.\n     * For the Java grammar on java.*, it dropped the memory requirements\n     * at the end from 25M to 16M. We don't store any of the full context\n     * graphs in the DFA because they are limited to local context only,\n     * but apparently there's a lot of repetition there as well. We optimize\n     * the config contexts before storing the config set in the DFA states\n     * by literally rebuilding them with cached subgraphs only.</p>\n     *\n     * <p>I tried a cache for use during closure operations, that was\n     * whacked after each adaptivePredict(). It cost a little bit\n     * more time I think and doesn't save on the overall footprint\n     * so it's not worth the complexity.</p>\n     */\n    this.atn = atn;\n    this.sharedContextCache = sharedContextCache;\n    return this;\n  }\n\n  getCachedContext(context) {\n    if (this.sharedContextCache === null) {\n      return context;\n    }\n    const visited = new HashMap();\n    return getCachedPredictionContext(context, this.sharedContextCache, visited);\n  }\n}\n\n// Must distinguish between missing edge and edge we know leads nowhere///\nATNSimulator.ERROR = new DFAState(0x7fffffff, new ATNConfigSet());\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { LexerIndexedCustomAction } from '../action/LexerIndexedCustomAction.js';\nimport { HashCode } from '../misc/HashCode.js';\n\nexport class LexerActionExecutor {\n  /**\n   * Represents an executor for a sequence of lexer actions which traversed during\n   * the matching operation of a lexer rule (token).\n   *\n   * <p>The executor tracks position information for position-dependent lexer actions\n   * efficiently, ensuring that actions appearing only at the end of the rule do\n   * not cause bloating of the {@link DFA} created for the lexer.</p>\n   */\n  constructor(lexerActions) {\n    this.lexerActions = lexerActions === null ? [] : lexerActions;\n    /**\n     * Caches the result of {@link //hashCode} since the hash code is an element\n     * of the performance-critical {@link LexerATNConfig//hashCode} operation\n     */\n    this.cachedHashCode = HashCode.hashStuff(lexerActions); // \"\".join([str(la) for la in\n    // lexerActions]))\n    return this;\n  }\n\n  /**\n   * Creates a {@link LexerActionExecutor} which executes the actions for\n   * the input {@code lexerActionExecutor} followed by a specified\n   * {@code lexerAction}.\n   *\n   * @param lexerActionExecutor The executor for actions already traversed by\n   * the lexer while matching a token within a particular\n   * {@link LexerATNConfig}. If this is {@code null}, the method behaves as\n   * though it were an empty executor.\n   * @param lexerAction The lexer action to execute after the actions\n   * specified in {@code lexerActionExecutor}.\n   *\n   * @return {LexerActionExecutor} A {@link LexerActionExecutor} for executing the combine actions\n   * of {@code lexerActionExecutor} and {@code lexerAction}.\n   */\n  static append(lexerActionExecutor, lexerAction) {\n    if (lexerActionExecutor === null) {\n      return new LexerActionExecutor([lexerAction]);\n    }\n    const lexerActions = lexerActionExecutor.lexerActions.concat([lexerAction]);\n    return new LexerActionExecutor(lexerActions);\n  }\n\n  /**\n   * Creates a {@link LexerActionExecutor} which encodes the current offset\n   * for position-dependent lexer actions.\n   *\n   * <p>Normally, when the executor encounters lexer actions where\n   * {@link LexerAction//isPositionDependent} returns {@code true}, it calls\n   * {@link IntStream//seek} on the input {@link CharStream} to set the input\n   * position to the <em>end</em> of the current token. This behavior provides\n   * for efficient DFA representation of lexer actions which appear at the end\n   * of a lexer rule, even when the lexer rule matches a variable number of\n   * characters.</p>\n   *\n   * <p>Prior to traversing a match transition in the ATN, the current offset\n   * from the token start index is assigned to all position-dependent lexer\n   * actions which have not already been assigned a fixed offset. By storing\n   * the offsets relative to the token start index, the DFA representation of\n   * lexer actions which appear in the middle of tokens remains efficient due\n   * to sharing among tokens of the same length, regardless of their absolute\n   * position in the input stream.</p>\n   *\n   * <p>If the current executor already has offsets assigned to all\n   * position-dependent lexer actions, the method returns {@code this}.</p>\n   *\n   * @param offset The current offset to assign to all position-dependent\n   * lexer actions which do not already have offsets assigned.\n   *\n   * @return {LexerActionExecutor} A {@link LexerActionExecutor} which stores input stream offsets\n   * for all position-dependent lexer actions.\n   */\n  fixOffsetBeforeMatch(offset) {\n    let updatedLexerActions = null;\n    for (let i = 0; i < this.lexerActions.length; i++) {\n      if (this.lexerActions[i].isPositionDependent && !(this.lexerActions[i] instanceof LexerIndexedCustomAction)) {\n        if (updatedLexerActions === null) {\n          updatedLexerActions = this.lexerActions.concat([]);\n        }\n        updatedLexerActions[i] = new LexerIndexedCustomAction(offset, this.lexerActions[i]);\n      }\n    }\n    if (updatedLexerActions === null) {\n      return this;\n    } else {\n      return new LexerActionExecutor(updatedLexerActions);\n    }\n  }\n\n  /**\n   * Execute the actions encapsulated by this executor within the context of a\n   * particular {@link Lexer}.\n   *\n   * <p>This method calls {@link IntStream//seek} to set the position of the\n   * {@code input} {@link CharStream} prior to calling\n   * {@link LexerAction//execute} on a position-dependent action. Before the\n   * method returns, the input position will be restored to the same position\n   * it was in when the method was invoked.</p>\n   *\n   * @param lexer The lexer instance.\n   * @param input The input stream which is the source for the current token.\n   * When this method is called, the current {@link IntStream//index} for\n   * {@code input} should be the start of the following token, i.e. 1\n   * character past the end of the current token.\n   * @param startIndex The token start index. This value may be passed to\n   * {@link IntStream//seek} to set the {@code input} position to the beginning\n   * of the token.\n   */\n  execute(lexer, input, startIndex) {\n    let requiresSeek = false;\n    const stopIndex = input.index;\n    try {\n      for (let i = 0; i < this.lexerActions.length; i++) {\n        let lexerAction = this.lexerActions[i];\n        if (lexerAction instanceof LexerIndexedCustomAction) {\n          const offset = lexerAction.offset;\n          input.seek(startIndex + offset);\n          lexerAction = lexerAction.action;\n          requiresSeek = startIndex + offset !== stopIndex;\n        } else if (lexerAction.isPositionDependent) {\n          input.seek(stopIndex);\n          requiresSeek = false;\n        }\n        lexerAction.execute(lexer);\n      }\n    } finally {\n      if (requiresSeek) {\n        input.seek(stopIndex);\n      }\n    }\n  }\n\n  hashCode() {\n    return this.cachedHashCode;\n  }\n\n  updateHashCode(hash) {\n    hash.update(this.cachedHashCode);\n  }\n\n  equals(other) {\n    if (this === other) {\n      return true;\n    } else if (!(other instanceof LexerActionExecutor)) {\n      return false;\n    } else if (this.cachedHashCode != other.cachedHashCode) {\n      return false;\n    } else if (this.lexerActions.length != other.lexerActions.length) {\n      return false;\n    } else {\n      const numActions = this.lexerActions.length;\n      for (let idx = 0; idx < numActions; ++idx) {\n        if (!this.lexerActions[idx].equals(other.lexerActions[idx])) {\n          return false;\n        }\n      }\n      return true;\n    }\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { DecisionState } from '../state/DecisionState.js';\nimport { ATNConfig } from './ATNConfig.js';\n\nexport class LexerATNConfig extends ATNConfig {\n  constructor(params, config) {\n    super(params, config);\n\n    // This is the backing field for {@link //getLexerActionExecutor}.\n    const lexerActionExecutor = params.lexerActionExecutor || null;\n    this.lexerActionExecutor = lexerActionExecutor || (config !== null ? config.lexerActionExecutor : null);\n    this.passedThroughNonGreedyDecision = config !== null ? this.checkNonGreedyDecision(config, this.state) : false;\n    this.hashCodeForConfigSet = LexerATNConfig.prototype.hashCode;\n    this.equalsForConfigSet = LexerATNConfig.prototype.equals;\n    return this;\n  }\n\n  updateHashCode(hash) {\n    hash.update(\n      this.state.stateNumber,\n      this.alt,\n      this.context,\n      this.semanticContext,\n      this.passedThroughNonGreedyDecision,\n      this.lexerActionExecutor,\n    );\n  }\n\n  equals(other) {\n    return (\n      this === other ||\n      (other instanceof LexerATNConfig &&\n        this.passedThroughNonGreedyDecision === other.passedThroughNonGreedyDecision &&\n        (this.lexerActionExecutor\n          ? this.lexerActionExecutor.equals(other.lexerActionExecutor)\n          : !other.lexerActionExecutor) &&\n        super.equals(other))\n    );\n  }\n\n  checkNonGreedyDecision(source, target) {\n    return source.passedThroughNonGreedyDecision || (target instanceof DecisionState && target.nonGreedy);\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * Provides an empty default implementation of {@link ANTLRErrorListener}. The\n * default implementation of each method does nothing, but can be overridden as\n * necessary.\n */\nexport class ErrorListener {\n  syntaxError(recognizer, offendingSymbol, line, column, msg, e) {}\n\n  reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {}\n\n  reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {}\n\n  reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs) {}\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { ErrorListener } from './ErrorListener.js';\n\n/**\n * {@inheritDoc}\n *\n * <p>\n * This implementation prints messages to {@link System//err} containing the\n * values of {@code line}, {@code charPositionInLine}, and {@code msg} using\n * the following format.</p>\n *\n * <pre>\n * line <em>line</em>:<em>charPositionInLine</em> <em>msg</em>\n * </pre>\n *\n */\nexport class ConsoleErrorListener extends ErrorListener {\n  constructor() {\n    super();\n  }\n\n  syntaxError(recognizer, offendingSymbol, line, column, msg, e) {\n    console.error('line ' + line + ':' + column + ' ' + msg);\n  }\n}\n\n/**\n * Provides a default instance of {@link ConsoleErrorListener}.\n */\nConsoleErrorListener.INSTANCE = new ConsoleErrorListener();\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { ErrorListener } from './ErrorListener.js';\n\nexport class ProxyErrorListener extends ErrorListener {\n  constructor(delegates) {\n    super();\n    if (delegates === null) {\n      throw 'delegates';\n    }\n    this.delegates = delegates;\n    return this;\n  }\n\n  syntaxError(recognizer, offendingSymbol, line, column, msg, e) {\n    this.delegates.map((d) => d.syntaxError(recognizer, offendingSymbol, line, column, msg, e));\n  }\n\n  reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n    this.delegates.map((d) => d.reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs));\n  }\n\n  reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n    this.delegates.map((d) =>\n      d.reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs),\n    );\n  }\n\n  reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n    this.delegates.map((d) => d.reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs));\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { Token } from './Token.js';\nimport { ConsoleErrorListener } from './error/ConsoleErrorListener.js';\nimport { ProxyErrorListener } from './error/ProxyErrorListener.js';\n\nexport class Recognizer {\n  constructor() {\n    this._listeners = [ConsoleErrorListener.INSTANCE];\n    this._interp = null;\n    this._stateNumber = -1;\n  }\n\n  get atn() {\n    return this._interp.atn;\n  }\n\n  get state() {\n    return this._stateNumber;\n  }\n\n  set state(state) {\n    this._stateNumber = state;\n  }\n\n  checkVersion(toolVersion) {\n    const runtimeVersion = '4.12.0';\n    if (runtimeVersion !== toolVersion) {\n      console.log('ANTLR runtime and generated code versions disagree: ' + runtimeVersion + '!=' + toolVersion);\n    }\n  }\n\n  addErrorListener(listener) {\n    this._listeners.push(listener);\n  }\n\n  removeErrorListeners() {\n    this._listeners = [];\n  }\n\n  getLiteralNames() {\n    return Object.getPrototypeOf(this).constructor.literalNames || [];\n  }\n\n  getSymbolicNames() {\n    return Object.getPrototypeOf(this).constructor.symbolicNames || [];\n  }\n\n  getTokenNames() {\n    if (!this.tokenNames) {\n      const literalNames = this.getLiteralNames();\n      const symbolicNames = this.getSymbolicNames();\n      const length = literalNames.length > symbolicNames.length ? literalNames.length : symbolicNames.length;\n      this.tokenNames = [];\n      for (let i = 0; i < length; i++) {\n        this.tokenNames[i] = literalNames[i] || symbolicNames[i] || '<INVALID';\n      }\n    }\n    return this.tokenNames;\n  }\n\n  getTokenTypeMap() {\n    const tokenNames = this.getTokenNames();\n    if (tokenNames === null) {\n      throw new Error('The current recognizer does not provide a list of token names.');\n    }\n    let result = this.tokenTypeMapCache[tokenNames];\n    if (result === undefined) {\n      // eslint-disable-next-line array-callback-return\n      result = tokenNames.reduce((o, k, i) => {\n        o[k] = i;\n      });\n      result.EOF = Token.EOF;\n      this.tokenTypeMapCache[tokenNames] = result;\n    }\n    return result;\n  }\n\n  /**\n   * Get a map from rule names to rule indexes.\n   * <p>Used for XPath and tree pattern compilation.</p>\n   */\n  getRuleIndexMap() {\n    const ruleNames = this.ruleNames;\n    if (ruleNames === null) {\n      throw new Error('The current recognizer does not provide a list of rule names.');\n    }\n    let result = this.ruleIndexMapCache[ruleNames]; // todo: should it be Recognizer.ruleIndexMapCache ?\n    if (result === undefined) {\n      // eslint-disable-next-line array-callback-return\n      result = ruleNames.reduce((o, k, i) => {\n        o[k] = i;\n      });\n      this.ruleIndexMapCache[ruleNames] = result;\n    }\n    return result;\n  }\n\n  getTokenType(tokenName) {\n    const ttype = this.getTokenTypeMap()[tokenName];\n    if (ttype !== undefined) {\n      return ttype;\n    } else {\n      return Token.INVALID_TYPE;\n    }\n  }\n\n  getSerializedATN() {\n    throw new Error('there is no serialized ATN');\n  }\n\n  // What is the error header, normally line/character position information?\n  getErrorHeader(e) {\n    const line = e.getOffendingToken().line;\n    const column = e.getOffendingToken().column;\n    return 'line ' + line + ':' + column;\n  }\n\n  /**\n   * How should a token be displayed in an error message? The default\n   * is to display just the text, but during development you might\n   * want to have a lot of information spit out.  Override in that case\n   * to use t.toString() (which, for CommonToken, dumps everything about\n   * the token). This is better than forcing you to override a method in\n   * your token objects because you don't have to go modify your lexer\n   * so that it creates a new Java type.\n   *\n   * @deprecated This method is not called by the ANTLR 4 Runtime. Specific\n   * implementations of {@link ANTLRErrorStrategy} may provide a similar\n   * feature when necessary. For example, see\n   * {@link DefaultErrorStrategy//getTokenErrorDisplay}. */\n  getTokenErrorDisplay(t) {\n    if (t === null) {\n      return '<no token>';\n    }\n    let s = t.text;\n    if (s === null) {\n      if (t.type === Token.EOF) {\n        s = '<EOF>';\n      } else {\n        s = '<' + t.type + '>';\n      }\n    }\n    s = s.replace('\\n', '\\\\n').replace('\\r', '\\\\r').replace('\\t', '\\\\t');\n    return \"'\" + s + \"'\";\n  }\n\n  getErrorListenerDispatch() {\n    return new ProxyErrorListener(this._listeners);\n  }\n\n  /**\n   * subclass needs to override these if there are sempreds or actions\n   * that the ATN interp needs to execute\n   */\n  sempred(localctx, ruleIndex, actionIndex) {\n    return true;\n  }\n\n  precpred(localctx, precedence) {\n    return true;\n  }\n}\n\nRecognizer.tokenTypeMapCache = {};\nRecognizer.ruleIndexMapCache = {};\n","import { Token } from './Token.js';\n\nexport class CommonToken extends Token {\n  constructor(source, type, channel, start, stop) {\n    super();\n    this.source = source !== undefined ? source : CommonToken.EMPTY_SOURCE;\n    this.type = type !== undefined ? type : null;\n    this.channel = channel !== undefined ? channel : Token.DEFAULT_CHANNEL;\n    this.start = start !== undefined ? start : -1;\n    this.stop = stop !== undefined ? stop : -1;\n    this.tokenIndex = -1;\n    if (this.source[0] !== null) {\n      this.line = source[0].line;\n      this.column = source[0].column;\n    } else {\n      this.column = -1;\n    }\n  }\n\n  get text() {\n    if (this._text !== null) {\n      return this._text;\n    }\n    const input = this.getInputStream();\n    if (input === null) {\n      return null;\n    }\n    const n = input.size;\n    if (this.start < n && this.stop < n) {\n      return input.getText(this.start, this.stop);\n    } else {\n      return '<EOF>';\n    }\n  }\n\n  set text(text) {\n    this._text = text;\n  }\n\n  /**\n   * Constructs a new {@link CommonToken} as a copy of another {@link Token}.\n   *\n   * <p>\n   * If {@code oldToken} is also a {@link CommonToken} instance, the newly\n   * constructed token will share a reference to the {@link //text} field and\n   * the {@link Pair} stored in {@link //source}. Otherwise, {@link //text} will\n   * be assigned the result of calling {@link //getText}, and {@link //source}\n   * will be constructed from the result of {@link Token//getTokenSource} and\n   * {@link Token//getInputStream}.</p>\n   *\n   * @param oldToken The token to copy.\n   */\n  clone() {\n    const t = new CommonToken(this.source, this.type, this.channel, this.start, this.stop);\n    t.tokenIndex = this.tokenIndex;\n    t.line = this.line;\n    t.column = this.column;\n    t.text = this.text;\n    return t;\n  }\n\n  cloneWithType(type) {\n    const t = new CommonToken(this.source, type, this.channel, this.start, this.stop);\n    t.tokenIndex = this.tokenIndex;\n    t.line = this.line;\n    t.column = this.column;\n    if (type === Token.EOF) t.text = '';\n    return t;\n  }\n\n  toString() {\n    let txt = this.text;\n    if (txt !== null) {\n      txt = txt.replace(/\\n/g, '\\\\n').replace(/\\r/g, '\\\\r').replace(/\\t/g, '\\\\t');\n    } else {\n      txt = '<no text>';\n    }\n    return (\n      '[@' +\n      this.tokenIndex +\n      ',' +\n      this.start +\n      ':' +\n      this.stop +\n      \"='\" +\n      txt +\n      \"',<\" +\n      this.type +\n      '>' +\n      (this.channel > 0 ? ',channel=' + this.channel : '') +\n      ',' +\n      this.line +\n      ':' +\n      this.column +\n      ']'\n    );\n  }\n}\n\n/**\n * An empty {@link Pair} which is used as the default value of\n * {@link //source} for tokens that do not have a source.\n */\nCommonToken.EMPTY_SOURCE = [null, null];\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { CommonToken } from './CommonToken.js';\n\nclass TokenFactory {}\n\n/**\n * This default implementation of {@link TokenFactory} creates\n * {@link CommonToken} objects.\n */\nexport class CommonTokenFactory extends TokenFactory {\n  constructor(copyText) {\n    super();\n    /**\n     * Indicates whether {@link CommonToken//setText} should be called after\n     * constructing tokens to explicitly set the text. This is useful for cases\n     * where the input stream might not be able to provide arbitrary substrings\n     * of text from the input after the lexer creates a token (e.g. the\n     * implementation of {@link CharStream//getText} in\n     * {@link UnbufferedCharStream} throws an\n     * {@link UnsupportedOperationException}). Explicitly setting the token text\n     * allows {@link Token//getText} to be called at any time regardless of the\n     * input stream implementation.\n     *\n     * <p>\n     * The default value is {@code false} to avoid the performance and memory\n     * overhead of copying text for every token unless explicitly requested.</p>\n     */\n    this.copyText = copyText === undefined ? false : copyText;\n  }\n\n  create(source, type, text, channel, start, stop, line, column) {\n    const t = new CommonToken(source, type, channel, start, stop);\n    t.line = line;\n    t.column = column;\n    if (text !== null) {\n      t.text = text;\n    } else if (this.copyText && source[1] !== null) {\n      t.text = source[1].getText(start, stop);\n    }\n    return t;\n  }\n\n  createThin(type, text) {\n    const t = new CommonToken(null, type);\n    t.text = text;\n    return t;\n  }\n}\n\n/**\n * The default {@link CommonTokenFactory} instance.\n *\n * <p>\n * This token factory does not explicitly copy token text when constructing\n * tokens.</p>\n */\nCommonTokenFactory.DEFAULT = new CommonTokenFactory();\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * The root of the ANTLR exception hierarchy. In general, ANTLR tracks just\n *  3 kinds of errors: prediction errors, failed predicate errors, and\n *  mismatched input errors. In each case, the parser knows where it is\n *  in the input, where it is in the ATN, the rule invocation stack,\n *  and what kind of problem occurred.\n */\n\nexport class RecognitionException extends Error {\n  constructor(params) {\n    super(params.message);\n    if (Error.captureStackTrace) Error.captureStackTrace(this, RecognitionException);\n    this.message = params.message;\n    this.recognizer = params.recognizer;\n    this.input = params.input;\n    this.ctx = params.ctx;\n    /**\n     * The current {@link Token} when an error occurred. Since not all streams\n     * support accessing symbols by index, we have to track the {@link Token}\n     * instance itself\n     */\n    this.offendingToken = null;\n    /**\n     * Get the ATN state number the parser was in at the time the error\n     * occurred. For {@link NoViableAltException} and\n     * {@link LexerNoViableAltException} exceptions, this is the\n     * {@link DecisionState} number. For others, it is the state whose outgoing\n     * edge we couldn't match.\n     */\n    this.offendingState = -1;\n    if (this.recognizer !== null) {\n      this.offendingState = this.recognizer.state;\n    }\n  }\n\n  /**\n   * Gets the set of input symbols which could potentially follow the\n   * previously matched symbol at the time this exception was thrown.\n   *\n   * <p>If the set of expected tokens is not known and could not be computed,\n   * this method returns {@code null}.</p>\n   *\n   * @return The set of token types that could potentially follow the current\n   * state in the ATN, or {@code null} if the information is not available.\n   */\n  getExpectedTokens() {\n    if (this.recognizer !== null) {\n      return this.recognizer.atn.getExpectedTokens(this.offendingState, this.ctx);\n    } else {\n      return null;\n    }\n  }\n\n  // <p>If the state number is not known, this method returns -1.</p>\n  toString() {\n    return this.message;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { RecognitionException } from './RecognitionException.js';\n\n/**\n * Indicates that the parser could not decide which of two or more paths\n * to take based upon the remaining input. It tracks the starting token\n * of the offending input and also knows where the parser was\n * in the various paths when the error. Reported by reportNoViableAlternative()\n */\n\nexport class NoViableAltException extends RecognitionException {\n  constructor(recognizer, input, startToken, offendingToken, deadEndConfigs, ctx) {\n    ctx = ctx || recognizer._ctx;\n    offendingToken = offendingToken || recognizer.getCurrentToken();\n    startToken = startToken || recognizer.getCurrentToken();\n    input = input || recognizer.getInputStream();\n    super({ message: '', recognizer: recognizer, input: input, ctx: ctx });\n    // Which configurations did we try at input.index() that couldn't match\n    // input.LT(1)?//\n    this.deadEndConfigs = deadEndConfigs;\n    // The token object at the start index; the input stream might\n    // not be buffering tokens so get a reference to it. (At the\n    // time the error occurred, of course the stream needs to keep a\n    // buffer all of the tokens but later we might not have access to those.)\n    this.startToken = startToken;\n    this.offendingToken = offendingToken;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { Interval } from '../misc/Interval.js';\nimport { RecognitionException } from './RecognitionException.js';\n\nexport class LexerNoViableAltException extends RecognitionException {\n  constructor(lexer, input, startIndex, deadEndConfigs) {\n    super({ message: '', recognizer: lexer, input: input, ctx: null });\n    this.startIndex = startIndex;\n    this.deadEndConfigs = deadEndConfigs;\n  }\n\n  toString() {\n    let symbol = '';\n    if (this.startIndex >= 0 && this.startIndex < this.input.size) {\n      symbol = this.input.getText(new Interval(this.startIndex, this.startIndex));\n    }\n    return 'LexerNoViableAltException' + symbol;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { RecognitionException } from './RecognitionException.js';\n\n/**\n * This signifies any kind of mismatched input exceptions such as\n * when the current input does not match the expected token.\n */\nexport class InputMismatchException extends RecognitionException {\n  constructor(recognizer) {\n    super({ message: '', recognizer: recognizer, input: recognizer.getInputStream(), ctx: recognizer._ctx });\n    this.offendingToken = recognizer.getCurrentToken();\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { PredicateTransition } from '../transition/PredicateTransition.js';\nimport { RecognitionException } from './RecognitionException.js';\n\n/**\n * A semantic predicate failed during validation. Validation of predicates\n * occurs when normally parsing the alternative just like matching a token.\n * Disambiguating predicate evaluation occurs when we test a predicate during\n * prediction.\n */\nexport class FailedPredicateException extends RecognitionException {\n  constructor(recognizer, predicate, message) {\n    super({\n      message: formatMessage(predicate, message || null),\n      recognizer: recognizer,\n      input: recognizer.getInputStream(),\n      ctx: recognizer._ctx,\n    });\n    const s = recognizer._interp.atn.states[recognizer.state];\n    const trans = s.transitions[0];\n    if (trans instanceof PredicateTransition) {\n      this.ruleIndex = trans.ruleIndex;\n      this.predicateIndex = trans.predIndex;\n    } else {\n      this.ruleIndex = 0;\n      this.predicateIndex = 0;\n    }\n    this.predicate = predicate;\n    this.offendingToken = recognizer.getCurrentToken();\n  }\n}\n\nfunction formatMessage(predicate, message) {\n  if (message !== null) {\n    return message;\n  } else {\n    return 'failed predicate: {' + predicate + '}?';\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { ErrorListener } from './ErrorListener.js';\nimport { Interval } from '../misc/Interval.js';\nimport { BitSet } from '../misc/BitSet.js';\n\n/**\n * This implementation of {@link ANTLRErrorListener} can be used to identify\n *  certain potential correctness and performance problems in grammars. \"Reports\"\n *  are made by calling {@link Parser//notifyErrorListeners} with the appropriate\n *  message.\n *\n *  <ul>\n *  <li><b>Ambiguities</b>: These are cases where more than one path through the\n *  grammar can match the input.</li>\n *  <li><b>Weak context sensitivity</b>: These are cases where full-context\n *  prediction resolved an SLL conflict to a unique alternative which equaled the\n *  minimum alternative of the SLL conflict.</li>\n *  <li><b>Strong (forced) context sensitivity</b>: These are cases where the\n *  full-context prediction resolved an SLL conflict to a unique alternative,\n *  <em>and</em> the minimum alternative of the SLL conflict was found to not be\n *  a truly viable alternative. Two-stage parsing cannot be used for inputs where\n *  this situation occurs.</li>\n *  </ul>\n */\nexport class DiagnosticErrorListener extends ErrorListener {\n  constructor(exactOnly) {\n    super();\n    exactOnly = exactOnly || true;\n    // whether all ambiguities or only exact ambiguities are reported.\n    this.exactOnly = exactOnly;\n  }\n\n  reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n    if (this.exactOnly && !exact) {\n      return;\n    }\n    const msg =\n      'reportAmbiguity d=' +\n      this.getDecisionDescription(recognizer, dfa) +\n      ': ambigAlts=' +\n      this.getConflictingAlts(ambigAlts, configs) +\n      \", input='\" +\n      recognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) +\n      \"'\";\n    recognizer.notifyErrorListeners(msg);\n  }\n\n  reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n    const msg =\n      'reportAttemptingFullContext d=' +\n      this.getDecisionDescription(recognizer, dfa) +\n      \", input='\" +\n      recognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) +\n      \"'\";\n    recognizer.notifyErrorListeners(msg);\n  }\n\n  reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n    const msg =\n      'reportContextSensitivity d=' +\n      this.getDecisionDescription(recognizer, dfa) +\n      \", input='\" +\n      recognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) +\n      \"'\";\n    recognizer.notifyErrorListeners(msg);\n  }\n\n  getDecisionDescription(recognizer, dfa) {\n    const decision = dfa.decision;\n    const ruleIndex = dfa.atnStartState.ruleIndex;\n\n    const ruleNames = recognizer.ruleNames;\n    if (ruleIndex < 0 || ruleIndex >= ruleNames.length) {\n      return '' + decision;\n    }\n    const ruleName = ruleNames[ruleIndex] || null;\n    if (ruleName === null || ruleName.length === 0) {\n      return '' + decision;\n    }\n    return `${decision} (${ruleName})`;\n  }\n\n  /**\n   * Computes the set of conflicting or ambiguous alternatives from a\n   * configuration set, if that information was not already provided by the\n   * parser.\n   *\n   * @param reportedAlts The set of conflicting or ambiguous alternatives, as\n   * reported by the parser.\n   * @param configs The conflicting or ambiguous configuration set.\n   * @return Returns {@code reportedAlts} if it is not {@code null}, otherwise\n   * returns the set of alternatives represented in {@code configs}.\n   */\n  getConflictingAlts(reportedAlts, configs) {\n    if (reportedAlts !== null) {\n      return reportedAlts;\n    }\n    const result = new BitSet();\n    for (let i = 0; i < configs.items.length; i++) {\n      result.add(configs.items[i].alt);\n    }\n    return `{${result.values().join(', ')}}`;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexport class ParseCancellationException extends Error {\n  constructor() {\n    super();\n    Error.captureStackTrace(this, ParseCancellationException);\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nexport class ErrorStrategy {\n  reset(recognizer) {}\n\n  recoverInline(recognizer) {}\n\n  recover(recognizer, e) {}\n\n  sync(recognizer) {}\n\n  inErrorRecoveryMode(recognizer) {}\n\n  reportError(recognizer) {}\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { FailedPredicateException } from './FailedPredicateException.js';\nimport { InputMismatchException } from './InputMismatchException.js';\nimport { NoViableAltException } from './NoViableAltException.js';\nimport { ATNState } from '../state/ATNState.js';\nimport { Token } from '../Token.js';\nimport { Interval } from '../misc/Interval.js';\nimport { IntervalSet } from '../misc/IntervalSet.js';\nimport { ErrorStrategy } from './ErrorStrategy.js';\n\n/**\n * This is the default implementation of {@link ANTLRErrorStrategy} used for\n * error reporting and recovery in ANTLR parsers.\n */\nexport class DefaultErrorStrategy extends ErrorStrategy {\n  constructor() {\n    super();\n    /**\n     * Indicates whether the error strategy is currently \"recovering from an\n     * error\". This is used to suppress reporting multiple error messages while\n     * attempting to recover from a detected syntax error.\n     *\n     * @see //inErrorRecoveryMode\n     */\n    this.errorRecoveryMode = false;\n\n    /**\n     * The index into the input stream where the last error occurred.\n     * This is used to prevent infinite loops where an error is found\n     * but no token is consumed during recovery...another error is found,\n     * ad nauseum. This is a failsafe mechanism to guarantee that at least\n     * one token/tree node is consumed for two errors.\n     */\n    this.lastErrorIndex = -1;\n    this.lastErrorStates = null;\n    this.nextTokensContext = null;\n    this.nextTokenState = 0;\n  }\n\n  /**\n   * <p>The default implementation simply calls {@link //endErrorCondition} to\n   * ensure that the handler is not in error recovery mode.</p>\n   */\n  reset(recognizer) {\n    this.endErrorCondition(recognizer);\n  }\n\n  /**\n   * This method is called to enter error recovery mode when a recognition\n   * exception is reported.\n   *\n   * @param recognizer the parser instance\n   */\n  beginErrorCondition(recognizer) {\n    this.errorRecoveryMode = true;\n  }\n\n  inErrorRecoveryMode(recognizer) {\n    return this.errorRecoveryMode;\n  }\n\n  /**\n   * This method is called to leave error recovery mode after recovering from\n   * a recognition exception.\n   * @param recognizer\n   */\n  endErrorCondition(recognizer) {\n    this.errorRecoveryMode = false;\n    this.lastErrorStates = null;\n    this.lastErrorIndex = -1;\n  }\n\n  /**\n   * {@inheritDoc}\n   * <p>The default implementation simply calls {@link //endErrorCondition}.</p>\n   */\n  reportMatch(recognizer) {\n    this.endErrorCondition(recognizer);\n  }\n\n  /**\n   * {@inheritDoc}\n   *\n   * <p>The default implementation returns immediately if the handler is already\n   * in error recovery mode. Otherwise, it calls {@link //beginErrorCondition}\n   * and dispatches the reporting task based on the runtime type of {@code e}\n   * according to the following table.</p>\n   *\n   * <ul>\n   * <li>{@link NoViableAltException}: Dispatches the call to\n   * {@link //reportNoViableAlternative}</li>\n   * <li>{@link InputMismatchException}: Dispatches the call to\n   * {@link //reportInputMismatch}</li>\n   * <li>{@link FailedPredicateException}: Dispatches the call to\n   * {@link //reportFailedPredicate}</li>\n   * <li>All other types: calls {@link Parser//notifyErrorListeners} to report\n   * the exception</li>\n   * </ul>\n   */\n  reportError(recognizer, e) {\n    // if we've already reported an error and have not matched a token\n    // yet successfully, don't report any errors.\n    if (this.inErrorRecoveryMode(recognizer)) {\n      return; // don't report spurious errors\n    }\n    this.beginErrorCondition(recognizer);\n    if (e instanceof NoViableAltException) {\n      this.reportNoViableAlternative(recognizer, e);\n    } else if (e instanceof InputMismatchException) {\n      this.reportInputMismatch(recognizer, e);\n    } else if (e instanceof FailedPredicateException) {\n      this.reportFailedPredicate(recognizer, e);\n    } else {\n      console.log('unknown recognition error type: ' + e.constructor.name);\n      console.log(e.stack);\n      recognizer.notifyErrorListeners(e.getOffendingToken(), e.getMessage(), e);\n    }\n  }\n\n  /**\n   *\n   * {@inheritDoc}\n   *\n   * <p>The default implementation resynchronizes the parser by consuming tokens\n   * until we find one in the resynchronization set--loosely the set of tokens\n   * that can follow the current rule.</p>\n   *\n   */\n  recover(recognizer, e) {\n    if (\n      this.lastErrorIndex === recognizer.getInputStream().index &&\n      this.lastErrorStates !== null &&\n      this.lastErrorStates.indexOf(recognizer.state) >= 0\n    ) {\n      // uh oh, another error at same token index and previously-visited\n      // state in ATN; must be a case where LT(1) is in the recovery\n      // token set so nothing got consumed. Consume a single token\n      // at least to prevent an infinite loop; this is a failsafe.\n      recognizer.consume();\n    }\n    this.lastErrorIndex = recognizer._input.index;\n    if (this.lastErrorStates === null) {\n      this.lastErrorStates = [];\n    }\n    this.lastErrorStates.push(recognizer.state);\n    const followSet = this.getErrorRecoverySet(recognizer);\n    this.consumeUntil(recognizer, followSet);\n  }\n\n  /**\n   * The default implementation of {@link ANTLRErrorStrategy//sync} makes sure\n   * that the current lookahead symbol is consistent with what were expecting\n   * at this point in the ATN. You can call this anytime but ANTLR only\n   * generates code to check before subrules/loops and each iteration.\n   *\n   * <p>Implements Jim Idle's magic sync mechanism in closures and optional\n   * subrules. E.g.,</p>\n   *\n   * <pre>\n   * a : sync ( stuff sync )* ;\n   * sync : {consume to what can follow sync} ;\n   * </pre>\n   *\n   * At the start of a sub rule upon error, {@link //sync} performs single\n   * token deletion, if possible. If it can't do that, it bails on the current\n   * rule and uses the default error recovery, which consumes until the\n   * resynchronization set of the current rule.\n   *\n   * <p>If the sub rule is optional ({@code (...)?}, {@code (...)*}, or block\n   * with an empty alternative), then the expected set includes what follows\n   * the subrule.</p>\n   *\n   * <p>During loop iteration, it consumes until it sees a token that can start a\n   * sub rule or what follows loop. Yes, that is pretty aggressive. We opt to\n   * stay in the loop as long as possible.</p>\n   *\n   * <p><strong>ORIGINS</strong></p>\n   *\n   * <p>Previous versions of ANTLR did a poor job of their recovery within loops.\n   * A single mismatch token or missing token would force the parser to bail\n   * out of the entire rules surrounding the loop. So, for rule</p>\n   *\n   * <pre>\n   * classDef : 'class' ID '{' member* '}'\n   * </pre>\n   *\n   * input with an extra token between members would force the parser to\n   * consume until it found the next class definition rather than the next\n   * member definition of the current class.\n   *\n   * <p>This functionality cost a little bit of effort because the parser has to\n   * compare token set at the start of the loop and at each iteration. If for\n   * some reason speed is suffering for you, you can turn off this\n   * functionality by simply overriding this method as a blank { }.</p>\n   *\n   */\n  sync(recognizer) {\n    // If already recovering, don't try to sync\n    if (this.inErrorRecoveryMode(recognizer)) {\n      return;\n    }\n    const s = recognizer._interp.atn.states[recognizer.state];\n    const la = recognizer.getTokenStream().LA(1);\n    // try cheaper subset first; might get lucky. seems to shave a wee bit off\n    const nextTokens = recognizer.atn.nextTokens(s);\n    if (nextTokens.contains(la)) {\n      this.nextTokensContext = null;\n      this.nextTokenState = ATNState.INVALID_STATE_NUMBER;\n      return;\n    } else if (nextTokens.contains(Token.EPSILON)) {\n      if (this.nextTokensContext === null) {\n        // It's possible the next token won't match information tracked\n        // by sync is restricted for performance.\n        this.nextTokensContext = recognizer._ctx;\n        this.nextTokensState = recognizer._stateNumber;\n      }\n      return;\n    }\n    switch (s.stateType) {\n      case ATNState.BLOCK_START:\n      case ATNState.STAR_BLOCK_START:\n      case ATNState.PLUS_BLOCK_START:\n      case ATNState.STAR_LOOP_ENTRY:\n        // report error and recover if possible\n        if (this.singleTokenDeletion(recognizer) !== null) {\n          return;\n        } else {\n          throw new InputMismatchException(recognizer);\n        }\n      case ATNState.PLUS_LOOP_BACK:\n      case ATNState.STAR_LOOP_BACK:\n        {\n          this.reportUnwantedToken(recognizer);\n          const expecting = new IntervalSet();\n          expecting.addSet(recognizer.getExpectedTokens());\n          const whatFollowsLoopIterationOrRule = expecting.addSet(this.getErrorRecoverySet(recognizer));\n          this.consumeUntil(recognizer, whatFollowsLoopIterationOrRule);\n        }\n        break;\n      default:\n      // do nothing if we can't identify the exact kind of ATN state\n    }\n  }\n\n  /**\n   * This is called by {@link //reportError} when the exception is a\n   * {@link NoViableAltException}.\n   *\n   * @see //reportError\n   *\n   * @param recognizer the parser instance\n   * @param e the recognition exception\n   */\n  reportNoViableAlternative(recognizer, e) {\n    const tokens = recognizer.getTokenStream();\n    let input;\n    if (tokens !== null) {\n      if (e.startToken.type === Token.EOF) {\n        input = '<EOF>';\n      } else {\n        input = tokens.getText(new Interval(e.startToken.tokenIndex, e.offendingToken.tokenIndex));\n      }\n    } else {\n      input = '<unknown input>';\n    }\n    const msg = 'no viable alternative at input ' + this.escapeWSAndQuote(input);\n    recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n  }\n\n  /**\n   * This is called by {@link //reportError} when the exception is an\n   * {@link InputMismatchException}.\n   *\n   * @see //reportError\n   *\n   * @param recognizer the parser instance\n   * @param e the recognition exception\n   */\n  reportInputMismatch(recognizer, e) {\n    const msg =\n      'mismatched input ' +\n      this.getTokenErrorDisplay(e.offendingToken) +\n      ' expecting ' +\n      e.getExpectedTokens().toString(recognizer.literalNames, recognizer.symbolicNames);\n    recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n  }\n\n  /**\n   * This is called by {@link //reportError} when the exception is a\n   * {@link FailedPredicateException}.\n   *\n   * @see //reportError\n   *\n   * @param recognizer the parser instance\n   * @param e the recognition exception\n   */\n  reportFailedPredicate(recognizer, e) {\n    const ruleName = recognizer.ruleNames[recognizer._ctx.ruleIndex];\n    const msg = 'rule ' + ruleName + ' ' + e.message;\n    recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n  }\n\n  /**\n   * This method is called to report a syntax error which requires the removal\n   * of a token from the input stream. At the time this method is called, the\n   * erroneous symbol is current {@code LT(1)} symbol and has not yet been\n   * removed from the input stream. When this method returns,\n   * {@code recognizer} is in error recovery mode.\n   *\n   * <p>This method is called when {@link //singleTokenDeletion} identifies\n   * single-token deletion as a viable recovery strategy for a mismatched\n   * input error.</p>\n   *\n   * <p>The default implementation simply returns if the handler is already in\n   * error recovery mode. Otherwise, it calls {@link //beginErrorCondition} to\n   * enter error recovery mode, followed by calling\n   * {@link Parser//notifyErrorListeners}.</p>\n   *\n   * @param recognizer the parser instance\n   *\n   */\n  reportUnwantedToken(recognizer) {\n    if (this.inErrorRecoveryMode(recognizer)) {\n      return;\n    }\n    this.beginErrorCondition(recognizer);\n    const t = recognizer.getCurrentToken();\n    const tokenName = this.getTokenErrorDisplay(t);\n    const expecting = this.getExpectedTokens(recognizer);\n    const msg =\n      'extraneous input ' +\n      tokenName +\n      ' expecting ' +\n      expecting.toString(recognizer.literalNames, recognizer.symbolicNames);\n    recognizer.notifyErrorListeners(msg, t, null);\n  }\n\n  /**\n   * This method is called to report a syntax error which requires the\n   * insertion of a missing token into the input stream. At the time this\n   * method is called, the missing token has not yet been inserted. When this\n   * method returns, {@code recognizer} is in error recovery mode.\n   *\n   * <p>This method is called when {@link //singleTokenInsertion} identifies\n   * single-token insertion as a viable recovery strategy for a mismatched\n   * input error.</p>\n   *\n   * <p>The default implementation simply returns if the handler is already in\n   * error recovery mode. Otherwise, it calls {@link //beginErrorCondition} to\n   * enter error recovery mode, followed by calling\n   * {@link Parser//notifyErrorListeners}.</p>\n   *\n   * @param recognizer the parser instance\n   */\n  reportMissingToken(recognizer) {\n    if (this.inErrorRecoveryMode(recognizer)) {\n      return;\n    }\n    this.beginErrorCondition(recognizer);\n    const t = recognizer.getCurrentToken();\n    const expecting = this.getExpectedTokens(recognizer);\n    const msg =\n      'missing ' +\n      expecting.toString(recognizer.literalNames, recognizer.symbolicNames) +\n      ' at ' +\n      this.getTokenErrorDisplay(t);\n    recognizer.notifyErrorListeners(msg, t, null);\n  }\n\n  /**\n   * <p>The default implementation attempts to recover from the mismatched input\n   * by using single token insertion and deletion as described below. If the\n   * recovery attempt fails, this method throws an\n   * {@link InputMismatchException}.</p>\n   *\n   * <p><strong>EXTRA TOKEN</strong> (single token deletion)</p>\n   *\n   * <p>{@code LA(1)} is not what we are looking for. If {@code LA(2)} has the\n   * right token, however, then assume {@code LA(1)} is some extra spurious\n   * token and delete it. Then consume and return the next token (which was\n   * the {@code LA(2)} token) as the successful result of the match operation.</p>\n   *\n   * <p>This recovery strategy is implemented by {@link\n   * //singleTokenDeletion}.</p>\n   *\n   * <p><strong>MISSING TOKEN</strong> (single token insertion)</p>\n   *\n   * <p>If current token (at {@code LA(1)}) is consistent with what could come\n   * after the expected {@code LA(1)} token, then assume the token is missing\n   * and use the parser's {@link TokenFactory} to create it on the fly. The\n   * \"insertion\" is performed by returning the created token as the successful\n   * result of the match operation.</p>\n   *\n   * <p>This recovery strategy is implemented by {@link\n   * //singleTokenInsertion}.</p>\n   *\n   * <p><strong>EXAMPLE</strong></p>\n   *\n   * <p>For example, Input {@code i=(3;} is clearly missing the {@code ')'}. When\n   * the parser returns from the nested call to {@code expr}, it will have\n   * call chain:</p>\n   *\n   * <pre>\n   * stat &rarr; expr &rarr; atom\n   * </pre>\n   *\n   * and it will be trying to match the {@code ')'} at this point in the\n   * derivation:\n   *\n   * <pre>\n   * =&gt; ID '=' '(' INT ')' ('+' atom)* ';'\n   * ^\n   * </pre>\n   *\n   * The attempt to match {@code ')'} will fail when it sees {@code ';'} and\n   * call {@link //recoverInline}. To recover, it sees that {@code LA(1)==';'}\n   * is in the set of tokens that can follow the {@code ')'} token reference\n   * in rule {@code atom}. It can assume that you forgot the {@code ')'}.\n   */\n  recoverInline(recognizer) {\n    // SINGLE TOKEN DELETION\n    const matchedSymbol = this.singleTokenDeletion(recognizer);\n    if (matchedSymbol !== null) {\n      // we have deleted the extra token.\n      // now, move past ttype token as if all were ok\n      recognizer.consume();\n      return matchedSymbol;\n    }\n    // SINGLE TOKEN INSERTION\n    if (this.singleTokenInsertion(recognizer)) {\n      return this.getMissingSymbol(recognizer);\n    }\n    // even that didn't work; must throw the exception\n    throw new InputMismatchException(recognizer);\n  }\n\n  /**\n   * This method implements the single-token insertion inline error recovery\n   * strategy. It is called by {@link //recoverInline} if the single-token\n   * deletion strategy fails to recover from the mismatched input. If this\n   * method returns {@code true}, {@code recognizer} will be in error recovery\n   * mode.\n   *\n   * <p>This method determines whether or not single-token insertion is viable by\n   * checking if the {@code LA(1)} input symbol could be successfully matched\n   * if it were instead the {@code LA(2)} symbol. If this method returns\n   * {@code true}, the caller is responsible for creating and inserting a\n   * token with the correct type to produce this behavior.</p>\n   *\n   * @param recognizer the parser instance\n   * @return {@code true} if single-token insertion is a viable recovery\n   * strategy for the current mismatched input, otherwise {@code false}\n   */\n  singleTokenInsertion(recognizer) {\n    const currentSymbolType = recognizer.getTokenStream().LA(1);\n    // if current token is consistent with what could come after current\n    // ATN state, then we know we're missing a token; error recovery\n    // is free to conjure up and insert the missing token\n    const atn = recognizer._interp.atn;\n    const currentState = atn.states[recognizer.state];\n    const next = currentState.transitions[0].target;\n    const expectingAtLL2 = atn.nextTokens(next, recognizer._ctx);\n    if (expectingAtLL2.contains(currentSymbolType)) {\n      this.reportMissingToken(recognizer);\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n  /**\n   * This method implements the single-token deletion inline error recovery\n   * strategy. It is called by {@link //recoverInline} to attempt to recover\n   * from mismatched input. If this method returns null, the parser and error\n   * handler state will not have changed. If this method returns non-null,\n   * {@code recognizer} will <em>not</em> be in error recovery mode since the\n   * returned token was a successful match.\n   *\n   * <p>If the single-token deletion is successful, this method calls\n   * {@link //reportUnwantedToken} to report the error, followed by\n   * {@link Parser//consume} to actually \"delete\" the extraneous token. Then,\n   * before returning {@link //reportMatch} is called to signal a successful\n   * match.</p>\n   *\n   * @param recognizer the parser instance\n   * @return the successfully matched {@link Token} instance if single-token\n   * deletion successfully recovers from the mismatched input, otherwise\n   * {@code null}\n   */\n  singleTokenDeletion(recognizer) {\n    const nextTokenType = recognizer.getTokenStream().LA(2);\n    const expecting = this.getExpectedTokens(recognizer);\n    if (expecting.contains(nextTokenType)) {\n      this.reportUnwantedToken(recognizer);\n      // print(\"recoverFromMismatchedToken deleting \" \\\n      // + str(recognizer.getTokenStream().LT(1)) \\\n      // + \" since \" + str(recognizer.getTokenStream().LT(2)) \\\n      // + \" is what we want\", file=sys.stderr)\n      recognizer.consume(); // simply delete extra token\n      // we want to return the token we're actually matching\n      const matchedSymbol = recognizer.getCurrentToken();\n      this.reportMatch(recognizer); // we know current token is correct\n      return matchedSymbol;\n    } else {\n      return null;\n    }\n  }\n\n  /**\n   * Conjure up a missing token during error recovery.\n   *\n   * The recognizer attempts to recover from single missing\n   * symbols. But, actions might refer to that missing symbol.\n   * For example, x=ID {f($x);}. The action clearly assumes\n   * that there has been an identifier matched previously and that\n   * $x points at that token. If that token is missing, but\n   * the next token in the stream is what we want we assume that\n   * this token is missing and we keep going. Because we\n   * have to return some token to replace the missing token,\n   * we have to conjure one up. This method gives the user control\n   * over the tokens returned for missing tokens. Mostly,\n   * you will want to create something special for identifier\n   * tokens. For literals such as '{' and ',', the default\n   * action in the parser or tree parser works. It simply creates\n   * a CommonToken of the appropriate type. The text will be the token.\n   * If you change what tokens must be created by the lexer,\n   * override this method to create the appropriate tokens.\n   *\n   */\n  getMissingSymbol(recognizer) {\n    const currentSymbol = recognizer.getCurrentToken();\n    const expecting = this.getExpectedTokens(recognizer);\n    const expectedTokenType = expecting.first(); // get any element\n    let tokenText;\n    if (expectedTokenType === Token.EOF) {\n      tokenText = '<missing EOF>';\n    } else {\n      tokenText = '<missing ' + recognizer.literalNames[expectedTokenType] + '>';\n    }\n    let current = currentSymbol;\n    const lookback = recognizer.getTokenStream().LT(-1);\n    if (current.type === Token.EOF && lookback !== null) {\n      current = lookback;\n    }\n    return recognizer\n      .getTokenFactory()\n      .create(\n        current.source,\n        expectedTokenType,\n        tokenText,\n        Token.DEFAULT_CHANNEL,\n        -1,\n        -1,\n        current.line,\n        current.column,\n      );\n  }\n\n  getExpectedTokens(recognizer) {\n    return recognizer.getExpectedTokens();\n  }\n\n  /**\n   * How should a token be displayed in an error message? The default\n   * is to display just the text, but during development you might\n   * want to have a lot of information spit out. Override in that case\n   * to use t.toString() (which, for CommonToken, dumps everything about\n   * the token). This is better than forcing you to override a method in\n   * your token objects because you don't have to go modify your lexer\n   * so that it creates a new Java type.\n   */\n  getTokenErrorDisplay(t) {\n    if (t === null) {\n      return '<no token>';\n    }\n    let s = t.text;\n    if (s === null) {\n      if (t.type === Token.EOF) {\n        s = '<EOF>';\n      } else {\n        s = '<' + t.type + '>';\n      }\n    }\n    return this.escapeWSAndQuote(s);\n  }\n\n  escapeWSAndQuote(s) {\n    s = s.replace(/\\n/g, '\\\\n');\n    s = s.replace(/\\r/g, '\\\\r');\n    s = s.replace(/\\t/g, '\\\\t');\n    return \"'\" + s + \"'\";\n  }\n\n  /**\n   * Compute the error recovery set for the current rule. During\n   * rule invocation, the parser pushes the set of tokens that can\n   * follow that rule reference on the stack; this amounts to\n   * computing FIRST of what follows the rule reference in the\n   * enclosing rule. See LinearApproximator.FIRST().\n   * This local follow set only includes tokens\n   * from within the rule; i.e., the FIRST computation done by\n   * ANTLR stops at the end of a rule.\n   *\n   * EXAMPLE\n   *\n   * When you find a \"no viable alt exception\", the input is not\n   * consistent with any of the alternatives for rule r. The best\n   * thing to do is to consume tokens until you see something that\n   * can legally follow a call to r//or* any rule that called r.\n   * You don't want the exact set of viable next tokens because the\n   * input might just be missing a token--you might consume the\n   * rest of the input looking for one of the missing tokens.\n   *\n   * Consider grammar:\n   *\n   * a : '[' b ']'\n   * | '(' b ')'\n   * ;\n   * b : c '^' INT ;\n   * c : ID\n   * | INT\n   * ;\n   *\n   * At each rule invocation, the set of tokens that could follow\n   * that rule is pushed on a stack. Here are the various\n   * context-sensitive follow sets:\n   *\n   * FOLLOW(b1_in_a) = FIRST(']') = ']'\n   * FOLLOW(b2_in_a) = FIRST(')') = ')'\n   * FOLLOW(c_in_b) = FIRST('^') = '^'\n   *\n   * Upon erroneous input \"[]\", the call chain is\n   *\n   * a -> b -> c\n   *\n   * and, hence, the follow context stack is:\n   *\n   * depth follow set start of rule execution\n   * 0 <EOF> a (from main())\n   * 1 ']' b\n   * 2 '^' c\n   *\n   * Notice that ')' is not included, because b would have to have\n   * been called from a different context in rule a for ')' to be\n   * included.\n   *\n   * For error recovery, we cannot consider FOLLOW(c)\n   * (context-sensitive or otherwise). We need the combined set of\n   * all context-sensitive FOLLOW sets--the set of all tokens that\n   * could follow any reference in the call chain. We need to\n   * resync to one of those tokens. Note that FOLLOW(c)='^' and if\n   * we resync'd to that token, we'd consume until EOF. We need to\n   * sync to context-sensitive FOLLOWs for a, b, and c: {']','^'}.\n   * In this case, for input \"[]\", LA(1) is ']' and in the set, so we would\n   * not consume anything. After printing an error, rule c would\n   * return normally. Rule b would not find the required '^' though.\n   * At this point, it gets a mismatched token error and throws an\n   * exception (since LA(1) is not in the viable following token\n   * set). The rule exception handler tries to recover, but finds\n   * the same recovery set and doesn't consume anything. Rule b\n   * exits normally returning to rule a. Now it finds the ']' (and\n   * with the successful match exits errorRecovery mode).\n   *\n   * So, you can see that the parser walks up the call chain looking\n   * for the token that was a member of the recovery set.\n   *\n   * Errors are not generated in errorRecovery mode.\n   *\n   * ANTLR's error recovery mechanism is based upon original ideas:\n   *\n   * \"Algorithms + Data Structures = Programs\" by Niklaus Wirth\n   *\n   * and\n   *\n   * \"A note on error recovery in recursive descent parsers\":\n   * http://portal.acm.org/citation.cfm?id=947902.947905\n   *\n   * Later, Josef Grosch had some good ideas:\n   *\n   * \"Efficient and Comfortable Error Recovery in Recursive Descent\n   * Parsers\":\n   * ftp://www.cocolab.com/products/cocktail/doca4.ps/ell.ps.zip\n   *\n   * Like Grosch I implement context-sensitive FOLLOW sets that are combined\n   * at run-time upon error to avoid overhead during parsing.\n   */\n  getErrorRecoverySet(recognizer) {\n    const atn = recognizer._interp.atn;\n    let ctx = recognizer._ctx;\n    const recoverSet = new IntervalSet();\n    while (ctx !== null && ctx.invokingState >= 0) {\n      // compute what follows who invoked us\n      const invokingState = atn.states[ctx.invokingState];\n      const rt = invokingState.transitions[0];\n      const follow = atn.nextTokens(rt.followState);\n      recoverSet.addSet(follow);\n      ctx = ctx.parentCtx;\n    }\n    recoverSet.removeOne(Token.EPSILON);\n    return recoverSet;\n  }\n\n  // Consume tokens until one matches the given token set.//\n  consumeUntil(recognizer, set) {\n    let ttype = recognizer.getTokenStream().LA(1);\n    while (ttype !== Token.EOF && !set.contains(ttype)) {\n      recognizer.consume();\n      ttype = recognizer.getTokenStream().LA(1);\n    }\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { InputMismatchException } from './InputMismatchException.js';\nimport { ParseCancellationException } from './ParseCancellationException.js';\nimport { DefaultErrorStrategy } from './DefaultErrorStrategy.js';\n\n/**\n * This implementation of {@link ANTLRErrorStrategy} responds to syntax errors\n * by immediately canceling the parse operation with a\n * {@link ParseCancellationException}. The implementation ensures that the\n * {@link ParserRuleContext//exception} field is set for all parse tree nodes\n * that were not completed prior to encountering the error.\n *\n * <p>\n * This error strategy is useful in the following scenarios.</p>\n *\n * <ul>\n * <li><strong>Two-stage parsing:</strong> This error strategy allows the first\n * stage of two-stage parsing to immediately terminate if an error is\n * encountered, and immediately fall back to the second stage. In addition to\n * avoiding wasted work by attempting to recover from errors here, the empty\n * implementation of {@link BailErrorStrategy//sync} improves the performance of\n * the first stage.</li>\n * <li><strong>Silent validation:</strong> When syntax errors are not being\n * reported or logged, and the parse result is simply ignored if errors occur,\n * the {@link BailErrorStrategy} avoids wasting work on recovering from errors\n * when the result will be ignored either way.</li>\n * </ul>\n *\n * <p>\n * {@code myparser.setErrorHandler(new BailErrorStrategy());}</p>\n *\n * @see Parser//setErrorHandler(ANTLRErrorStrategy)\n * */\nexport class BailErrorStrategy extends DefaultErrorStrategy {\n  constructor() {\n    super();\n  }\n\n  /**\n   * Instead of recovering from exception {@code e}, re-throw it wrapped\n   * in a {@link ParseCancellationException} so it is not caught by the\n   * rule function catches. Use {@link Exception//getCause()} to get the\n   * original {@link RecognitionException}.\n   */\n  recover(recognizer, e) {\n    let context = recognizer._ctx;\n    while (context !== null) {\n      context.exception = e;\n      context = context.parentCtx;\n    }\n    throw new ParseCancellationException(e);\n  }\n\n  /**\n   * Make sure we don't attempt to recover inline; if the parser\n   * successfully recovers, it won't throw an exception.\n   */\n  recoverInline(recognizer) {\n    this.recover(recognizer, new InputMismatchException(recognizer));\n  }\n\n  // Make sure we don't attempt to recover from problems in subrules.//\n  sync(recognizer) {\n    // pass\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { Token } from './Token.js';\nimport { Recognizer } from './Recognizer.js';\nimport { CommonTokenFactory } from './CommonTokenFactory.js';\nimport { RecognitionException } from './error/index.js';\nimport { LexerNoViableAltException } from './error/index.js';\n\n/**\n * A lexer is recognizer that draws input symbols from a character stream.\n * lexer grammars result in a subclass of this object. A Lexer object\n * uses simplified match() and error recovery mechanisms in the interest of speed.\n */\nexport class Lexer extends Recognizer {\n  constructor(input) {\n    super();\n    this._input = input;\n    this._factory = CommonTokenFactory.DEFAULT;\n    this._tokenFactorySourcePair = [this, input];\n\n    this._interp = null; // child classes must populate this\n\n    /**\n     * The goal of all lexer rules/methods is to create a token object.\n     * this is an instance variable as multiple rules may collaborate to\n     * create a single token. nextToken will return this object after\n     * matching lexer rule(s). If you subclass to allow multiple token\n     * emissions, then set this to the last token to be matched or\n     * something nonnull so that the auto token emit mechanism will not\n     * emit another token.\n     */\n    this._token = null;\n\n    /**\n     * What character index in the stream did the current token start at?\n     * Needed, for example, to get the text for current token. Set at\n     * the start of nextToken.\n     */\n    this._tokenStartCharIndex = -1;\n\n    // The line on which the first character of the token resides///\n    this._tokenStartLine = -1;\n\n    // The character position of first character within the line///\n    this._tokenStartColumn = -1;\n\n    // Once we see EOF on char stream, next token will be EOF.\n    // If you have DONE : EOF ; then you see DONE EOF.\n    this._hitEOF = false;\n\n    // The channel number for the current token///\n    this._channel = Token.DEFAULT_CHANNEL;\n\n    // The token type for the current token///\n    this._type = Token.INVALID_TYPE;\n\n    this._modeStack = [];\n    this._mode = Lexer.DEFAULT_MODE;\n\n    /**\n     * You can set the text for the current token to override what is in\n     * the input char buffer. Use setText() or can set this instance var.\n     */\n    this._text = null;\n  }\n\n  get inputStream() {\n    return this._input;\n  }\n\n  set inputStream(input) {\n    this._input = null;\n    this._tokenFactorySourcePair = [this, this._input];\n    this.reset();\n    this._input = input;\n    this._tokenFactorySourcePair = [this, this._input];\n  }\n\n  get sourceName() {\n    return this._input.sourceName;\n  }\n\n  get type() {\n    return this._type;\n  }\n\n  set type(type) {\n    this._type = type;\n  }\n\n  get line() {\n    return this._interp.line;\n  }\n\n  set line(line) {\n    this._interp.line = line;\n  }\n\n  get column() {\n    return this._interp.column;\n  }\n\n  set column(column) {\n    this._interp.column = column;\n  }\n\n  get text() {\n    if (this._text !== null) {\n      return this._text;\n    } else {\n      return this._interp.getText(this._input);\n    }\n  }\n\n  set text(text) {\n    this._text = text;\n  }\n\n  reset() {\n    // wack Lexer state variables\n    if (this._input !== null) {\n      this._input.seek(0); // rewind the input\n    }\n    this._token = null;\n    this._type = Token.INVALID_TYPE;\n    this._channel = Token.DEFAULT_CHANNEL;\n    this._tokenStartCharIndex = -1;\n    this._tokenStartColumn = -1;\n    this._tokenStartLine = -1;\n    this._text = null;\n\n    this._hitEOF = false;\n    this._mode = Lexer.DEFAULT_MODE;\n    this._modeStack = [];\n\n    this._interp.reset();\n  }\n\n  // Return a token from this source; i.e., match a token on the char stream.\n  nextToken() {\n    if (this._input === null) {\n      throw 'nextToken requires a non-null input stream.';\n    }\n\n    /**\n     * Mark start location in char stream so unbuffered streams are\n     * guaranteed at least have text of current token\n     */\n    const tokenStartMarker = this._input.mark();\n    try {\n      for (;;) {\n        if (this._hitEOF) {\n          this.emitEOF();\n          return this._token;\n        }\n        this._token = null;\n        this._channel = Token.DEFAULT_CHANNEL;\n        this._tokenStartCharIndex = this._input.index;\n        this._tokenStartColumn = this._interp.column;\n        this._tokenStartLine = this._interp.line;\n        this._text = null;\n        let continueOuter = false;\n        for (;;) {\n          this._type = Token.INVALID_TYPE;\n          let ttype = Lexer.SKIP;\n          try {\n            ttype = this._interp.match(this._input, this._mode);\n          } catch (e) {\n            if (e instanceof RecognitionException) {\n              this.notifyListeners(e); // report error\n              this.recover(e);\n            } else {\n              console.log(e.stack);\n              throw e;\n            }\n          }\n          if (this._input.LA(1) === Token.EOF) {\n            this._hitEOF = true;\n          }\n          if (this._type === Token.INVALID_TYPE) {\n            this._type = ttype;\n          }\n          if (this._type === Lexer.SKIP) {\n            continueOuter = true;\n            break;\n          }\n          if (this._type !== Lexer.MORE) {\n            break;\n          }\n        }\n        if (continueOuter) {\n          continue;\n        }\n        if (this._token === null) {\n          this.emit();\n        }\n        return this._token;\n      }\n    } finally {\n      // make sure we release marker after match or\n      // unbuffered char stream will keep buffering\n      this._input.release(tokenStartMarker);\n    }\n  }\n\n  /**\n   * Instruct the lexer to skip creating a token for current lexer rule\n   * and look for another token. nextToken() knows to keep looking when\n   * a lexer rule finishes with token set to SKIP_TOKEN. Recall that\n   * if token==null at end of any token rule, it creates one for you\n   * and emits it.\n   */\n  skip() {\n    this._type = Lexer.SKIP;\n  }\n\n  more() {\n    this._type = Lexer.MORE;\n  }\n\n  mode(m) {\n    this._mode = m;\n  }\n\n  pushMode(m) {\n    if (this._interp.debug) {\n      console.log('pushMode ' + m);\n    }\n    this._modeStack.push(this._mode);\n    this.mode(m);\n  }\n\n  popMode() {\n    if (this._modeStack.length === 0) {\n      throw 'Empty Stack';\n    }\n    if (this._interp.debug) {\n      console.log('popMode back to ' + this._modeStack.slice(0, -1));\n    }\n    this.mode(this._modeStack.pop());\n    return this._mode;\n  }\n\n  /**\n   * By default does not support multiple emits per nextToken invocation\n   * for efficiency reasons. Subclass and override this method, nextToken,\n   * and getToken (to push tokens into a list and pull from that list\n   * rather than a single variable as this implementation does).\n   */\n  emitToken(token) {\n    this._token = token;\n  }\n\n  /**\n   * The standard method called to automatically emit a token at the\n   * outermost lexical rule. The token object should point into the\n   * char buffer start..stop. If there is a text override in 'text',\n   * use that to set the token's text. Override this method to emit\n   * custom Token objects or provide a new factory.\n   */\n  emit() {\n    const t = this._factory.create(\n      this._tokenFactorySourcePair,\n      this._type,\n      this._text,\n      this._channel,\n      this._tokenStartCharIndex,\n      this.getCharIndex() - 1,\n      this._tokenStartLine,\n      this._tokenStartColumn,\n    );\n    this.emitToken(t);\n    return t;\n  }\n\n  emitEOF() {\n    const cpos = this.column;\n    const lpos = this.line;\n    const eof = this._factory.create(\n      this._tokenFactorySourcePair,\n      Token.EOF,\n      null,\n      Token.DEFAULT_CHANNEL,\n      this._input.index,\n      this._input.index - 1,\n      lpos,\n      cpos,\n    );\n    this.emitToken(eof);\n    return eof;\n  }\n\n  // What is the index of the current character of lookahead?///\n  getCharIndex() {\n    return this._input.index;\n  }\n\n  /**\n   * Return a list of all Token objects in input char stream.\n   * Forces load of all tokens. Does not include EOF token.\n   */\n  getAllTokens() {\n    const tokens = [];\n    let t = this.nextToken();\n    while (t.type !== Token.EOF) {\n      tokens.push(t);\n      t = this.nextToken();\n    }\n    return tokens;\n  }\n\n  notifyListeners(e) {\n    const start = this._tokenStartCharIndex;\n    const stop = this._input.index;\n    const text = this._input.getText(start, stop);\n    const msg = \"token recognition error at: '\" + this.getErrorDisplay(text) + \"'\";\n    const listener = this.getErrorListenerDispatch();\n    listener.syntaxError(this, null, this._tokenStartLine, this._tokenStartColumn, msg, e);\n  }\n\n  getErrorDisplay(s) {\n    const d = [];\n    for (let i = 0; i < s.length; i++) {\n      d.push(s[i]);\n    }\n    return d.join('');\n  }\n\n  getErrorDisplayForChar(c) {\n    if (c.charCodeAt(0) === Token.EOF) {\n      return '<EOF>';\n    } else if (c === '\\n') {\n      return '\\\\n';\n    } else if (c === '\\t') {\n      return '\\\\t';\n    } else if (c === '\\r') {\n      return '\\\\r';\n    } else {\n      return c;\n    }\n  }\n\n  getCharErrorDisplay(c) {\n    return \"'\" + this.getErrorDisplayForChar(c) + \"'\";\n  }\n\n  /**\n   * Lexers can normally match any char in it's vocabulary after matching\n   * a token, so do the easy thing and just kill a character and hope\n   * it all works out. You can instead use the rule invocation stack\n   * to do sophisticated error recovery if you are in a fragment rule.\n   */\n  recover(re) {\n    if (this._input.LA(1) !== Token.EOF) {\n      if (re instanceof LexerNoViableAltException) {\n        // skip a char and try again\n        this._interp.consume(this._input);\n      } else {\n        // TODO: Do we lose character or line position information?\n        this._input.consume();\n      }\n    }\n  }\n}\n\nLexer.DEFAULT_MODE = 0;\nLexer.MORE = -2;\nLexer.SKIP = -3;\n\nLexer.DEFAULT_TOKEN_CHANNEL = Token.DEFAULT_CHANNEL;\nLexer.HIDDEN = Token.HIDDEN_CHANNEL;\nLexer.MIN_CHAR_VALUE = 0x0000;\nLexer.MAX_CHAR_VALUE = 0x10ffff;\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { ATNConfigSet } from './ATNConfigSet.js';\nimport { HashSet } from '../misc/HashSet.js';\n\nexport class OrderedATNConfigSet extends ATNConfigSet {\n  constructor() {\n    super();\n    this.configLookup = new HashSet();\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { Token } from '../Token.js';\nimport { Lexer } from './../Lexer.js';\nimport { ATN } from './ATN.js';\nimport { ATNSimulator } from './ATNSimulator.js';\nimport { DFAState } from '../dfa/DFAState.js';\nimport { OrderedATNConfigSet } from './OrderedATNConfigSet.js';\nimport { PredictionContext } from '../context/PredictionContext.js';\nimport { SingletonPredictionContext } from '../context/SingletonPredictionContext.js';\nimport { RuleStopState } from '../state/RuleStopState.js';\nimport { LexerATNConfig } from './LexerATNConfig.js';\nimport { Transition } from '../transition/Transition.js';\nimport { LexerActionExecutor } from './LexerActionExecutor.js';\nimport { LexerNoViableAltException } from '../error/LexerNoViableAltException.js';\n\nfunction resetSimState(sim) {\n  sim.index = -1;\n  sim.line = 0;\n  sim.column = -1;\n  sim.dfaState = null;\n}\n\nclass SimState {\n  constructor() {\n    resetSimState(this);\n  }\n\n  reset() {\n    resetSimState(this);\n  }\n}\n\nexport class LexerATNSimulator extends ATNSimulator {\n  /**\n   * When we hit an accept state in either the DFA or the ATN, we\n   * have to notify the character stream to start buffering characters\n   * via {@link IntStream//mark} and record the current state. The current sim state\n   * includes the current index into the input, the current line,\n   * and current character position in that line. Note that the Lexer is\n   * tracking the starting line and characterization of the token. These\n   * variables track the \"state\" of the simulator when it hits an accept state.\n   *\n   * <p>We track these variables separately for the DFA and ATN simulation\n   * because the DFA simulation often has to fail over to the ATN\n   * simulation. If the ATN simulation fails, we need the DFA to fall\n   * back to its previously accepted state, if any. If the ATN succeeds,\n   * then the ATN does the accept and the DFA simulator that invoked it\n   * can simply return the predicted token type.</p>\n   */\n  constructor(recog, atn, decisionToDFA, sharedContextCache) {\n    super(atn, sharedContextCache);\n    this.decisionToDFA = decisionToDFA;\n    this.recog = recog;\n    /**\n     * The current token's starting index into the character stream.\n     * Shared across DFA to ATN simulation in case the ATN fails and the\n     * DFA did not have a previous accept state. In this case, we use the\n     * ATN-generated exception object\n     */\n    this.startIndex = -1;\n    // line number 1..n within the input///\n    this.line = 1;\n    /**\n     * The index of the character relative to the beginning of the line\n     * 0..n-1\n     */\n    this.column = 0;\n    this.mode = Lexer.DEFAULT_MODE;\n    /**\n     * Used during DFA/ATN exec to record the most recent accept configuration\n     * info\n     */\n    this.prevAccept = new SimState();\n  }\n\n  copyState(simulator) {\n    this.column = simulator.column;\n    this.line = simulator.line;\n    this.mode = simulator.mode;\n    this.startIndex = simulator.startIndex;\n  }\n\n  match(input, mode) {\n    this.mode = mode;\n    const mark = input.mark();\n    try {\n      this.startIndex = input.index;\n      this.prevAccept.reset();\n      const dfa = this.decisionToDFA[mode];\n      if (dfa.s0 === null) {\n        return this.matchATN(input);\n      } else {\n        return this.execATN(input, dfa.s0);\n      }\n    } finally {\n      input.release(mark);\n    }\n  }\n\n  reset() {\n    this.prevAccept.reset();\n    this.startIndex = -1;\n    this.line = 1;\n    this.column = 0;\n    this.mode = Lexer.DEFAULT_MODE;\n  }\n\n  matchATN(input) {\n    const startState = this.atn.modeToStartState[this.mode];\n\n    if (LexerATNSimulator.debug) {\n      console.log('matchATN mode ' + this.mode + ' start: ' + startState);\n    }\n    const old_mode = this.mode;\n    const s0_closure = this.computeStartState(input, startState);\n    const suppressEdge = s0_closure.hasSemanticContext;\n    s0_closure.hasSemanticContext = false;\n\n    const next = this.addDFAState(s0_closure);\n    if (!suppressEdge) {\n      this.decisionToDFA[this.mode].s0 = next;\n    }\n\n    const predict = this.execATN(input, next);\n\n    if (LexerATNSimulator.debug) {\n      console.log('DFA after matchATN: ' + this.decisionToDFA[old_mode].toLexerString());\n    }\n    return predict;\n  }\n\n  execATN(input, ds0) {\n    if (LexerATNSimulator.debug) {\n      console.log('start state closure=' + ds0.configs);\n    }\n    if (ds0.isAcceptState) {\n      // allow zero-length tokens\n      this.captureSimState(this.prevAccept, input, ds0);\n    }\n    let t = input.LA(1);\n    let s = ds0; // s is current/from DFA state\n\n    for (;;) {\n      // while more work\n      if (LexerATNSimulator.debug) {\n        console.log('execATN loop starting closure: ' + s.configs);\n      }\n\n      /**\n       * As we move src->trg, src->trg, we keep track of the previous trg to\n       * avoid looking up the DFA state again, which is expensive.\n       * If the previous target was already part of the DFA, we might\n       * be able to avoid doing a reach operation upon t. If s!=null,\n       * it means that semantic predicates didn't prevent us from\n       * creating a DFA state. Once we know s!=null, we check to see if\n       * the DFA state has an edge already for t. If so, we can just reuse\n       * it's configuration set; there's no point in re-computing it.\n       * This is kind of like doing DFA simulation within the ATN\n       * simulation because DFA simulation is really just a way to avoid\n       * computing reach/closure sets. Technically, once we know that\n       * we have a previously added DFA state, we could jump over to\n       * the DFA simulator. But, that would mean popping back and forth\n       * a lot and making things more complicated algorithmically.\n       * This optimization makes a lot of sense for loops within DFA.\n       * A character will take us back to an existing DFA state\n       * that already has lots of edges out of it. e.g., .* in comments.\n       * print(\"Target for:\" + str(s) + \" and:\" + str(t))\n       */\n      let target = this.getExistingTargetState(s, t);\n      // print(\"Existing:\" + str(target))\n      if (target === null) {\n        target = this.computeTargetState(input, s, t);\n        // print(\"Computed:\" + str(target))\n      }\n      if (target === ATNSimulator.ERROR) {\n        break;\n      }\n      // If this is a consumable input element, make sure to consume before\n      // capturing the accept state so the input index, line, and char\n      // position accurately reflect the state of the interpreter at the\n      // end of the token.\n      if (t !== Token.EOF) {\n        this.consume(input);\n      }\n      if (target.isAcceptState) {\n        this.captureSimState(this.prevAccept, input, target);\n        if (t === Token.EOF) {\n          break;\n        }\n      }\n      t = input.LA(1);\n      s = target; // flip; current DFA target becomes new src/from state\n    }\n    return this.failOrAccept(this.prevAccept, input, s.configs, t);\n  }\n\n  /**\n   * Get an existing target state for an edge in the DFA. If the target state\n   * for the edge has not yet been computed or is otherwise not available,\n   * this method returns {@code null}.\n   *\n   * @param s The current DFA state\n   * @param t The next input symbol\n   * @return The existing target DFA state for the given input symbol\n   * {@code t}, or {@code null} if the target state for this edge is not\n   * already cached\n   */\n  getExistingTargetState(s, t) {\n    if (s.edges === null || t < LexerATNSimulator.MIN_DFA_EDGE || t > LexerATNSimulator.MAX_DFA_EDGE) {\n      return null;\n    }\n\n    let target = s.edges[t - LexerATNSimulator.MIN_DFA_EDGE];\n    if (target === undefined) {\n      target = null;\n    }\n    if (LexerATNSimulator.debug && target !== null) {\n      console.log('reuse state ' + s.stateNumber + ' edge to ' + target.stateNumber);\n    }\n    return target;\n  }\n\n  /**\n   * Compute a target state for an edge in the DFA, and attempt to add the\n   * computed state and corresponding edge to the DFA.\n   *\n   * @param input The input stream\n   * @param s The current DFA state\n   * @param t The next input symbol\n   *\n   * @return The computed target DFA state for the given input symbol\n   * {@code t}. If {@code t} does not lead to a valid DFA state, this method\n   * returns {@link //ERROR}.\n   */\n  computeTargetState(input, s, t) {\n    const reach = new OrderedATNConfigSet();\n    // if we don't find an existing DFA state\n    // Fill reach starting from closure, following t transitions\n    this.getReachableConfigSet(input, s.configs, reach, t);\n\n    if (reach.items.length === 0) {\n      // we got nowhere on t from s\n      if (!reach.hasSemanticContext) {\n        // we got nowhere on t, don't throw out this knowledge; it'd\n        // cause a failover from DFA later.\n        this.addDFAEdge(s, t, ATNSimulator.ERROR);\n      }\n      // stop when we can't match any more char\n      return ATNSimulator.ERROR;\n    }\n    // Add an edge from s to target DFA found/created for reach\n    return this.addDFAEdge(s, t, null, reach);\n  }\n\n  failOrAccept(prevAccept, input, reach, t) {\n    if (this.prevAccept.dfaState !== null) {\n      const lexerActionExecutor = prevAccept.dfaState.lexerActionExecutor;\n      this.accept(input, lexerActionExecutor, this.startIndex, prevAccept.index, prevAccept.line, prevAccept.column);\n      return prevAccept.dfaState.prediction;\n    } else {\n      // if no accept and EOF is first char, return EOF\n      if (t === Token.EOF && input.index === this.startIndex) {\n        return Token.EOF;\n      }\n      throw new LexerNoViableAltException(this.recog, input, this.startIndex, reach);\n    }\n  }\n\n  /**\n   * Given a starting configuration set, figure out all ATN configurations\n   * we can reach upon input {@code t}. Parameter {@code reach} is a return\n   * parameter.\n   */\n  getReachableConfigSet(input, closure, reach, t) {\n    // this is used to skip processing for configs which have a lower priority\n    // than a config that already reached an accept state for the same rule\n    let skipAlt = ATN.INVALID_ALT_NUMBER;\n    for (let i = 0; i < closure.items.length; i++) {\n      const cfg = closure.items[i];\n      const currentAltReachedAcceptState = cfg.alt === skipAlt;\n      if (currentAltReachedAcceptState && cfg.passedThroughNonGreedyDecision) {\n        continue;\n      }\n      if (LexerATNSimulator.debug) {\n        console.log('testing %s at %s\\n', this.getTokenName(t), cfg.toString(this.recog, true));\n      }\n      for (let j = 0; j < cfg.state.transitions.length; j++) {\n        const trans = cfg.state.transitions[j]; // for each transition\n        const target = this.getReachableTarget(trans, t);\n        if (target !== null) {\n          let lexerActionExecutor = cfg.lexerActionExecutor;\n          if (lexerActionExecutor !== null) {\n            lexerActionExecutor = lexerActionExecutor.fixOffsetBeforeMatch(input.index - this.startIndex);\n          }\n          const treatEofAsEpsilon = t === Token.EOF;\n          const config = new LexerATNConfig({ state: target, lexerActionExecutor: lexerActionExecutor }, cfg);\n          if (this.closure(input, config, reach, currentAltReachedAcceptState, true, treatEofAsEpsilon)) {\n            // any remaining configs for this alt have a lower priority\n            // than the one that just reached an accept state.\n            skipAlt = cfg.alt;\n          }\n        }\n      }\n    }\n  }\n\n  accept(input, lexerActionExecutor, startIndex, index, line, charPos) {\n    if (LexerATNSimulator.debug) {\n      console.log('ACTION %s\\n', lexerActionExecutor);\n    }\n    // seek to after last char in token\n    input.seek(index);\n    this.line = line;\n    this.column = charPos;\n    if (lexerActionExecutor !== null && this.recog !== null) {\n      lexerActionExecutor.execute(this.recog, input, startIndex);\n    }\n  }\n\n  getReachableTarget(trans, t) {\n    if (trans.matches(t, 0, Lexer.MAX_CHAR_VALUE)) {\n      return trans.target;\n    } else {\n      return null;\n    }\n  }\n\n  computeStartState(input, p) {\n    const initialContext = PredictionContext.EMPTY;\n    const configs = new OrderedATNConfigSet();\n    for (let i = 0; i < p.transitions.length; i++) {\n      const target = p.transitions[i].target;\n      const cfg = new LexerATNConfig({ state: target, alt: i + 1, context: initialContext }, null);\n      this.closure(input, cfg, configs, false, false, false);\n    }\n    return configs;\n  }\n\n  /**\n   * Since the alternatives within any lexer decision are ordered by\n   * preference, this method stops pursuing the closure as soon as an accept\n   * state is reached. After the first accept state is reached by depth-first\n   * search from {@code config}, all other (potentially reachable) states for\n   * this rule would have a lower priority.\n   *\n   * @return {Boolean} {@code true} if an accept state is reached, otherwise\n   * {@code false}.\n   */\n  closure(input, config, configs, currentAltReachedAcceptState, speculative, treatEofAsEpsilon) {\n    let cfg = null;\n    if (LexerATNSimulator.debug) {\n      console.log('closure(' + config.toString(this.recog, true) + ')');\n    }\n    if (config.state instanceof RuleStopState) {\n      if (LexerATNSimulator.debug) {\n        if (this.recog !== null) {\n          console.log('closure at %s rule stop %s\\n', this.recog.ruleNames[config.state.ruleIndex], config);\n        } else {\n          console.log('closure at rule stop %s\\n', config);\n        }\n      }\n      if (config.context === null || config.context.hasEmptyPath()) {\n        if (config.context === null || config.context.isEmpty()) {\n          configs.add(config);\n          return true;\n        } else {\n          configs.add(new LexerATNConfig({ state: config.state, context: PredictionContext.EMPTY }, config));\n          currentAltReachedAcceptState = true;\n        }\n      }\n      if (config.context !== null && !config.context.isEmpty()) {\n        for (let i = 0; i < config.context.length; i++) {\n          if (config.context.getReturnState(i) !== PredictionContext.EMPTY_RETURN_STATE) {\n            const newContext = config.context.getParent(i); // \"pop\" return state\n            const returnState = this.atn.states[config.context.getReturnState(i)];\n            cfg = new LexerATNConfig({ state: returnState, context: newContext }, config);\n            currentAltReachedAcceptState = this.closure(\n              input,\n              cfg,\n              configs,\n              currentAltReachedAcceptState,\n              speculative,\n              treatEofAsEpsilon,\n            );\n          }\n        }\n      }\n      return currentAltReachedAcceptState;\n    }\n    // optimization\n    if (!config.state.epsilonOnlyTransitions) {\n      if (!currentAltReachedAcceptState || !config.passedThroughNonGreedyDecision) {\n        configs.add(config);\n      }\n    }\n    for (let j = 0; j < config.state.transitions.length; j++) {\n      const trans = config.state.transitions[j];\n      cfg = this.getEpsilonTarget(input, config, trans, configs, speculative, treatEofAsEpsilon);\n      if (cfg !== null) {\n        currentAltReachedAcceptState = this.closure(\n          input,\n          cfg,\n          configs,\n          currentAltReachedAcceptState,\n          speculative,\n          treatEofAsEpsilon,\n        );\n      }\n    }\n    return currentAltReachedAcceptState;\n  }\n\n  // side-effect: can alter configs.hasSemanticContext\n  getEpsilonTarget(input, config, trans, configs, speculative, treatEofAsEpsilon) {\n    let cfg = null;\n    if (trans.serializationType === Transition.RULE) {\n      const newContext = SingletonPredictionContext.create(config.context, trans.followState.stateNumber);\n      cfg = new LexerATNConfig({ state: trans.target, context: newContext }, config);\n    } else if (trans.serializationType === Transition.PRECEDENCE) {\n      throw 'Precedence predicates are not supported in lexers.';\n    } else if (trans.serializationType === Transition.PREDICATE) {\n      // Track traversing semantic predicates. If we traverse,\n      // we cannot add a DFA state for this \"reach\" computation\n      // because the DFA would not test the predicate again in the\n      // future. Rather than creating collections of semantic predicates\n      // like v3 and testing them on prediction, v4 will test them on the\n      // fly all the time using the ATN not the DFA. This is slower but\n      // semantically it's not used that often. One of the key elements to\n      // this predicate mechanism is not adding DFA states that see\n      // predicates immediately afterwards in the ATN. For example,\n\n      // a : ID {p1}? | ID {p2}? ;\n\n      // should create the start state for rule 'a' (to save start state\n      // competition), but should not create target of ID state. The\n      // collection of ATN states the following ID references includes\n      // states reached by traversing predicates. Since this is when we\n      // test them, we cannot cash the DFA state target of ID.\n\n      if (LexerATNSimulator.debug) {\n        console.log('EVAL rule ' + trans.ruleIndex + ':' + trans.predIndex);\n      }\n      configs.hasSemanticContext = true;\n      if (this.evaluatePredicate(input, trans.ruleIndex, trans.predIndex, speculative)) {\n        cfg = new LexerATNConfig({ state: trans.target }, config);\n      }\n    } else if (trans.serializationType === Transition.ACTION) {\n      if (config.context === null || config.context.hasEmptyPath()) {\n        // execute actions anywhere in the start rule for a token.\n        //\n        // TODO: if the entry rule is invoked recursively, some\n        // actions may be executed during the recursive call. The\n        // problem can appear when hasEmptyPath() is true but\n        // isEmpty() is false. In this case, the config needs to be\n        // split into two contexts - one with just the empty path\n        // and another with everything but the empty path.\n        // Unfortunately, the current algorithm does not allow\n        // getEpsilonTarget to return two configurations, so\n        // additional modifications are needed before we can support\n        // the split operation.\n        const lexerActionExecutor = LexerActionExecutor.append(\n          config.lexerActionExecutor,\n          this.atn.lexerActions[trans.actionIndex],\n        );\n        cfg = new LexerATNConfig({ state: trans.target, lexerActionExecutor: lexerActionExecutor }, config);\n      } else {\n        // ignore actions in referenced rules\n        cfg = new LexerATNConfig({ state: trans.target }, config);\n      }\n    } else if (trans.serializationType === Transition.EPSILON) {\n      cfg = new LexerATNConfig({ state: trans.target }, config);\n    } else if (\n      trans.serializationType === Transition.ATOM ||\n      trans.serializationType === Transition.RANGE ||\n      trans.serializationType === Transition.SET\n    ) {\n      if (treatEofAsEpsilon) {\n        if (trans.matches(Token.EOF, 0, Lexer.MAX_CHAR_VALUE)) {\n          cfg = new LexerATNConfig({ state: trans.target }, config);\n        }\n      }\n    }\n    return cfg;\n  }\n\n  /**\n   * Evaluate a predicate specified in the lexer.\n   *\n   * <p>If {@code speculative} is {@code true}, this method was called before\n   * {@link //consume} for the matched character. This method should call\n   * {@link //consume} before evaluating the predicate to ensure position\n   * sensitive values, including {@link Lexer//getText}, {@link Lexer//getLine},\n   * and {@link Lexer//getcolumn}, properly reflect the current\n   * lexer state. This method should restore {@code input} and the simulator\n   * to the original state before returning (i.e. undo the actions made by the\n   * call to {@link //consume}.</p>\n   *\n   * @param input The input stream.\n   * @param ruleIndex The rule containing the predicate.\n   * @param predIndex The index of the predicate within the rule.\n   * @param speculative {@code true} if the current index in {@code input} is\n   * one character before the predicate's location.\n   *\n   * @return {@code true} if the specified predicate evaluates to\n   * {@code true}.\n   */\n  evaluatePredicate(input, ruleIndex, predIndex, speculative) {\n    // assume true if no recognizer was provided\n    if (this.recog === null) {\n      return true;\n    }\n    if (!speculative) {\n      return this.recog.sempred(null, ruleIndex, predIndex);\n    }\n    const savedcolumn = this.column;\n    const savedLine = this.line;\n    const index = input.index;\n    const marker = input.mark();\n    try {\n      this.consume(input);\n      return this.recog.sempred(null, ruleIndex, predIndex);\n    } finally {\n      this.column = savedcolumn;\n      this.line = savedLine;\n      input.seek(index);\n      input.release(marker);\n    }\n  }\n\n  captureSimState(settings, input, dfaState) {\n    settings.index = input.index;\n    settings.line = this.line;\n    settings.column = this.column;\n    settings.dfaState = dfaState;\n  }\n\n  addDFAEdge(from_, tk, to, cfgs) {\n    if (to === undefined) {\n      to = null;\n    }\n    if (cfgs === undefined) {\n      cfgs = null;\n    }\n    if (to === null && cfgs !== null) {\n      // leading to this call, ATNConfigSet.hasSemanticContext is used as a\n      // marker indicating dynamic predicate evaluation makes this edge\n      // dependent on the specific input sequence, so the static edge in the\n      // DFA should be omitted. The target DFAState is still created since\n      // execATN has the ability to resynchronize with the DFA state cache\n      // following the predicate evaluation step.\n      //\n      // TJP notes: next time through the DFA, we see a pred again and eval.\n      // If that gets us to a previously created (but dangling) DFA\n      // state, we can continue in pure DFA mode from there.\n      // /\n      const suppressEdge = cfgs.hasSemanticContext;\n      cfgs.hasSemanticContext = false;\n\n      to = this.addDFAState(cfgs);\n\n      if (suppressEdge) {\n        return to;\n      }\n    }\n    // add the edge\n    if (tk < LexerATNSimulator.MIN_DFA_EDGE || tk > LexerATNSimulator.MAX_DFA_EDGE) {\n      // Only track edges within the DFA bounds\n      return to;\n    }\n    if (LexerATNSimulator.debug) {\n      console.log('EDGE ' + from_ + ' -> ' + to + ' upon ' + tk);\n    }\n    if (from_.edges === null) {\n      // make room for tokens 1..n and -1 masquerading as index 0\n      from_.edges = [];\n    }\n    from_.edges[tk - LexerATNSimulator.MIN_DFA_EDGE] = to; // connect\n\n    return to;\n  }\n\n  /**\n   * Add a new DFA state if there isn't one with this set of\n   * configurations already. This method also detects the first\n   * configuration containing an ATN rule stop state. Later, when\n   * traversing the DFA, we will know which rule to accept.\n   */\n  addDFAState(configs) {\n    const proposed = new DFAState(null, configs);\n    let firstConfigWithRuleStopState = null;\n    for (let i = 0; i < configs.items.length; i++) {\n      const cfg = configs.items[i];\n      if (cfg.state instanceof RuleStopState) {\n        firstConfigWithRuleStopState = cfg;\n        break;\n      }\n    }\n    if (firstConfigWithRuleStopState !== null) {\n      proposed.isAcceptState = true;\n      proposed.lexerActionExecutor = firstConfigWithRuleStopState.lexerActionExecutor;\n      proposed.prediction = this.atn.ruleToTokenType[firstConfigWithRuleStopState.state.ruleIndex];\n    }\n    const dfa = this.decisionToDFA[this.mode];\n    const existing = dfa.states.get(proposed);\n    if (existing !== null) {\n      return existing;\n    }\n    const newState = proposed;\n    newState.stateNumber = dfa.states.length;\n    configs.setReadonly(true);\n    newState.configs = configs;\n    dfa.states.add(newState);\n    return newState;\n  }\n\n  getDFA(mode) {\n    return this.decisionToDFA[mode];\n  }\n\n  // Get the text matched so far for the current token.\n  getText(input) {\n    // index is first lookahead char, don't include.\n    return input.getText(this.startIndex, input.index - 1);\n  }\n\n  consume(input) {\n    const curChar = input.LA(1);\n    if (curChar === '\\n'.charCodeAt(0)) {\n      this.line += 1;\n      this.column = 0;\n    } else {\n      this.column += 1;\n    }\n    input.consume();\n  }\n\n  getTokenName(tt) {\n    if (tt === -1) {\n      return 'EOF';\n    } else {\n      return \"'\" + String.fromCharCode(tt) + \"'\";\n    }\n  }\n}\n\nLexerATNSimulator.debug = false;\nLexerATNSimulator.dfa_debug = false;\n\nLexerATNSimulator.MIN_DFA_EDGE = 0;\nLexerATNSimulator.MAX_DFA_EDGE = 127; // forces unicode to stay in ATN\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n/**\n * Map a predicate to a predicted alternative.\n */\nexport class PredPrediction {\n  constructor(pred, alt) {\n    this.alt = alt;\n    this.pred = pred;\n  }\n\n  toString() {\n    return '(' + this.pred + ', ' + this.alt + ')';\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexport class AltDict {\n  constructor() {\n    this.data = {};\n  }\n\n  get(key) {\n    return this.data['k-' + key] || null;\n  }\n\n  set(key, value) {\n    this.data['k-' + key] = value;\n  }\n\n  values() {\n    return Object.keys(this.data)\n      .filter((key) => key.startsWith('k-'))\n      .map((key) => this.data[key], this);\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { ATN } from './ATN.js';\nimport { RuleStopState } from '../state/RuleStopState.js';\nimport { ATNConfigSet } from './ATNConfigSet.js';\nimport { ATNConfig } from './ATNConfig.js';\nimport { SemanticContext } from './SemanticContext.js';\nimport { BitSet } from '../misc/BitSet.js';\nimport { AltDict } from '../misc/AltDict.js';\nimport { HashCode } from '../misc/HashCode.js';\nimport { HashMap } from '../misc/HashMap.js';\n\n/**\n * This enumeration defines the prediction modes available in ANTLR 4 along with\n * utility methods for analyzing configuration sets for conflicts and/or\n * ambiguities.\n */\nexport const PredictionMode = {\n  /**\n   * The SLL(*) prediction mode. This prediction mode ignores the current\n   * parser context when making predictions. This is the fastest prediction\n   * mode, and provides correct results for many grammars. This prediction\n   * mode is more powerful than the prediction mode provided by ANTLR 3, but\n   * may result in syntax errors for grammar and input combinations which are\n   * not SLL.\n   *\n   * <p>\n   * When using this prediction mode, the parser will either return a correct\n   * parse tree (i.e. the same parse tree that would be returned with the\n   * {@link //LL} prediction mode), or it will report a syntax error. If a\n   * syntax error is encountered when using the {@link //SLL} prediction mode,\n   * it may be due to either an actual syntax error in the input or indicate\n   * that the particular combination of grammar and input requires the more\n   * powerful {@link //LL} prediction abilities to complete successfully.</p>\n   *\n   * <p>\n   * This prediction mode does not provide any guarantees for prediction\n   * behavior for syntactically-incorrect inputs.</p>\n   */\n  SLL: 0,\n\n  /**\n   * The LL(*) prediction mode. This prediction mode allows the current parser\n   * context to be used for resolving SLL conflicts that occur during\n   * prediction. This is the fastest prediction mode that guarantees correct\n   * parse results for all combinations of grammars with syntactically correct\n   * inputs.\n   *\n   * <p>\n   * When using this prediction mode, the parser will make correct decisions\n   * for all syntactically-correct grammar and input combinations. However, in\n   * cases where the grammar is truly ambiguous this prediction mode might not\n   * report a precise answer for <em>exactly which</em> alternatives are\n   * ambiguous.</p>\n   *\n   * <p>\n   * This prediction mode does not provide any guarantees for prediction\n   * behavior for syntactically-incorrect inputs.</p>\n   */\n  LL: 1,\n\n  /**\n   *\n   * The LL(*) prediction mode with exact ambiguity detection. In addition to\n   * the correctness guarantees provided by the {@link //LL} prediction mode,\n   * this prediction mode instructs the prediction algorithm to determine the\n   * complete and exact set of ambiguous alternatives for every ambiguous\n   * decision encountered while parsing.\n   *\n   * <p>\n   * This prediction mode may be used for diagnosing ambiguities during\n   * grammar development. Due to the performance overhead of calculating sets\n   * of ambiguous alternatives, this prediction mode should be avoided when\n   * the exact results are not necessary.</p>\n   *\n   * <p>\n   * This prediction mode does not provide any guarantees for prediction\n   * behavior for syntactically-incorrect inputs.</p>\n   */\n  LL_EXACT_AMBIG_DETECTION: 2,\n\n  /**\n   *\n   * Computes the SLL prediction termination condition.\n   *\n   * <p>\n   * This method computes the SLL prediction termination condition for both of\n   * the following cases.</p>\n   *\n   * <ul>\n   * <li>The usual SLL+LL fallback upon SLL conflict</li>\n   * <li>Pure SLL without LL fallback</li>\n   * </ul>\n   *\n   * <p><strong>COMBINED SLL+LL PARSING</strong></p>\n   *\n   * <p>When LL-fallback is enabled upon SLL conflict, correct predictions are\n   * ensured regardless of how the termination condition is computed by this\n   * method. Due to the substantially higher cost of LL prediction, the\n   * prediction should only fall back to LL when the additional lookahead\n   * cannot lead to a unique SLL prediction.</p>\n   *\n   * <p>Assuming combined SLL+LL parsing, an SLL configuration set with only\n   * conflicting subsets should fall back to full LL, even if the\n   * configuration sets don't resolve to the same alternative (e.g.\n   * {@code {1,2}} and {@code {3,4}}. If there is at least one non-conflicting\n   * configuration, SLL could continue with the hopes that more lookahead will\n   * resolve via one of those non-conflicting configurations.</p>\n   *\n   * <p>Here's the prediction termination rule them: SLL (for SLL+LL parsing)\n   * stops when it sees only conflicting configuration subsets. In contrast,\n   * full LL keeps going when there is uncertainty.</p>\n   *\n   * <p><strong>HEURISTIC</strong></p>\n   *\n   * <p>As a heuristic, we stop prediction when we see any conflicting subset\n   * unless we see a state that only has one alternative associated with it.\n   * The single-alt-state thing lets prediction continue upon rules like\n   * (otherwise, it would admit defeat too soon):</p>\n   *\n   * <p>{@code [12|1|[], 6|2|[], 12|2|[]]. s : (ID | ID ID?) ';' ;}</p>\n   *\n   * <p>When the ATN simulation reaches the state before {@code ';'}, it has a\n   * DFA state that looks like: {@code [12|1|[], 6|2|[], 12|2|[]]}. Naturally\n   * {@code 12|1|[]} and {@code 12|2|[]} conflict, but we cannot stop\n   * processing this node because alternative to has another way to continue,\n   * via {@code [6|2|[]]}.</p>\n   *\n   * <p>It also let's us continue for this rule:</p>\n   *\n   * <p>{@code [1|1|[], 1|2|[], 8|3|[]] a : A | A | A B ;}</p>\n   *\n   * <p>After matching input A, we reach the stop state for rule A, state 1.\n   * State 8 is the state right before B. Clearly alternatives 1 and 2\n   * conflict and no amount of further lookahead will separate the two.\n   * However, alternative 3 will be able to continue and so we do not stop\n   * working on this state. In the previous example, we're concerned with\n   * states associated with the conflicting alternatives. Here alt 3 is not\n   * associated with the conflicting configs, but since we can continue\n   * looking for input reasonably, don't declare the state done.</p>\n   *\n   * <p><strong>PURE SLL PARSING</strong></p>\n   *\n   * <p>To handle pure SLL parsing, all we have to do is make sure that we\n   * combine stack contexts for configurations that differ only by semantic\n   * predicate. From there, we can do the usual SLL termination heuristic.</p>\n   *\n   * <p><strong>PREDICATES IN SLL+LL PARSING</strong></p>\n   *\n   * <p>SLL decisions don't evaluate predicates until after they reach DFA stop\n   * states because they need to create the DFA cache that works in all\n   * semantic situations. In contrast, full LL evaluates predicates collected\n   * during start state computation so it can ignore predicates thereafter.\n   * This means that SLL termination detection can totally ignore semantic\n   * predicates.</p>\n   *\n   * <p>Implementation-wise, {@link ATNConfigSet} combines stack contexts but not\n   * semantic predicate contexts so we might see two configurations like the\n   * following.</p>\n   *\n   * <p>{@code (s, 1, x, {}), (s, 1, x', {p})}</p>\n   *\n   * <p>Before testing these configurations against others, we have to merge\n   * {@code x} and {@code x'} (without modifying the existing configurations).\n   * For example, we test {@code (x+x')==x''} when looking for conflicts in\n   * the following configurations.</p>\n   *\n   * <p>{@code (s, 1, x, {}), (s, 1, x', {p}), (s, 2, x'', {})}</p>\n   *\n   * <p>If the configuration set has predicates (as indicated by\n   * {@link ATNConfigSet//hasSemanticContext}), this algorithm makes a copy of\n   * the configurations to strip out all of the predicates so that a standard\n   * {@link ATNConfigSet} will merge everything ignoring predicates.</p>\n   */\n  hasSLLConflictTerminatingPrediction: function (mode, configs) {\n    // Configs in rule stop states indicate reaching the end of the decision\n    // rule (local context) or end of start rule (full context). If all\n    // configs meet this condition, then none of the configurations is able\n    // to match additional input so we terminate prediction.\n    //\n    if (PredictionMode.allConfigsInRuleStopStates(configs)) {\n      return true;\n    }\n    // pure SLL mode parsing\n    if (mode === PredictionMode.SLL) {\n      // Don't bother with combining configs from different semantic\n      // contexts if we can fail over to full LL; costs more time\n      // since we'll often fail over anyway.\n      if (configs.hasSemanticContext) {\n        // dup configs, tossing out semantic predicates\n        const dup = new ATNConfigSet();\n        for (let i = 0; i < configs.items.length; i++) {\n          let c = configs.items[i];\n          c = new ATNConfig({ semanticContext: SemanticContext.NONE }, c);\n          dup.add(c);\n        }\n        configs = dup;\n      }\n      // now we have combined contexts for configs with dissimilar preds\n    }\n    // pure SLL or combined SLL+LL mode parsing\n    const altsets = PredictionMode.getConflictingAltSubsets(configs);\n    return PredictionMode.hasConflictingAltSet(altsets) && !PredictionMode.hasStateAssociatedWithOneAlt(configs);\n  },\n\n  /**\n   * Checks if any configuration in {@code configs} is in a\n   * {@link RuleStopState}. Configurations meeting this condition have reached\n   * the end of the decision rule (local context) or end of start rule (full\n   * context).\n   *\n   * @param configs the configuration set to test\n   * @return {@code true} if any configuration in {@code configs} is in a\n   * {@link RuleStopState}, otherwise {@code false}\n   */\n  hasConfigInRuleStopState: function (configs) {\n    for (let i = 0; i < configs.items.length; i++) {\n      const c = configs.items[i];\n      if (c.state instanceof RuleStopState) {\n        return true;\n      }\n    }\n    return false;\n  },\n\n  /**\n   * Checks if all configurations in {@code configs} are in a\n   * {@link RuleStopState}. Configurations meeting this condition have reached\n   * the end of the decision rule (local context) or end of start rule (full\n   * context).\n   *\n   * @param configs the configuration set to test\n   * @return {@code true} if all configurations in {@code configs} are in a\n   * {@link RuleStopState}, otherwise {@code false}\n   */\n  allConfigsInRuleStopStates: function (configs) {\n    for (let i = 0; i < configs.items.length; i++) {\n      const c = configs.items[i];\n      if (!(c.state instanceof RuleStopState)) {\n        return false;\n      }\n    }\n    return true;\n  },\n\n  /**\n   *\n   * Full LL prediction termination.\n   *\n   * <p>Can we stop looking ahead during ATN simulation or is there some\n   * uncertainty as to which alternative we will ultimately pick, after\n   * consuming more input? Even if there are partial conflicts, we might know\n   * that everything is going to resolve to the same minimum alternative. That\n   * means we can stop since no more lookahead will change that fact. On the\n   * other hand, there might be multiple conflicts that resolve to different\n   * minimums. That means we need more look ahead to decide which of those\n   * alternatives we should predict.</p>\n   *\n   * <p>The basic idea is to split the set of configurations {@code C}, into\n   * conflicting subsets {@code (s, _, ctx, _)} and singleton subsets with\n   * non-conflicting configurations. Two configurations conflict if they have\n   * identical {@link ATNConfig//state} and {@link ATNConfig//context} values\n   * but different {@link ATNConfig//alt} value, e.g. {@code (s, i, ctx, _)}\n   * and {@code (s, j, ctx, _)} for {@code i!=j}.</p>\n   *\n   * <p>Reduce these configuration subsets to the set of possible alternatives.\n   * You can compute the alternative subsets in one pass as follows:</p>\n   *\n   * <p>{@code A_s,ctx = {i | (s, i, ctx, _)}} for each configuration in\n   * {@code C} holding {@code s} and {@code ctx} fixed.</p>\n   *\n   * <p>Or in pseudo-code, for each configuration {@code c} in {@code C}:</p>\n   *\n   * <pre>\n   * map[c] U= c.{@link ATNConfig//alt alt} // map hash/equals uses s and x, not\n   * alt and not pred\n   * </pre>\n   *\n   * <p>The values in {@code map} are the set of {@code A_s,ctx} sets.</p>\n   *\n   * <p>If {@code |A_s,ctx|=1} then there is no conflict associated with\n   * {@code s} and {@code ctx}.</p>\n   *\n   * <p>Reduce the subsets to singletons by choosing a minimum of each subset. If\n   * the union of these alternative subsets is a singleton, then no amount of\n   * more lookahead will help us. We will always pick that alternative. If,\n   * however, there is more than one alternative, then we are uncertain which\n   * alternative to predict and must continue looking for resolution. We may\n   * or may not discover an ambiguity in the future, even if there are no\n   * conflicting subsets this round.</p>\n   *\n   * <p>The biggest sin is to terminate early because it means we've made a\n   * decision but were uncertain as to the eventual outcome. We haven't used\n   * enough lookahead. On the other hand, announcing a conflict too late is no\n   * big deal; you will still have the conflict. It's just inefficient. It\n   * might even look until the end of file.</p>\n   *\n   * <p>No special consideration for semantic predicates is required because\n   * predicates are evaluated on-the-fly for full LL prediction, ensuring that\n   * no configuration contains a semantic context during the termination\n   * check.</p>\n   *\n   * <p><strong>CONFLICTING CONFIGS</strong></p>\n   *\n   * <p>Two configurations {@code (s, i, x)} and {@code (s, j, x')}, conflict\n   * when {@code i!=j} but {@code x=x'}. Because we merge all\n   * {@code (s, i, _)} configurations together, that means that there are at\n   * most {@code n} configurations associated with state {@code s} for\n   * {@code n} possible alternatives in the decision. The merged stacks\n   * complicate the comparison of configuration contexts {@code x} and\n   * {@code x'}. Sam checks to see if one is a subset of the other by calling\n   * merge and checking to see if the merged result is either {@code x} or\n   * {@code x'}. If the {@code x} associated with lowest alternative {@code i}\n   * is the superset, then {@code i} is the only possible prediction since the\n   * others resolve to {@code min(i)} as well. However, if {@code x} is\n   * associated with {@code j>i} then at least one stack configuration for\n   * {@code j} is not in conflict with alternative {@code i}. The algorithm\n   * should keep going, looking for more lookahead due to the uncertainty.</p>\n   *\n   * <p>For simplicity, I'm doing a equality check between {@code x} and\n   * {@code x'} that lets the algorithm continue to consume lookahead longer\n   * than necessary. The reason I like the equality is of course the\n   * simplicity but also because that is the test you need to detect the\n   * alternatives that are actually in conflict.</p>\n   *\n   * <p><strong>CONTINUE/STOP RULE</strong></p>\n   *\n   * <p>Continue if union of resolved alternative sets from non-conflicting and\n   * conflicting alternative subsets has more than one alternative. We are\n   * uncertain about which alternative to predict.</p>\n   *\n   * <p>The complete set of alternatives, {@code [i for (_,i,_)]}, tells us which\n   * alternatives are still in the running for the amount of input we've\n   * consumed at this point. The conflicting sets let us to strip away\n   * configurations that won't lead to more states because we resolve\n   * conflicts to the configuration with a minimum alternate for the\n   * conflicting set.</p>\n   *\n   * <p><strong>CASES</strong></p>\n   *\n   * <ul>\n   *\n   * <li>no conflicts and more than 1 alternative in set =&gt; continue</li>\n   *\n   * <li> {@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s, 3, z)},\n   * {@code (s', 1, y)}, {@code (s', 2, y)} yields non-conflicting set\n   * {@code {3}} U conflicting sets {@code min({1,2})} U {@code min({1,2})} =\n   * {@code {1,3}} =&gt; continue\n   * </li>\n   *\n   * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 1, y)},\n   * {@code (s', 2, y)}, {@code (s'', 1, z)} yields non-conflicting set\n   * {@code {1}} U conflicting sets {@code min({1,2})} U {@code min({1,2})} =\n   * {@code {1}} =&gt; stop and predict 1</li>\n   *\n   * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 1, y)},\n   * {@code (s', 2, y)} yields conflicting, reduced sets {@code {1}} U\n   * {@code {1}} = {@code {1}} =&gt; stop and predict 1, can announce\n   * ambiguity {@code {1,2}}</li>\n   *\n   * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 2, y)},\n   * {@code (s', 3, y)} yields conflicting, reduced sets {@code {1}} U\n   * {@code {2}} = {@code {1,2}} =&gt; continue</li>\n   *\n   * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 3, y)},\n   * {@code (s', 4, y)} yields conflicting, reduced sets {@code {1}} U\n   * {@code {3}} = {@code {1,3}} =&gt; continue</li>\n   *\n   * </ul>\n   *\n   * <p><strong>EXACT AMBIGUITY DETECTION</strong></p>\n   *\n   * <p>If all states report the same conflicting set of alternatives, then we\n   * know we have the exact ambiguity set.</p>\n   *\n   * <p><code>|A_<em>i</em>|&gt;1</code> and\n   * <code>A_<em>i</em> = A_<em>j</em></code> for all <em>i</em>, <em>j</em>.</p>\n   *\n   * <p>In other words, we continue examining lookahead until all {@code A_i}\n   * have more than one alternative and all {@code A_i} are the same. If\n   * {@code A={{1,2}, {1,3}}}, then regular LL prediction would terminate\n   * because the resolved set is {@code {1}}. To determine what the real\n   * ambiguity is, we have to know whether the ambiguity is between one and\n   * two or one and three so we keep going. We can only stop prediction when\n   * we need exact ambiguity detection when the sets look like\n   * {@code A={{1,2}}} or {@code {{1,2},{1,2}}}, etc...</p>\n   */\n  resolvesToJustOneViableAlt: function (altsets) {\n    return PredictionMode.getSingleViableAlt(altsets);\n  },\n\n  /**\n   * Determines if every alternative subset in {@code altsets} contains more\n   * than one alternative.\n   *\n   * @param altsets a collection of alternative subsets\n   * @return {@code true} if every {@link BitSet} in {@code altsets} has\n   * {@link BitSet//cardinality cardinality} &gt; 1, otherwise {@code false}\n   */\n  allSubsetsConflict: function (altsets) {\n    return !PredictionMode.hasNonConflictingAltSet(altsets);\n  },\n  /**\n   * Determines if any single alternative subset in {@code altsets} contains\n   * exactly one alternative.\n   *\n   * @param altsets a collection of alternative subsets\n   * @return {@code true} if {@code altsets} contains a {@link BitSet} with\n   * {@link BitSet//cardinality cardinality} 1, otherwise {@code false}\n   */\n  hasNonConflictingAltSet: function (altsets) {\n    for (let i = 0; i < altsets.length; i++) {\n      const alts = altsets[i];\n      if (alts.length === 1) {\n        return true;\n      }\n    }\n    return false;\n  },\n\n  /**\n   * Determines if any single alternative subset in {@code altsets} contains\n   * more than one alternative.\n   *\n   * @param altsets a collection of alternative subsets\n   * @return {@code true} if {@code altsets} contains a {@link BitSet} with\n   * {@link BitSet//cardinality cardinality} &gt; 1, otherwise {@code false}\n   */\n  hasConflictingAltSet: function (altsets) {\n    for (let i = 0; i < altsets.length; i++) {\n      const alts = altsets[i];\n      if (alts.length > 1) {\n        return true;\n      }\n    }\n    return false;\n  },\n\n  /**\n   * Determines if every alternative subset in {@code altsets} is equivalent.\n   *\n   * @param altsets a collection of alternative subsets\n   * @return {@code true} if every member of {@code altsets} is equal to the\n   * others, otherwise {@code false}\n   */\n  allSubsetsEqual: function (altsets) {\n    let first = null;\n    for (let i = 0; i < altsets.length; i++) {\n      const alts = altsets[i];\n      if (first === null) {\n        first = alts;\n      } else if (alts !== first) {\n        return false;\n      }\n    }\n    return true;\n  },\n\n  /**\n   * Returns the unique alternative predicted by all alternative subsets in\n   * {@code altsets}. If no such alternative exists, this method returns\n   * {@link ATN//INVALID_ALT_NUMBER}.\n   *\n   * @param altsets a collection of alternative subsets\n   */\n  getUniqueAlt: function (altsets) {\n    const all = PredictionMode.getAlts(altsets);\n    if (all.length === 1) {\n      return all.minValue();\n    } else {\n      return ATN.INVALID_ALT_NUMBER;\n    }\n  },\n\n  /**\n   * Gets the complete set of represented alternatives for a collection of\n   * alternative subsets. This method returns the union of each {@link BitSet}\n   * in {@code altsets}.\n   *\n   * @param altsets a collection of alternative subsets\n   * @return the set of represented alternatives in {@code altsets}\n   */\n  getAlts: function (altsets) {\n    const all = new BitSet();\n    altsets.map(function (alts) {\n      all.or(alts);\n    });\n    return all;\n  },\n\n  /**\n   * This function gets the conflicting alt subsets from a configuration set.\n   * For each configuration {@code c} in {@code configs}:\n   *\n   * <pre>\n   * map[c] U= c.{@link ATNConfig//alt alt} // map hash/equals uses s and x, not\n   * alt and not pred\n   * </pre>\n   */\n  getConflictingAltSubsets: function (configs) {\n    const configToAlts = new HashMap();\n    configToAlts.hashFunction = function (cfg) {\n      HashCode.hashStuff(cfg.state.stateNumber, cfg.context);\n    };\n    configToAlts.equalsFunction = function (c1, c2) {\n      return c1.state.stateNumber === c2.state.stateNumber && c1.context.equals(c2.context);\n    };\n    configs.items.map(function (cfg) {\n      let alts = configToAlts.get(cfg);\n      if (alts === null) {\n        alts = new BitSet();\n        configToAlts.set(cfg, alts);\n      }\n      alts.add(cfg.alt);\n    });\n    return configToAlts.getValues();\n  },\n\n  /**\n   * Get a map from state to alt subset from a configuration set. For each\n   * configuration {@code c} in {@code configs}:\n   *\n   * <pre>\n   * map[c.{@link ATNConfig//state state}] U= c.{@link ATNConfig//alt alt}\n   * </pre>\n   */\n  getStateToAltMap: function (configs) {\n    const m = new AltDict();\n    configs.items.map(function (c) {\n      let alts = m.get(c.state);\n      if (alts === null) {\n        alts = new BitSet();\n        m.set(c.state, alts);\n      }\n      alts.add(c.alt);\n    });\n    return m;\n  },\n\n  hasStateAssociatedWithOneAlt: function (configs) {\n    const values = PredictionMode.getStateToAltMap(configs).values();\n    for (let i = 0; i < values.length; i++) {\n      if (values[i].length === 1) {\n        return true;\n      }\n    }\n    return false;\n  },\n\n  getSingleViableAlt: function (altsets) {\n    let result = null;\n    for (let i = 0; i < altsets.length; i++) {\n      const alts = altsets[i];\n      const minAlt = alts.minValue();\n      if (result === null) {\n        result = minAlt;\n      } else if (result !== minAlt) {\n        // more than 1 viable alt\n        return ATN.INVALID_ALT_NUMBER;\n      }\n    }\n    return result;\n  },\n};\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { HashMap } from '../misc/HashMap.js';\n\nexport class DoubleDict {\n  constructor(defaultMapCtor) {\n    this.defaultMapCtor = defaultMapCtor || HashMap;\n    this.cacheMap = new this.defaultMapCtor();\n  }\n\n  get(a, b) {\n    const d = this.cacheMap.get(a) || null;\n    return d === null ? null : d.get(b) || null;\n  }\n\n  set(a, b, o) {\n    let d = this.cacheMap.get(a) || null;\n    if (d === null) {\n      d = new this.defaultMapCtor();\n      this.cacheMap.set(a, d);\n    }\n    d.set(b, o);\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { ATN } from './ATN.js';\nimport { ATNState } from '../state/ATNState.js';\nimport { RuleStopState } from '../state/RuleStopState.js';\nimport { ATNConfig } from './ATNConfig.js';\nimport { ATNConfigSet } from './ATNConfigSet.js';\nimport { Token } from '../Token.js';\nimport { DFAState } from '../dfa/DFAState.js';\nimport { PredPrediction } from '../dfa/PredPrediction.js';\nimport { ATNSimulator } from './ATNSimulator.js';\nimport { PredictionMode } from './PredictionMode.js';\nimport { RuleContext } from '../context/RuleContext.js';\nimport { SemanticContext } from './SemanticContext.js';\nimport { PredictionContext } from '../context/PredictionContext.js';\nimport { Interval } from '../misc/Interval.js';\nimport { Transition } from '../transition/Transition.js';\nimport { SetTransition } from '../transition/SetTransition.js';\nimport { NotSetTransition } from '../transition/NotSetTransition.js';\nimport { RuleTransition } from '../transition/RuleTransition.js';\nimport { ActionTransition } from '../transition/ActionTransition.js';\nimport { NoViableAltException } from '../error/NoViableAltException.js';\nimport { SingletonPredictionContext } from '../context/SingletonPredictionContext.js';\nimport { predictionContextFromRuleContext } from '../context/PredictionContextUtils.js';\nimport { AtomTransition } from '../transition/AtomTransition.js';\nimport { arrayToString } from '../utils/index.js';\nimport { BitSet } from '../misc/BitSet.js';\nimport { DoubleDict } from '../utils/DoubleDict.js';\nimport { HashSet } from '../misc/HashSet.js';\n\n/**\n * The embodiment of the adaptive LL(*), ALL(*), parsing strategy.\n *\n * <p>\n * The basic complexity of the adaptive strategy makes it harder to understand.\n * We begin with ATN simulation to build paths in a DFA. Subsequent prediction\n * requests go through the DFA first. If they reach a state without an edge for\n * the current symbol, the algorithm fails over to the ATN simulation to\n * complete the DFA path for the current input (until it finds a conflict state\n * or uniquely predicting state).</p>\n *\n * <p>\n * All of that is done without using the outer context because we want to create\n * a DFA that is not dependent upon the rule invocation stack when we do a\n * prediction. One DFA works in all contexts. We avoid using context not\n * necessarily because it's slower, although it can be, but because of the DFA\n * caching problem. The closure routine only considers the rule invocation stack\n * created during prediction beginning in the decision rule. For example, if\n * prediction occurs without invoking another rule's ATN, there are no context\n * stacks in the configurations. When lack of context leads to a conflict, we\n * don't know if it's an ambiguity or a weakness in the strong LL(*) parsing\n * strategy (versus full LL(*)).</p>\n *\n * <p>\n * When SLL yields a configuration set with conflict, we rewind the input and\n * retry the ATN simulation, this time using full outer context without adding\n * to the DFA. Configuration context stacks will be the full invocation stacks\n * from the start rule. If we get a conflict using full context, then we can\n * definitively say we have a true ambiguity for that input sequence. If we\n * don't get a conflict, it implies that the decision is sensitive to the outer\n * context. (It is not context-sensitive in the sense of context-sensitive\n * grammars.)</p>\n *\n * <p>\n * The next time we reach this DFA state with an SLL conflict, through DFA\n * simulation, we will again retry the ATN simulation using full context mode.\n * This is slow because we can't save the results and have to \"interpret\" the\n * ATN each time we get that input.</p>\n *\n * <p>\n * <strong>CACHING FULL CONTEXT PREDICTIONS</strong></p>\n *\n * <p>\n * We could cache results from full context to predicted alternative easily and\n * that saves a lot of time but doesn't work in presence of predicates. The set\n * of visible predicates from the ATN start state changes depending on the\n * context, because closure can fall off the end of a rule. I tried to cache\n * tuples (stack context, semantic context, predicted alt) but it was slower\n * than interpreting and much more complicated. Also required a huge amount of\n * memory. The goal is not to create the world's fastest parser anyway. I'd like\n * to keep this algorithm simple. By launching multiple threads, we can improve\n * the speed of parsing across a large number of files.</p>\n *\n * <p>\n * There is no strict ordering between the amount of input used by SLL vs LL,\n * which makes it really hard to build a cache for full context. Let's say that\n * we have input A B C that leads to an SLL conflict with full context X. That\n * implies that using X we might only use A B but we could also use A B C D to\n * resolve conflict. Input A B C D could predict alternative 1 in one position\n * in the input and A B C E could predict alternative 2 in another position in\n * input. The conflicting SLL configurations could still be non-unique in the\n * full context prediction, which would lead us to requiring more input than the\n * original A B C.  To make a  prediction cache work, we have to track  the exact\n * input  used during the previous prediction. That amounts to a cache that maps\n * X to a specific DFA for that context.</p>\n *\n * <p>\n * Something should be done for left-recursive expression predictions. They are\n * likely LL(1) + pred eval. Easier to do the whole SLL unless error and retry\n * with full LL thing Sam does.</p>\n *\n * <p>\n * <strong>AVOIDING FULL CONTEXT PREDICTION</strong></p>\n *\n * <p>\n * We avoid doing full context retry when the outer context is empty, we did not\n * dip into the outer context by falling off the end of the decision state rule,\n * or when we force SLL mode.</p>\n *\n * <p>\n * As an example of the not dip into outer context case, consider as super\n * constructor calls versus function calls. One grammar might look like\n * this:</p>\n *\n * <pre>\n * ctorBody\n *   : '{' superCall? stat* '}'\n *   ;\n * </pre>\n *\n * <p>\n * Or, you might see something like</p>\n *\n * <pre>\n * stat\n *   : superCall ';'\n *   | expression ';'\n *   | ...\n *   ;\n * </pre>\n *\n * <p>\n * In both cases I believe that no closure operations will dip into the outer\n * context. In the first case ctorBody in the worst case will stop at the '}'.\n * In the 2nd case it should stop at the ';'. Both cases should stay within the\n * entry rule and not dip into the outer context.</p>\n *\n * <p>\n * <strong>PREDICATES</strong></p>\n *\n * <p>\n * Predicates are always evaluated if present in either SLL or LL both. SLL and\n * LL simulation deals with predicates differently. SLL collects predicates as\n * it performs closure operations like ANTLR v3 did. It delays predicate\n * evaluation until it reaches and accept state. This allows us to cache the SLL\n * ATN simulation whereas, if we had evaluated predicates on-the-fly during\n * closure, the DFA state configuration sets would be different and we couldn't\n * build up a suitable DFA.</p>\n *\n * <p>\n * When building a DFA accept state during ATN simulation, we evaluate any\n * predicates and return the sole semantically valid alternative. If there is\n * more than 1 alternative, we report an ambiguity. If there are 0 alternatives,\n * we throw an exception. Alternatives without predicates act like they have\n * true predicates. The simple way to think about it is to strip away all\n * alternatives with false predicates and choose the minimum alternative that\n * remains.</p>\n *\n * <p>\n * When we start in the DFA and reach an accept state that's predicated, we test\n * those and return the minimum semantically viable alternative. If no\n * alternatives are viable, we throw an exception.</p>\n *\n * <p>\n * During full LL ATN simulation, closure always evaluates predicates and\n * on-the-fly. This is crucial to reducing the configuration set size during\n * closure. It hits a landmine when parsing with the Java grammar, for example,\n * without this on-the-fly evaluation.</p>\n *\n * <p>\n * <strong>SHARING DFA</strong></p>\n *\n * <p>\n * All instances of the same parser share the same decision DFAs through a\n * static field. Each instance gets its own ATN simulator but they share the\n * same {@link //decisionToDFA} field. They also share a\n * {@link PredictionContextCache} object that makes sure that all\n * {@link PredictionContext} objects are shared among the DFA states. This makes\n * a big size difference.</p>\n *\n * <p>\n * <strong>THREAD SAFETY</strong></p>\n *\n * <p>\n * The {@link ParserATNSimulator} locks on the {@link //decisionToDFA} field when\n * it adds a new DFA object to that array. {@link //addDFAEdge}\n * locks on the DFA for the current decision when setting the\n * {@link DFAState//edges} field. {@link //addDFAState} locks on\n * the DFA for the current decision when looking up a DFA state to see if it\n * already exists. We must make sure that all requests to add DFA states that\n * are equivalent result in the same shared DFA object. This is because lots of\n * threads will be trying to update the DFA at once. The\n * {@link //addDFAState} method also locks inside the DFA lock\n * but this time on the shared context cache when it rebuilds the\n * configurations' {@link PredictionContext} objects using cached\n * subgraphs/nodes. No other locking occurs, even during DFA simulation. This is\n * safe as long as we can guarantee that all threads referencing\n * {@code s.edge[t]} get the same physical target {@link DFAState}, or\n * {@code null}. Once into the DFA, the DFA simulation does not reference the\n * {@link DFA//states} map. It follows the {@link DFAState//edges} field to new\n * targets. The DFA simulator will either find {@link DFAState//edges} to be\n * {@code null}, to be non-{@code null} and {@code dfa.edges[t]} null, or\n * {@code dfa.edges[t]} to be non-null. The\n * {@link //addDFAEdge} method could be racing to set the field\n * but in either case the DFA simulator works; if {@code null}, and requests ATN\n * simulation. It could also race trying to get {@code dfa.edges[t]}, but either\n * way it will work because it's not doing a test and set operation.</p>\n *\n * <p>\n * <strong>Starting with SLL then failing to combined SLL/LL (Two-Stage\n * Parsing)</strong></p>\n *\n * <p>\n * Sam pointed out that if SLL does not give a syntax error, then there is no\n * point in doing full LL, which is slower. We only have to try LL if we get a\n * syntax error. For maximum speed, Sam starts the parser set to pure SLL\n * mode with the {@link BailErrorStrategy}:</p>\n *\n * <pre>\n * parser.{@link Parser//getInterpreter() getInterpreter()}.{@link //setPredictionMode setPredictionMode}{@code (}{@link PredictionMode//SLL}{@code )};\n * parser.{@link Parser//setErrorHandler setErrorHandler}(new {@link BailErrorStrategy}());\n * </pre>\n *\n * <p>\n * If it does not get a syntax error, then we're done. If it does get a syntax\n * error, we need to retry with the combined SLL/LL strategy.</p>\n *\n * <p>\n * The reason this works is as follows. If there are no SLL conflicts, then the\n * grammar is SLL (at least for that input set). If there is an SLL conflict,\n * the full LL analysis must yield a set of viable alternatives which is a\n * subset of the alternatives reported by SLL. If the LL set is a singleton,\n * then the grammar is LL but not SLL. If the LL set is the same size as the SLL\n * set, the decision is SLL. If the LL set has size &gt; 1, then that decision\n * is truly ambiguous on the current input. If the LL set is smaller, then the\n * SLL conflict resolution might choose an alternative that the full LL would\n * rule out as a possibility based upon better context information. If that's\n * the case, then the SLL parse will definitely get an error because the full LL\n * analysis says it's not viable. If SLL conflict resolution chooses an\n * alternative within the LL set, them both SLL and LL would choose the same\n * alternative because they both choose the minimum of multiple conflicting\n * alternatives.</p>\n *\n * <p>\n * Let's say we have a set of SLL conflicting alternatives {@code {1, 2, 3}} and\n * a smaller LL set called <em>s</em>. If <em>s</em> is {@code {2, 3}}, then SLL\n * parsing will get an error because SLL will pursue alternative 1. If\n * <em>s</em> is {@code {1, 2}} or {@code {1, 3}} then both SLL and LL will\n * choose the same alternative because alternative one is the minimum of either\n * set. If <em>s</em> is {@code {2}} or {@code {3}} then SLL will get a syntax\n * error. If <em>s</em> is {@code {1}} then SLL will succeed.</p>\n *\n * <p>\n * Of course, if the input is invalid, then we will get an error for sure in\n * both SLL and LL parsing. Erroneous input will therefore require 2 passes over\n * the input.</p>\n */\nexport class ParserATNSimulator extends ATNSimulator {\n  constructor(parser, atn, decisionToDFA, sharedContextCache) {\n    super(atn, sharedContextCache);\n    this.parser = parser;\n    this.decisionToDFA = decisionToDFA;\n    // SLL, LL, or LL + exact ambig detection?//\n    this.predictionMode = PredictionMode.LL;\n    // LAME globals to avoid parameters!!!!! I need these down deep in predTransition\n    this._input = null;\n    this._startIndex = 0;\n    this._outerContext = null;\n    this._dfa = null;\n    /**\n     * Each prediction operation uses a cache for merge of prediction contexts.\n     *  Don't keep around as it wastes huge amounts of memory. DoubleKeyMap\n     *  isn't synchronized but we're ok since two threads shouldn't reuse same\n     *  parser/atnsim object because it can only handle one input at a time.\n     *  This maps graphs a and b to merged result c. (a,b)&rarr;c. We can avoid\n     *  the merge if we ever see a and b again.  Note that (b,a)&rarr;c should\n     *  also be examined during cache lookup.\n     */\n    this.mergeCache = null;\n    this.debug = false;\n    this.debug_closure = false;\n    this.debug_add = false;\n    this.trace_atn_sim = false;\n    this.dfa_debug = false;\n    this.retry_debug = false;\n  }\n\n  reset() {}\n\n  adaptivePredict(input, decision, outerContext) {\n    if (this.debug || this.trace_atn_sim) {\n      console.log(\n        'adaptivePredict decision ' +\n          decision +\n          ' exec LA(1)==' +\n          this.getLookaheadName(input) +\n          ' line ' +\n          input.LT(1).line +\n          ':' +\n          input.LT(1).column,\n      );\n    }\n    this._input = input;\n    this._startIndex = input.index;\n    this._outerContext = outerContext;\n\n    const dfa = this.decisionToDFA[decision];\n    this._dfa = dfa;\n    const m = input.mark();\n    const index = input.index;\n\n    // Now we are certain to have a specific decision's DFA\n    // But, do we still need an initial state?\n    try {\n      let s0;\n      if (dfa.precedenceDfa) {\n        // the start state for a precedence DFA depends on the current\n        // parser precedence, and is provided by a DFA method.\n        s0 = dfa.getPrecedenceStartState(this.parser.getPrecedence());\n      } else {\n        // the start state for a \"regular\" DFA is just s0\n        s0 = dfa.s0;\n      }\n      if (s0 === null) {\n        if (outerContext === null) {\n          outerContext = RuleContext.EMPTY;\n        }\n        if (this.debug) {\n          console.log(\n            'predictATN decision ' +\n              dfa.decision +\n              ' exec LA(1)==' +\n              this.getLookaheadName(input) +\n              ', outerContext=' +\n              outerContext.toString(this.parser.ruleNames),\n          );\n        }\n\n        const fullCtx = false;\n        let s0_closure = this.computeStartState(dfa.atnStartState, RuleContext.EMPTY, fullCtx);\n\n        if (dfa.precedenceDfa) {\n          // If this is a precedence DFA, we use applyPrecedenceFilter\n          // to convert the computed start state to a precedence start\n          // state. We then use DFA.setPrecedenceStartState to set the\n          // appropriate start state for the precedence level rather\n          // than simply setting DFA.s0.\n          //\n          dfa.s0.configs = s0_closure; // not used for prediction but useful to know start configs anyway\n          s0_closure = this.applyPrecedenceFilter(s0_closure);\n          s0 = this.addDFAState(dfa, new DFAState(null, s0_closure));\n          dfa.setPrecedenceStartState(this.parser.getPrecedence(), s0);\n        } else {\n          s0 = this.addDFAState(dfa, new DFAState(null, s0_closure));\n          dfa.s0 = s0;\n        }\n      }\n      const alt = this.execATN(dfa, s0, input, index, outerContext);\n      if (this.debug) {\n        console.log('DFA after predictATN: ' + dfa.toString(this.parser.literalNames, this.parser.symbolicNames));\n      }\n      return alt;\n    } finally {\n      this._dfa = null;\n      this.mergeCache = null; // wack cache after each prediction\n      input.seek(index);\n      input.release(m);\n    }\n  }\n\n  /**\n   * Performs ATN simulation to compute a predicted alternative based\n   *  upon the remaining input, but also updates the DFA cache to avoid\n   *  having to traverse the ATN again for the same input sequence.\n   *\n   * There are some key conditions we're looking for after computing a new\n   * set of ATN configs (proposed DFA state):\n   *       if the set is empty, there is no viable alternative for current symbol\n   *       does the state uniquely predict an alternative?\n   *       does the state have a conflict that would prevent us from\n   *         putting it on the work list?\n   *\n   * We also have some key operations to do:\n   *       add an edge from previous DFA state to potentially new DFA state, D,\n   *         upon current symbol but only if adding to work list, which means in all\n   *         cases except no viable alternative (and possibly non-greedy decisions?)\n   *       collecting predicates and adding semantic context to DFA accept states\n   *       adding rule context to context-sensitive DFA accept states\n   *       consuming an input symbol\n   *       reporting a conflict\n   *       reporting an ambiguity\n   *       reporting a context sensitivity\n   *       reporting insufficient predicates\n   *\n   * cover these cases:\n   *    dead end\n   *    single alt\n   *    single alt + preds\n   *    conflict\n   *    conflict + preds\n   *\n   */\n  execATN(dfa, s0, input, startIndex, outerContext) {\n    if (this.debug || this.trace_atn_sim) {\n      console.log(\n        'execATN decision ' +\n          dfa.decision +\n          ', DFA state ' +\n          s0 +\n          ', LA(1)==' +\n          this.getLookaheadName(input) +\n          ' line ' +\n          input.LT(1).line +\n          ':' +\n          input.LT(1).column,\n      );\n    }\n    let alt;\n    let previousD = s0;\n\n    if (this.debug) {\n      console.log('s0 = ' + s0);\n    }\n    let t = input.LA(1);\n    for (;;) {\n      // while more work\n      let D = this.getExistingTargetState(previousD, t);\n      if (D === null) {\n        D = this.computeTargetState(dfa, previousD, t);\n      }\n      if (D === ATNSimulator.ERROR) {\n        // if any configs in previous dipped into outer context, that\n        // means that input up to t actually finished entry rule\n        // at least for SLL decision. Full LL doesn't dip into outer\n        // so don't need special case.\n        // We will get an error no matter what so delay until after\n        // decision; better error message. Also, no reachable target\n        // ATN states in SLL implies LL will also get nowhere.\n        // If conflict in states that dip out, choose min since we\n        // will get error no matter what.\n        const e = this.noViableAlt(input, outerContext, previousD.configs, startIndex);\n        input.seek(startIndex);\n        alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previousD.configs, outerContext);\n        if (alt !== ATN.INVALID_ALT_NUMBER) {\n          return alt;\n        } else {\n          throw e;\n        }\n      }\n      if (D.requiresFullContext && this.predictionMode !== PredictionMode.SLL) {\n        // IF PREDS, MIGHT RESOLVE TO SINGLE ALT => SLL (or syntax error)\n        let conflictingAlts = null;\n        if (D.predicates !== null) {\n          if (this.debug) {\n            console.log('DFA state has preds in DFA sim LL failover');\n          }\n          const conflictIndex = input.index;\n          if (conflictIndex !== startIndex) {\n            input.seek(startIndex);\n          }\n          conflictingAlts = this.evalSemanticContext(D.predicates, outerContext, true);\n          if (conflictingAlts.length === 1) {\n            if (this.debug) {\n              console.log('Full LL avoided');\n            }\n            return conflictingAlts.minValue();\n          }\n          if (conflictIndex !== startIndex) {\n            // restore the index so reporting the fallback to full\n            // context occurs with the index at the correct spot\n            input.seek(conflictIndex);\n          }\n        }\n        if (this.dfa_debug) {\n          console.log('ctx sensitive state ' + outerContext + ' in ' + D);\n        }\n        const fullCtx = true;\n        const s0_closure = this.computeStartState(dfa.atnStartState, outerContext, fullCtx);\n        this.reportAttemptingFullContext(dfa, conflictingAlts, D.configs, startIndex, input.index);\n        alt = this.execATNWithFullContext(dfa, D, s0_closure, input, startIndex, outerContext);\n        return alt;\n      }\n      if (D.isAcceptState) {\n        if (D.predicates === null) {\n          return D.prediction;\n        }\n        const stopIndex = input.index;\n        input.seek(startIndex);\n        const alts = this.evalSemanticContext(D.predicates, outerContext, true);\n        if (alts.length === 0) {\n          throw this.noViableAlt(input, outerContext, D.configs, startIndex);\n        } else if (alts.length === 1) {\n          return alts.minValue();\n        } else {\n          // report ambiguity after predicate evaluation to make sure the correct set of ambig alts is reported.\n          this.reportAmbiguity(dfa, D, startIndex, stopIndex, false, alts, D.configs);\n          return alts.minValue();\n        }\n      }\n      previousD = D;\n\n      if (t !== Token.EOF) {\n        input.consume();\n        t = input.LA(1);\n      }\n    }\n  }\n\n  /**\n   * Get an existing target state for an edge in the DFA. If the target state\n   * for the edge has not yet been computed or is otherwise not available,\n   * this method returns {@code null}.\n   *\n   * @param previousD The current DFA state\n   * @param t The next input symbol\n   * @return The existing target DFA state for the given input symbol\n   * {@code t}, or {@code null} if the target state for this edge is not\n   * already cached\n   */\n  getExistingTargetState(previousD, t) {\n    const edges = previousD.edges;\n    if (edges === null) {\n      return null;\n    } else {\n      return edges[t + 1] || null;\n    }\n  }\n\n  /**\n   * Compute a target state for an edge in the DFA, and attempt to add the\n   * computed state and corresponding edge to the DFA.\n   *\n   * @param dfa The DFA\n   * @param previousD The current DFA state\n   * @param t The next input symbol\n   *\n   * @return The computed target DFA state for the given input symbol\n   * {@code t}. If {@code t} does not lead to a valid DFA state, this method\n   * returns {@link //ERROR\n   */\n  computeTargetState(dfa, previousD, t) {\n    const reach = this.computeReachSet(previousD.configs, t, false);\n    if (reach === null) {\n      this.addDFAEdge(dfa, previousD, t, ATNSimulator.ERROR);\n      return ATNSimulator.ERROR;\n    }\n    // create new target state; we'll add to DFA after it's complete\n    let D = new DFAState(null, reach);\n\n    const predictedAlt = this.getUniqueAlt(reach);\n\n    if (this.debug) {\n      const altSubSets = PredictionMode.getConflictingAltSubsets(reach);\n      console.log(\n        'SLL altSubSets=' +\n          arrayToString(altSubSets) +\n          /*\", previous=\" + previousD.configs + */\n          ', configs=' +\n          reach +\n          ', predict=' +\n          predictedAlt +\n          ', allSubsetsConflict=' +\n          PredictionMode.allSubsetsConflict(altSubSets) +\n          ', conflictingAlts=' +\n          this.getConflictingAlts(reach),\n      );\n    }\n    if (predictedAlt !== ATN.INVALID_ALT_NUMBER) {\n      // NO CONFLICT, UNIQUELY PREDICTED ALT\n      D.isAcceptState = true;\n      D.configs.uniqueAlt = predictedAlt;\n      D.prediction = predictedAlt;\n    } else if (PredictionMode.hasSLLConflictTerminatingPrediction(this.predictionMode, reach)) {\n      // MORE THAN ONE VIABLE ALTERNATIVE\n      D.configs.conflictingAlts = this.getConflictingAlts(reach);\n      D.requiresFullContext = true;\n      // in SLL-only mode, we will stop at this state and return the minimum alt\n      D.isAcceptState = true;\n      D.prediction = D.configs.conflictingAlts.minValue();\n    }\n    if (D.isAcceptState && D.configs.hasSemanticContext) {\n      this.predicateDFAState(D, this.atn.getDecisionState(dfa.decision));\n      if (D.predicates !== null) {\n        D.prediction = ATN.INVALID_ALT_NUMBER;\n      }\n    }\n    // all adds to dfa are done after we've created full D state\n    D = this.addDFAEdge(dfa, previousD, t, D);\n    return D;\n  }\n\n  predicateDFAState(dfaState, decisionState) {\n    // We need to test all predicates, even in DFA states that\n    // uniquely predict alternative.\n    const nalts = decisionState.transitions.length;\n    // Update DFA so reach becomes accept state with (predicate,alt)\n    // pairs if preds found for conflicting alts\n    const altsToCollectPredsFrom = this.getConflictingAltsOrUniqueAlt(dfaState.configs);\n    const altToPred = this.getPredsForAmbigAlts(altsToCollectPredsFrom, dfaState.configs, nalts);\n    if (altToPred !== null) {\n      dfaState.predicates = this.getPredicatePredictions(altsToCollectPredsFrom, altToPred);\n      dfaState.prediction = ATN.INVALID_ALT_NUMBER; // make sure we use preds\n    } else {\n      // There are preds in configs but they might go away\n      // when OR'd together like {p}? || NONE == NONE. If neither\n      // alt has preds, resolve to min alt\n      dfaState.prediction = altsToCollectPredsFrom.minValue();\n    }\n  }\n\n  // comes back with reach.uniqueAlt set to a valid alt\n  execATNWithFullContext(\n    dfa,\n    D, // how far we got before failing over\n    s0,\n    input,\n    startIndex,\n    outerContext,\n  ) {\n    if (this.debug || this.trace_atn_sim) {\n      console.log('execATNWithFullContext ' + s0);\n    }\n    const fullCtx = true;\n    let foundExactAmbig = false;\n    let reach;\n    let previous = s0;\n    input.seek(startIndex);\n    let t = input.LA(1);\n    let predictedAlt = -1;\n    for (;;) {\n      // while more work\n      reach = this.computeReachSet(previous, t, fullCtx);\n      if (reach === null) {\n        // if any configs in previous dipped into outer context, that\n        // means that input up to t actually finished entry rule\n        // at least for LL decision. Full LL doesn't dip into outer\n        // so don't need special case.\n        // We will get an error no matter what so delay until after\n        // decision; better error message. Also, no reachable target\n        // ATN states in SLL implies LL will also get nowhere.\n        // If conflict in states that dip out, choose min since we\n        // will get error no matter what.\n        const e = this.noViableAlt(input, outerContext, previous, startIndex);\n        input.seek(startIndex);\n        const alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previous, outerContext);\n        if (alt !== ATN.INVALID_ALT_NUMBER) {\n          return alt;\n        } else {\n          throw e;\n        }\n      }\n      const altSubSets = PredictionMode.getConflictingAltSubsets(reach);\n      if (this.debug) {\n        console.log(\n          'LL altSubSets=' +\n            altSubSets +\n            ', predict=' +\n            PredictionMode.getUniqueAlt(altSubSets) +\n            ', resolvesToJustOneViableAlt=' +\n            PredictionMode.resolvesToJustOneViableAlt(altSubSets),\n        );\n      }\n      reach.uniqueAlt = this.getUniqueAlt(reach);\n      // unique prediction?\n      if (reach.uniqueAlt !== ATN.INVALID_ALT_NUMBER) {\n        predictedAlt = reach.uniqueAlt;\n        break;\n      } else if (this.predictionMode !== PredictionMode.LL_EXACT_AMBIG_DETECTION) {\n        predictedAlt = PredictionMode.resolvesToJustOneViableAlt(altSubSets);\n        if (predictedAlt !== ATN.INVALID_ALT_NUMBER) {\n          break;\n        }\n      } else {\n        // In exact ambiguity mode, we never try to terminate early.\n        // Just keeps scarfing until we know what the conflict is\n        if (PredictionMode.allSubsetsConflict(altSubSets) && PredictionMode.allSubsetsEqual(altSubSets)) {\n          foundExactAmbig = true;\n          predictedAlt = PredictionMode.getSingleViableAlt(altSubSets);\n          break;\n        }\n        // else there are multiple non-conflicting subsets or\n        // we're not sure what the ambiguity is yet.\n        // So, keep going.\n      }\n      previous = reach;\n      if (t !== Token.EOF) {\n        input.consume();\n        t = input.LA(1);\n      }\n    }\n    // If the configuration set uniquely predicts an alternative,\n    // without conflict, then we know that it's a full LL decision\n    // not SLL.\n    if (reach.uniqueAlt !== ATN.INVALID_ALT_NUMBER) {\n      this.reportContextSensitivity(dfa, predictedAlt, reach, startIndex, input.index);\n      return predictedAlt;\n    }\n    // We do not check predicates here because we have checked them\n    // on-the-fly when doing full context prediction.\n\n    //\n    // In non-exact ambiguity detection mode, we might\tactually be able to\n    // detect an exact ambiguity, but I'm not going to spend the cycles\n    // needed to check. We only emit ambiguity warnings in exact ambiguity\n    // mode.\n    //\n    // For example, we might know that we have conflicting configurations.\n    // But, that does not mean that there is no way forward without a\n    // conflict. It's possible to have nonconflicting alt subsets as in:\n\n    // altSubSets=[{1, 2}, {1, 2}, {1}, {1, 2}]\n\n    // from\n    //\n    //    [(17,1,[5 $]), (13,1,[5 10 $]), (21,1,[5 10 $]), (11,1,[$]),\n    //     (13,2,[5 10 $]), (21,2,[5 10 $]), (11,2,[$])]\n    //\n    // In this case, (17,1,[5 $]) indicates there is some next sequence that\n    // would resolve this without conflict to alternative 1. Any other viable\n    // next sequence, however, is associated with a conflict.  We stop\n    // looking for input because no amount of further lookahead will alter\n    // the fact that we should predict alternative 1.  We just can't say for\n    // sure that there is an ambiguity without looking further.\n\n    this.reportAmbiguity(dfa, D, startIndex, input.index, foundExactAmbig, null, reach);\n\n    return predictedAlt;\n  }\n\n  computeReachSet(closure, t, fullCtx) {\n    if (this.debug) {\n      console.log('in computeReachSet, starting closure: ' + closure);\n    }\n    if (this.mergeCache === null) {\n      this.mergeCache = new DoubleDict();\n    }\n    const intermediate = new ATNConfigSet(fullCtx);\n\n    // Configurations already in a rule stop state indicate reaching the end\n    // of the decision rule (local context) or end of the start rule (full\n    // context). Once reached, these configurations are never updated by a\n    // closure operation, so they are handled separately for the performance\n    // advantage of having a smaller intermediate set when calling closure.\n    //\n    // For full-context reach operations, separate handling is required to\n    // ensure that the alternative matching the longest overall sequence is\n    // chosen when multiple such configurations can match the input.\n\n    let skippedStopStates = null;\n\n    // First figure out where we can reach on input t\n    for (let i = 0; i < closure.items.length; i++) {\n      const c = closure.items[i];\n      if (this.debug) {\n        console.log('testing ' + this.getTokenName(t) + ' at ' + c);\n      }\n      if (c.state instanceof RuleStopState) {\n        if (fullCtx || t === Token.EOF) {\n          if (skippedStopStates === null) {\n            skippedStopStates = [];\n          }\n          skippedStopStates.push(c);\n          if (this.debug_add) {\n            console.log('added ' + c + ' to skippedStopStates');\n          }\n        }\n        continue;\n      }\n      for (let j = 0; j < c.state.transitions.length; j++) {\n        const trans = c.state.transitions[j];\n        const target = this.getReachableTarget(trans, t);\n        if (target !== null) {\n          const cfg = new ATNConfig({ state: target }, c);\n          intermediate.add(cfg, this.mergeCache);\n          if (this.debug_add) {\n            console.log('added ' + cfg + ' to intermediate');\n          }\n        }\n      }\n    }\n    // Now figure out where the reach operation can take us...\n    let reach = null;\n\n    // This block optimizes the reach operation for intermediate sets which\n    // trivially indicate a termination state for the overall\n    // adaptivePredict operation.\n    //\n    // The conditions assume that intermediate\n    // contains all configurations relevant to the reach set, but this\n    // condition is not true when one or more configurations have been\n    // withheld in skippedStopStates, or when the current symbol is EOF.\n    //\n    if (skippedStopStates === null && t !== Token.EOF) {\n      if (intermediate.items.length === 1) {\n        // Don't pursue the closure if there is just one state.\n        // It can only have one alternative; just add to result\n        // Also don't pursue the closure if there is unique alternative\n        // among the configurations.\n        reach = intermediate;\n      } else if (this.getUniqueAlt(intermediate) !== ATN.INVALID_ALT_NUMBER) {\n        // Also don't pursue the closure if there is unique alternative\n        // among the configurations.\n        reach = intermediate;\n      }\n    }\n    // If the reach set could not be trivially determined, perform a closure\n    // operation on the intermediate set to compute its initial value.\n    //\n    if (reach === null) {\n      reach = new ATNConfigSet(fullCtx);\n      const closureBusy = new HashSet();\n      const treatEofAsEpsilon = t === Token.EOF;\n      for (let k = 0; k < intermediate.items.length; k++) {\n        this.closure(intermediate.items[k], reach, closureBusy, false, fullCtx, treatEofAsEpsilon);\n      }\n    }\n    if (t === Token.EOF) {\n      // After consuming EOF no additional input is possible, so we are\n      // only interested in configurations which reached the end of the\n      // decision rule (local context) or end of the start rule (full\n      // context). Update reach to contain only these configurations. This\n      // handles both explicit EOF transitions in the grammar and implicit\n      // EOF transitions following the end of the decision or start rule.\n      //\n      // When reach==intermediate, no closure operation was performed. In\n      // this case, removeAllConfigsNotInRuleStopState needs to check for\n      // reachable rule stop states as well as configurations already in\n      // a rule stop state.\n      //\n      // This is handled before the configurations in skippedStopStates,\n      // because any configurations potentially added from that list are\n      // already guaranteed to meet this condition whether or not it's\n      // required.\n      //\n      reach = this.removeAllConfigsNotInRuleStopState(reach, reach === intermediate);\n    }\n    // If skippedStopStates!==null, then it contains at least one\n    // configuration. For full-context reach operations, these\n    // configurations reached the end of the start rule, in which case we\n    // only add them back to reach if no configuration during the current\n    // closure operation reached such a state. This ensures adaptivePredict\n    // chooses an alternative matching the longest overall sequence when\n    // multiple alternatives are viable.\n    //\n    if (skippedStopStates !== null && (!fullCtx || !PredictionMode.hasConfigInRuleStopState(reach))) {\n      for (let l = 0; l < skippedStopStates.length; l++) {\n        reach.add(skippedStopStates[l], this.mergeCache);\n      }\n    }\n\n    if (this.trace_atn_sim) {\n      console.log('computeReachSet ' + closure + ' -> ' + reach);\n    }\n\n    if (reach.items.length === 0) {\n      return null;\n    } else {\n      return reach;\n    }\n  }\n\n  /**\n   * Return a configuration set containing only the configurations from\n   * {@code configs} which are in a {@link RuleStopState}. If all\n   * configurations in {@code configs} are already in a rule stop state, this\n   * method simply returns {@code configs}.\n   *\n   * <p>When {@code lookToEndOfRule} is true, this method uses\n   * {@link ATN//nextTokens} for each configuration in {@code configs} which is\n   * not already in a rule stop state to see if a rule stop state is reachable\n   * from the configuration via epsilon-only transitions.</p>\n   *\n   * @param configs the configuration set to update\n   * @param lookToEndOfRule when true, this method checks for rule stop states\n   * reachable by epsilon-only transitions from each configuration in\n   * {@code configs}.\n   *\n   * @return {@code configs} if all configurations in {@code configs} are in a\n   * rule stop state, otherwise return a new configuration set containing only\n   * the configurations from {@code configs} which are in a rule stop state\n   */\n  removeAllConfigsNotInRuleStopState(configs, lookToEndOfRule) {\n    if (PredictionMode.allConfigsInRuleStopStates(configs)) {\n      return configs;\n    }\n    const result = new ATNConfigSet(configs.fullCtx);\n    for (let i = 0; i < configs.items.length; i++) {\n      const config = configs.items[i];\n      if (config.state instanceof RuleStopState) {\n        result.add(config, this.mergeCache);\n        continue;\n      }\n      if (lookToEndOfRule && config.state.epsilonOnlyTransitions) {\n        const nextTokens = this.atn.nextTokens(config.state);\n        if (nextTokens.contains(Token.EPSILON)) {\n          const endOfRuleState = this.atn.ruleToStopState[config.state.ruleIndex];\n          result.add(new ATNConfig({ state: endOfRuleState }, config), this.mergeCache);\n        }\n      }\n    }\n    return result;\n  }\n\n  computeStartState(p, ctx, fullCtx) {\n    // always at least the implicit call to start rule\n    const initialContext = predictionContextFromRuleContext(this.atn, ctx);\n    const configs = new ATNConfigSet(fullCtx);\n\n    if (this.trace_atn_sim) {\n      console.log('computeStartState from ATN state ' + p + ' initialContext=' + initialContext.toString(this.parser));\n    }\n\n    for (let i = 0; i < p.transitions.length; i++) {\n      const target = p.transitions[i].target;\n      const c = new ATNConfig({ state: target, alt: i + 1, context: initialContext }, null);\n      const closureBusy = new HashSet();\n      this.closure(c, configs, closureBusy, true, fullCtx, false);\n    }\n    return configs;\n  }\n\n  /**\n   * This method transforms the start state computed by\n   * {@link //computeStartState} to the special start state used by a\n   * precedence DFA for a particular precedence value. The transformation\n   * process applies the following changes to the start state's configuration\n   * set.\n   *\n   * <ol>\n   * <li>Evaluate the precedence predicates for each configuration using\n   * {@link SemanticContext//evalPrecedence}.</li>\n   * <li>Remove all configurations which predict an alternative greater than\n   * 1, for which another configuration that predicts alternative 1 is in the\n   * same ATN state with the same prediction context. This transformation is\n   * valid for the following reasons:\n   * <ul>\n   * <li>The closure block cannot contain any epsilon transitions which bypass\n   * the body of the closure, so all states reachable via alternative 1 are\n   * part of the precedence alternatives of the transformed left-recursive\n   * rule.</li>\n   * <li>The \"primary\" portion of a left recursive rule cannot contain an\n   * epsilon transition, so the only way an alternative other than 1 can exist\n   * in a state that is also reachable via alternative 1 is by nesting calls\n   * to the left-recursive rule, with the outer calls not being at the\n   * preferred precedence level.</li>\n   * </ul>\n   * </li>\n   * </ol>\n   *\n   * <p>\n   * The prediction context must be considered by this filter to address\n   * situations like the following.\n   * </p>\n   * <code>\n   * <pre>\n   * grammar TA;\n   * prog: statement* EOF;\n   * statement: letterA | statement letterA 'b' ;\n   * letterA: 'a';\n   * </pre>\n   * </code>\n   * <p>\n   * If the above grammar, the ATN state immediately before the token\n   * reference {@code 'a'} in {@code letterA} is reachable from the left edge\n   * of both the primary and closure blocks of the left-recursive rule\n   * {@code statement}. The prediction context associated with each of these\n   * configurations distinguishes between them, and prevents the alternative\n   * which stepped out to {@code prog} (and then back in to {@code statement}\n   * from being eliminated by the filter.\n   * </p>\n   *\n   * @param configs The configuration set computed by\n   * {@link //computeStartState} as the start state for the DFA.\n   * @return The transformed configuration set representing the start state\n   * for a precedence DFA at a particular precedence level (determined by\n   * calling {@link Parser//getPrecedence})\n   */\n  applyPrecedenceFilter(configs) {\n    let config;\n    const statesFromAlt1 = [];\n    const configSet = new ATNConfigSet(configs.fullCtx);\n    for (let i = 0; i < configs.items.length; i++) {\n      config = configs.items[i];\n      // handle alt 1 first\n      if (config.alt !== 1) {\n        continue;\n      }\n      const updatedContext = config.semanticContext.evalPrecedence(this.parser, this._outerContext);\n      if (updatedContext === null) {\n        // the configuration was eliminated\n        continue;\n      }\n      statesFromAlt1[config.state.stateNumber] = config.context;\n      if (updatedContext !== config.semanticContext) {\n        configSet.add(new ATNConfig({ semanticContext: updatedContext }, config), this.mergeCache);\n      } else {\n        configSet.add(config, this.mergeCache);\n      }\n    }\n    for (let i = 0; i < configs.items.length; i++) {\n      config = configs.items[i];\n      if (config.alt === 1) {\n        // already handled\n        continue;\n      }\n      // In the future, this elimination step could be updated to also\n      // filter the prediction context for alternatives predicting alt>1\n      // (basically a graph subtraction algorithm).\n      if (!config.precedenceFilterSuppressed) {\n        const context = statesFromAlt1[config.state.stateNumber] || null;\n        if (context !== null && context.equals(config.context)) {\n          // eliminated\n          continue;\n        }\n      }\n      configSet.add(config, this.mergeCache);\n    }\n    return configSet;\n  }\n\n  getReachableTarget(trans, ttype) {\n    if (trans.matches(ttype, 0, this.atn.maxTokenType)) {\n      return trans.target;\n    } else {\n      return null;\n    }\n  }\n\n  getPredsForAmbigAlts(ambigAlts, configs, nalts) {\n    // REACH=[1|1|[]|0:0, 1|2|[]|0:1]\n    // altToPred starts as an array of all null contexts. The entry at index i\n    // corresponds to alternative i. altToPred[i] may have one of three values:\n    //   1. null: no ATNConfig c is found such that c.alt==i\n    //   2. SemanticContext.NONE: At least one ATNConfig c exists such that\n    //      c.alt==i and c.semanticContext==SemanticContext.NONE. In other words,\n    //      alt i has at least one unpredicated config.\n    //   3. Non-NONE Semantic Context: There exists at least one, and for all\n    //      ATNConfig c such that c.alt==i, c.semanticContext!=SemanticContext.NONE.\n    //\n    // From this, it is clear that NONE||anything==NONE.\n    //\n    let altToPred = [];\n    for (let i = 0; i < configs.items.length; i++) {\n      const c = configs.items[i];\n      if (ambigAlts.has(c.alt)) {\n        altToPred[c.alt] = SemanticContext.orContext(altToPred[c.alt] || null, c.semanticContext);\n      }\n    }\n    let nPredAlts = 0;\n    for (let i = 1; i < nalts + 1; i++) {\n      const pred = altToPred[i] || null;\n      if (pred === null) {\n        altToPred[i] = SemanticContext.NONE;\n      } else if (pred !== SemanticContext.NONE) {\n        nPredAlts += 1;\n      }\n    }\n    // nonambig alts are null in altToPred\n    if (nPredAlts === 0) {\n      altToPred = null;\n    }\n    if (this.debug) {\n      console.log('getPredsForAmbigAlts result ' + arrayToString(altToPred));\n    }\n    return altToPred;\n  }\n\n  getPredicatePredictions(ambigAlts, altToPred) {\n    const pairs = [];\n    let containsPredicate = false;\n    for (let i = 1; i < altToPred.length; i++) {\n      const pred = altToPred[i];\n      // unpredicated is indicated by SemanticContext.NONE\n      if (ambigAlts !== null && ambigAlts.has(i)) {\n        pairs.push(new PredPrediction(pred, i));\n      }\n      if (pred !== SemanticContext.NONE) {\n        containsPredicate = true;\n      }\n    }\n    if (!containsPredicate) {\n      return null;\n    }\n    return pairs;\n  }\n\n  /**\n   * This method is used to improve the localization of error messages by\n   * choosing an alternative rather than throwing a\n   * {@link NoViableAltException} in particular prediction scenarios where the\n   * {@link //ERROR} state was reached during ATN simulation.\n   *\n   * <p>\n   * The default implementation of this method uses the following\n   * algorithm to identify an ATN configuration which successfully parsed the\n   * decision entry rule. Choosing such an alternative ensures that the\n   * {@link ParserRuleContext} returned by the calling rule will be complete\n   * and valid, and the syntax error will be reported later at a more\n   * localized location.</p>\n   *\n   * <ul>\n   * <li>If a syntactically valid path or paths reach the end of the decision rule and\n   * they are semantically valid if predicated, return the min associated alt.</li>\n   * <li>Else, if a semantically invalid but syntactically valid path exist\n   * or paths exist, return the minimum associated alt.\n   * </li>\n   * <li>Otherwise, return {@link ATN//INVALID_ALT_NUMBER}.</li>\n   * </ul>\n   *\n   * <p>\n   * In some scenarios, the algorithm described above could predict an\n   * alternative which will result in a {@link FailedPredicateException} in\n   * the parser. Specifically, this could occur if the <em>only</em> configuration\n   * capable of successfully parsing to the end of the decision rule is\n   * blocked by a semantic predicate. By choosing this alternative within\n   * {@link //adaptivePredict} instead of throwing a\n   * {@link NoViableAltException}, the resulting\n   * {@link FailedPredicateException} in the parser will identify the specific\n   * predicate which is preventing the parser from successfully parsing the\n   * decision rule, which helps developers identify and correct logic errors\n   * in semantic predicates.\n   * </p>\n   *\n   * @param configs The ATN configurations which were valid immediately before\n   * the {@link //ERROR} state was reached\n   * @param outerContext The is the \\gamma_0 initial parser context from the paper\n   * or the parser stack at the instant before prediction commences.\n   *\n   * @return The value to return from {@link //adaptivePredict}, or\n   * {@link ATN//INVALID_ALT_NUMBER} if a suitable alternative was not\n   * identified and {@link //adaptivePredict} should report an error instead\n   */\n  getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(configs, outerContext) {\n    const cfgs = this.splitAccordingToSemanticValidity(configs, outerContext);\n    const semValidConfigs = cfgs[0];\n    const semInvalidConfigs = cfgs[1];\n    let alt = this.getAltThatFinishedDecisionEntryRule(semValidConfigs);\n    if (alt !== ATN.INVALID_ALT_NUMBER) {\n      // semantically/syntactically viable path exists\n      return alt;\n    }\n    // Is there a syntactically valid path with a failed pred?\n    if (semInvalidConfigs.items.length > 0) {\n      alt = this.getAltThatFinishedDecisionEntryRule(semInvalidConfigs);\n      if (alt !== ATN.INVALID_ALT_NUMBER) {\n        // syntactically viable path exists\n        return alt;\n      }\n    }\n    return ATN.INVALID_ALT_NUMBER;\n  }\n\n  getAltThatFinishedDecisionEntryRule(configs) {\n    const alts = [];\n    for (let i = 0; i < configs.items.length; i++) {\n      const c = configs.items[i];\n      if (c.reachesIntoOuterContext > 0 || (c.state instanceof RuleStopState && c.context.hasEmptyPath())) {\n        if (alts.indexOf(c.alt) < 0) {\n          alts.push(c.alt);\n        }\n      }\n    }\n    if (alts.length === 0) {\n      return ATN.INVALID_ALT_NUMBER;\n    } else {\n      return Math.min.apply(null, alts);\n    }\n  }\n\n  /**\n   * Walk the list of configurations and split them according to\n   * those that have preds evaluating to true/false.  If no pred, assume\n   * true pred and include in succeeded set.  Returns Pair of sets.\n   *\n   * Create a new set so as not to alter the incoming parameter.\n   *\n   * Assumption: the input stream has been restored to the starting point\n   * prediction, which is where predicates need to evaluate.*/\n  splitAccordingToSemanticValidity(configs, outerContext) {\n    const succeeded = new ATNConfigSet(configs.fullCtx);\n    const failed = new ATNConfigSet(configs.fullCtx);\n    for (let i = 0; i < configs.items.length; i++) {\n      const c = configs.items[i];\n      if (c.semanticContext !== SemanticContext.NONE) {\n        const predicateEvaluationResult = c.semanticContext.evaluate(this.parser, outerContext);\n        if (predicateEvaluationResult) {\n          succeeded.add(c);\n        } else {\n          failed.add(c);\n        }\n      } else {\n        succeeded.add(c);\n      }\n    }\n    return [succeeded, failed];\n  }\n\n  /**\n   * Look through a list of predicate/alt pairs, returning alts for the\n   * pairs that win. A {@code NONE} predicate indicates an alt containing an\n   * unpredicated config which behaves as \"always true.\" If !complete\n   * then we stop at the first predicate that evaluates to true. This\n   * includes pairs with null predicates.\n   */\n  evalSemanticContext(predPredictions, outerContext, complete) {\n    const predictions = new BitSet();\n    for (let i = 0; i < predPredictions.length; i++) {\n      const pair = predPredictions[i];\n      if (pair.pred === SemanticContext.NONE) {\n        predictions.add(pair.alt);\n        if (!complete) {\n          break;\n        }\n        continue;\n      }\n      const predicateEvaluationResult = pair.pred.evaluate(this.parser, outerContext);\n      if (this.debug || this.dfa_debug) {\n        console.log('eval pred ' + pair + '=' + predicateEvaluationResult);\n      }\n      if (predicateEvaluationResult) {\n        if (this.debug || this.dfa_debug) {\n          console.log('PREDICT ' + pair.alt);\n        }\n        predictions.add(pair.alt);\n        if (!complete) {\n          break;\n        }\n      }\n    }\n    return predictions;\n  }\n\n  // TODO: If we are doing predicates, there is no point in pursuing\n  //     closure operations if we reach a DFA state that uniquely predicts\n  //     alternative. We will not be caching that DFA state and it is a\n  //     waste to pursue the closure. Might have to advance when we do\n  //     ambig detection thought :(\n  //\n  closure(config, configs, closureBusy, collectPredicates, fullCtx, treatEofAsEpsilon) {\n    const initialDepth = 0;\n    this.closureCheckingStopState(\n      config,\n      configs,\n      closureBusy,\n      collectPredicates,\n      fullCtx,\n      initialDepth,\n      treatEofAsEpsilon,\n    );\n  }\n\n  closureCheckingStopState(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {\n    if (this.trace_atn_sim || this.debug_closure) {\n      console.log('closure(' + config.toString(this.parser, true) + ')');\n    }\n    if (config.state instanceof RuleStopState) {\n      // We hit rule end. If we have context info, use it\n      // run thru all possible stack tops in ctx\n      if (!config.context.isEmpty()) {\n        for (let i = 0; i < config.context.length; i++) {\n          if (config.context.getReturnState(i) === PredictionContext.EMPTY_RETURN_STATE) {\n            if (fullCtx) {\n              configs.add(\n                new ATNConfig(\n                  {\n                    state: config.state,\n                    context: PredictionContext.EMPTY,\n                  },\n                  config,\n                ),\n                this.mergeCache,\n              );\n              continue;\n            } else {\n              // we have no context info, just chase follow links (if greedy)\n              if (this.debug) {\n                console.log('FALLING off rule ' + this.getRuleName(config.state.ruleIndex));\n              }\n              this.closure_(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon);\n            }\n            continue;\n          }\n          const returnState = this.atn.states[config.context.getReturnState(i)];\n          const newContext = config.context.getParent(i); // \"pop\" return state\n          const parms = {\n            state: returnState,\n            alt: config.alt,\n            context: newContext,\n            semanticContext: config.semanticContext,\n          };\n          const c = new ATNConfig(parms, null);\n          // While we have context to pop back from, we may have\n          // gotten that context AFTER having falling off a rule.\n          // Make sure we track that we are now out of context.\n          c.reachesIntoOuterContext = config.reachesIntoOuterContext;\n          this.closureCheckingStopState(\n            c,\n            configs,\n            closureBusy,\n            collectPredicates,\n            fullCtx,\n            depth - 1,\n            treatEofAsEpsilon,\n          );\n        }\n        return;\n      } else if (fullCtx) {\n        // reached end of start rule\n        configs.add(config, this.mergeCache);\n        return;\n      } else {\n        // else if we have no context info, just chase follow links (if greedy)\n        if (this.debug) {\n          console.log('FALLING off rule ' + this.getRuleName(config.state.ruleIndex));\n        }\n      }\n    }\n    this.closure_(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon);\n  }\n\n  // Do the actual work of walking epsilon edges//\n  closure_(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {\n    const p = config.state;\n    // optimization\n    if (!p.epsilonOnlyTransitions) {\n      configs.add(config, this.mergeCache);\n      // make sure to not return here, because EOF transitions can act as\n      // both epsilon transitions and non-epsilon transitions.\n    }\n    for (let i = 0; i < p.transitions.length; i++) {\n      if (i === 0 && this.canDropLoopEntryEdgeInLeftRecursiveRule(config)) continue;\n\n      const t = p.transitions[i];\n      const continueCollecting = collectPredicates && !(t instanceof ActionTransition);\n      const c = this.getEpsilonTarget(config, t, continueCollecting, depth === 0, fullCtx, treatEofAsEpsilon);\n      if (c !== null) {\n        let newDepth = depth;\n        if (config.state instanceof RuleStopState) {\n          // target fell off end of rule; mark resulting c as having dipped into outer context\n          // We can't get here if incoming config was rule stop and we had context\n          // track how far we dip into outer context.  Might\n          // come in handy and we avoid evaluating context dependent\n          // preds if this is > 0.\n          if (this._dfa !== null && this._dfa.precedenceDfa) {\n            if (t.outermostPrecedenceReturn === this._dfa.atnStartState.ruleIndex) {\n              c.precedenceFilterSuppressed = true;\n            }\n          }\n\n          c.reachesIntoOuterContext += 1;\n          if (closureBusy.add(c) !== c) {\n            // avoid infinite recursion for right-recursive rules\n            continue;\n          }\n          configs.dipsIntoOuterContext = true; // TODO: can remove? only care when we add to set per middle of this method\n          newDepth -= 1;\n          if (this.debug) {\n            console.log('dips into outer ctx: ' + c);\n          }\n        } else {\n          if (!t.isEpsilon && closureBusy.add(c) !== c) {\n            // avoid infinite recursion for EOF* and EOF+\n            continue;\n          }\n          if (t instanceof RuleTransition) {\n            // latch when newDepth goes negative - once we step out of the entry context we can't return\n            if (newDepth >= 0) {\n              newDepth += 1;\n            }\n          }\n        }\n        this.closureCheckingStopState(\n          c,\n          configs,\n          closureBusy,\n          continueCollecting,\n          fullCtx,\n          newDepth,\n          treatEofAsEpsilon,\n        );\n      }\n    }\n  }\n\n  canDropLoopEntryEdgeInLeftRecursiveRule(config) {\n    // return False\n    const p = config.state;\n    // First check to see if we are in StarLoopEntryState generated during\n    // left-recursion elimination. For efficiency, also check if\n    // the context has an empty stack case. If so, it would mean\n    // global FOLLOW so we can't perform optimization\n    // Are we the special loop entry/exit state? or SLL wildcard\n    if (p.stateType !== ATNState.STAR_LOOP_ENTRY) return false;\n    if (\n      p.stateType !== ATNState.STAR_LOOP_ENTRY ||\n      !p.isPrecedenceDecision ||\n      config.context.isEmpty() ||\n      config.context.hasEmptyPath()\n    )\n      return false;\n\n    // Require all return states to return back to the same rule that p is in.\n    const numCtxs = config.context.length;\n    for (let i = 0; i < numCtxs; i++) {\n      // for each stack context\n      const returnState = this.atn.states[config.context.getReturnState(i)];\n      if (returnState.ruleIndex !== p.ruleIndex) return false;\n    }\n\n    const decisionStartState = p.transitions[0].target;\n    const blockEndStateNum = decisionStartState.endState.stateNumber;\n    const blockEndState = this.atn.states[blockEndStateNum];\n\n    // Verify that the top of each stack context leads to loop entry/exit\n    // state through epsilon edges and w/o leaving rule.\n    for (let i = 0; i < numCtxs; i++) {\n      // for each stack context\n      const returnStateNumber = config.context.getReturnState(i);\n      const returnState = this.atn.states[returnStateNumber];\n      // all states must have single outgoing epsilon edge\n      if (returnState.transitions.length !== 1 || !returnState.transitions[0].isEpsilon) return false;\n\n      // Look for prefix op case like 'not expr', (' type ')' expr\n      const returnStateTarget = returnState.transitions[0].target;\n      if (returnState.stateType === ATNState.BLOCK_END && returnStateTarget === p) continue;\n\n      // Look for 'expr op expr' or case where expr's return state is block end\n      // of (...)* internal block; the block end points to loop back\n      // which points to p but we don't need to check that\n      if (returnState === blockEndState) continue;\n\n      // Look for ternary expr ? expr : expr. The return state points at block end,\n      // which points at loop entry state\n      if (returnStateTarget === blockEndState) continue;\n\n      // Look for complex prefix 'between expr and expr' case where 2nd expr's\n      // return state points at block end state of (...)* internal block\n      if (\n        returnStateTarget.stateType === ATNState.BLOCK_END &&\n        returnStateTarget.transitions.length === 1 &&\n        returnStateTarget.transitions[0].isEpsilon &&\n        returnStateTarget.transitions[0].target === p\n      )\n        continue;\n\n      // anything else ain't conforming\n      return false;\n    }\n    return true;\n  }\n\n  getRuleName(index) {\n    if (this.parser !== null && index >= 0) {\n      return this.parser.ruleNames[index];\n    } else {\n      return '<rule ' + index + '>';\n    }\n  }\n\n  getEpsilonTarget(config, t, collectPredicates, inContext, fullCtx, treatEofAsEpsilon) {\n    switch (t.serializationType) {\n      case Transition.RULE:\n        return this.ruleTransition(config, t);\n      case Transition.PRECEDENCE:\n        return this.precedenceTransition(config, t, collectPredicates, inContext, fullCtx);\n      case Transition.PREDICATE:\n        return this.predTransition(config, t, collectPredicates, inContext, fullCtx);\n      case Transition.ACTION:\n        return this.actionTransition(config, t);\n      case Transition.EPSILON:\n        return new ATNConfig({ state: t.target }, config);\n      case Transition.ATOM:\n      case Transition.RANGE:\n      case Transition.SET:\n        // EOF transitions act like epsilon transitions after the first EOF\n        // transition is traversed\n        if (treatEofAsEpsilon) {\n          if (t.matches(Token.EOF, 0, 1)) {\n            return new ATNConfig({ state: t.target }, config);\n          }\n        }\n        return null;\n      default:\n        return null;\n    }\n  }\n\n  actionTransition(config, t) {\n    if (this.debug) {\n      const index = t.actionIndex === -1 ? 65535 : t.actionIndex;\n      console.log('ACTION edge ' + t.ruleIndex + ':' + index);\n    }\n    return new ATNConfig({ state: t.target }, config);\n  }\n\n  precedenceTransition(config, pt, collectPredicates, inContext, fullCtx) {\n    if (this.debug) {\n      console.log('PRED (collectPredicates=' + collectPredicates + ') ' + pt.precedence + '>=_p, ctx dependent=true');\n      if (this.parser !== null) {\n        console.log('context surrounding pred is ' + arrayToString(this.parser.getRuleInvocationStack()));\n      }\n    }\n    let c = null;\n    if (collectPredicates && inContext) {\n      if (fullCtx) {\n        // In full context mode, we can evaluate predicates on-the-fly\n        // during closure, which dramatically reduces the size of\n        // the config sets. It also obviates the need to test predicates\n        // later during conflict resolution.\n        const currentPosition = this._input.index;\n        this._input.seek(this._startIndex);\n        const predSucceeds = pt.getPredicate().evaluate(this.parser, this._outerContext);\n        this._input.seek(currentPosition);\n        if (predSucceeds) {\n          c = new ATNConfig({ state: pt.target }, config); // no pred context\n        }\n      } else {\n        const newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());\n        c = new ATNConfig({ state: pt.target, semanticContext: newSemCtx }, config);\n      }\n    } else {\n      c = new ATNConfig({ state: pt.target }, config);\n    }\n    if (this.debug) {\n      console.log('config from pred transition=' + c);\n    }\n    return c;\n  }\n\n  predTransition(config, pt, collectPredicates, inContext, fullCtx) {\n    if (this.debug) {\n      console.log(\n        'PRED (collectPredicates=' +\n          collectPredicates +\n          ') ' +\n          pt.ruleIndex +\n          ':' +\n          pt.predIndex +\n          ', ctx dependent=' +\n          pt.isCtxDependent,\n      );\n      if (this.parser !== null) {\n        console.log('context surrounding pred is ' + arrayToString(this.parser.getRuleInvocationStack()));\n      }\n    }\n    let c = null;\n    if (collectPredicates && ((pt.isCtxDependent && inContext) || !pt.isCtxDependent)) {\n      if (fullCtx) {\n        // In full context mode, we can evaluate predicates on-the-fly\n        // during closure, which dramatically reduces the size of\n        // the config sets. It also obviates the need to test predicates\n        // later during conflict resolution.\n        const currentPosition = this._input.index;\n        this._input.seek(this._startIndex);\n        const predSucceeds = pt.getPredicate().evaluate(this.parser, this._outerContext);\n        this._input.seek(currentPosition);\n        if (predSucceeds) {\n          c = new ATNConfig({ state: pt.target }, config); // no pred context\n        }\n      } else {\n        const newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());\n        c = new ATNConfig({ state: pt.target, semanticContext: newSemCtx }, config);\n      }\n    } else {\n      c = new ATNConfig({ state: pt.target }, config);\n    }\n    if (this.debug) {\n      console.log('config from pred transition=' + c);\n    }\n    return c;\n  }\n\n  ruleTransition(config, t) {\n    if (this.debug) {\n      console.log('CALL rule ' + this.getRuleName(t.target.ruleIndex) + ', ctx=' + config.context);\n    }\n    const returnState = t.followState;\n    const newContext = SingletonPredictionContext.create(config.context, returnState.stateNumber);\n    return new ATNConfig({ state: t.target, context: newContext }, config);\n  }\n\n  getConflictingAlts(configs) {\n    const altsets = PredictionMode.getConflictingAltSubsets(configs);\n    return PredictionMode.getAlts(altsets);\n  }\n\n  /**\n   * Sam pointed out a problem with the previous definition, v3, of\n   * ambiguous states. If we have another state associated with conflicting\n   * alternatives, we should keep going. For example, the following grammar\n   *\n   * s : (ID | ID ID?) ';' ;\n   *\n   * When the ATN simulation reaches the state before ';', it has a DFA\n   * state that looks like: [12|1|[], 6|2|[], 12|2|[]]. Naturally\n   * 12|1|[] and 12|2|[] conflict, but we cannot stop processing this node\n   * because alternative to has another way to continue, via [6|2|[]].\n   * The key is that we have a single state that has config's only associated\n   * with a single alternative, 2, and crucially the state transitions\n   * among the configurations are all non-epsilon transitions. That means\n   * we don't consider any conflicts that include alternative 2. So, we\n   * ignore the conflict between alts 1 and 2. We ignore a set of\n   * conflicting alts when there is an intersection with an alternative\n   * associated with a single alt state in the state&rarr;config-list map.\n   *\n   * It's also the case that we might have two conflicting configurations but\n   * also a 3rd nonconflicting configuration for a different alternative:\n   * [1|1|[], 1|2|[], 8|3|[]]. This can come about from grammar:\n   *\n   * a : A | A | A B ;\n   *\n   * After matching input A, we reach the stop state for rule A, state 1.\n   * State 8 is the state right before B. Clearly alternatives 1 and 2\n   * conflict and no amount of further lookahead will separate the two.\n   * However, alternative 3 will be able to continue and so we do not\n   * stop working on this state. In the previous example, we're concerned\n   * with states associated with the conflicting alternatives. Here alt\n   * 3 is not associated with the conflicting configs, but since we can continue\n   * looking for input reasonably, I don't declare the state done. We\n   * ignore a set of conflicting alts when we have an alternative\n   * that we still need to pursue\n   */\n  getConflictingAltsOrUniqueAlt(configs) {\n    let conflictingAlts = null;\n    if (configs.uniqueAlt !== ATN.INVALID_ALT_NUMBER) {\n      conflictingAlts = new BitSet();\n      conflictingAlts.add(configs.uniqueAlt);\n    } else {\n      conflictingAlts = configs.conflictingAlts;\n    }\n    return conflictingAlts;\n  }\n\n  getTokenName(t) {\n    if (t === Token.EOF) {\n      return 'EOF';\n    }\n    if (this.parser !== null && this.parser.literalNames !== null) {\n      if (t >= this.parser.literalNames.length && t >= this.parser.symbolicNames.length) {\n        console.log('' + t + ' ttype out of range: ' + this.parser.literalNames);\n        console.log('' + this.parser.getInputStream().getTokens());\n      } else {\n        const name = this.parser.literalNames[t] || this.parser.symbolicNames[t];\n        return name + '<' + t + '>';\n      }\n    }\n    return '' + t;\n  }\n\n  getLookaheadName(input) {\n    return this.getTokenName(input.LA(1));\n  }\n\n  /**\n   * Used for debugging in adaptivePredict around execATN but I cut\n   * it out for clarity now that alg. works well. We can leave this\n   * \"dead\" code for a bit\n   */\n  dumpDeadEndConfigs(nvae) {\n    console.log('dead end configs: ');\n    const decs = nvae.getDeadEndConfigs();\n    for (let i = 0; i < decs.length; i++) {\n      const c = decs[i];\n      let trans = 'no edges';\n      if (c.state.transitions.length > 0) {\n        const t = c.state.transitions[0];\n        if (t instanceof AtomTransition) {\n          trans = 'Atom ' + this.getTokenName(t.label);\n        } else if (t instanceof SetTransition) {\n          const neg = t instanceof NotSetTransition;\n          trans = (neg ? '~' : '') + 'Set ' + t.set;\n        }\n      }\n      console.error(c.toString(this.parser, true) + ':' + trans);\n    }\n  }\n\n  noViableAlt(input, outerContext, configs, startIndex) {\n    return new NoViableAltException(this.parser, input, input.get(startIndex), input.LT(1), configs, outerContext);\n  }\n\n  getUniqueAlt(configs) {\n    let alt = ATN.INVALID_ALT_NUMBER;\n    for (let i = 0; i < configs.items.length; i++) {\n      const c = configs.items[i];\n      if (alt === ATN.INVALID_ALT_NUMBER) {\n        alt = c.alt; // found first alt\n      } else if (c.alt !== alt) {\n        return ATN.INVALID_ALT_NUMBER;\n      }\n    }\n    return alt;\n  }\n\n  /**\n   * Add an edge to the DFA, if possible. This method calls\n   * {@link //addDFAState} to ensure the {@code to} state is present in the\n   * DFA. If {@code from} is {@code null}, or if {@code t} is outside the\n   * range of edges that can be represented in the DFA tables, this method\n   * returns without adding the edge to the DFA.\n   *\n   * <p>If {@code to} is {@code null}, this method returns {@code null}.\n   * Otherwise, this method returns the {@link DFAState} returned by calling\n   * {@link //addDFAState} for the {@code to} state.</p>\n   *\n   * @param dfa The DFA\n   * @param from_ The source state for the edge\n   * @param t The input symbol\n   * @param to The target state for the edge\n   *\n   * @return If {@code to} is {@code null}, this method returns {@code null};\n   * otherwise this method returns the result of calling {@link //addDFAState}\n   * on {@code to}\n   */\n  addDFAEdge(dfa, from_, t, to) {\n    if (this.debug) {\n      console.log('EDGE ' + from_ + ' -> ' + to + ' upon ' + this.getTokenName(t));\n    }\n    if (to === null) {\n      return null;\n    }\n    to = this.addDFAState(dfa, to); // used existing if possible not incoming\n    if (from_ === null || t < -1 || t > this.atn.maxTokenType) {\n      return to;\n    }\n    if (from_.edges === null) {\n      from_.edges = [];\n    }\n    from_.edges[t + 1] = to; // connect\n\n    if (this.debug) {\n      const literalNames = this.parser === null ? null : this.parser.literalNames;\n      const symbolicNames = this.parser === null ? null : this.parser.symbolicNames;\n      console.log('DFA=\\n' + dfa.toString(literalNames, symbolicNames));\n    }\n    return to;\n  }\n\n  /**\n   * Add state {@code D} to the DFA if it is not already present, and return\n   * the actual instance stored in the DFA. If a state equivalent to {@code D}\n   * is already in the DFA, the existing state is returned. Otherwise this\n   * method returns {@code D} after adding it to the DFA.\n   *\n   * <p>If {@code D} is {@link //ERROR}, this method returns {@link //ERROR} and\n   * does not change the DFA.</p>\n   *\n   * @param dfa The dfa\n   * @param D The DFA state to add\n   * @return The state stored in the DFA. This will be either the existing\n   * state if {@code D} is already in the DFA, or {@code D} itself if the\n   * state was not already present\n   */\n  addDFAState(dfa, D) {\n    if (D === ATNSimulator.ERROR) {\n      return D;\n    }\n    const existing = dfa.states.get(D);\n    if (existing !== null) {\n      if (this.trace_atn_sim) console.log('addDFAState ' + D + ' exists');\n      return existing;\n    }\n    D.stateNumber = dfa.states.length;\n    if (!D.configs.readOnly) {\n      D.configs.optimizeConfigs(this);\n      D.configs.setReadonly(true);\n    }\n\n    if (this.trace_atn_sim) console.log('addDFAState new ' + D);\n\n    dfa.states.add(D);\n    if (this.debug) {\n      console.log('adding new DFA state: ' + D);\n    }\n    return D;\n  }\n\n  reportAttemptingFullContext(dfa, conflictingAlts, configs, startIndex, stopIndex) {\n    if (this.debug || this.retry_debug) {\n      const interval = new Interval(startIndex, stopIndex + 1);\n      console.log(\n        'reportAttemptingFullContext decision=' +\n          dfa.decision +\n          ':' +\n          configs +\n          ', input=' +\n          this.parser.getTokenStream().getText(interval),\n      );\n    }\n    if (this.parser !== null) {\n      this.parser\n        .getErrorListenerDispatch()\n        .reportAttemptingFullContext(this.parser, dfa, startIndex, stopIndex, conflictingAlts, configs);\n    }\n  }\n\n  reportContextSensitivity(dfa, prediction, configs, startIndex, stopIndex) {\n    if (this.debug || this.retry_debug) {\n      const interval = new Interval(startIndex, stopIndex + 1);\n      console.log(\n        'reportContextSensitivity decision=' +\n          dfa.decision +\n          ':' +\n          configs +\n          ', input=' +\n          this.parser.getTokenStream().getText(interval),\n      );\n    }\n    if (this.parser !== null) {\n      this.parser\n        .getErrorListenerDispatch()\n        .reportContextSensitivity(this.parser, dfa, startIndex, stopIndex, prediction, configs);\n    }\n  }\n\n  // If context sensitive parsing, we know it's ambiguity not conflict//\n  reportAmbiguity(dfa, D, startIndex, stopIndex, exact, ambigAlts, configs) {\n    if (this.debug || this.retry_debug) {\n      const interval = new Interval(startIndex, stopIndex + 1);\n      console.log(\n        'reportAmbiguity ' + ambigAlts + ':' + configs + ', input=' + this.parser.getTokenStream().getText(interval),\n      );\n    }\n    if (this.parser !== null) {\n      this.parser\n        .getErrorListenerDispatch()\n        .reportAmbiguity(this.parser, dfa, startIndex, stopIndex, exact, ambigAlts, configs);\n    }\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { PredictionContext } from '../context/PredictionContext.js';\nimport { HashMap } from '../misc/HashMap.js';\n\n/**\n * Used to cache {@link PredictionContext} objects. Its used for the shared\n * context cash associated with contexts in DFA states. This cache\n * can be used for both lexers and parsers.\n */\nexport class PredictionContextCache {\n  constructor() {\n    this.cache = new HashMap();\n  }\n\n  get length() {\n    return this.cache.length;\n  }\n\n  /**\n   * Add a context to the cache and return it. If the context already exists,\n   * return that one instead and do not add a new context to the cache.\n   * Protect shared cache from unsafe thread access.\n   */\n  add(ctx) {\n    if (ctx === PredictionContext.EMPTY) {\n      return PredictionContext.EMPTY;\n    }\n    const existing = this.cache.get(ctx) || null;\n    if (existing !== null) {\n      return existing;\n    }\n    this.cache.set(ctx, ctx);\n    return ctx;\n  }\n\n  get(ctx) {\n    return this.cache.get(ctx) || null;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexport class ParseTreeListener {\n  visitTerminal(node) {}\n\n  visitErrorNode(node) {}\n\n  enterEveryRule(node) {}\n\n  exitEveryRule(node) {}\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexport class ParseTreeVisitor {\n  visit(ctx) {\n    if (Array.isArray(ctx)) {\n      return ctx.map(function (child) {\n        return child.accept(this);\n      }, this);\n    } else {\n      return ctx.accept(this);\n    }\n  }\n\n  visitChildren(ctx) {\n    if (ctx.children) {\n      return this.visit(ctx.children);\n    } else {\n      return null;\n    }\n  }\n\n  visitTerminal(node) {}\n\n  visitErrorNode(node) {}\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { TerminalNode } from './TerminalNode.js';\nimport { ErrorNode } from './ErrorNode.js';\n\nexport class ParseTreeWalker {\n  /**\n   * Performs a walk on the given parse tree starting at the root and going down recursively\n   * with depth-first search. On each node, {@link ParseTreeWalker//enterRule} is called before\n   * recursively walking down into child nodes, then\n   * {@link ParseTreeWalker//exitRule} is called after the recursive call to wind up.\n   * @param listener The listener used by the walker to process grammar rules\n   * @param t The parse tree to be walked on\n   */\n  walk(listener, t) {\n    const errorNode = t instanceof ErrorNode || (t.isErrorNode !== undefined && t.isErrorNode());\n    if (errorNode) {\n      listener.visitErrorNode(t);\n    } else if (t instanceof TerminalNode) {\n      listener.visitTerminal(t);\n    } else {\n      this.enterRule(listener, t);\n      for (let i = 0; i < t.getChildCount(); i++) {\n        const child = t.getChild(i);\n        this.walk(listener, child);\n      }\n      this.exitRule(listener, t);\n    }\n  }\n\n  /**\n   * Enters a grammar rule by first triggering the generic event {@link ParseTreeListener//enterEveryRule}\n   * then by triggering the event specific to the given parse tree node\n   * @param listener The listener responding to the trigger events\n   * @param r The grammar rule containing the rule context\n   */\n  enterRule(listener, r) {\n    const ctx = r.ruleContext;\n    listener.enterEveryRule(ctx);\n    ctx.enterRule(listener);\n  }\n\n  /**\n   * Exits a grammar rule by first triggering the event specific to the given parse tree node\n   * then by triggering the generic event {@link ParseTreeListener//exitEveryRule}\n   * @param listener The listener responding to the trigger events\n   * @param r The grammar rule containing the rule context\n   */\n  exitRule(listener, r) {\n    const ctx = r.ruleContext;\n    ctx.exitRule(listener);\n    listener.exitEveryRule(ctx);\n  }\n}\n\nParseTreeWalker.DEFAULT = new ParseTreeWalker();\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { Interval } from '../misc/Interval.js';\nimport { Token } from '../Token.js';\nimport { TerminalNode } from './TerminalNode.js';\n\nexport class TerminalNodeImpl extends TerminalNode {\n  constructor(symbol) {\n    super();\n    this.parentCtx = null;\n    this.symbol = symbol;\n  }\n\n  getChild(i) {\n    return null;\n  }\n\n  getSymbol() {\n    return this.symbol;\n  }\n\n  getParent() {\n    return this.parentCtx;\n  }\n\n  getPayload() {\n    return this.symbol;\n  }\n\n  getSourceInterval() {\n    if (this.symbol === null) {\n      return Interval.INVALID_INTERVAL;\n    }\n    const tokenIndex = this.symbol.tokenIndex;\n    return new Interval(tokenIndex, tokenIndex);\n  }\n\n  getChildCount() {\n    return 0;\n  }\n\n  accept(visitor) {\n    return visitor.visitTerminal(this);\n  }\n\n  getText() {\n    return this.symbol.text;\n  }\n\n  toString() {\n    if (this.symbol.type === Token.EOF) {\n      return '<EOF>';\n    } else {\n      return this.symbol.text;\n    }\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n/**\n * Represents a token that was consumed during resynchronization\n * rather than during a valid match operation. For example,\n * we will create this kind of a node during single token insertion\n * and deletion as well as during \"consume until error recovery set\"\n * upon no viable alternative exceptions.\n */\nimport { TerminalNodeImpl } from './TerminalNodeImpl.js';\n\nexport class ErrorNodeImpl extends TerminalNodeImpl {\n  constructor(token) {\n    super(token);\n  }\n\n  isErrorNode() {\n    return true;\n  }\n\n  accept(visitor) {\n    return visitor.visitErrorNode(this);\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { RuleContext } from './RuleContext.js';\nimport { TerminalNode } from '../tree/index.js';\nimport { TerminalNodeImpl } from '../tree/TerminalNodeImpl.js';\nimport { ErrorNodeImpl } from '../tree/ErrorNodeImpl.js';\nimport { Interval } from '../misc/Interval.js';\n\n/**\n * A rule invocation record for parsing.\n *\n *  Contains all of the information about the current rule not stored in the\n *  RuleContext. It handles parse tree children list, Any ATN state\n *  tracing, and the default values available for rule indications:\n *  start, stop, rule index, current alt number, current\n *  ATN state.\n *\n *  Subclasses made for each rule and grammar track the parameters,\n *  return values, locals, and labels specific to that rule. These\n *  are the objects that are returned from rules.\n *\n *  Note text is not an actual field of a rule return value; it is computed\n *  from start and stop using the input stream's toString() method.  I\n *  could add a ctor to this so that we can pass in and store the input\n *  stream, but I'm not sure we want to do that.  It would seem to be undefined\n *  to get the .text property anyway if the rule matches tokens from multiple\n *  input streams.\n *\n *  I do not use getters for fields of objects that are used simply to\n *  group values such as this aggregate.  The getters/setters are there to\n *  satisfy the superclass interface.\n */\nexport class ParserRuleContext extends RuleContext {\n  constructor(parent, invokingStateNumber) {\n    super(parent, invokingStateNumber);\n    /**\n     * If we are debugging or building a parse tree for a visitor,\n     * we need to track all of the tokens and rule invocations associated\n     * with this rule's context. This is empty for parsing w/o tree constr.\n     * operation because we don't the need to track the details about\n     * how we parse this rule.\n     */\n    this.children = null;\n    this.start = null;\n    this.stop = null;\n    /**\n     * The exception that forced this rule to return. If the rule successfully\n     * completed, this is {@code null}.\n     */\n    this.exception = null;\n  }\n\n  // COPY a ctx (I'm deliberately not using copy constructor)\n  copyFrom(ctx) {\n    // from RuleContext\n    this.parentCtx = ctx.parentCtx;\n    this.invokingState = ctx.invokingState;\n    this.children = null;\n    this.start = ctx.start;\n    this.stop = ctx.stop;\n    // copy any error nodes to alt label node\n    if (ctx.children) {\n      this.children = [];\n      // reset parent pointer for any error nodes\n      ctx.children.map(function (child) {\n        if (child instanceof ErrorNodeImpl) {\n          this.children.push(child);\n          child.parentCtx = this;\n        }\n      }, this);\n    }\n  }\n\n  // Double dispatch methods for listeners\n  enterRule(listener) {}\n\n  exitRule(listener) {}\n\n  // Does not set parent link; other add methods do that\n  addChild(child) {\n    if (this.children === null) {\n      this.children = [];\n    }\n    this.children.push(child);\n    return child;\n  }\n\n  /** Used by enterOuterAlt to toss out a RuleContext previously added as\n   * we entered a rule. If we have // label, we will need to remove\n   * generic ruleContext object.\n   */\n  removeLastChild() {\n    if (this.children !== null) {\n      this.children.pop();\n    }\n  }\n\n  addTokenNode(token) {\n    const node = new TerminalNodeImpl(token);\n    this.addChild(node);\n    node.parentCtx = this;\n    return node;\n  }\n\n  addErrorNode(badToken) {\n    const node = new ErrorNodeImpl(badToken);\n    this.addChild(node);\n    node.parentCtx = this;\n    return node;\n  }\n\n  getChild(i, type) {\n    type = type || null;\n    if (this.children === null || i < 0 || i >= this.children.length) {\n      return null;\n    }\n    if (type === null) {\n      return this.children[i];\n    } else {\n      for (let j = 0; j < this.children.length; j++) {\n        const child = this.children[j];\n        if (child instanceof type) {\n          if (i === 0) {\n            return child;\n          } else {\n            i -= 1;\n          }\n        }\n      }\n      return null;\n    }\n  }\n\n  getToken(ttype, i) {\n    if (this.children === null || i < 0 || i >= this.children.length) {\n      return null;\n    }\n    for (let j = 0; j < this.children.length; j++) {\n      const child = this.children[j];\n      if (child instanceof TerminalNode) {\n        if (child.symbol.type === ttype) {\n          if (i === 0) {\n            return child;\n          } else {\n            i -= 1;\n          }\n        }\n      }\n    }\n    return null;\n  }\n\n  getTokens(ttype) {\n    if (this.children === null) {\n      return [];\n    } else {\n      const tokens = [];\n      for (let j = 0; j < this.children.length; j++) {\n        const child = this.children[j];\n        if (child instanceof TerminalNode) {\n          if (child.symbol.type === ttype) {\n            tokens.push(child);\n          }\n        }\n      }\n      return tokens;\n    }\n  }\n\n  getTypedRuleContext(ctxType, i) {\n    return this.getChild(i, ctxType);\n  }\n\n  getTypedRuleContexts(ctxType) {\n    if (this.children === null) {\n      return [];\n    } else {\n      const contexts = [];\n      for (let j = 0; j < this.children.length; j++) {\n        const child = this.children[j];\n        if (child instanceof ctxType) {\n          contexts.push(child);\n        }\n      }\n      return contexts;\n    }\n  }\n\n  getChildCount() {\n    if (this.children === null) {\n      return 0;\n    } else {\n      return this.children.length;\n    }\n  }\n\n  getSourceInterval() {\n    if (this.start === null || this.stop === null) {\n      return Interval.INVALID_INTERVAL;\n    } else {\n      return new Interval(this.start.tokenIndex, this.stop.tokenIndex);\n    }\n  }\n}\n\nRuleContext.EMPTY = new ParserRuleContext();\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { ParserRuleContext } from './ParserRuleContext.js';\n\nexport class InterpreterRuleContext extends ParserRuleContext {\n  constructor(parent, invokingStateNumber, ruleIndex) {\n    super(parent, invokingStateNumber);\n    this.ruleIndex = ruleIndex;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { arrayToString } from '../utils/arrayToString.js';\n\n/**\n * A DFA walker that knows how to dump them to serialized strings.\n */\nexport class DFASerializer {\n  constructor(dfa, literalNames, symbolicNames) {\n    this.dfa = dfa;\n    this.literalNames = literalNames || [];\n    this.symbolicNames = symbolicNames || [];\n  }\n\n  toString() {\n    if (this.dfa.s0 === null) {\n      return null;\n    }\n    let buf = '';\n    const states = this.dfa.sortedStates();\n    for (let i = 0; i < states.length; i++) {\n      const s = states[i];\n      if (s.edges !== null) {\n        const n = s.edges.length;\n        for (let j = 0; j < n; j++) {\n          const t = s.edges[j] || null;\n          if (t !== null && t.stateNumber !== 0x7fffffff) {\n            buf = buf.concat(this.getStateString(s));\n            buf = buf.concat('-');\n            buf = buf.concat(this.getEdgeLabel(j));\n            buf = buf.concat('->');\n            buf = buf.concat(this.getStateString(t));\n            buf = buf.concat('\\n');\n          }\n        }\n      }\n    }\n    return buf.length === 0 ? null : buf;\n  }\n\n  getEdgeLabel(i) {\n    if (i === 0) {\n      return 'EOF';\n    } else if (this.literalNames !== null || this.symbolicNames !== null) {\n      return this.literalNames[i - 1] || this.symbolicNames[i - 1];\n    } else {\n      return String.fromCharCode(i - 1);\n    }\n  }\n\n  getStateString(s) {\n    const baseStateStr = (s.isAcceptState ? ':' : '') + 's' + s.stateNumber + (s.requiresFullContext ? '^' : '');\n    if (s.isAcceptState) {\n      if (s.predicates !== null) {\n        return baseStateStr + '=>' + arrayToString(s.predicates);\n      } else {\n        return baseStateStr + '=>' + s.prediction.toString();\n      }\n    } else {\n      return baseStateStr;\n    }\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { DFASerializer } from './DFASerializer.js';\n\nexport class LexerDFASerializer extends DFASerializer {\n  constructor(dfa) {\n    super(dfa, null);\n  }\n\n  getEdgeLabel(i) {\n    return \"'\" + String.fromCharCode(i) + \"'\";\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { DFAState } from './DFAState.js';\nimport { StarLoopEntryState } from '../state/StarLoopEntryState.js';\nimport { ATNConfigSet } from './../atn/ATNConfigSet.js';\nimport { DFASerializer } from './DFASerializer.js';\nimport { LexerDFASerializer } from './LexerDFASerializer.js';\nimport { HashSet } from '../misc/HashSet.js';\n\nexport class DFA {\n  constructor(atnStartState, decision) {\n    if (decision === undefined) {\n      decision = 0;\n    }\n    /**\n     * From which ATN state did we create this DFA?\n     */\n    this.atnStartState = atnStartState;\n    this.decision = decision;\n    /**\n     * A set of all DFA states. Use {@link Map} so we can get old state back\n     * ({@link Set} only allows you to see if it's there).\n     */\n    this._states = new HashSet();\n    this.s0 = null;\n    /**\n     * {@code true} if this DFA is for a precedence decision; otherwise,\n     * {@code false}. This is the backing field for {@link //isPrecedenceDfa},\n     * {@link //setPrecedenceDfa}\n     */\n    this.precedenceDfa = false;\n    if (atnStartState instanceof StarLoopEntryState) {\n      if (atnStartState.isPrecedenceDecision) {\n        this.precedenceDfa = true;\n        const precedenceState = new DFAState(null, new ATNConfigSet());\n        precedenceState.edges = [];\n        precedenceState.isAcceptState = false;\n        precedenceState.requiresFullContext = false;\n        this.s0 = precedenceState;\n      }\n    }\n  }\n\n  get states() {\n    return this._states;\n  }\n\n  /**\n   * Get the start state for a specific precedence value.\n   *\n   * @param precedence The current precedence.\n   * @return The start state corresponding to the specified precedence, or\n   * {@code null} if no start state exists for the specified precedence.\n   *\n   * @throws IllegalStateException if this is not a precedence DFA.\n   * @see //isPrecedenceDfa()\n   */\n  getPrecedenceStartState(precedence) {\n    if (!this.precedenceDfa) {\n      throw 'Only precedence DFAs may contain a precedence start state.';\n    }\n    // s0.edges is never null for a precedence DFA\n    if (precedence < 0 || precedence >= this.s0.edges.length) {\n      return null;\n    }\n    return this.s0.edges[precedence] || null;\n  }\n\n  /**\n   * Set the start state for a specific precedence value.\n   *\n   * @param precedence The current precedence.\n   * @param startState The start state corresponding to the specified\n   * precedence.\n   *\n   * @throws IllegalStateException if this is not a precedence DFA.\n   * @see //isPrecedenceDfa()\n   */\n  setPrecedenceStartState(precedence, startState) {\n    if (!this.precedenceDfa) {\n      throw 'Only precedence DFAs may contain a precedence start state.';\n    }\n    if (precedence < 0) {\n      return;\n    }\n\n    /**\n     * synchronization on s0 here is ok. when the DFA is turned into a\n     * precedence DFA, s0 will be initialized once and not updated again\n     * s0.edges is never null for a precedence DFA\n     */\n    this.s0.edges[precedence] = startState;\n  }\n\n  /**\n   * Sets whether this is a precedence DFA. If the specified value differs\n   * from the current DFA configuration, the following actions are taken;\n   * otherwise no changes are made to the current DFA.\n   *\n   * <ul>\n   * <li>The {@link //states} map is cleared</li>\n   * <li>If {@code precedenceDfa} is {@code false}, the initial state\n   * {@link //s0} is set to {@code null}; otherwise, it is initialized to a new\n   * {@link DFAState} with an empty outgoing {@link DFAState//edges} array to\n   * store the start states for individual precedence values.</li>\n   * <li>The {@link //precedenceDfa} field is updated</li>\n   * </ul>\n   *\n   * @param precedenceDfa {@code true} if this is a precedence DFA; otherwise,\n   * {@code false}\n   */\n  setPrecedenceDfa(precedenceDfa) {\n    if (this.precedenceDfa !== precedenceDfa) {\n      this._states = new HashSet();\n      if (precedenceDfa) {\n        const precedenceState = new DFAState(null, new ATNConfigSet());\n        precedenceState.edges = [];\n        precedenceState.isAcceptState = false;\n        precedenceState.requiresFullContext = false;\n        this.s0 = precedenceState;\n      } else {\n        this.s0 = null;\n      }\n      this.precedenceDfa = precedenceDfa;\n    }\n  }\n\n  /**\n   * Return a list of all states in this DFA, ordered by state number.\n   */\n  sortedStates() {\n    const list = this._states.values();\n    return list.sort(function (a, b) {\n      return a.stateNumber - b.stateNumber;\n    });\n  }\n\n  toString(literalNames, symbolicNames) {\n    literalNames = literalNames || null;\n    symbolicNames = symbolicNames || null;\n    if (this.s0 === null) {\n      return '';\n    }\n    const serializer = new DFASerializer(this, literalNames, symbolicNames);\n    return serializer.toString();\n  }\n\n  toLexerString() {\n    if (this.s0 === null) {\n      return '';\n    }\n    const serializer = new LexerDFASerializer(this);\n    return serializer.toString();\n  }\n}\n","export function stringToCharArray(str) {\n  let result = new Uint16Array(str.length);\n  for (let i = 0; i < str.length; i++) {\n    result[i] = str.charCodeAt(i);\n  }\n  return result;\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n// this is just to keep meaningful parameter types to Parser\nexport class TokenStream {}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { Token } from './Token.js';\nimport { Lexer } from './Lexer.js';\nimport { Interval } from './misc/Interval.js';\nimport { TokenStream } from './TokenStream.js';\n\n/**\n * This implementation of {@link TokenStream} loads tokens from a\n * {@link TokenSource} on-demand, and places the tokens in a buffer to provide\n * access to any previous token by index.\n *\n * <p>\n * This token stream ignores the value of {@link Token//getChannel}. If your\n * parser requires the token stream filter tokens to only those on a particular\n * channel, such as {@link Token//DEFAULT_CHANNEL} or\n * {@link Token//HIDDEN_CHANNEL}, use a filtering token stream such a\n * {@link CommonTokenStream}.</p>\n */\nexport class BufferedTokenStream extends TokenStream {\n  constructor(tokenSource) {\n    super();\n    // The {@link TokenSource} from which tokens for this stream are fetched.\n    this.tokenSource = tokenSource;\n    /**\n     * A collection of all tokens fetched from the token source. The list is\n     * considered a complete view of the input once {@link //fetchedEOF} is set\n     * to {@code true}.\n     */\n    this.tokens = [];\n\n    /**\n     * The index into {@link //tokens} of the current token (next token to\n     * {@link //consume}). {@link //tokens}{@code [}{@link //p}{@code ]} should\n     * be\n     * {@link //LT LT(1)}.\n     *\n     * <p>This field is set to -1 when the stream is first constructed or when\n     * {@link //setTokenSource} is called, indicating that the first token has\n     * not yet been fetched from the token source. For additional information,\n     * see the documentation of {@link IntStream} for a description of\n     * Initializing Methods.</p>\n     */\n    this.index = -1;\n\n    /**\n     * Indicates whether the {@link Token//EOF} token has been fetched from\n     * {@link //tokenSource} and added to {@link //tokens}. This field improves\n     * performance for the following cases:\n     *\n     * <ul>\n     * <li>{@link //consume}: The lookahead check in {@link //consume} to\n     * prevent\n     * consuming the EOF symbol is optimized by checking the values of\n     * {@link //fetchedEOF} and {@link //p} instead of calling {@link\n     * //LA}.</li>\n     * <li>{@link //fetch}: The check to prevent adding multiple EOF symbols\n     * into\n     * {@link //tokens} is trivial with this field.</li>\n     * <ul>\n     */\n    this.fetchedEOF = false;\n  }\n\n  mark() {\n    return 0;\n  }\n\n  release(marker) {\n    // no resources to release\n  }\n\n  reset() {\n    this.seek(0);\n  }\n\n  seek(index) {\n    this.lazyInit();\n    this.index = this.adjustSeekIndex(index);\n  }\n\n  get(index) {\n    this.lazyInit();\n    return this.tokens[index];\n  }\n\n  consume() {\n    let skipEofCheck = false;\n    if (this.index >= 0) {\n      if (this.fetchedEOF) {\n        // the last token in tokens is EOF. skip check if p indexes any\n        // fetched token except the last.\n        skipEofCheck = this.index < this.tokens.length - 1;\n      } else {\n        // no EOF token in tokens. skip check if p indexes a fetched token.\n        skipEofCheck = this.index < this.tokens.length;\n      }\n    } else {\n      // not yet initialized\n      skipEofCheck = false;\n    }\n    if (!skipEofCheck && this.LA(1) === Token.EOF) {\n      throw new Error('cannot consume EOF');\n    }\n    if (this.sync(this.index + 1)) {\n      this.index = this.adjustSeekIndex(this.index + 1);\n    }\n  }\n\n  /**\n   * Make sure index {@code i} in tokens has a token.\n   *\n   * @return {Boolean} {@code true} if a token is located at index {@code i}, otherwise\n   * {@code false}.\n   * @see //get(int i)\n   */\n  sync(i) {\n    const n = i - this.tokens.length + 1; // how many more elements we need?\n    if (n > 0) {\n      const fetched = this.fetch(n);\n      return fetched >= n;\n    }\n    return true;\n  }\n\n  /**\n   * Add {@code n} elements to buffer.\n   *\n   * @return {Number} The actual number of elements added to the buffer.\n   */\n  fetch(n) {\n    if (this.fetchedEOF) {\n      return 0;\n    }\n    for (let i = 0; i < n; i++) {\n      const t = this.tokenSource.nextToken();\n      t.tokenIndex = this.tokens.length;\n      this.tokens.push(t);\n      if (t.type === Token.EOF) {\n        this.fetchedEOF = true;\n        return i + 1;\n      }\n    }\n    return n;\n  }\n\n  // Get all tokens from start..stop inclusively///\n  getTokens(start, stop, types) {\n    if (types === undefined) {\n      types = null;\n    }\n    if (start < 0 || stop < 0) {\n      return null;\n    }\n    this.lazyInit();\n    const subset = [];\n    if (stop >= this.tokens.length) {\n      stop = this.tokens.length - 1;\n    }\n    for (let i = start; i < stop; i++) {\n      const t = this.tokens[i];\n      if (t.type === Token.EOF) {\n        break;\n      }\n      if (types === null || types.contains(t.type)) {\n        subset.push(t);\n      }\n    }\n    return subset;\n  }\n\n  LA(i) {\n    return this.LT(i).type;\n  }\n\n  LB(k) {\n    if (this.index - k < 0) {\n      return null;\n    }\n    return this.tokens[this.index - k];\n  }\n\n  LT(k) {\n    this.lazyInit();\n    if (k === 0) {\n      return null;\n    }\n    if (k < 0) {\n      return this.LB(-k);\n    }\n    const i = this.index + k - 1;\n    this.sync(i);\n    if (i >= this.tokens.length) {\n      // return EOF token\n      // EOF must be last token\n      return this.tokens[this.tokens.length - 1];\n    }\n    return this.tokens[i];\n  }\n\n  /**\n   * Allowed derived classes to modify the behavior of operations which change\n   * the current stream position by adjusting the target token index of a seek\n   * operation. The default implementation simply returns {@code i}. If an\n   * exception is thrown in this method, the current stream index should not be\n   * changed.\n   *\n   * <p>For example, {@link CommonTokenStream} overrides this method to ensure\n   * that\n   * the seek target is always an on-channel token.</p>\n   *\n   * @param {Number} i The target token index.\n   * @return {Number} The adjusted target token index.\n   */\n  adjustSeekIndex(i) {\n    return i;\n  }\n\n  lazyInit() {\n    if (this.index === -1) {\n      this.setup();\n    }\n  }\n\n  setup() {\n    this.sync(0);\n    this.index = this.adjustSeekIndex(0);\n  }\n\n  // Reset this token stream by setting its token source.///\n  setTokenSource(tokenSource) {\n    this.tokenSource = tokenSource;\n    this.tokens = [];\n    this.index = -1;\n    this.fetchedEOF = false;\n  }\n\n  /**\n   * Given a starting index, return the index of the next token on channel.\n   * Return i if tokens[i] is on channel. Return -1 if there are no tokens\n   * on channel between i and EOF.\n   */\n  nextTokenOnChannel(i, channel) {\n    this.sync(i);\n    if (i >= this.tokens.length) {\n      return -1;\n    }\n    let token = this.tokens[i];\n    while (token.channel !== this.channel) {\n      if (token.type === Token.EOF) {\n        return -1;\n      }\n      i += 1;\n      this.sync(i);\n      token = this.tokens[i];\n    }\n    return i;\n  }\n\n  /**\n   * Given a starting index, return the index of the previous token on channel.\n   * Return i if tokens[i] is on channel. Return -1 if there are no tokens\n   * on channel between i and 0.\n   */\n  previousTokenOnChannel(i, channel) {\n    while (i >= 0 && this.tokens[i].channel !== channel) {\n      i -= 1;\n    }\n    return i;\n  }\n\n  /**\n   * Collect all tokens on specified channel to the right of\n   * the current token up until we see a token on DEFAULT_TOKEN_CHANNEL or\n   * EOF. If channel is -1, find any non default channel token.\n   */\n  getHiddenTokensToRight(tokenIndex, channel) {\n    if (channel === undefined) {\n      channel = -1;\n    }\n    this.lazyInit();\n    if (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n      throw String(tokenIndex) + ' not in 0..' + this.tokens.length - 1;\n    }\n    const nextOnChannel = this.nextTokenOnChannel(tokenIndex + 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n    const from_ = tokenIndex + 1;\n    // if none onchannel to right, nextOnChannel=-1 so set to = last token\n    const to = nextOnChannel === -1 ? this.tokens.length - 1 : nextOnChannel;\n    return this.filterForChannel(from_, to, channel);\n  }\n\n  /**\n   * Collect all tokens on specified channel to the left of\n   * the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.\n   * If channel is -1, find any non default channel token.\n   */\n  getHiddenTokensToLeft(tokenIndex, channel) {\n    if (channel === undefined) {\n      channel = -1;\n    }\n    this.lazyInit();\n    if (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n      throw String(tokenIndex) + ' not in 0..' + this.tokens.length - 1;\n    }\n    const prevOnChannel = this.previousTokenOnChannel(tokenIndex - 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n    if (prevOnChannel === tokenIndex - 1) {\n      return null;\n    }\n    // if none on channel to left, prevOnChannel=-1 then from=0\n    const from_ = prevOnChannel + 1;\n    const to = tokenIndex - 1;\n    return this.filterForChannel(from_, to, channel);\n  }\n\n  filterForChannel(left, right, channel) {\n    const hidden = [];\n    for (let i = left; i < right + 1; i++) {\n      const t = this.tokens[i];\n      if (channel === -1) {\n        if (t.channel !== Lexer.DEFAULT_TOKEN_CHANNEL) {\n          hidden.push(t);\n        }\n      } else if (t.channel === channel) {\n        hidden.push(t);\n      }\n    }\n    if (hidden.length === 0) {\n      return null;\n    }\n    return hidden;\n  }\n\n  getSourceName() {\n    return this.tokenSource.getSourceName();\n  }\n\n  // Get the text of all tokens in this buffer.///\n  getText(interval) {\n    this.lazyInit();\n    this.fill();\n    if (!interval) {\n      interval = new Interval(0, this.tokens.length - 1);\n    }\n    let start = interval.start;\n    if (start instanceof Token) {\n      start = start.tokenIndex;\n    }\n    let stop = interval.stop;\n    if (stop instanceof Token) {\n      stop = stop.tokenIndex;\n    }\n    if (start === null || stop === null || start < 0 || stop < 0) {\n      return '';\n    }\n    if (stop >= this.tokens.length) {\n      stop = this.tokens.length - 1;\n    }\n    let s = '';\n    for (let i = start; i < stop + 1; i++) {\n      const t = this.tokens[i];\n      if (t.type === Token.EOF) {\n        break;\n      }\n      s = s + t.text;\n    }\n    return s;\n  }\n\n  // Get all tokens from lexer until EOF///\n  fill() {\n    this.lazyInit();\n    // noinspection StatementWithEmptyBodyJS\n    while (this.fetch(1000) === 1000);\n  }\n}\n\nObject.defineProperty(BufferedTokenStream, 'size', {\n  get: function () {\n    return this.tokens.length;\n  },\n});\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n/* ! https://mths.be/codepointat v0.2.0 by @mathias */\nif (!String.prototype.codePointAt) {\n  (function () {\n    // needed to support `apply`/`call` with `undefined`/`null`\n    let defineProperty = (function () {\n      // IE 8 only supports `Object.defineProperty` on DOM elements\n      let result;\n      try {\n        const object = {};\n        const $defineProperty = Object.defineProperty;\n        result = $defineProperty(object, object, object) && $defineProperty;\n      } catch (error) {\n        /* eslint no-empty: [ \"off\" ] */\n      }\n      return result;\n    })();\n    const codePointAt = function (position) {\n      if (this == null) {\n        throw TypeError();\n      }\n      const string = String(this);\n      const size = string.length;\n      // `ToInteger`\n      let index = position ? Number(position) : 0;\n      if (index !== index) {\n        // better `isNaN`\n        index = 0;\n      }\n      // Account for out-of-bounds indices:\n      if (index < 0 || index >= size) {\n        return undefined;\n      }\n      // Get the first code unit\n      const first = string.charCodeAt(index);\n      let second;\n      if (\n        // check if it’s the start of a surrogate pair\n        first >= 0xd800 &&\n        first <= 0xdbff && // high surrogate\n        size > index + 1 // there is a next code unit\n      ) {\n        second = string.charCodeAt(index + 1);\n        if (second >= 0xdc00 && second <= 0xdfff) {\n          // low surrogate\n          // https://mathiasbynens.be/notes/javascript-encoding#surrogate-formulae\n          return (first - 0xd800) * 0x400 + second - 0xdc00 + 0x10000;\n        }\n      }\n      return first;\n    };\n    if (defineProperty) {\n      defineProperty(String.prototype, 'codePointAt', {\n        value: codePointAt,\n        configurable: true,\n        writable: true,\n      });\n    } else {\n      String.prototype.codePointAt = codePointAt;\n    }\n  })();\n}\n\nexport const CodePointAt = String.prototype.codePointAt;\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n/* ! https://mths.be/fromcodepoint v0.2.1 by @mathias */\nif (!String.fromCodePoint) {\n  (function () {\n    const defineProperty = (function () {\n      // IE 8 only supports `Object.defineProperty` on DOM elements\n      let result;\n      try {\n        const object = {};\n        const $defineProperty = Object.defineProperty;\n        result = $defineProperty(object, object, object) && $defineProperty;\n      } catch (error) {\n        /* eslint no-empty: [ \"off\" ] */\n      }\n      return result;\n    })();\n    const stringFromCharCode = String.fromCharCode;\n    const floor = Math.floor;\n    const fromCodePoint = function (_) {\n      const MAX_SIZE = 0x4000;\n      const codeUnits = [];\n      let highSurrogate;\n      let lowSurrogate;\n      let index = -1;\n      const length = arguments.length;\n      if (!length) {\n        return '';\n      }\n      let result = '';\n      while (++index < length) {\n        let codePoint = Number(arguments[index]);\n        if (\n          !isFinite(codePoint) || // `NaN`, `+Infinity`, or `-Infinity`\n          codePoint < 0 || // not a valid Unicode code point\n          codePoint > 0x10ffff || // not a valid Unicode code point\n          floor(codePoint) !== codePoint // not an integer\n        ) {\n          throw RangeError('Invalid code point: ' + codePoint);\n        }\n        if (codePoint <= 0xffff) {\n          // BMP code point\n          codeUnits.push(codePoint);\n        } else {\n          // Astral code point; split in surrogate halves\n          // https://mathiasbynens.be/notes/javascript-encoding#surrogate-formulae\n          codePoint -= 0x10000;\n          highSurrogate = (codePoint >> 10) + 0xd800;\n          lowSurrogate = (codePoint % 0x400) + 0xdc00;\n          codeUnits.push(highSurrogate, lowSurrogate);\n        }\n        if (index + 1 === length || codeUnits.length > MAX_SIZE) {\n          result += stringFromCharCode.apply(null, codeUnits);\n          codeUnits.length = 0;\n        }\n      }\n      return result;\n    };\n    if (defineProperty) {\n      defineProperty(String, 'fromCodePoint', {\n        value: fromCodePoint,\n        configurable: true,\n        writable: true,\n      });\n    } else {\n      String.fromCodePoint = fromCodePoint;\n    }\n  })();\n}\n\nexport const FromCodePoint = String.prototype.fromCodePoint;\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { Token } from './Token.js';\nimport './polyfills/codepointat.js';\nimport './polyfills/fromcodepoint.js';\n\n/**\n * If decodeToUnicodeCodePoints is true, the input is treated\n * as a series of Unicode code points.\n *\n * Otherwise, the input is treated as a series of 16-bit UTF-16 code\n * units.\n */\nexport class CharStream {\n  constructor(data, decodeToUnicodeCodePoints) {\n    this.name = '<empty>';\n    this.strdata = data;\n    this.decodeToUnicodeCodePoints = decodeToUnicodeCodePoints || false;\n    // _loadString - Vacuum all input from a string and then treat it like a buffer.\n    this._index = 0;\n    this.data = [];\n    if (this.decodeToUnicodeCodePoints) {\n      for (let i = 0; i < this.strdata.length; ) {\n        const codePoint = this.strdata.codePointAt(i);\n        this.data.push(codePoint);\n        i += codePoint <= 0xffff ? 1 : 2;\n      }\n    } else {\n      this.data = new Array(this.strdata.length);\n      for (let i = 0; i < this.strdata.length; i++) {\n        this.data[i] = this.strdata.charCodeAt(i);\n      }\n    }\n    this._size = this.data.length;\n  }\n\n  get index() {\n    return this._index;\n  }\n\n  get size() {\n    return this._size;\n  }\n\n  /**\n   * Reset the stream so that it's in the same state it was\n   * when the object was created *except* the data array is not\n   * touched.\n   */\n  reset() {\n    this._index = 0;\n  }\n\n  consume() {\n    if (this._index >= this._size) {\n      // assert this.LA(1) == Token.EOF\n      throw 'cannot consume EOF';\n    }\n    this._index += 1;\n  }\n\n  LA(offset) {\n    if (offset === 0) {\n      return 0; // undefined\n    }\n    if (offset < 0) {\n      offset += 1; // e.g., translate LA(-1) to use offset=0\n    }\n    const pos = this._index + offset - 1;\n    if (pos < 0 || pos >= this._size) {\n      // invalid\n      return Token.EOF;\n    }\n    return this.data[pos];\n  }\n\n  LT(offset) {\n    return this.LA(offset);\n  }\n\n  // mark/release do nothing; we have entire buffer\n  mark() {\n    return -1;\n  }\n\n  release(marker) {}\n\n  /**\n   * consume() ahead until p==_index; can't just set p=_index as we must\n   * update line and column. If we seek backwards, just set p\n   */\n  seek(_index) {\n    if (_index <= this._index) {\n      this._index = _index; // just jump; don't update stream state (line,\n      // ...)\n      return;\n    }\n    // seek forward\n    this._index = Math.min(_index, this._size);\n  }\n\n  getText(start, stop) {\n    if (stop >= this._size) {\n      stop = this._size - 1;\n    }\n    if (start >= this._size) {\n      return '';\n    } else {\n      if (this.decodeToUnicodeCodePoints) {\n        let result = '';\n        for (let i = start; i <= stop; i++) {\n          result += String.fromCodePoint(this.data[i]);\n        }\n        return result;\n      } else {\n        return this.strdata.slice(start, stop + 1);\n      }\n    }\n  }\n\n  toString() {\n    return this.strdata;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { CharStream } from './CharStream.js';\n\n/**\n * @deprecated Use CharStream instead\n */\nexport class InputStream extends CharStream {\n  constructor(data, decodeToUnicodeCodePoints) {\n    super(data, decodeToUnicodeCodePoints);\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { InputStream } from './InputStream.js';\n\n/**\n * This is an InputStream that is loaded from a file all at once\n * when you construct the object.\n */\nexport class FileStream extends InputStream {\n  constructor(fileName, encoding, decodeToUnicodeCodePoints) {\n    super(null, decodeToUnicodeCodePoints);\n    throw new Error('FileStream is only available when running in Node!');\n  }\n\n  static fromPath(path, encoding, callback) {\n    throw new Error('FileStream is only available when running in Node!');\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { CharStream } from './CharStream.js';\nimport { FileStream } from './FileStream.js';\n\n/**\n * Utility functions to create InputStreams from various sources.\n *\n * All returned InputStreams support the full range of Unicode\n * up to U+10FFFF (the default behavior of InputStream only supports\n * code points up to U+FFFF).\n */\nexport class CharStreams {\n  // Creates an InputStream from a string.\n  static fromString(str) {\n    return new CharStream(str, true);\n  }\n\n  /**\n   * Asynchronously creates an InputStream from a blob given the\n   * encoding of the bytes in that blob (defaults to 'utf8' if\n   * encoding is null).\n   *\n   * Invokes onLoad(result) on success, onError(error) on\n   * failure.\n   */\n  static fromBlob(blob, encoding, onLoad, onError) {\n    const reader = new window.FileReader();\n    reader.onload = function (e) {\n      const is = new CharStream(e.target.result, true);\n      onLoad(is);\n    };\n    reader.onerror = onError;\n    reader.readAsText(blob, encoding);\n  }\n\n  /**\n   * Creates an InputStream from a Buffer given the\n   * encoding of the bytes in that buffer (defaults to 'utf8' if\n   * encoding is null).\n   */\n  static fromBuffer(buffer, encoding) {\n    return new CharStream(buffer.toString(encoding), true);\n  }\n\n  /** Asynchronously creates an InputStream from a file on disk given\n   * the encoding of the bytes in that file (defaults to 'utf8' if\n   * encoding is null).\n   *\n   * Invokes callback(error, result) on completion.\n   */\n  static fromPath(path, encoding, callback) {\n    FileStream.fromPath(path, encoding, callback);\n  }\n\n  /**\n   * Synchronously creates an InputStream given a path to a file\n   * on disk and the encoding of the bytes in that file (defaults to\n   * 'utf8' if encoding is null).\n   */\n  static fromPathSync(path, encoding) {\n    return new FileStream(path, encoding);\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { Token } from './Token.js';\nimport { BufferedTokenStream } from './BufferedTokenStream.js';\n\n/**\n * This class extends {@link BufferedTokenStream} with functionality to filter\n * token streams to tokens on a particular channel (tokens where\n * {@link Token//getChannel} returns a particular value).\n *\n * <p>\n * This token stream provides access to all tokens by index or when calling\n * methods like {@link //getText}. The channel filtering is only used for code\n * accessing tokens via the lookahead methods {@link //LA}, {@link //LT}, and\n * {@link //LB}.</p>\n *\n * <p>\n * By default, tokens are placed on the default channel\n * ({@link Token//DEFAULT_CHANNEL}), but may be reassigned by using the\n * {@code ->channel(HIDDEN)} lexer command, or by using an embedded action to\n * call {@link Lexer//setChannel}.\n * </p>\n *\n * <p>\n * Note: lexer rules which use the {@code ->skip} lexer command or call\n * {@link Lexer//skip} do not produce tokens at all, so input text matched by\n * such a rule will not be available as part of the token stream, regardless of\n * channel.</p>\n */\nexport class CommonTokenStream extends BufferedTokenStream {\n  constructor(lexer, channel) {\n    super(lexer);\n    this.channel = channel === undefined ? Token.DEFAULT_CHANNEL : channel;\n  }\n\n  adjustSeekIndex(i) {\n    return this.nextTokenOnChannel(i, this.channel);\n  }\n\n  LB(k) {\n    if (k === 0 || this.index - k < 0) {\n      return null;\n    }\n    let i = this.index;\n    let n = 1;\n    // find k good tokens looking backwards\n    while (n <= k) {\n      // skip off-channel tokens\n      i = this.previousTokenOnChannel(i - 1, this.channel);\n      n += 1;\n    }\n    if (i < 0) {\n      return null;\n    }\n    return this.tokens[i];\n  }\n\n  LT(k) {\n    this.lazyInit();\n    if (k === 0) {\n      return null;\n    }\n    if (k < 0) {\n      return this.LB(-k);\n    }\n    let i = this.index;\n    let n = 1; // we know tokens[pos] is a good one\n    // find k good tokens\n    while (n < k) {\n      // skip off-channel tokens, but make sure to not look past EOF\n      if (this.sync(i + 1)) {\n        i = this.nextTokenOnChannel(i + 1, this.channel);\n      }\n      n += 1;\n    }\n    return this.tokens[i];\n  }\n\n  // Count EOF just once.\n  getNumberOfOnChannelTokens() {\n    let n = 0;\n    this.fill();\n    for (let i = 0; i < this.tokens.length; i++) {\n      const t = this.tokens[i];\n      if (t.channel === this.channel) {\n        n += 1;\n      }\n      if (t.type === Token.EOF) {\n        break;\n      }\n    }\n    return n;\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { ParseTreeListener } from './tree/ParseTreeListener.js';\n\nexport class TraceListener extends ParseTreeListener {\n  constructor(parser) {\n    super();\n    this.parser = parser;\n  }\n\n  enterEveryRule(ctx) {\n    console.log('enter   ' + this.parser.ruleNames[ctx.ruleIndex] + ', LT(1)=' + this.parser._input.LT(1).text);\n  }\n\n  visitTerminal(node) {\n    console.log('consume ' + node.symbol + ' rule ' + this.parser.ruleNames[this.parser._ctx.ruleIndex]);\n  }\n\n  exitEveryRule(ctx) {\n    console.log('exit    ' + this.parser.ruleNames[ctx.ruleIndex] + ', LT(1)=' + this.parser._input.LT(1).text);\n  }\n}\n","/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport { Token } from './Token.js';\nimport { TerminalNode } from './tree/TerminalNode.js';\nimport { ErrorNode } from './tree/ErrorNode.js';\nimport { Recognizer } from './Recognizer.js';\nimport { DefaultErrorStrategy } from './error/DefaultErrorStrategy.js';\nimport { ATNDeserializer } from './atn/ATNDeserializer.js';\nimport { ATNDeserializationOptions } from './atn/ATNDeserializationOptions.js';\nimport { TraceListener } from './TraceListener.js';\n\nexport class Parser extends Recognizer {\n  /**\n   * this is all the parsing support code essentially; most of it is error\n   * recovery stuff.\n   */\n  constructor(input) {\n    super();\n    // The input stream.\n    this._input = null;\n    /**\n     * The error handling strategy for the parser. The default value is a new\n     * instance of {@link DefaultErrorStrategy}.\n     */\n    this._errHandler = new DefaultErrorStrategy();\n    this._precedenceStack = [];\n    this._precedenceStack.push(0);\n    /**\n     * The {@link ParserRuleContext} object for the currently executing rule.\n     * this is always non-null during the parsing process.\n     */\n    this._ctx = null;\n    /**\n     * Specifies whether or not the parser should construct a parse tree during\n     * the parsing process. The default value is {@code true}.\n     */\n    this.buildParseTrees = true;\n    /**\n     * When {@link //setTrace}{@code (true)} is called, a reference to the\n     * {@link TraceListener} is stored here so it can be easily removed in a\n     * later call to {@link //setTrace}{@code (false)}. The listener itself is\n     * implemented as a parser listener so this field is not directly used by\n     * other parser methods.\n     */\n    this._tracer = null;\n    /**\n     * The list of {@link ParseTreeListener} listeners registered to receive\n     * events during the parse.\n     */\n    this._parseListeners = null;\n    /**\n     * The number of syntax errors reported during parsing. this value is\n     * incremented each time {@link //notifyErrorListeners} is called.\n     */\n    this._syntaxErrors = 0;\n    this.setInputStream(input);\n  }\n\n  // reset the parser's state\n  reset() {\n    if (this._input !== null) {\n      this._input.seek(0);\n    }\n    this._errHandler.reset(this);\n    this._ctx = null;\n    this._syntaxErrors = 0;\n    this.setTrace(false);\n    this._precedenceStack = [];\n    this._precedenceStack.push(0);\n    if (this._interp !== null) {\n      this._interp.reset();\n    }\n  }\n\n  /**\n   * Match current input symbol against {@code ttype}. If the symbol type\n   * matches, {@link ANTLRErrorStrategy//reportMatch} and {@link //consume} are\n   * called to complete the match process.\n   *\n   * <p>If the symbol type does not match,\n   * {@link ANTLRErrorStrategy//recoverInline} is called on the current error\n   * strategy to attempt recovery. If {@link //buildParseTree} is\n   * {@code true} and the token index of the symbol returned by\n   * {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to\n   * the parse tree by calling {@link ParserRuleContext//addErrorNode}.</p>\n   *\n   * @param ttype the token type to match\n   * @return the matched symbol\n   * @throws RecognitionException if the current input symbol did not match\n   * {@code ttype} and the error strategy could not recover from the\n   * mismatched symbol\n   */\n  match(ttype) {\n    let t = this.getCurrentToken();\n    if (t.type === ttype) {\n      this._errHandler.reportMatch(this);\n      this.consume();\n    } else {\n      t = this._errHandler.recoverInline(this);\n      if (this.buildParseTrees && t.tokenIndex === -1) {\n        // we must have conjured up a new token during single token\n        // insertion\n        // if it's not the current symbol\n        this._ctx.addErrorNode(t);\n      }\n    }\n    return t;\n  }\n\n  /**\n   * Match current input symbol as a wildcard. If the symbol type matches\n   * (i.e. has a value greater than 0), {@link ANTLRErrorStrategy//reportMatch}\n   * and {@link //consume} are called to complete the match process.\n   *\n   * <p>If the symbol type does not match,\n   * {@link ANTLRErrorStrategy//recoverInline} is called on the current error\n   * strategy to attempt recovery. If {@link //buildParseTree} is\n   * {@code true} and the token index of the symbol returned by\n   * {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to\n   * the parse tree by calling {@link ParserRuleContext//addErrorNode}.</p>\n   *\n   * @return the matched symbol\n   * @throws RecognitionException if the current input symbol did not match\n   * a wildcard and the error strategy could not recover from the mismatched\n   * symbol\n   */\n  matchWildcard() {\n    let t = this.getCurrentToken();\n    if (t.type > 0) {\n      this._errHandler.reportMatch(this);\n      this.consume();\n    } else {\n      t = this._errHandler.recoverInline(this);\n      if (this.buildParseTrees && t.tokenIndex === -1) {\n        // we must have conjured up a new token during single token\n        // insertion\n        // if it's not the current symbol\n        this._ctx.addErrorNode(t);\n      }\n    }\n    return t;\n  }\n\n  getParseListeners() {\n    return this._parseListeners || [];\n  }\n\n  /**\n   * Registers {@code listener} to receive events during the parsing process.\n   *\n   * <p>To support output-preserving grammar transformations (including but not\n   * limited to left-recursion removal, automated left-factoring, and\n   * optimized code generation), calls to listener methods during the parse\n   * may differ substantially from calls made by\n   * {@link ParseTreeWalker//DEFAULT} used after the parse is complete. In\n   * particular, rule entry and exit events may occur in a different order\n   * during the parse than after the parser. In addition, calls to certain\n   * rule entry methods may be omitted.</p>\n   *\n   * <p>With the following specific exceptions, calls to listener events are\n   * <em>deterministic</em>, i.e. for identical input the calls to listener\n   * methods will be the same.</p>\n   *\n   * <ul>\n   * <li>Alterations to the grammar used to generate code may change the\n   * behavior of the listener calls.</li>\n   * <li>Alterations to the command line options passed to ANTLR 4 when\n   * generating the parser may change the behavior of the listener calls.</li>\n   * <li>Changing the version of the ANTLR Tool used to generate the parser\n   * may change the behavior of the listener calls.</li>\n   * </ul>\n   *\n   * @param listener the listener to add\n   *\n   * @throws NullPointerException if {@code} listener is {@code null}\n   */\n  addParseListener(listener) {\n    if (listener === null) {\n      throw new Error('listener');\n    }\n    if (this._parseListeners === null) {\n      this._parseListeners = [];\n    }\n    this._parseListeners.push(listener);\n  }\n\n  /**\n   * Remove {@code listener} from the list of parse listeners.\n   *\n   * <p>If {@code listener} is {@code null} or has not been added as a parse\n   * listener, this method does nothing.</p>\n   * @param listener the listener to remove\n   */\n  removeParseListener(listener) {\n    if (this._parseListeners !== null) {\n      const idx = this._parseListeners.indexOf(listener);\n      if (idx >= 0) {\n        this._parseListeners.splice(idx, 1);\n      }\n      if (this._parseListeners.length === 0) {\n        this._parseListeners = null;\n      }\n    }\n  }\n\n  // Remove all parse listeners.\n  removeParseListeners() {\n    this._parseListeners = null;\n  }\n\n  // Notify any parse listeners of an enter rule event.\n  triggerEnterRuleEvent() {\n    if (this._parseListeners !== null) {\n      const ctx = this._ctx;\n      this._parseListeners.forEach((listener) => {\n        listener.enterEveryRule(ctx);\n        ctx.enterRule(listener);\n      });\n    }\n  }\n\n  /**\n   * Notify any parse listeners of an exit rule event.\n   * @see //addParseListener\n   */\n  triggerExitRuleEvent() {\n    if (this._parseListeners !== null) {\n      // reverse order walk of listeners\n      const ctx = this._ctx;\n      this._parseListeners\n        .slice(0)\n        .reverse()\n        .forEach((listener) => {\n          ctx.exitRule(listener);\n          listener.exitEveryRule(ctx);\n        });\n    }\n  }\n\n  getTokenFactory() {\n    return this._input.tokenSource._factory;\n  }\n\n  // Tell our token source and error strategy about a new way to create tokens.\n  setTokenFactory(factory) {\n    this._input.tokenSource._factory = factory;\n  }\n\n  /**\n   * The ATN with bypass alternatives is expensive to create so we create it\n   * lazily.\n   *\n   * @throws UnsupportedOperationException if the current parser does not\n   * implement the {@link //getSerializedATN()} method.\n   */\n  getATNWithBypassAlts() {\n    const serializedAtn = this.getSerializedATN();\n    if (serializedAtn === null) {\n      throw new Error('The current parser does not support an ATN with bypass alternatives.');\n    }\n    let result = this.bypassAltsAtnCache[serializedAtn];\n    if (result === null) {\n      const deserializationOptions = new ATNDeserializationOptions();\n      deserializationOptions.generateRuleBypassTransitions = true;\n      result = new ATNDeserializer(deserializationOptions).deserialize(serializedAtn);\n      this.bypassAltsAtnCache[serializedAtn] = result;\n    }\n    return result;\n  }\n\n  getInputStream() {\n    return this.getTokenStream();\n  }\n\n  setInputStream(input) {\n    this.setTokenStream(input);\n  }\n\n  getTokenStream() {\n    return this._input;\n  }\n\n  // Set the token stream and reset the parser.\n  setTokenStream(input) {\n    this._input = null;\n    this.reset();\n    this._input = input;\n  }\n\n  /**\n   * Match needs to return the current input symbol, which gets put\n   * into the label for the associated token ref; e.g., x=ID.\n   */\n  getCurrentToken() {\n    return this._input.LT(1);\n  }\n\n  notifyErrorListeners(msg, offendingToken, err) {\n    offendingToken = offendingToken || null;\n    err = err || null;\n    if (offendingToken === null) {\n      offendingToken = this.getCurrentToken();\n    }\n    this._syntaxErrors += 1;\n    const line = offendingToken.line;\n    const column = offendingToken.column;\n    const listener = this.getErrorListenerDispatch();\n    listener.syntaxError(this, offendingToken, line, column, msg, err);\n  }\n\n  /**\n   * Consume and return the {@linkplain //getCurrentToken current symbol}.\n   *\n   * <p>E.g., given the following input with {@code A} being the current\n   * lookahead symbol, this function moves the cursor to {@code B} and returns\n   * {@code A}.</p>\n   *\n   * <pre>\n   * A B\n   * ^\n   * </pre>\n   *\n   * If the parser is not in error recovery mode, the consumed symbol is added\n   * to the parse tree using {@link ParserRuleContext//addChild(Token)}, and\n   * {@link ParseTreeListener//visitTerminal} is called on any parse listeners.\n   * If the parser <em>is</em> in error recovery mode, the consumed symbol is\n   * added to the parse tree using\n   * {@link ParserRuleContext//addErrorNode(Token)}, and\n   * {@link ParseTreeListener//visitErrorNode} is called on any parse\n   * listeners.\n   */\n  consume() {\n    const o = this.getCurrentToken();\n    if (o.type !== Token.EOF) {\n      this.getInputStream().consume();\n    }\n    const hasListener = this._parseListeners !== null && this._parseListeners.length > 0;\n    if (this.buildParseTrees || hasListener) {\n      let node;\n      if (this._errHandler.inErrorRecoveryMode(this)) {\n        node = this._ctx.addErrorNode(o);\n      } else {\n        node = this._ctx.addTokenNode(o);\n      }\n      node.invokingState = this.state;\n      if (hasListener) {\n        this._parseListeners.forEach((listener) => {\n          if (node instanceof ErrorNode || (node.isErrorNode !== undefined && node.isErrorNode())) {\n            listener.visitErrorNode(node);\n          } else if (node instanceof TerminalNode) {\n            listener.visitTerminal(node);\n          }\n        });\n      }\n    }\n    return o;\n  }\n\n  addContextToParseTree() {\n    // add current context to parent if we have a parent\n    if (this._ctx.parentCtx !== null) {\n      this._ctx.parentCtx.addChild(this._ctx);\n    }\n  }\n\n  /**\n   * Always called by generated parsers upon entry to a rule. Access field\n   * {@link //_ctx} get the current context.\n   */\n  enterRule(localctx, state, ruleIndex) {\n    this.state = state;\n    this._ctx = localctx;\n    this._ctx.start = this._input.LT(1);\n    if (this.buildParseTrees) {\n      this.addContextToParseTree();\n    }\n    this.triggerEnterRuleEvent();\n  }\n\n  exitRule() {\n    this._ctx.stop = this._input.LT(-1);\n    // trigger event on _ctx, before it reverts to parent\n    this.triggerExitRuleEvent();\n    this.state = this._ctx.invokingState;\n    this._ctx = this._ctx.parentCtx;\n  }\n\n  enterOuterAlt(localctx, altNum) {\n    localctx.setAltNumber(altNum);\n    // if we have new localctx, make sure we replace existing ctx\n    // that is previous child of parse tree\n    if (this.buildParseTrees && this._ctx !== localctx) {\n      if (this._ctx.parentCtx !== null) {\n        this._ctx.parentCtx.removeLastChild();\n        this._ctx.parentCtx.addChild(localctx);\n      }\n    }\n    this._ctx = localctx;\n  }\n\n  /**\n   * Get the precedence level for the top-most precedence rule.\n   *\n   * @return The precedence level for the top-most precedence rule, or -1 if\n   * the parser context is not nested within a precedence rule.\n   */\n  getPrecedence() {\n    if (this._precedenceStack.length === 0) {\n      return -1;\n    } else {\n      return this._precedenceStack[this._precedenceStack.length - 1];\n    }\n  }\n\n  // eslint-disable-next-line max-params\n  enterRecursionRule(localctx, state, ruleIndex, precedence) {\n    this.state = state;\n    this._precedenceStack.push(precedence);\n    this._ctx = localctx;\n    this._ctx.start = this._input.LT(1);\n    this.triggerEnterRuleEvent(); // simulates rule entry for left-recursive rules\n  }\n\n  // Like {@link //enterRule} but for recursive rules.\n  pushNewRecursionContext(localctx, state, ruleIndex) {\n    const previous = this._ctx;\n    previous.parentCtx = localctx;\n    previous.invokingState = state;\n    previous.stop = this._input.LT(-1);\n\n    this._ctx = localctx;\n    this._ctx.start = previous.start;\n    if (this.buildParseTrees) {\n      this._ctx.addChild(previous);\n    }\n    this.triggerEnterRuleEvent(); // simulates rule entry for left-recursive rules\n  }\n\n  unrollRecursionContexts(parentCtx) {\n    this._precedenceStack.pop();\n    this._ctx.stop = this._input.LT(-1);\n    const retCtx = this._ctx; // save current ctx (return value)\n    // unroll so _ctx is as it was before call to recursive method\n    const parseListeners = this.getParseListeners();\n    if (parseListeners !== null && parseListeners.length > 0) {\n      while (this._ctx !== parentCtx) {\n        this.triggerExitRuleEvent();\n        this._ctx = this._ctx.parentCtx;\n      }\n    } else {\n      this._ctx = parentCtx;\n    }\n    // hook into tree\n    retCtx.parentCtx = parentCtx;\n    if (this.buildParseTrees && parentCtx !== null) {\n      // add return ctx into invoking rule's tree\n      parentCtx.addChild(retCtx);\n    }\n  }\n\n  getInvokingContext(ruleIndex) {\n    let ctx = this._ctx;\n    while (ctx !== null) {\n      if (ctx.ruleIndex === ruleIndex) {\n        return ctx;\n      }\n      ctx = ctx.parentCtx;\n    }\n    return null;\n  }\n\n  precpred(localctx, precedence) {\n    return precedence >= this._precedenceStack[this._precedenceStack.length - 1];\n  }\n\n  inContext(context) {\n    // TODO: useful in parser?\n    return false;\n  }\n\n  /**\n   * Checks whether or not {@code symbol} can follow the current state in the\n   * ATN. The behavior of this method is equivalent to the following, but is\n   * implemented such that the complete context-sensitive follow set does not\n   * need to be explicitly constructed.\n   *\n   * <pre>\n   * return getExpectedTokens().contains(symbol);\n   * </pre>\n   *\n   * @param symbol the symbol type to check\n   * @return {@code true} if {@code symbol} can follow the current state in\n   * the ATN, otherwise {@code false}.\n   */\n  isExpectedToken(symbol) {\n    const atn = this._interp.atn;\n    let ctx = this._ctx;\n    const s = atn.states[this.state];\n    let following = atn.nextTokens(s);\n    if (following.contains(symbol)) {\n      return true;\n    }\n    if (!following.contains(Token.EPSILON)) {\n      return false;\n    }\n    while (ctx !== null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {\n      const invokingState = atn.states[ctx.invokingState];\n      const rt = invokingState.transitions[0];\n      following = atn.nextTokens(rt.followState);\n      if (following.contains(symbol)) {\n        return true;\n      }\n      ctx = ctx.parentCtx;\n    }\n    if (following.contains(Token.EPSILON) && symbol === Token.EOF) {\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n  /**\n   * Computes the set of input symbols which could follow the current parser\n   * state and context, as given by {@link //getState} and {@link //getContext},\n   * respectively.\n   *\n   * @see ATN//getExpectedTokens(int, RuleContext)\n   */\n  getExpectedTokens() {\n    return this._interp.atn.getExpectedTokens(this.state, this._ctx);\n  }\n\n  getExpectedTokensWithinCurrentRule() {\n    const atn = this._interp.atn;\n    const s = atn.states[this.state];\n    return atn.nextTokens(s);\n  }\n\n  // Get a rule's index (i.e., {@code RULE_ruleName} field) or -1 if not found.\n  getRuleIndex(ruleName) {\n    const ruleIndex = this.getRuleIndexMap()[ruleName];\n    if (ruleIndex !== null) {\n      return ruleIndex;\n    } else {\n      return -1;\n    }\n  }\n\n  /**\n   * Return List&lt;String&gt; of the rule names in your parser instance\n   * leading up to a call to the current rule. You could override if\n   * you want more details such as the file/line info of where\n   * in the ATN a rule is invoked.\n   *\n   * this is very useful for error messages.\n   */\n  getRuleInvocationStack(p) {\n    p = p || null;\n    if (p === null) {\n      p = this._ctx;\n    }\n    const stack = [];\n    while (p !== null) {\n      // compute what follows who invoked us\n      const ruleIndex = p.ruleIndex;\n      if (ruleIndex < 0) {\n        stack.push('n/a');\n      } else {\n        stack.push(this.ruleNames[ruleIndex]);\n      }\n      p = p.parentCtx;\n    }\n    return stack;\n  }\n\n  // For debugging and other purposes.\n  getDFAStrings() {\n    return this._interp.decisionToDFA.toString();\n  }\n\n  // For debugging and other purposes.\n  dumpDFA() {\n    let seenOne = false;\n    for (let i = 0; i < this._interp.decisionToDFA.length; i++) {\n      const dfa = this._interp.decisionToDFA[i];\n      if (dfa.states.length > 0) {\n        if (seenOne) {\n          console.log();\n        }\n        this.printer.println('Decision ' + dfa.decision + ':');\n        this.printer.print(dfa.toString(this.literalNames, this.symbolicNames));\n        seenOne = true;\n      }\n    }\n  }\n\n  /*\n      \"\t\t\tprinter = function() {\\r\\n\" +\n      \"\t\t\t\tthis.println = function(s) { document.getElementById('output') += s + '\\\\n'; }\\r\\n\" +\n      \"\t\t\t\tthis.print = function(s) { document.getElementById('output') += s; }\\r\\n\" +\n      \"\t\t\t};\\r\\n\" +\n      */\n  getSourceName() {\n    return this._input.sourceName;\n  }\n\n  /**\n   * During a parse is sometimes useful to listen in on the rule entry and exit\n   * events as well as token matches. this is for quick and dirty debugging.\n   */\n  setTrace(trace) {\n    if (!trace) {\n      this.removeParseListener(this._tracer);\n      this._tracer = null;\n    } else {\n      if (this._tracer !== null) {\n        this.removeParseListener(this._tracer);\n      }\n      this._tracer = new TraceListener(this);\n      this.addParseListener(this._tracer);\n    }\n  }\n}\n\n/**\n * this field maps from the serialized ATN string to the deserialized {@link\n * ATN} with\n * bypass alternatives.\n *\n * @see ATNDeserializationOptions//isGenerateRuleBypassTransitions()\n */\nParser.bypassAltsAtnCache = {};\n","/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexport class TokenSource {}\n"],"names":["__webpack_require__","exports","definition","key","o","Object","defineProperty","enumerable","get","obj","prop","prototype","hasOwnProperty","call","Symbol","toStringTag","value","HashCode","_classCallCheck","this","count","hash","i","arguments","length","Array","isArray","update","apply","k","_typeof","hashCode","updateHashCode","console","log","toString","finish","LexerAction","action","actionType","isPositionDependent","other","LexerActionType","CHANNEL","CUSTOM","MODE","MORE","POP_MODE","PUSH_MODE","SKIP","TYPE","LexerChannelAction","_LexerAction","_inherits","_super","_createSuper","channel","_this","lexer","_channel","LexerCustomAction","ruleIndex","actionIndex","LexerIndexedCustomAction","offset","execute","LexerModeAction","mode","LexerMoreAction","more","INSTANCE","LexerPopModeAction","popMode","LexerPushModeAction","pushMode","LexerSkipAction","skip","LexerTypeAction","type","Transition","_createClass","target","undefined","isEpsilon","label","EPSILON","RANGE","RULE","PREDICATE","ATOM","ACTION","SET","NOT_SET","WILDCARD","PRECEDENCE","serializationNames","serializationTypes","EpsilonTransition","RangeTransition","RuleTransition","PredicateTransition","AtomTransition","ActionTransition","SetTransition","NotSetTransition","WildcardTransition","PrecedencePredicateTransition","AbstractPredicateTransition","_Transition","Token","source","start","stop","tokenIndex","line","column","_text","set","text","equalArrays","a","b","equals","standardHashCodeFunction","standardEqualsFunction","valueToString","v","arrayToString","map","join","INVALID_TYPE","MIN_USER_TOKEN_TYPE","EOF","DEFAULT_CHANNEL","HIDDEN_CHANNEL","HASH_KEY_PREFIX","HashSet","hashFunction","equalsFunction","data","keys","filter","startsWith","reduce","accum","item","values","push","_this2","flatMap","SemanticContext","parser","outerContext","NONE","result","AND","opnds","OR","_SemanticContext","operands","add","precedencePredicates","filterPrecedencePredicates","reduced","p","precedence","from","evaluate","differs","context","evaluated","evalPrecedence","andContext","s","slice","_SemanticContext2","_super2","sort","compareTo","PrecedencePredicate","checkParams","params","isCfg","state","alt","semanticContext","reachesIntoOuterContext","props","precedenceFilterSuppressed","ATNConfig","config","checkContext","stateNumber","Interval","INVALID_INTERVAL","IntervalSet","intervals","readOnly","interval","acc","val","addInterval","l","h","toAdd","clone","pos","existing","splice","Math","min","max","forEach","current","next","toRemove","removeRange","contains","removeOne","n","x","replace","literalNames","symbolicNames","elemsAreChar","toTokenString","toCharString","toIndexString","names","String","fromCharCode","j","elementName","token","ATNState","atn","INVALID_STATE_NUMBER","stateType","epsilonOnlyTransitions","transitions","nextTokenWithinRule","trans","index","BASIC","RULE_START","BLOCK_START","PLUS_BLOCK_START","STAR_BLOCK_START","TOKEN_START","RULE_STOP","BLOCK_END","STAR_LOOP_BACK","STAR_LOOP_ENTRY","PLUS_LOOP_BACK","LOOP_END","RuleStopState","_ATNState","_possibleConstructorReturn","_assertThisInitialized","ruleStart","followState","serializationType","symbol","minVocabSymbol","maxVocabSymbol","addOne","_SetTransition","_get","_getPrototypeOf","Tree","SyntaxTree","_Tree","ParseTree","_SyntaxTree","RuleNode","_ParseTree","Error","TerminalNode","ErrorNode","_TerminalNode","Trees","toStringTree","tree","ruleNames","recog","getNodeText","escapeSpaces","escapeWhitespace","c","getChildCount","res","getChild","concat","t","altNumber","ruleContext","getAltNumber","payload","getPayload","getChildren","list","getAncestors","ancestors","getParent","findAllTokenNodes","ttype","findAllNodes","findAllRuleNodes","findTokens","nodes","_findAllNodes","descendants","RuleContext","_RuleNode","parent","invokingState","parentCtx","children","child","getText","visitor","visitChildren","isEmpty","ri","PredictionContext","cachedHashCode","EMPTY","getReturnState","EMPTY_RETURN_STATE","globalNodeCount","id","trace_atn_sim","ArrayPredictionContext","_PredictionContext","parents","returnStates","SingletonPredictionContext","returnState","up","EmptyPredictionContext","_SingletonPredictionC","HashMap","hashKey","entries","entry","oldValue","e","predictionContextFromRuleContext","transition","states","create","getCachedPredictionContext","contextCache","visited","changed","updated","merge","rootIsWildcard","mergeCache","previous","rootMerge","payloads","mergeRoot","spc","singleParent","apc","a_","mergeSingletons","mergedReturnStates","fill","mergedParents","a_parent","b_parent","M","uniqueParents","containsKey","q","combineCommonParents","mergeArrays","getAllContextNodes","BitSet","hashStuff","LL1Analyzer","look","lookBusy","_LOOK","HIT_PRED","stopState","ctx","r","lookContext","calledRuleStack","seeThruPreds","addEOF","has","removed","remove","constructor","newContext","addRange","maxTokenType","complement","addSet","ATN","grammarType","decisionToState","ruleToStartState","ruleToStopState","modeNameToStartState","ruleToTokenType","lexerActions","modeToStartState","LOOK","nextTokensInContext","nextTokensNoContext","decision","following","nextTokens","expected","rt","hashATNConfig","hashCodeForConfigSet","equalATNConfigs","equalsForConfigSet","INVALID_ALT_NUMBER","ATNConfigSet","fullCtx","configLookup","configs","uniqueAlt","conflictingAlts","hasSemanticContext","dipsIntoOuterContext","merged","preds","interpreter","getCachedContext","coll","containsFast","ATNDeserializationOptions","copyFrom","verifyATN","generateRuleBypassTransitions","defaultOptions","ATNType","LEXER","PARSER","BasicState","DecisionState","nonGreedy","BlockStartState","_DecisionState","endState","BlockEndState","startState","LoopEndState","loopBackState","RuleStartState","isPrecedenceRule","TokensStartState","PlusLoopbackState","StarLoopbackState","StarLoopEntryState","isPrecedenceDecision","PlusBlockStartState","_BlockStartState","StarBlockStartState","BasicBlockStartState","label_","makeLabel","isCtxDependent","outermostPrecedenceReturn","Predicate","predIndex","localctx","sempred","_AbstractPredicateTra","precpred","initArray","tmp","ATNDeserializer","options","deserializationOptions","stateFactories","actionFactories","legacy","reset","checkVersion","skipUUID","readATN","readStates","readRules","readModes","sets","readSets","readInt","bind","readInt32","readEdges","readDecisions","readLexerActions","markPrecedenceDecisions","SERIALIZED_VERSION","charCodeAt","temp","split","version","pair","loopBackStateNumbers","endStateNumbers","nstates","stype","stateFactory","loopBackStateNumber","endStateNumber","addState","numNonGreedyStates","numPrecedenceStates","nrules","tokenType","nmodes","reader","m","iset","i1","i2","nedges","src","trg","arg1","arg2","arg3","edgeFactory","addTransition","ndecisions","decState","data1","data2","lexerActionFactory","generateRuleBypassTransition","idx","bypassStart","bypassStop","defineDecisionState","excludeTransition","stateIsEndStateFor","matchState","maybeLoopEndState","checkCondition","condition","message","sf","af","DFAState","edges","isAcceptState","prediction","lexerActionExecutor","requiresFullContext","predicates","alts","ATNSimulator","sharedContextCache","ERROR","LexerActionExecutor","updatedLexerActions","input","startIndex","requiresSeek","stopIndex","lexerAction","seek","numActions","LexerATNConfig","_ATNConfig","passedThroughNonGreedyDecision","checkNonGreedyDecision","ErrorListener","recognizer","offendingSymbol","msg","dfa","exact","ambigAlts","ConsoleErrorListener","_ErrorListener","error","ProxyErrorListener","delegates","d","syntaxError","reportAmbiguity","reportAttemptingFullContext","reportContextSensitivity","Recognizer","_listeners","_interp","_stateNumber","toolVersion","runtimeVersion","listener","getPrototypeOf","tokenNames","getLiteralNames","getSymbolicNames","getTokenNames","tokenTypeMapCache","ruleIndexMapCache","tokenName","getTokenTypeMap","getOffendingToken","CommonToken","_Token","EMPTY_SOURCE","getInputStream","size","txt","TokenFactory","CommonTokenFactory","_TokenFactory","copyText","DEFAULT","RecognitionException","_Error","_wrapNativeSuper","captureStackTrace","offendingToken","offendingState","getExpectedTokens","NoViableAltException","_RecognitionException","startToken","deadEndConfigs","_ctx","getCurrentToken","LexerNoViableAltException","InputMismatchException","FailedPredicateException","predicate","formatMessage","predicateIndex","DiagnosticErrorListener","exactOnly","getDecisionDescription","getConflictingAlts","getTokenStream","notifyErrorListeners","atnStartState","ruleName","reportedAlts","items","ParseCancellationException","ErrorStrategy","DefaultErrorStrategy","_ErrorStrategy","errorRecoveryMode","lastErrorIndex","lastErrorStates","nextTokensContext","nextTokenState","endErrorCondition","inErrorRecoveryMode","beginErrorCondition","reportNoViableAlternative","reportInputMismatch","reportFailedPredicate","name","stack","getMessage","indexOf","consume","_input","followSet","getErrorRecoverySet","consumeUntil","la","LA","nextTokensState","singleTokenDeletion","reportUnwantedToken","expecting","whatFollowsLoopIterationOrRule","tokens","escapeWSAndQuote","getTokenErrorDisplay","matchedSymbol","singleTokenInsertion","getMissingSymbol","currentSymbolType","reportMissingToken","nextTokenType","reportMatch","tokenText","currentSymbol","expectedTokenType","first","lookback","LT","getTokenFactory","recoverSet","follow","BailErrorStrategy","_DefaultErrorStrategy","exception","recover","Lexer","_Recognizer","_factory","_tokenFactorySourcePair","_token","_tokenStartCharIndex","_tokenStartLine","_tokenStartColumn","_hitEOF","_type","_modeStack","_mode","DEFAULT_MODE","sourceName","tokenStartMarker","mark","emitEOF","continueOuter","match","notifyListeners","emit","release","debug","pop","getCharIndex","emitToken","cpos","lpos","eof","nextToken","getErrorDisplay","getErrorListenerDispatch","getErrorDisplayForChar","re","DEFAULT_TOKEN_CHANNEL","HIDDEN","MIN_CHAR_VALUE","MAX_CHAR_VALUE","OrderedATNConfigSet","_ATNConfigSet","resetSimState","sim","dfaState","SimState","LexerATNSimulator","_ATNSimulator","decisionToDFA","prevAccept","simulator","s0","matchATN","execATN","old_mode","s0_closure","computeStartState","suppressEdge","addDFAState","predict","toLexerString","ds0","captureSimState","getExistingTargetState","computeTargetState","failOrAccept","MIN_DFA_EDGE","MAX_DFA_EDGE","reach","getReachableConfigSet","addDFAEdge","accept","closure","skipAlt","cfg","currentAltReachedAcceptState","getTokenName","getReachableTarget","fixOffsetBeforeMatch","treatEofAsEpsilon","charPos","matches","initialContext","speculative","hasEmptyPath","getEpsilonTarget","evaluatePredicate","append","savedcolumn","savedLine","marker","settings","from_","tk","to","cfgs","proposed","firstConfigWithRuleStopState","newState","setReadonly","tt","dfa_debug","PredPrediction","pred","AltDict","PredictionMode","SLL","LL","LL_EXACT_AMBIG_DETECTION","hasSLLConflictTerminatingPrediction","allConfigsInRuleStopStates","dup","altsets","getConflictingAltSubsets","hasConflictingAltSet","hasStateAssociatedWithOneAlt","hasConfigInRuleStopState","resolvesToJustOneViableAlt","getSingleViableAlt","allSubsetsConflict","hasNonConflictingAltSet","allSubsetsEqual","getUniqueAlt","all","getAlts","minValue","or","configToAlts","c1","c2","getValues","getStateToAltMap","minAlt","DoubleDict","defaultMapCtor","cacheMap","ParserATNSimulator","predictionMode","_startIndex","_outerContext","_dfa","debug_closure","debug_add","retry_debug","getLookaheadName","precedenceDfa","getPrecedenceStartState","getPrecedence","applyPrecedenceFilter","setPrecedenceStartState","previousD","D","noViableAlt","getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule","conflictIndex","evalSemanticContext","execATNWithFullContext","computeReachSet","predictedAlt","altSubSets","predicateDFAState","getDecisionState","decisionState","nalts","altsToCollectPredsFrom","getConflictingAltsOrUniqueAlt","altToPred","getPredsForAmbigAlts","getPredicatePredictions","foundExactAmbig","intermediate","skippedStopStates","closureBusy","removeAllConfigsNotInRuleStopState","lookToEndOfRule","endOfRuleState","statesFromAlt1","configSet","updatedContext","orContext","nPredAlts","pairs","containsPredicate","splitAccordingToSemanticValidity","semValidConfigs","semInvalidConfigs","getAltThatFinishedDecisionEntryRule","succeeded","failed","predPredictions","complete","predictions","predicateEvaluationResult","collectPredicates","closureCheckingStopState","depth","parms","getRuleName","closure_","canDropLoopEntryEdgeInLeftRecursiveRule","continueCollecting","newDepth","numCtxs","blockEndStateNum","blockEndState","returnStateNumber","returnStateTarget","inContext","ruleTransition","precedenceTransition","predTransition","actionTransition","pt","getRuleInvocationStack","currentPosition","predSucceeds","getPredicate","newSemCtx","getTokens","nvae","decs","getDeadEndConfigs","optimizeConfigs","PredictionContextCache","cache","ParseTreeListener","node","ParseTreeVisitor","visit","ParseTreeWalker","isErrorNode","visitErrorNode","visitTerminal","enterRule","walk","exitRule","enterEveryRule","exitEveryRule","TerminalNodeImpl","ErrorNodeImpl","_TerminalNodeImpl","ParserRuleContext","_RuleContext","invokingStateNumber","addChild","badToken","ctxType","contexts","InterpreterRuleContext","_ParserRuleContext","DFASerializer","buf","sortedStates","getStateString","getEdgeLabel","baseStateStr","LexerDFASerializer","_DFASerializer","DFA","_states","precedenceState","stringToCharArray","str","Uint16Array","TokenStream","codePointAt","BufferedTokenStream","_TokenStream","tokenSource","fetchedEOF","lazyInit","adjustSeekIndex","sync","fetch","types","subset","LB","setup","nextOnChannel","nextTokenOnChannel","filterForChannel","prevOnChannel","previousTokenOnChannel","left","right","hidden","getSourceName","object","$defineProperty","position","TypeError","string","Number","second","configurable","writable","fromCodePoint","stringFromCharCode","floor","_","highSurrogate","lowSurrogate","codeUnits","codePoint","isFinite","RangeError","CharStream","decodeToUnicodeCodePoints","strdata","_index","_size","InputStream","_CharStream","FileStream","_InputStream","fileName","encoding","path","callback","CharStreams","blob","onLoad","onError","window","FileReader","onload","is","onerror","readAsText","buffer","fromPath","CommonTokenStream","_BufferedTokenStream","TraceListener","_ParseTreeListener","Parser","_errHandler","_precedenceStack","buildParseTrees","_tracer","_parseListeners","_syntaxErrors","setInputStream","setTrace","recoverInline","addErrorNode","reverse","factory","serializedAtn","getSerializedATN","bypassAltsAtnCache","deserialize","setTokenStream","err","hasListener","addTokenNode","addContextToParseTree","triggerEnterRuleEvent","triggerExitRuleEvent","altNum","setAltNumber","removeLastChild","retCtx","parseListeners","getParseListeners","getRuleIndexMap","seenOne","printer","println","print","trace","removeParseListener","addParseListener","TokenSource"],"sourceRoot":""}